{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>HYDROLIB-core is the core library of Python wrappers around the D-HYDRO model files (input and output) and model engines (kernel libraries). It can serve as the basis for various pre- and postprocessing tools for a modelling workflow of hydrodynamic simulations.</p>"},{"location":"#more-information","title":"More information","text":"<p>Some quickstarts:</p> <ul> <li>First users: Installation and Tutorials.</li> <li>Developers: List of supported functionalities,   API reference, and   How to contribute.</li> <li>Releases: hydrolib-core on PyPI, ChangeLog.</li> <li>Known issues and requested features: via GitHub issues.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#091-2025-05-30","title":"0.9.1 (2025-05-30)","text":""},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>parser: refactor and enhance <code>read_polyfile</code> functionality (#550) (#828)</li> <li>parser: refactor and enhance <code>read_polyfile</code> functionality</li> <li>CrossLocModel:  extend CrossLocModel to accept a single cross-section (#820)</li> <li>crossloc: improve validation and test support for single cross-section use</li> </ul>"},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li>path: improve relative and case-insensitive path resolution (#829)</li> <li>path: improve relative and case-insensitive path resolution</li> <li>test: ignore version lines in file comparison to prevent test failures (#819)</li> <li>test: ignore version lines in file comparison to prevent test failures</li> </ul>"},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li>core: restructure base and model modules, improve test coverage (#834)</li> <li>core: restructure base and model modules, improve test coverage (#834)</li> <li>dimr: refactor dirm tests and modules (#826)</li> </ul>"},{"location":"changelog/#090-2025-05-16","title":"0.9.0 (2025-05-16)","text":""},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>extforce: Introduce External forcing conversion tool with modular converters (UNST-8490, UNST-8528, UNST-8553) (#647)</li> <li>extforce: Introduce External forcing conversion tool with modular converters (UNST-8490, UNST-8528, UNST-8553)</li> <li>meshkernel: support refined parameters and clipping inside polygons with holes (#776)</li> <li>meshkernel: support refined parameters and clipping inside polygons with holes</li> </ul>"},{"location":"changelog/#081-2025-02-04","title":"0.8.1 (2025-02-04)","text":""},{"location":"changelog/#feat_2","title":"Feat","text":"<ul> <li>Support Fortran scientific notation in .tim files (e.g., 1d0) (#720)</li> <li>Corrected comment for layerType (#697)</li> </ul>"},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>failing docs (#728)</li> </ul>"},{"location":"changelog/#080-2024-07-09","title":"0.8.0 (2024-07-09)","text":""},{"location":"changelog/#feat_3","title":"Feat","text":"<ul> <li>Prevent duplicate contacts/links in <code>Link1d2d</code> by replacing Link1d2d._process() with properties (#674)</li> <li>Move jadelvappos to physics section. (#672)</li> <li>Make research wave section optional again. (#671)</li> <li>Fix remaining keywords (#670)</li> <li>Add support for spaces polyline names (#652)</li> <li>Add support for optional [sedtrails] research section. (#651)</li> <li>Don't write keywords with None values (#663)</li> <li>Add/move more mdu keywords (#654)</li> <li>Raise error for unknown keywords (#632)</li> <li>Added support for research keywords (#642)</li> <li>Add support for python 3.12 (#640)</li> <li>Use caching to prevent reading files multiple times (#641)</li> <li>Add missing mdu keywords (#628)</li> <li>properly writing number of processes in dimr_config.xml (#623)</li> </ul>"},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>Ensure mesh_2d_edge_x and mesh_2d_edge_y are written to nc file. (#645)</li> <li>locationtype should not be written for CrossSections or ObservationCrossSections (#683)</li> </ul>"},{"location":"changelog/#070-2024-03-11","title":"0.7.0 (2024-03-11)","text":""},{"location":"changelog/#feat_4","title":"Feat","text":"<ul> <li>Use new <code>contacts_set</code> function from MeshKernel 4.0.2 (#575)</li> <li>Bump MeshKernel version to ^4.0.2 (#594)</li> <li>Add support for Python 3.10 (#586)</li> </ul>"},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li>It is not possible to refine meshes with cell sizes smaller than 10 m (#611)</li> <li>Fix show tree output for old external forcing file (ExtOldForcing class) (#581)</li> </ul>"},{"location":"changelog/#061-2024-01-12","title":"0.6.1 (2024-01-12)","text":""},{"location":"changelog/#060-2023-11-16","title":"0.6.0 (2023-11-16)","text":""},{"location":"changelog/#feat_5","title":"Feat","text":"<ul> <li>Add filetype 10 (polyfile) to class ExtOldFileType (#565)</li> <li>Add missing oldext quantities (#557)</li> </ul>"},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>Rainfall Runoff .bui file with multiple stations gives parse error</li> </ul>"},{"location":"changelog/#052-2023-04-19","title":"0.5.2 (2023-04-19)","text":""},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>failing unittest + SonarCloud security issue (#541)</li> </ul>"},{"location":"changelog/#051-2023-04-17","title":"0.5.1 (2023-04-17)","text":""},{"location":"changelog/#feat_6","title":"Feat","text":"<ul> <li>Add the quantity <code>nudge_salinity_temperature</code> to ext old file header.</li> <li>Support the old style external forcings file</li> <li>Add support for several coastal MDU keywords</li> <li>Add support for .tim files and .bc files in the structure file</li> <li>Support meteo blocks in external forcings file (#477)</li> <li>Remove indentation from MDU file</li> <li>Add 4 missing 1D2D settings to FMModel</li> <li>Support *.tim files</li> <li>Add XYN classes to public API (#492)</li> <li>Include old and new observation crossections into MDU FMModel.output class (#470)</li> <li>Support observation crosssection .pli via existing PolyFile class (#464)</li> <li>Add support for 3D Z-sigma settings in MDU</li> <li>Support loading+saving models with configurable OS path style formats (#361)</li> <li>Add support for observation point xyn files (#472)</li> <li>Support filepath as str besides Path for all model classes under FileBasedModel (#469)</li> <li>Add validation for NaN values in datablocks</li> </ul>"},{"location":"changelog/#fix_6","title":"Fix","text":"<ul> <li>Fixed issues with the new release script</li> <li>Special characters should be parsed correctly from file</li> <li>MDU keywords such as 1d2dLinkFile are written to file without comments (#528)</li> <li>UGRID network files without faces should be accepted</li> <li>correct handling of whitespace and comments in observation point .xyn files (#508)</li> <li>Fix resolving of relative paths containing <code>..</code> when not using the <code>resolve_casing</code> option.</li> <li>ignore trailing values or text on polyline data lines to better support boundary polyfiles (#482)</li> <li>Reading invalid formatted plifile should raise error instead of warning</li> <li>polyline serializer should print empty trailing comment lines</li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>Make sure of the new Pydantic 1.10 functionality</li> </ul>"},{"location":"changelog/#041-2023-01-26","title":"0.4.1 (2023-01-26)","text":""},{"location":"changelog/#fix_7","title":"Fix","text":"<ul> <li><code>_add_nodes_to_segments</code> fixed (#440)</li> </ul>"},{"location":"changelog/#040-2023-01-23","title":"0.4.0 (2023-01-23)","text":""},{"location":"changelog/#feat_7","title":"Feat","text":"<ul> <li>Remove io namespace and add convenient imports/API at several directory levels (#438)</li> <li>Added the option for all supported files to customize the float formatting when saving (#406)</li> <li>Suppress warning in polyfile parser that the white space at the start of the line is ignored (#409)</li> <li>Change data block default spacing from 4 to 2 (#407)</li> <li>Add support for non-recursively loading models (#401)</li> </ul>"},{"location":"changelog/#fix_8","title":"Fix","text":"<ul> <li>Fixed polylinefile validation for Structure and its subclasses (#416)</li> <li>Rename variable in generate_nodes function (#437)</li> <li>Ensure that QuantityUnitPairs that are not part of a vector are correctly parsed (#420)</li> <li>Enum values are incorrectly written to files (#403)</li> </ul>"},{"location":"changelog/#refactor_2","title":"Refactor","text":"<ul> <li>Small refactoring of the VectorQuantityUnitPairs and VectorForcingBase (#422)</li> <li>Move the base module in XYZ back to IO (#418)</li> <li>Refactored support for vectors in .bc files (#394)</li> </ul>"},{"location":"changelog/#031-2022-10-25","title":"0.3.1 (2022-10-25)","text":""},{"location":"changelog/#feat_8","title":"Feat","text":"<ul> <li>option <code>resolve_casing</code> to fix filepath casing between different OS's.</li> <li>Added support for the use of vectors within forcing models with a t3d or timeseries function type.</li> <li>Added possibility to take structure positions into account when discretizing 1d mesh</li> <li>Add support for branches.gui file (#333)</li> <li>Drop extra fields for INIBasedModels if they are not in file format definition</li> <li>Support crs file for observation cross sections (#289)</li> <li>implement mesh generation for pipes (#294) and fix support different reference system (#298) (#299)</li> <li>removed the writeBalanceFile keyword from the mdu</li> <li>support copying generic files/models (#281)</li> <li>Support extra MDU sections (#284)</li> <li>add binder support with a dockerfile (#264)</li> </ul>"},{"location":"changelog/#fix_9","title":"Fix","text":"<ul> <li>Add backwards compatibility for the old \"percentage from bed\" vertical position type.</li> <li>Fix freeze when printing a ForcingModel with multiple [forcing] blocks by omitting the datablocks.</li> <li>T3D header is not correct (#356)</li> <li>Change AutoStart type from bool to int (#349)</li> <li>Skip serialization of empty INI properties when configured (#336)</li> <li>Net writer should not produce NaN as fill values (#363)</li> <li>Change type of xcoordinates and ycoordinates in Lateral class from int to float (#351)</li> <li>Fix that single structure in StructureModel class is correctly converted to a list (#352)</li> <li>Ensure poly files can be saved (#344)</li> <li>write correct branchorder to net file (#335)</li> <li>add zdatum vertical position type (#324)</li> <li>parse vertical positions to list (#325)</li> <li>make <code>has_z_values</code> parameter optional in <code>polyfile.parser.read_polyfile</code> (#312)</li> <li>Remove unnessary indent in .bc datablocks (#304)</li> <li>Fix the types of 4 fields in the MDU file (#283)</li> </ul>"},{"location":"changelog/#refactor_3","title":"Refactor","text":"<ul> <li>Location specification root validator (#347)</li> </ul>"},{"location":"changelog/#030-2022-07-11","title":"0.3.0 (2022-07-11)","text":""},{"location":"changelog/#fix_10","title":"Fix","text":"<ul> <li>Add water level location validation DamBreaks</li> <li>allow empty file paths in the .fnm file</li> <li>Add modeltype 21 to RR node for open water precipitation/evaporation (#261)</li> <li>filemodel: ResolveRelativeMode is incorrectly set when reading a model with 'pathsRelativeToParent' set to false (#259)</li> </ul>"},{"location":"changelog/#feat_9","title":"Feat","text":"<ul> <li>network: additional mesh funcs dhydamo</li> <li>support .bc files and more in lateral discharge (#244)</li> <li>add support for observation point ini file (#236)</li> <li>support .bc files and more in lateral discharge</li> </ul>"},{"location":"changelog/#refactor_4","title":"Refactor","text":"<ul> <li>rr: place all RR-related code+tests in own rr subpackage (#235)</li> <li>remove dead code of _process_edges_for_branch</li> </ul>"},{"location":"changelog/#021-2022-03-15","title":"0.2.1 (2022-03-15)","text":""},{"location":"changelog/#fix_11","title":"Fix","text":"<ul> <li>parser: correctly parse model input fields with leading digits, such as 1D2DLinkFile.</li> <li>parser: allow empty friction specification in all crossdef types. (#206).</li> </ul>"},{"location":"changelog/#020-2021-12-17","title":"0.2.0 (2021-12-17)","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>RainfallRunoff files: [NodeFile][hydrolib.core.io.rr.topology.models.NodeFile] (#138)   and [LinkFile][hydrolib.core.io.rr.topology.models.LinkFile] (#140)</li> <li>D-Flow FM files:<ul> <li>Initial field files: [IniFieldModel][hydrolib.core.io.inifield.models.IniFieldModel],   also added 1D Field INI format: [OneDFieldModel][hydrolib.core.io.onedfield.models.OneDFieldModel] (#119).</li> <li>1D Roughness INI files: [FrictionModel][hydrolib.core.io.friction.models.FrictionModel] (#118).</li> <li>Storage node files: [StorageNodeModel][hydrolib.core.io.storagenode.models.StorageNodeModel] (#131).</li> <li>General structure:  [GeneralStructure][hydrolib.core.io.structure.models.GeneralStructure] (#79).</li> </ul> </li> <li>Many additions to the API documentation.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>All classes that have fields with \"keyword values\" (such as <code>frictionType = WhiteColebrook</code>) now use Enum classes for those values.   See for example [FrictionType][hydrolib.core.io.friction.models.FrictionType] and [FlowDirection][hydrolib.core.io.structure.models.FlowDirection]   (#98)</li> <li>All crosssection definition type now supported as subclasses of   [CrossSection][hydrolib.core.io.crosssection.models.CrossSectionDefinition] (#117)</li> <li>Cross section definition and location classes have been moved from <code>hydrolib.core.io.ini.models</code>   to <code>hydrolib.core.io.crosssection.models</code>. (#149)</li> <li>Changed behavior for file paths in saved files (#96).   More information about: technical background and a tutorial.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Too strict validation of optional fields in culvert (#75), pump (#76),   weir (#77), orifice (#78).</li> <li>Floating point parser breaks reading/writing of keyword UnifFrictCoef1D2D (#103)</li> <li>DIMR config has invalid control element for a single component model (#127)</li> <li>DataBlockINIBasedModel.datablock should also support strings (astronomic in .bc files) (#137)</li> <li>Saving .bc files incorrectly writes repeated key names as a semicolon-separated list (#101)</li> <li>Do not write absolute file paths to file (#96)</li> </ul>"},{"location":"changelog/#015-2021-11-02","title":"0.1.5 (2021-11-02)","text":""},{"location":"changelog/#014-2021-11-02","title":"0.1.4 (2021-11-02)","text":""},{"location":"changelog/#013-2021-08-05","title":"0.1.3 (2021-08-05)","text":""},{"location":"changelog/#fix_12","title":"Fix","text":"<ul> <li>netcdf serialization path.</li> </ul>"},{"location":"changelog/#012-2021-08-05","title":"0.1.2 (2021-08-05)","text":""},{"location":"changelog/#fix_13","title":"Fix","text":"<ul> <li>test_version: Fix updated version</li> </ul>"},{"location":"changelog/#011-2021-08-05","title":"0.1.1 (2021-08-05)","text":""},{"location":"changelog/#fix_14","title":"Fix","text":"<ul> <li>NetworkModel: Fix default init of Network within NetworkModel</li> </ul>"},{"location":"releasenotes/","title":"Release notes","text":""},{"location":"releasenotes/#hydrolib-core-052-release-notes","title":"HYDROLIB-core 0.5.2 Release Notes","text":"<p>HYDROLIB-core 0.5.2 only contains 'cosmetic' changes, and is otherwise equal to 0.5.1. See 0.5.1 release notes for the main 0.5 release notes.</p>"},{"location":"releasenotes/#hydrolib-core-051-release-notes","title":"HYDROLIB-core 0.5.1 Release Notes","text":"<p>HYDROLIB-core 0.5.1 mainly adds more support for D-Flow FM 2D3D models in coastal applications.</p>"},{"location":"releasenotes/#compatibility-notes","title":"Compatibility Notes","text":"<p>Support for MacOS is temporarily dropped, due to an upgrade to MeshKernel 2.0.2, which has no MacOS version at the moment. We aim to re-enable this support in future releases.</p>"},{"location":"releasenotes/#new-features","title":"New Features","text":"<ul> <li>Support for cross-platform path style (#361), more info in the loading and saving tutorial.</li> <li>Support for more MDU keywords (1D2D: see #489, 2D/3D: see #474, #486).</li> <li>Support for <code>[Meteo]</code> blocks in external forcings files (#446)</li> <li>Support for various legacy file formats, to facilitate future model conversions:<ul> <li>Observation point <code>*.xyn</code> files (#459).</li> <li>Observation crosssection <code>*.pli</code> files (#364,#461).</li> <li>Old external forcings file <code>*.ext</code>  (#369).</li> <li>Support for timeseries in <code>*.tim</code> files (#348), also included in structure files (#497) and external meteo forcings (#446).</li> </ul> </li> </ul>"},{"location":"releasenotes/#improvements","title":"Improvements","text":"<ul> <li>All file-based model class constructors now accept file path as a <code>str</code>, in addition to the already existing <code>pathlib.Path</code> (#365).</li> <li>MeshKernel dependency was updated to version 2.0.2, which has more functionality in its API (#450).</li> </ul>"},{"location":"releasenotes/#bugfixes","title":"Bugfixes","text":"<p>See the detailed ChangeLog on GitHub.</p>"},{"location":"releasenotes/#archive","title":"Archive","text":"<p>Pre-0.5.0 release notes are available via the ChangeLog on GitHub.</p>"},{"location":"guides/contributing/","title":"Contributing","text":""},{"location":"guides/contributing/#tooling","title":"Tooling","text":""},{"location":"guides/contributing/#poetry","title":"Poetry","text":"<p>We use <code>poetry</code> to manage our package and its dependencies. More information on the separate Poetry page.</p>"},{"location":"guides/contributing/#pytest","title":"Pytest","text":"<p>We use <code>pytest</code> to test our package. Run it with <code>poetry run pytest</code> to test your code changes locally.</p>"},{"location":"guides/contributing/#black","title":"Black","text":"<p>We use <code>black</code> as an autoformatter. It is also run during CI and will fail if it's not formatted beforehand.</p>"},{"location":"guides/contributing/#isort","title":"Isort","text":"<p>We use <code>isort</code> as an autoformatter.</p>"},{"location":"guides/contributing/#commitizen","title":"Commitizen","text":"<p>We use <code>commitizen</code> to automatically bump the version number. If you use conventional commit messages, the <code>changelog.md</code> is generated automatically. More details below under \"Merging\".</p>"},{"location":"guides/contributing/#development","title":"Development","text":""},{"location":"guides/contributing/#branches","title":"Branches","text":"<p>For each issue or feature, a separate branch should be created from the main. To keep the branches organized each branch should be created with a prefix in the name: * <code>feat/</code> for new features and feature improvements; * <code>fix/</code> for bugfixes; * <code>docs/</code> for documentation; * <code>chore/</code> for tasks, tool changes, configuration work, everything not relevant for external users.</p> <p>After this prefix, preferrably add the issue number, followed by a brief title using underscores. For example: <code>feat/160_obsfile</code> or, <code>fix/197_validation_pump_stages</code>.</p>"},{"location":"guides/contributing/#pull-requests","title":"Pull requests","text":"<p>When starting development on a branch, a pull request should be created for reviews and continous integration.  In the description text area on GitHub, use a closing keyword such that this PR will be automatically linked to the issue. For example: <code>Fixes #160</code>.</p> <p>During continuous integration, the checks will be run with several Python versions on Windows, Ubuntu and MacOS. The checks consist of running the tests, checking the code formatting and running SonarCloud.  We advise to use a draft pull request, to prevent the branch to be merged back before developement is finished. When the branch is ready for review, you can update the status of the pull request to \"ready for review\".</p>"},{"location":"guides/contributing/#reviews","title":"Reviews","text":"<p>When an issue is ready for review, it should be moved to the \"Ready for review\" column on the GitHub board for visibility. </p>"},{"location":"guides/contributing/#merging","title":"Merging","text":"<p>Merging a branch can only happen when a pull request is accepted through review. When a pull request is accepted the changes should be merged back with the \"squash and merge\" option. The merge commit message should adhere to the conventional commit guidelines. * In the first textfield of the GitHub commit form, use for example: <code>feat: Support 3D timeseries in .bc file</code>, without any PR/issue references. * In the text area of the GitHub commit form, optionally add some more description details on the commit. * In the same text area, add footer line <code>Refs: #&lt;issuenr&gt;</code>, and if needed an extra line <code>BREAKING CHANGE: explanation</code>. Don't forget a blank line between footer lines and the preceding description lines (if present).</p>"},{"location":"guides/contributing/#coding-guidelines","title":"Coding guidelines","text":"<ul> <li>If there is code that needs to be tested, there should be tests written for it.</li> <li>If there are any additions or changes to the public API, the documentation should be updated. </li> <li>Files should be added to the appropriate folder to keep modules and objects within the correct scope.</li> </ul>"},{"location":"guides/contributing/#releasing","title":"Releasing","text":""},{"location":"guides/contributing/#making-a-release-on-github-and-pypi","title":"Making a release on GitHub and PyPi","text":"<p>When we are releasing hydrolib-core, we want to create a release on GitHub and PyPi. This should only be done by one of the hydrolib-core maintainers. To prepare for releasing, please make sure you have a clean checkout of the latest <code>main</code> branch and follow these steps:</p> <ul> <li>Go to the root level your hydrolib-core checkout location</li> <li>Open your command line in this location</li> <li>Perform the following commands:<ul> <li>Ensure that you are using the poetry environment (this contains commitizen), optionally run this command in a fresh environment:  <pre><code>poetry install\n</code></pre></li> <li>Update the Changelog before bumping the release version (use the version tag instead of the raw version number (so without \"v\" in our case)):  <pre><code>cz changelog --unreleased-version=\"0.3.1\" --incremental\n</code></pre></li> <li>Use MAJOR, MINOR or PATCH to increment the version  <pre><code>cz bump --increment {MAJOR,MINOR,PATCH}\n</code></pre></li> <li>Push the tags and changes to git  <pre><code>git push --tags\ngit push\n</code></pre></li> <li>Build the wheels and publish the package to PyPi (get an API token in your PyPI account)  <pre><code>poetry build\npoetry publish --username __token__ --password [PYPI_API_TOKEN]\n</code></pre>  You will need a PyPI account and permissions for this publish step. Ask a maintainer for help if you need this.</li> </ul> </li> <li>Go to the hydrolib-core GitHub page.</li> <li>Go to <code>Releases</code> and click on <code>Draft a new release</code>.</li> <li>Fill in the <code>Release title</code> field with <code>Release v&lt;VERSION&gt;</code>, with <code>&lt;VERSION&gt;</code> in the full format <code>&lt;MAJOR&gt;.&lt;MINOR&gt;.&lt;PATCH&gt;</code>, for example <code>Release v0.3.0</code>.</li> <li>Choose the appropriate version tag in the <code>Choose a tag</code> dropdown box (typically <code>&lt;VERSION&gt;</code> without \"v\" prefix).</li> <li>Click on <code>Generate release notes</code>.</li> <li>Click on <code>Publish release</code>.</li> <li>Celebrate </li> </ul>"},{"location":"guides/devcontainers/","title":"Devcontainers: Developing HYDROLIB in an isolated environment","text":"<p>A common struggle while working on any software project, is to ensure all of your  dependencies are available and you can actually build the software, run the tests etc. While any developer is free to choose their own toolchain, environment etc, HYDROLIB-Core includes the necessary files to run the project within a so called devcontainer within Visual Studio Code. With the help of Docker, we can spin up an independent development environment, ensuring that HYDROLIB-Core works out of the box and you are insulated from any specific local configurations on your machines. This should allow you to start working on HYDROLIB-Core quickly. </p> <p>The following sub sections will walk you through the necessary dependencies, and how to use it,  and modify it, to fit your own needs. This will be done in the following order:</p> <ul> <li>Requirements: Docker and Visual Studio Code Remote - Containers extension</li> <li>Dockerfile configures python, poetry and other dependencies</li> <li>devcontainer.json specifies how visual studio code should be configured</li> <li>External references</li> </ul>"},{"location":"guides/devcontainers/#requirements-docker-and-visual-studio-code-remote-containers-extension","title":"Requirements: Docker and Visual Studio Code Remote - Containers extension","text":"<p>In order to run HYDROLIB in a dev container we need the following dependencies</p> <ul> <li>Docker</li> <li>Visual Studio Code</li> <li>Visual Studio Code Remote - Containers extension</li> </ul> <p>Docker will ensure we can spin up an isolated container. A full tutorial on how to use Docker is outside the scope of this tutorial, however the Getting Started guide of Docker should provide you with the steps to install Docker on your machine.</p> <p>Visual Studio Code is the editor we will use. The website should provide you with the necessary steps to install it.</p> <p>Lastly, we need to install the Visual Studio Code Remote - Containers extension.  The install button on the marketplace should walk you through the steps to install it. </p>"},{"location":"guides/devcontainers/#run-hydrolib-in-a-devcontainer-by-executing-reopen-in-container-command","title":"Run HYDROLIB in a devcontainer by executing \"Reopen in container\" command","text":"<p>With all of the dependencies set up, we should be able to run HYDROLIB within our devcontainer. When opening the HYDROLIB-Core  repository in Visual Studio Code, we should either get a pop-up asking us to reopen the project within a remote container,  or we can select the  \"Open a Remote Window\" button, the green button in the bottom left corner of your visual studio  code window, after which we can select \"Reopen in container\". Both will then spin up a new container in which we can work. Note that if it is the first time starting our repository, or if we have made changes to the Docker Images we might need to build the container, which could take a few moments.</p> <p>Once opened in a separate container, we can start a terminal to verify everything is  working correctly. First, we need to ensure the correct python interpreter is used.  We want to use the virtual environment created by poetry, which default resides in  <code>./.venv/</code>. Visual Studio Code might prompt you to select an interpreter. If it does press the 'Select Python Interpreter', and select the virtual environment residing in <code>./.venv/</code>. If it does not explicitly prompt you (or if you want to change it later on), press <code>ctrl + shift + p</code>, and select 'Python: Select Interpreter'. If it currently is  not set to the virtual environment, change it to the correct interpreter.</p> <p>It should now be possible to run the HYDROLIB-Core tests within our container by opening  the 'Testing' tab. If the 'Testing' is not already configured in the  <code>./.vscode/settings.json</code>, we will need to configure the Python tests:</p> <ol> <li>click the 'Configure Python Tests' button in the 'Testing' tab</li> <li>Select 'pytest' in the pop-up window</li> <li>Select 'tests', this will ensure tests are located in our 'tests' directory</li> </ol> <p>Once this is done all tests should pass as they would normally.</p>"},{"location":"guides/devcontainers/#dockerfile-configures-python-poetry-and-other-dependencies","title":"Dockerfile configures python, poetry and other dependencies","text":"<p>The Dockerfile which specifies our specific devcontainer can be found here in the repository. Currently, it extends the python 3.9 buster image provided by the Python foundation. It then does  the following:</p> <ul> <li>Installs Poetry 1.1.11 and configure the necessary paths</li> <li>Copies the poetry.lock and pyproject.toml and installs the project</li> <li>Installs git within the container</li> </ul> <p>This should provide us with a ready to go environment to run HYDROLIB-Core with.</p>"},{"location":"guides/devcontainers/#devcontainerjson-specifies-how-visual-studio-code-should-be-configured","title":"devcontainer.json specifies how visual studio code should be configured","text":"<p>We can further customise our environment by editing the devcontainer.json located here in the repository.  In particular, you can add any Visual Studio Code extensions you require for your work to the extensions field. Currently it is populated with several common Python extensions which we use to develop HYDROLIB.</p> <p>For a full overview how to customise this file, you can find the documentation here</p>"},{"location":"guides/devcontainers/#external-references","title":"External references:","text":"<ul> <li>Developing inside a Container - VS Code docs</li> <li>Develop with containers - VS Code docs (guide specific for  python)</li> <li>Document docker poetry best practices - Poetry issue</li> </ul>"},{"location":"guides/developers/","title":"Developer guide","text":"<p>This guide contains some more in-depth guidelines, tasks and examples that developers should adhere to when working on hydrolib-core. In addition to being a useful resource for developing, this documentation can also be helpful for code reviews.</p>"},{"location":"guides/developers/#explicitly-exposing-the-public-api","title":"Explicitly exposing the public API","text":"<p>Whenever you add new functionality that should (or could) be used by the users, make sure you explicitly expose them in the correct <code>__init__.py</code> files.</p> <p>For example, you have developed a new <code>TimModel</code> class that represents a <code>.tim</code> file. The <code>TimModel</code> makes use of the <code>TimParser</code> class and <code>TimSerializer</code> class. While the <code>TimModel</code> class should be publicly exposed to the users, because it is part of the public API, the parser and serializer classes are implementation details that users should not be concerned with. The parser and serializer should therefore not be publicly exposed to the users. </p> <p>To expose the <code>TimModel</code> explicitly to our users, you have to update both the <code>hydrolib/core/dflowfm/tim/__init__.py</code> (assuming you created a new <code>tim</code> folder for this new functionality) and the <code>hydrolib/core/dflowfm/__init__.py</code>:</p> <pre><code># hydrolib/core/dflowfm/tim/__init__.py\nfrom .models import TimModel\n\n__all__ = [\n    \"TimModel\",\n]\n</code></pre> <pre><code># hydrolib/core/dflowfm/__init__.py\n...\n...\nfrom .tim import *\n</code></pre>"},{"location":"guides/developers/#updating-the-documentation","title":"Updating the documentation","text":"<p>In the hydrolib-core repository there are several reference files that are used to automatically generate the API reference. If you add or make changes to the existing API, always make sure the API reference is still up to date.</p> <p>Let's use the example mentioned before, where the <code>TimModel</code> was introduced in hydrolib-core. Since this is new functionality that affects the API, we have to update the reference files. The API reference files are located at <code>docs\\reference</code>. Since the <code>TimModel</code> was newly introduced, we should create a new file named <code>tim.md</code>. The contents of this file include a short description about what the '.tim' file is and what it is used for, followed by the actual API. You do not have to manually write the API, that is done for us by mkdocs. Since the newly introduced <code>TimParser</code> and <code>TimSerializer</code> are not part of the public API, they should not be added to the reference file. </p> <p>An example of such an <code>.md</code> can be found below:</p> <pre><code># Timeseries .tim files\nTimeseries .tim files are timeseries input files \nfor a [D-Flow FM](glossary.md#d-flow-fm) model.\nThe support of .tim files is discontinued and are replaced by the [.bc file](#bc-file).\n\nThey are represented by the class below.\n\n## Model\n::: hydrolib.core.dflowfm.tim.models\n</code></pre>"},{"location":"guides/developers/#updating-the-functionalities-sheet","title":"Updating the functionalities sheet","text":"<p>To generate a list of D-HYDRO functionalities, grouped by kernel, and the current status of support inside hydrolib-core, we use an Excel sheet. This Excel sheet can be found at <code>docs\\topics\\dhydro_support_hydrolib-core.xlsx</code>. Each time you add support for new D-HYDRO functionalities, this Excel file has to be updated. Detailed information on how to update the Excel file correctly can be found inside the Excel file itself.</p>"},{"location":"guides/documentation/","title":"Documentation","text":"<p>We use MKdocs for documentation. For full documentation visit mkdocs.org.</p> <p>The documentation itself is written with https://documentation.divio.com/ structure in mind,  creating different categories: - Guides - Tutorials - Reference - Topics</p>"},{"location":"guides/documentation/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"guides/documentation/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"guides/gettinghelp/","title":"Getting help","text":"<p>See the How-to's and Tutorials to get started using hydrolib-core. For building you own tools upon hydrolib-core, see the API reference for more complete documentation of all current features.</p> <p>If you are missing functionality, please check the list of supported functionalities first.</p> <p>If you think you've encountered a bug, please check the open GitHub issues. Feel free to open a new issue if your issue is not yet known.</p> <p>You can contact the package maintainers about any remaining questions you have.</p>"},{"location":"guides/poetry/","title":"Installation using Poetry","text":"<p>You can use a Poetry-based installation if you are using hydrolib-core from a local clone of the Github repository, for example if you intend to contribute to the code.</p>"},{"location":"guides/poetry/#clone-the-github-repo","title":"Clone the GitHub repo","text":"<p>Use your own preferred way of cloning the GitHub repository of hydrolib-core. In the examples below it is placed in <code>C:\\checkouts\\HYDROLIB-core_git</code>.</p>"},{"location":"guides/poetry/#use-poetry-to-install-hydrolib-core","title":"Use Poetry to install hydrolib-core","text":"<p>We use <code>poetry</code> to manage our package and its dependencies.</p> <p>Note</p> <p>If you use <code>conda</code>, do not combine conda virtual environments with the poetry virtual environment. In other words, run the <code>poetry install</code> command from the <code>base</code> conda environment.</p> <ol> <li>Download + installation instructions for Poetry are here.</li> <li> <p>After installation of Poetry itself, now use it to install your local clone of the hydrolib-core package, as follows.    Make sure Poetry is available on your <code>PATH</code> and run <code>poetry install</code> in the hydrolib-core directory in your shell of choice.    This will create a virtual environment in which hydrolib-core is installed and made available for use in your own scripts.    For example in an Anaconda PowerShell: <pre><code>(base) PS C:\\checkouts\\HYDROLIB-core_git&gt; poetry install\nCreating virtualenv hydrolib-core-kHkQBdtS-py3.8 in C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\nInstalling dependencies from lock file\n\nPackage operations: 67 installs, 0 updates, 0 removals\n\n  * Installing six (1.16.0)\n[..]\nInstalling the current project: hydrolib-core (0.1.5)\n(base) PS C:\\checkouts\\HYDROLIB-core_git&gt; \n</code></pre>    If you need to use an already existing Python installation, you can activate it and run <code>poetry env use system</code> before <code>poetry install</code>.</p> </li> <li> <p>Test your installation, by running the hydrolib-core pytest suite via poetry: <pre><code>(base) PS C:\\checkouts\\HYDROLIB-core_git&gt; poetry run pytest\n===================================== test session starts ======================================\nplatform win32 -- Python 3.8.8, pytest-6.2.5, py-1.10.0, pluggy-1.0.0\nrootdir: C:\\checkouts\\HYDROLIB-core_git, configfile: pyproject.toml\nplugins: cov-2.12.1\ncollected 473 items / 2 deselected / 471 selected\n\ntests\\io\\dflowfm\\ini\\test_ini.py ........................................................ [  3%]\ntests\\io\\dflowfm\\test_bc.py ....                                                          [  4%]\ntests\\io\\dflowfm\\test_ext.py ........................................................     [  5%]\ntests\\io\\dflowfm\\test_fnm.py ..................                                           [ 11%]\ntests\\io\\dflowfm\\test_net.py ............                                                 [ 11%]\ntests\\io\\dflowfm\\test_parser.py .                                                         [ 12%]\ntests\\io\\dflowfm\\test_polyfile.py ........................................................[ 23%]\n....................................                                                      [ 27%]\ntests\\io\\dflowfm\\test_structure.py .......................................................[ 42%]\n.........................................................                                 [ 54%]\ntests\\io\\dimr\\test_dimr.py ...                                                            [ 56%]\ntests\\io\\rr\\meteo\\test_bui.py ...........................                                 [ 57%]\ntests\\io\\test_docker.py .                                                                 [ 70%]\ntests\\test_model.py ...............                                                       [ 78%]\ntests\\test_utils.py .......                                                               [ 91%]\n.........................................                                                 [100%]\n\n============================== 471 passed, 2 deselected in 3.50s ===============================\n(base) PS C:\\checkouts\\HYDROLIB-core_git&gt;\n</code></pre></p> </li> <li>Start using hydrolib-core. You can launch your favourite editor (for example VS Code) by first starting a poetry shell with the virtual hydrolib-core environment: <pre><code>(base) PS C:\\checkouts\\HYDROLIB-core_git&gt; poetry shell\n(base) PS C:\\checkouts\\HYDROLIB-core_git&gt; code\n</code></pre></li> </ol>"},{"location":"guides/poetry/#frequently-asked-questions","title":"Frequently asked questions","text":"<ul> <li>How to fix \"File ... does not exist\" errors during <code>poetry install</code> as in the example below? <pre><code>  * Installing six (1.16.0)\n\n  ValueError\n\n  File \\C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\artifacts\\48\\e6\\04\\8118155ae3ec3a16dd2a213bbf7a7d8a62c596b2e90f73a22c896269f1\\six-1.16.0-py2.py3-none-any.whl does not exist\n</code></pre>   This may occur when a conda environment was activated.   Delete the <code>AppData\\Local\\pypoetry\\Cache</code> directory.   Then run <code>conda deactivate</code> to return to the base environment.   Finally, rerun <code>poetry install</code>.</li> </ul>"},{"location":"guides/setup/","title":"Installation using pip","text":"<p>You can use a pip-based installation if you simply want to use hydrolib-core, without making contributions to the package yourself.</p> <p>You should be able to install hydrolib-core with: <pre><code>pip install hydrolib-core\n</code></pre></p>"},{"location":"guides/setup/#conda-specifics","title":"Conda specifics","text":"<p>Note</p> <p>If you use <code>conda</code>, it is advisable to install hydrolib-core within a new environment with only <code>conda-forge</code> as channel. </p> <p>If you want to create a fresh test environment for hydrolib-core, you could use the following command (only once): <pre><code>conda create -n hydrolib python=3.12 -c conda-forge\n</code></pre> Prior to the <code>pip install</code>, first activate the desired environment: <pre><code>conda activate hydrolib\n</code></pre></p> <p>After successful installation, you should be able to do the \"Basic Model\" tutorial.</p>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>The list below is a nonexhaustive list of terminology and concepts used in HYDROLIB(-core) and Delft3D Flexible Mesh.</p>"},{"location":"reference/glossary/#a","title":"A","text":""},{"location":"reference/glossary/#b","title":"B","text":""},{"location":"reference/glossary/#bc-file","title":"BC file","text":"<p>Input file containing the actual forcing data for model forcings specified elsewhere in the model input, for example time series or astronomical components. Originates from boundary conditions as specified in the external forcings file, but nowadays also used in structure files. More details about the syntax and the various supported function types in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#boundary-condition","title":"Boundary condition","text":"<p>Flow (or constituent) boundary condition that forces a D-Flow FM model, such as waterlevel and discharge boundary conditions. Defined in the external forcings file. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#branch","title":"Branch","text":"<p>The network edges in a network topology of 1D models. The computational grid points are positioned on these branches using branch id and a chainage value.</p>"},{"location":"reference/glossary/#branch-id","title":"Branch Id","text":"<p>Identification text string for a particular branch in a 1D network.</p>"},{"location":"reference/glossary/#c","title":"C","text":""},{"location":"reference/glossary/#chainage","title":"Chainage","text":"<p>The distance along a 1D network branch to define a specific location on that branch. Always used in combination with a branch Id.</p>"},{"location":"reference/glossary/#cf-conventions","title":"CF conventions","text":"<p>Established metadata conventions for storing all kinds of data, e.g., model input and output, in NetCDF files. More details on: https://cfconventions.org/. HYDROLIB-core and Delft3D Flexible Mesh rely on CF, and extend this with UGRID conventions where unstructured grids are applicable.</p>"},{"location":"reference/glossary/#computational-backend","title":"Computational backend","text":"<p>Computational core, also called kernel. The program/library of simulation software that does the actual calculations. Often also available with a graphical user interface on top of it.</p>"},{"location":"reference/glossary/#cross-section-files","title":"Cross section files","text":"<p>Input files for D-Flow FM that define the 1D network's cross sections. Two parts: cross section definition file and cross section location files. Not to be confused with observation cross section files!</p>"},{"location":"reference/glossary/#cross-section-definition-file","title":"Cross section definition file","text":"<p>Input file for D-Flow FM that defines the various cross section shapes in a model with a 1D network. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#cross-section-location-file","title":"Cross section location file","text":"<p>Input file for D-Flow FM that defines the location of cross section shapes in a model with a 1D network. Each location refers to a (possible shared) cross section definition. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#d","title":"D","text":""},{"location":"reference/glossary/#deltares-conventions","title":"Deltares conventions","text":"<p>A proposal for additional NetCDF conventions that build on the existing UGRID conventions, intended to properly describe 1D network topologies as a coordinate space on which 1D computational grids are defined. Also 1D2D grid couplings are included. More details in: the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#d-flow-fm","title":"D-Flow FM","text":"<p>D-Flow Flexible Mesh. The computational backend that solves 1D/2D/3D hydrodynamics in the Delf3D Flexible Mesh Suite. Toplevel input is the MDU file. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#d-hydro-suite-1d2d-beta","title":"D-HYDRO Suite 1D2D (Beta)","text":"<p>Integral software suite for hydraulic 1D2D modelling, including rainfall runoff and realtime control. More details on: https://www.deltares.nl/nl/d-hydro-suite-1d2d-beta/.</p>"},{"location":"reference/glossary/#dimr","title":"DIMR","text":"<p>Deltares Integrated Model Runner. Executable/library that runs integrated models by coupling multiple computational backends in a simulation timeloop. Uses a single DIMR config file as input.</p>"},{"location":"reference/glossary/#dimr-config-file","title":"DIMR config file","text":"<p>Input file for DIMR (typically <code>dimr_config.xml</code>) for an integrated model run, describing which models are coupled and which quantities need to be exchanged.</p>"},{"location":"reference/glossary/#e","title":"E","text":""},{"location":"reference/glossary/#edge-mesh","title":"Edge (mesh)","text":"<p>A geometrical \"line\" in a 1D, 2D or 3D mesh. Connects two mesh nodes as its end points. Building block of the UGRID-conventions.</p>"},{"location":"reference/glossary/#external-forcings-file","title":"External forcings file","text":"<p>Input file for D-Flow FM describing model forcings such as boundary conditions, laterals and meteo. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#f","title":"F","text":""},{"location":"reference/glossary/#face-mesh","title":"Face (mesh)","text":"<p>A geometrical \"cell\" in a 2D mesh. Formed by 3 or more mesh nodes as its vertices. Building block of the UGRID-conventions.</p>"},{"location":"reference/glossary/#flow-link","title":"Flow link","text":"<p>An open connection/interface between two flow nodes in the staggered D-Flow FM model grid. Is the same as a \"velocity point\", and corresponds with (but is not equal to) an edge, both in 1D and in 2D. In 3D a flow link corresponds with a 3D face between two volumes.</p>"},{"location":"reference/glossary/#flow-node","title":"Flow node","text":"<p>A single finite volume \"cell\" in the staggered D-Flow FM model grid. Is the same as a \"pressure point\", and is in fact a face in 2D/3D or a node in 1D.</p>"},{"location":"reference/glossary/#g","title":"G","text":""},{"location":"reference/glossary/#grid","title":"Grid","text":"<p>The computational grid on which a flow simulation is done. The grid for D-Flow FM is defined in an input net file, and also appears (slightly differently) in the output map file.</p>"},{"location":"reference/glossary/#grid-snapping","title":"Grid snapping","text":"<p>The snapping of D-Flow FM model input in x,y-coordinates to discrete locations in the staggered model grid. This process makes most model input independent of the chosen model grid and grid resolution. Snapping is done either to (sets of) flow nodes or (sequence of) flow links, depending on whether pressure-point data or velocity-point data is concerned.</p>"},{"location":"reference/glossary/#h","title":"H","text":""},{"location":"reference/glossary/#his-file","title":"His file","text":"<p>Output file of D-Flow FM containing model results as time series on a specific set of discrete locations, which are typically the hydraulic structures, observation stations and more. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#i","title":"I","text":""},{"location":"reference/glossary/#integrated-model","title":"Integrated model","text":"<p>Model consisting of more than one model. Typically used when multiple computational backends are coupled, for example D-Flow FM and Rainfall Runoff or D-Flow FM and Real Time Control. Integrated models can be run using the Deltares Integrated Model Runner (DIMR).</p>"},{"location":"reference/glossary/#ini-files","title":"INI-files","text":"<p>Delft3D FM uses several input files that are formatted in an INI-like syntax. The abstract syntax depends on the particular file type, see: cross section files, initial field file, external forcings file, MDU file, observation files, rougness file, structure file.</p>"},{"location":"reference/glossary/#initial-field-file","title":"Initial field file","text":"<p>Input file for D-Flow FM describing initial conditions and other spatially varying parameter fields. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#j","title":"J","text":""},{"location":"reference/glossary/#k","title":"K","text":""},{"location":"reference/glossary/#l","title":"L","text":""},{"location":"reference/glossary/#lateral","title":"Lateral","text":"<p>Lateral discharge in D-Flow FM, which acts as a source (or sink) of volume. Defined in the external forcings file. The actual forcing data may come from timeseries in a .bc file or from RR a coupled/integrated model. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#m","title":"M","text":""},{"location":"reference/glossary/#map-file","title":"Map file","text":"<p>Output file of D-Flow FM containing the model results on all grid points. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#mdu-file","title":"MDU file","text":"<p>Main input file of D-Flow FM. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#meteo","title":"meteo","text":"<p>Meteorological forcings of a model. Typically sources (or sinks) of volume via precipitation and evaporation, or forcing via wind. For D-Flow FM defined in the external forcings file. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#mesh","title":"mesh","text":"<p>See grid.</p>"},{"location":"reference/glossary/#n","title":"N","text":""},{"location":"reference/glossary/#net-file","title":"Net file","text":"<p>Or grid file. Input file for D-Flow FM containing the computational model grid. Format is NetCDF, adhering to CF- and UGRID-conventions, and optionally also the Deltares-extension for 1D network topology and geometry.</p>"},{"location":"reference/glossary/#netcdf","title":"NetCDF","text":"<p>File format used by HYDROLIB-core and Delft3D Flexible Mesh for the model input grid and for model results in output files. These files typically adhere to the CF conventions and sometimes UGRID conventions.</p>"},{"location":"reference/glossary/#node-mesh","title":"Node (mesh)","text":"<p>A geometrical \"point\" in a 1D, 2D or 3D mesh. Defined by x- and y-coordinate, in 3D also a z-coordinate. Can be connected by mesh edges, and can form the vertices of a mesh face. Building block of the UGRID-conventions.</p>"},{"location":"reference/glossary/#o","title":"O","text":""},{"location":"reference/glossary/#observation-files","title":"Observation files","text":"<p>Files that define the model locations for which output should be produced in the his file. Two types: observation point file and observation cross section file.</p>"},{"location":"reference/glossary/#observation-cross-section-file","title":"Observation cross section file","text":"<p>Input file for D-Flow FM that describes the model locations for which (cumulative) flow \"flux\" output should be produced in the his file. For example: cumulative discharge, salinity transport. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#observation-point-file","title":"Observation point file","text":"<p>Input file for D-Flow FM that describes the model point locations for which local output should be produced in the his file. For example: waterlevel, velocity vector/magnitude, tracer concentration as instantanous values. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#p","title":"P","text":""},{"location":"reference/glossary/#polyline-file","title":"Polyline file","text":"<p>File containing a sequence of polylines in model coordinates. Each polyline has header lines with a label and row+column count, and at least a list of x, y-points. More than 2 columns may be present (z, data1, ...) for particular model inputs, see for example the fixed weir file. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#polygon-file","title":"Polygon file","text":"<p>See polyline file. The point sequences are interpreted as closed polygons.</p>"},{"location":"reference/glossary/#q","title":"Q","text":""},{"location":"reference/glossary/#r","title":"R","text":""},{"location":"reference/glossary/#rainfall-runoff","title":"Rainfall Runoff","text":"<p>RR for short. The computational backend that solves lumped rainfall runoff, offering various runoff concepts. Toplevel input is the <code>sobek_3b.fnm</code> file. Part of the D-Hydrology software module. More details on: https://www.deltares.nl/en/software/module/d-hydrology.</p>"},{"location":"reference/glossary/#real-time-control","title":"Real Time Control","text":"<p>RTC for short. The computational backend for real-time control of hydraulic model components (typically hydraulic structures). Toplevel input is in various <code>rtc*.xml</code> files. Part of the D-Real Time Control software module. More details on: https://www.deltares.nl/en/software/module/d-real-time-control.</p>"},{"location":"reference/glossary/#roughness-file","title":"Roughness file","text":"<p>Input file for D-Flow FM describing roughness values on the 1D network. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#s","title":"S","text":""},{"location":"reference/glossary/#sample-file","title":"Sample file","text":"<p>File containing an unstructured set of sample point values. Typically used as input file for initial fields or other spatially varying fields in the initial fields file. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#staggered-grid","title":"Staggered grid","text":"<p>Discretization method used in D-Flow FM where the PDE variables are not all defined on the same topological grid locations. Water level, concentrations and other volume-related variables are defined on the pressure points (also: flow nodes), and the fluxes and other transport-related variables are defined on the velocity points (also: flow links).</p>"},{"location":"reference/glossary/#structure-file","title":"Structure file","text":"<p>Input file for D-Flow FM containing the hydraulic structures. Format is INI-like. More details in the Delft3D FM User Manual.</p>"},{"location":"reference/glossary/#t","title":"T","text":""},{"location":"reference/glossary/#u","title":"U","text":""},{"location":"reference/glossary/#ugrid-conventions","title":"UGRID conventions","text":"<p>Metadata conventions for storing unstructured grids in NetCDF files. More details on: http://ugrid-conventions.github.io/ugrid-conventions/.</p>"},{"location":"reference/glossary/#v","title":"V","text":""},{"location":"reference/glossary/#volume-mesh","title":"volume (mesh)","text":"<p>A geometrical \"cell\" in a 3D mesh. Formed by 4 or more mesh nodes as its vertices (or: 4 or more mesh faces as its \"sides\"). Building block of the UGRID-conventions.</p>"},{"location":"reference/glossary/#w","title":"W","text":""},{"location":"reference/glossary/#x","title":"X","text":""},{"location":"reference/glossary/#xyz-file","title":"XYZ file","text":"<p>See sample file.</p>"},{"location":"reference/glossary/#y","title":"Y","text":""},{"location":"reference/glossary/#z","title":"Z","text":""},{"location":"reference/gui/","title":"GUI files","text":"<p>The GUI module provides the logic to create and validate GUI specific models for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>A .gui file is described by the classes below.</p>"},{"location":"reference/gui/#gui-models","title":"GUI models","text":"<p>namespace for storing the branches as branches.gui file</p>"},{"location":"reference/gui/#hydrolib.core.dflowfm.gui.models.Branch","title":"<code>Branch</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A branch that is included in the branches.gui file.</p> Source code in <code>hydrolib/core/dflowfm/gui/models.py</code> <pre><code>class Branch(INIBasedModel):\n    \"\"\"\n    A branch that is included in the branches.gui file.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        name: Optional[str] = \"Unique branch id.\"\n        branchtype: Optional[str] = Field(\n            \"Channel = 0, SewerConnection = 1, Pipe = 2.\", alias=\"branchType\"\n        )\n        islengthcustom: Optional[str] = Field(\n            \"branch length specified by user.\", alias=\"isLengthCustom\"\n        )\n        sourcecompartmentname: Optional[str] = Field(\n            \"Source compartment name this sewer connection is beginning.\",\n            alias=\"sourceCompartmentName\",\n        )\n        targetcompartmentname: Optional[str] = Field(\n            \"Source compartment name this sewer connection is beginning.\",\n            alias=\"targetCompartmentName\",\n        )\n        material: Optional[str] = Field(\n            \"0 = Unknown, 1 = Concrete, 2 = CastIron, 3 = StoneWare, 4 = Hdpe, \"\n            \"5 = Masonry, 6 = SheetMetal, 7 = Polyester, 8 = Polyvinylchlorid, 9 = Steel\"\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Branch\"] = \"Branch\"\n\n    name: str = Field(\"name\", max_length=255, alias=\"name\")\n    branchtype: int = Field(0, alias=\"branchType\")\n    islengthcustom: Optional[bool] = Field(True, alias=\"isLengthCustom\")\n    sourcecompartmentname: Optional[str] = Field(None, alias=\"sourceCompartmentName\")\n    targetcompartmentname: Optional[str] = Field(None, alias=\"targetCompartmentName\")\n    material: Optional[int] = Field(None, alias=\"material\")\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n\n    @root_validator\n    @classmethod\n    def _validate_branch(cls, values: dict):\n        if values.get(\"branchtype\") == 2 and (\n            values.get(\"sourcecompartmentname\") is None\n            and values.get(\"targetcompartmentname\") is None\n        ):\n            raise ValueError(\n                \"Either sourceCompartmentName or targetCompartmentName should be provided when branchType is 2.\"\n            )\n\n        return values\n\n    @validator(\"branchtype\")\n    def _validate_branchtype(cls, branchtype: int):\n        allowed_branchtypes = [0, 1, 2]\n        if branchtype not in allowed_branchtypes:\n            str_allowed_branchtypes = [str(i) for i in allowed_branchtypes]\n            error_msg = f\"branchType ({branchtype}) is not allowed. Allowed values: {', '.join(str_allowed_branchtypes)}\"\n            raise ValueError(error_msg)\n\n        return branchtype\n\n    @validator(\"material\")\n    def _validate_material(cls, material: int):\n        allowed_materials = range(10)\n        if material not in allowed_materials:\n            str_allowed_materials = [str(i) for i in allowed_materials]\n            error_msg = f\"material ({material}) is not allowed. Allowed values: {', '.join(str_allowed_materials)}\"\n            raise ValueError(error_msg)\n\n        return material\n</code></pre>"},{"location":"reference/gui/#hydrolib.core.dflowfm.gui.models.BranchGeneral","title":"<code>BranchGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The branches.gui file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/gui/models.py</code> <pre><code>class BranchGeneral(INIGeneral):\n    \"\"\"The branches.gui file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'branches'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"branches\"] = Field(\"branches\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/gui/#hydrolib.core.dflowfm.gui.models.BranchModel","title":"<code>BranchModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall branch model that contains the contents of one branches.gui file.</p> <p>This model is not referenced under a FMModel.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>BranchGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>branch(List[Branch])</code> <code>BranchGeneral</code> <p>List of <code>[Branch]</code> blocks for all branches.</p> Source code in <code>hydrolib/core/dflowfm/gui/models.py</code> <pre><code>class BranchModel(INIModel):\n    \"\"\"\n    The overall branch model that contains the contents of one branches.gui file.\n\n    This model is not referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel].\n\n    Attributes:\n        general (BranchGeneral): `[General]` block with file metadata.\n        branch(List[Branch]): List of `[Branch]` blocks for all branches.\n    \"\"\"\n\n    general: BranchGeneral = BranchGeneral()\n    branch: List[Branch] = []\n\n    _make_list = make_list_validator(\"branch\")\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".gui\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"branches\"\n</code></pre>"},{"location":"reference/ini/","title":"INI format","text":"<p>The ini module provides the generic logic for parsing Deltares ini based files, such as the mdu, structures files, as well as more complex files such as the boundary condition (bc) files.</p> <p>Note that specific attribute files that employ this ini format often have their own dedicated module (and separate API doc page). These include:</p> <ul> <li>MDU file (<code>hydrolib.core.dflowfm.mdu</code>)</li> <li>External forcing file (<code>hydrolib.core.dflowfm.ext</code>)</li> <li>Initial fields and parameter file (<code>hydrolib.core.dflowfm.inifield</code>)</li> <li>Structure file (<code>hydrolib.core.dflowfm.structure</code>)</li> <li>1D roughness (<code>hydrolib.core.dflowfm.friction</code>)</li> <li>Cross section files (<code>hydrolib.core.dflowfm.crosssection</code>)</li> <li>Storage node file (<code>hydrolib.core.dflowfm.storagenode</code>)</li> </ul> <p>Following below is the documentation for the INI format base classes.</p>"},{"location":"reference/ini/#model","title":"Model","text":""},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.DataBlockINIBasedModel","title":"<code>DataBlockINIBasedModel</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>DataBlockINIBasedModel defines the base model for ini models with datablocks.</p> <p>This class extends the functionality of INIBasedModel to handle structured data blocks commonly found in INI files. It provides validation, serialization, and conversion methods for working with these data blocks.</p> <p>Attributes:</p> Name Type Description <code>datablock</code> <code>Datablock</code> <p>(class attribute) the actual data columns.</p> <p>datablock (List[List[Union[float, str]]]):     A two-dimensional list representing the data block. Each sub-list corresponds to     a row in the data block, and the values can be either floats or strings.</p> <p>Parameters:</p> Name Type Description Default <code>datablock</code> <code>List[List[Union[float, str]]]</code> <p>The initial data block for the model. Defaults to an empty list.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If a NaN value is found within the data block.</p> See Also <p>INIBasedModel: The parent class for models representing INI-based configurations. INISerializerConfig: Provides configuration for INI serialization.</p> <p>Examples:</p> <p>Create a model and validate its data block:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import DataBlockINIBasedModel\n&gt;&gt;&gt; model = DataBlockINIBasedModel(datablock=[[1.0, 2.0], [3.0, 4.0]])\n&gt;&gt;&gt; print(model.datablock)\n[[1.0, 2.0], [3.0, 4.0]]\n</code></pre></p> <p>Attempt to create a model with invalid data:     <pre><code>&gt;&gt;&gt; try:\n...     model = DataBlockINIBasedModel(datablock=[[1.0, None]])\n... except Exception as e:\n...     print(e)\n1 validation error for DataBlockINIBasedModel\ndatablock -&gt; 0 -&gt; 1\n  none is not an allowed value (type=type_error.none.not_allowed)\n</code></pre></p> Notes <ul> <li>The class includes a validator to ensure that no NaN values are present in the data block.</li> <li>Data blocks are converted to a serialized format for writing to INI files.</li> </ul> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>class DataBlockINIBasedModel(INIBasedModel):\n    \"\"\"DataBlockINIBasedModel defines the base model for ini models with datablocks.\n\n    This class extends the functionality of INIBasedModel to handle structured data blocks\n    commonly found in INI files. It provides validation, serialization, and conversion methods\n    for working with these data blocks.\n\n    Attributes:\n        datablock (Datablock): (class attribute) the actual data columns.\n\n    Attributes:\n    datablock (List[List[Union[float, str]]]):\n        A two-dimensional list representing the data block. Each sub-list corresponds to\n        a row in the data block, and the values can be either floats or strings.\n\n    Args:\n        datablock (List[List[Union[float, str]]], optional):\n            The initial data block for the model. Defaults to an empty list.\n\n    Raises:\n        ValueError: If a NaN value is found within the data block.\n\n    See Also:\n        INIBasedModel: The parent class for models representing INI-based configurations.\n        INISerializerConfig: Provides configuration for INI serialization.\n\n    Examples:\n        Create a model and validate its data block:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import DataBlockINIBasedModel\n            &gt;&gt;&gt; model = DataBlockINIBasedModel(datablock=[[1.0, 2.0], [3.0, 4.0]])\n            &gt;&gt;&gt; print(model.datablock)\n            [[1.0, 2.0], [3.0, 4.0]]\n\n            ```\n\n        Attempt to create a model with invalid data:\n            ```python\n            &gt;&gt;&gt; try:\n            ...     model = DataBlockINIBasedModel(datablock=[[1.0, None]])\n            ... except Exception as e:\n            ...     print(e)\n            1 validation error for DataBlockINIBasedModel\n            datablock -&gt; 0 -&gt; 1\n              none is not an allowed value (type=type_error.none.not_allowed)\n\n            ```\n\n    Notes:\n        - The class includes a validator to ensure that no NaN values are present in the data block.\n        - Data blocks are converted to a serialized format for writing to INI files.\n    \"\"\"\n\n    datablock: Datablock = Field(default_factory=list)\n\n    _make_lists = make_list_validator(\"datablock\")\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"\n        The DataBlockINIBasedModel does not need to raise an error on unknown keywords.\n\n        Returns:\n            Optional[UnknownKeywordErrorManager]: Returns None as unknown keywords are ignored.\n        \"\"\"\n        return None\n\n    def as_dataframe(self) -&gt; DataFrame:\n        \"\"\"Convert the datablock as a pandas DataFrame\n\n        - The first number from each list in the block as an index for that row.\n\n        Returns:\n            DataFrame: The datablock as a pandas DataFrame.\n\n        Examples:\n                &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import DataBlockINIBasedModel\n                &gt;&gt;&gt; model = DataBlockINIBasedModel(datablock=[[0, 10, 100], [1, 20, 200]])\n                &gt;&gt;&gt; df = model.as_dataframe()\n                &gt;&gt;&gt; print(df)\n                        0      1\n                0.0  10.0  100.0\n                1.0  20.0  200.0\n        \"\"\"\n        df = DataFrame(self.datablock).set_index(0)\n        df.index.name = None\n        df.columns = range(len(df.columns))\n        return df\n\n    def _to_section(\n        self,\n        config: DataBlockINIBasedSerializerConfig,\n        save_settings: ModelSaveSettings,\n    ) -&gt; Section:\n        \"\"\"\n        Converts the current model to an INI Section representation.\n\n        Args:\n            config (DataBlockINIBasedSerializerConfig): Configuration for serializing the data block.\n            save_settings (ModelSaveSettings): Settings for saving the model.\n\n        Returns:\n            Section: The INI Section containing serialized data and the data block.\n        \"\"\"\n        section = super()._to_section(config, save_settings)\n        section.datablock = self._to_datablock(config)\n        return section\n\n    def _to_datablock(self, config: DataBlockINIBasedSerializerConfig) -&gt; List[List]:\n        \"\"\"\n        Converts the data block to a serialized format based on the configuration.\n\n        Args:\n            config (DataBlockINIBasedSerializerConfig): Configuration for serializing the data block.\n\n        Returns:\n            List[List]: A serialized representation of the data block.\n        \"\"\"\n        converted_datablock = []\n\n        for row in self.datablock:\n            converted_row = (\n                DataBlockINIBasedModel.convert_value(value, config) for value in row\n            )\n            converted_datablock.append(list(converted_row))\n\n        return converted_datablock\n\n    @classmethod\n    def convert_value(\n        cls, value: Union[float, str], config: DataBlockINIBasedSerializerConfig\n    ) -&gt; str:\n        \"\"\"\n        Converts a value in the data block to its serialized string representation.\n\n        Args:\n            value (Union[float, str]): The value to be converted.\n            config (DataBlockINIBasedSerializerConfig): Configuration for the conversion.\n\n        Returns:\n            str: The serialized string representation of the value.\n        \"\"\"\n        if isinstance(value, float):\n            return f\"{value:{config.float_format_datablock}}\"\n\n        return value\n\n    @validator(\"datablock\")\n    def _validate_no_nans_are_present(cls, datablock: Datablock) -&gt; Datablock:\n        \"\"\"Validate that the datablock does not have any NaN values.\n\n        Args:\n            datablock (Datablock): The datablock to validate.\n\n        Raises:\n            ValueError: When a NaN is present in the datablock.\n\n        Returns:\n            Datablock: The validated datablock.\n        \"\"\"\n        if any(cls._is_float_and_nan(value) for row in datablock for value in row):\n            raise ValueError(\"NaN is not supported in datablocks.\")\n\n        return datablock\n\n    @staticmethod\n    def _is_float_and_nan(value: float) -&gt; bool:\n        \"\"\"\n        Determines whether a value is a float and is NaN.\n\n        Args:\n            value (float): The value to check.\n\n        Returns:\n            bool: True if the value is a NaN float; otherwise, False.\n        \"\"\"\n        return isinstance(value, float) and isnan(value)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.DataBlockINIBasedModel.as_dataframe","title":"<code>as_dataframe()</code>","text":"<p>Convert the datablock as a pandas DataFrame</p> <ul> <li>The first number from each list in the block as an index for that row.</li> </ul> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>DataFrame</code> <p>The datablock as a pandas DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import DataBlockINIBasedModel\n&gt;&gt;&gt; model = DataBlockINIBasedModel(datablock=[[0, 10, 100], [1, 20, 200]])\n&gt;&gt;&gt; df = model.as_dataframe()\n&gt;&gt;&gt; print(df)\n        0      1\n0.0  10.0  100.0\n1.0  20.0  200.0\n</code></pre> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>def as_dataframe(self) -&gt; DataFrame:\n    \"\"\"Convert the datablock as a pandas DataFrame\n\n    - The first number from each list in the block as an index for that row.\n\n    Returns:\n        DataFrame: The datablock as a pandas DataFrame.\n\n    Examples:\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import DataBlockINIBasedModel\n            &gt;&gt;&gt; model = DataBlockINIBasedModel(datablock=[[0, 10, 100], [1, 20, 200]])\n            &gt;&gt;&gt; df = model.as_dataframe()\n            &gt;&gt;&gt; print(df)\n                    0      1\n            0.0  10.0  100.0\n            1.0  20.0  200.0\n    \"\"\"\n    df = DataFrame(self.datablock).set_index(0)\n    df.index.name = None\n    df.columns = range(len(df.columns))\n    return df\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.DataBlockINIBasedModel.convert_value","title":"<code>convert_value(value, config)</code>  <code>classmethod</code>","text":"<p>Converts a value in the data block to its serialized string representation.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[float, str]</code> <p>The value to be converted.</p> required <code>config</code> <code>DataBlockINIBasedSerializerConfig</code> <p>Configuration for the conversion.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The serialized string representation of the value.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@classmethod\ndef convert_value(\n    cls, value: Union[float, str], config: DataBlockINIBasedSerializerConfig\n) -&gt; str:\n    \"\"\"\n    Converts a value in the data block to its serialized string representation.\n\n    Args:\n        value (Union[float, str]): The value to be converted.\n        config (DataBlockINIBasedSerializerConfig): Configuration for the conversion.\n\n    Returns:\n        str: The serialized string representation of the value.\n    \"\"\"\n    if isinstance(value, float):\n        return f\"{value:{config.float_format_datablock}}\"\n\n    return value\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel","title":"<code>INIBasedModel</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>INIBasedModel defines the base model for blocks/chapters inside an INIModel (*.ini file).</p> <ul> <li>Abstract base class for representing INI-style configuration file blocks or chapters.</li> <li>This class serves as the foundational model for handling blocks within INI configuration files. It supports creating instances from parsed INI sections, adding arbitrary fields, and ensuring well-defined serialization and deserialization behavior. Subclasses are expected to define specific behavior and headers for their respective INI blocks.</li> </ul> <p>Attributes:</p> Name Type Description <code>comments</code> <code>Optional[Comments]</code> <p>Optional Comments if defined by the user, containing descriptions for all data fields.</p> <p>Parameters:</p> Name Type Description Default <code>comments</code> <code>Optional[Comments]</code> <p>Comments for the model fields. Defaults to None.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If unknown fields are encountered during validation.</p> See Also <p>BaseModel: The Pydantic base model extended by this class. INISerializerConfig: Provides configuration for INI serialization.</p> <p>Examples:</p> <p>Define a custom INI block subclass:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import INIBasedModel\n&gt;&gt;&gt; class MyModel(INIBasedModel):\n...     _header = \"MyHeader\"\n...     field_a: str = \"default_value\"\n</code></pre></p> <p>Parse an INI section:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.ini.io_models import Section\n&gt;&gt;&gt; section = Section(header=\"MyHeader\", content=[{\"key\": \"field_a\", \"value\": \"value\"}])\n&gt;&gt;&gt; model = MyModel.parse_obj(section.flatten())\n&gt;&gt;&gt; print(model.field_a)\nvalue\n</code></pre></p> <p>Serialize a model to an INI format:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.ini.serializer import INISerializerConfig\n&gt;&gt;&gt; from hydrolib.core.base.models import ModelSaveSettings\n&gt;&gt;&gt; config = INISerializerConfig()\n&gt;&gt;&gt; section = model._to_section(config, save_settings=ModelSaveSettings())\n&gt;&gt;&gt; print(section.header)\nMyHeader\n</code></pre></p> Notes <ul> <li>Subclasses can override the <code>_header</code> attribute to define the INI block header.</li> <li>Arbitrary fields can be added dynamically and are included during serialization.</li> </ul> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>class INIBasedModel(BaseModel, ABC):\n    \"\"\"INIBasedModel defines the base model for blocks/chapters\n    inside an INIModel (*.ini file).\n\n    - Abstract base class for representing INI-style configuration file blocks or chapters.\n    - This class serves as the foundational model for handling blocks within INI configuration files.\n    It supports creating instances from parsed INI sections, adding arbitrary fields, and ensuring\n    well-defined serialization and deserialization behavior. Subclasses are expected to define\n    specific behavior and headers for their respective INI blocks.\n\n    Attributes:\n        comments (Optional[Comments]):\n            Optional Comments if defined by the user, containing descriptions for all data fields.\n\n    Args:\n        comments (Optional[Comments], optional):\n            Comments for the model fields. Defaults to None.\n\n    Raises:\n        ValueError: If unknown fields are encountered during validation.\n\n    See Also:\n        BaseModel: The Pydantic base model extended by this class.\n        INISerializerConfig: Provides configuration for INI serialization.\n\n\n    Examples:\n        Define a custom INI block subclass:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.models import INIBasedModel\n            &gt;&gt;&gt; class MyModel(INIBasedModel):\n            ...     _header = \"MyHeader\"\n            ...     field_a: str = \"default_value\"\n\n            ```\n\n        Parse an INI section:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.io_models import Section\n            &gt;&gt;&gt; section = Section(header=\"MyHeader\", content=[{\"key\": \"field_a\", \"value\": \"value\"}])\n            &gt;&gt;&gt; model = MyModel.parse_obj(section.flatten())\n            &gt;&gt;&gt; print(model.field_a)\n            value\n\n            ```\n\n        Serialize a model to an INI format:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.ini.serializer import INISerializerConfig\n            &gt;&gt;&gt; from hydrolib.core.base.models import ModelSaveSettings\n            &gt;&gt;&gt; config = INISerializerConfig()\n            &gt;&gt;&gt; section = model._to_section(config, save_settings=ModelSaveSettings())\n            &gt;&gt;&gt; print(section.header)\n            MyHeader\n\n            ```\n\n    Notes:\n        - Subclasses can override the `_header` attribute to define the INI block header.\n        - Arbitrary fields can be added dynamically and are included during serialization.\n    \"\"\"\n\n    _header: str = \"\"\n    _file_path_style_converter = FilePathStyleConverter()\n    _scientific_notation_regex = compile(\n        r\"([\\d.]+)([dD])([+-]?\\d{1,3})\"\n    )  # matches a float: 1d9, 1D-3, 1.D+4, etc.\n\n    class Config:\n        extra = Extra.ignore\n        arbitrary_types_allowed = False\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"\n        Retrieves the error manager for handling unknown keywords in INI files.\n\n        Returns:\n            Optional[UnknownKeywordErrorManager]:\n                An instance of the error manager or None if unknown keywords are allowed.\n        \"\"\"\n        return UnknownKeywordErrorManager()\n\n    @classmethod\n    def _supports_comments(cls) -&gt; bool:\n        \"\"\"\n        Indicates whether the model supports comments for its fields.\n\n        Returns:\n            bool: True if comments are supported; otherwise, False.\n        \"\"\"\n        return True\n\n    @classmethod\n    def _duplicate_keys_as_list(cls) -&gt; bool:\n        \"\"\"\n        Indicates whether duplicate keys in INI sections should be treated as lists.\n\n        Returns:\n            bool: True if duplicate keys should be treated as lists; otherwise, False.\n        \"\"\"\n        return False\n\n    @classmethod\n    def get_list_delimiter(cls) -&gt; str:\n        \"\"\"List delimiter string that will be used for serializing\n        list field values for any IniBasedModel, **if** that field has\n        no custom list delimiter.\n\n        This function should be overridden by any subclass for a particular\n        filetype that needs a specific/different list separator.\n        \"\"\"\n        return \" \"\n\n    @classmethod\n    def get_list_field_delimiter(cls, field_key: str) -&gt; str:\n        \"\"\"List delimiter string that will be used for serializing\n        the given field's value.\n        The returned delimiter is either the field's custom list delimiter\n        if that was specified using Field(.., delimiter=\"..\"), or the\n        default list delimiter for the model class that this field belongs\n        to.\n\n        Args:\n            field_key (str): the original field key (not its alias).\n\n        Returns:\n            str: the delimiter string to be used for serializing the given field.\n        \"\"\"\n        delimiter = None\n        if (field := cls.__fields__.get(field_key)) and isinstance(field, ModelField):\n            delimiter = field.field_info.extra.get(\"delimiter\")\n        if not delimiter:\n            delimiter = cls.get_list_delimiter()\n\n        return delimiter\n\n    class Comments(BaseModel, ABC):\n        \"\"\"\n        Represents the comments associated with fields in an INIBasedModel.\n\n        Attributes:\n            Arbitrary fields can be added dynamically to store comments.\n\n        Config:\n            extra: Extra.allow\n                Allows dynamic fields for comments.\n            arbitrary_types_allowed: bool\n                Indicates that only known types are allowed.\n        \"\"\"\n\n        class Config:\n            extra = Extra.allow\n            arbitrary_types_allowed = False\n\n    comments: Optional[Comments] = Comments()\n\n    @root_validator(pre=True)\n    def _validate_unknown_keywords(cls, values):\n        \"\"\"\n        Validates fields and raises errors for unknown keywords.\n\n        Args:\n            values (dict): Dictionary of field values to validate.\n\n        Returns:\n            dict: Validated field values.\n\n        Raises:\n            ValueError: If unknown keywords are found.\n        \"\"\"\n        unknown_keyword_error_manager = cls._get_unknown_keyword_error_manager()\n        do_not_validate = cls._exclude_from_validation(values)\n        if unknown_keyword_error_manager:\n            unknown_keyword_error_manager.raise_error_for_unknown_keywords(\n                values,\n                cls._header,\n                cls.__fields__,\n                cls._exclude_fields() | do_not_validate,\n            )\n        return values\n\n    @root_validator(pre=True)\n    def _skip_nones_and_set_header(cls, values):\n        \"\"\"Drop None fields for known fields.\n\n        Filters out None values and sets the model header.\n\n        Args:\n            values (dict): Dictionary of field values.\n\n        Returns:\n            dict: Updated field values with None values removed.\n        \"\"\"\n        dropkeys = []\n        for k, v in values.items():\n            if v is None and k in cls.__fields__.keys():\n                dropkeys.append(k)\n\n        logger.info(f\"Dropped unset keys: {dropkeys}\")\n        for k in dropkeys:\n            values.pop(k)\n\n        if \"_header\" in values:\n            values[\"_header\"] = cls._header\n\n        return values\n\n    @validator(\"comments\", always=True, allow_reuse=True)\n    def comments_matches_has_comments(cls, v):\n        \"\"\"\n        Validates the presence of comments if supported by the model.\n\n        Args:\n            v (Any): The comments field value.\n\n        Returns:\n            Any: Validated comments field value.\n        \"\"\"\n        if not cls._supports_comments() and v is not None:\n            logging.warning(f\"Dropped unsupported comments from {cls.__name__} init.\")\n            v = None\n        return v\n\n    @validator(\"*\", pre=True, allow_reuse=True)\n    def replace_fortran_scientific_notation_for_floats(cls, value, field):\n        \"\"\"\n        Converts FORTRAN-style scientific notation to standard notation for float fields.\n\n        Args:\n            value (Any): The field value to process.\n            field (Field): The field being processed.\n\n        Returns:\n            Any: The processed field value.\n        \"\"\"\n        if field.type_ != float:\n            return value\n\n        return cls._replace_fortran_scientific_notation(value)\n\n    @classmethod\n    def _replace_fortran_scientific_notation(cls, value):\n        \"\"\"\n        Replaces FORTRAN-style scientific notation in a value.\n\n        Args:\n            value (Any): The value to process.\n\n        Returns:\n            Any: The processed value.\n        \"\"\"\n        if isinstance(value, str):\n            return cls._scientific_notation_regex.sub(r\"\\1e\\3\", value)\n        if isinstance(value, list):\n            for i, v in enumerate(value):\n                if isinstance(v, str):\n                    value[i] = cls._scientific_notation_regex.sub(r\"\\1e\\3\", v)\n\n        return value\n\n    @classmethod\n    def validate(cls: Type[\"INIBasedModel\"], value: Any) -&gt; \"INIBasedModel\":\n        \"\"\"\n        Validates a value as an instance of INIBasedModel.\n\n        Args:\n            value (Any): The value to validate.\n\n        Returns:\n            INIBasedModel: The validated instance.\n        \"\"\"\n        if isinstance(value, Section):\n            value = value.flatten(\n                cls._duplicate_keys_as_list(), cls._supports_comments()\n            )\n\n        return super().validate(value)\n\n    @classmethod\n    def _exclude_from_validation(cls, input_data: Optional[dict] = None) -&gt; Set:\n        \"\"\"\n        Fields that should not be checked when validating existing fields as they will be dynamically added.\n\n        Args:\n            input_data (Optional[dict]): Input data to process.\n\n        Returns:\n            Set: Set of field names to exclude from validation.\n        \"\"\"\n        return set()\n\n    @classmethod\n    def _exclude_fields(cls) -&gt; Set:\n        \"\"\"\n        Defines fields to exclude from serialization.\n\n        Returns:\n            Set: Set of field names to exclude.\n        \"\"\"\n        return {\"comments\", \"datablock\", \"_header\"}\n\n    def _convert_value(\n        self,\n        key: str,\n        v: Any,\n        config: INISerializerConfig,\n        save_settings: ModelSaveSettings,\n    ) -&gt; str:\n        \"\"\"\n        Converts a field value to its serialized string representation.\n\n        Args:\n            key (str): The field key.\n            v (Any): The field value.\n            config (INISerializerConfig): Configuration for serialization.\n            save_settings (ModelSaveSettings): Settings for saving the model.\n\n        Returns:\n            str: The serialized value.\n        \"\"\"\n        if isinstance(v, bool):\n            return str(int(v))\n        elif isinstance(v, list):\n            convert_value = lambda x: self._convert_value(key, x, config, save_settings)\n            return self.__class__.get_list_field_delimiter(key).join(\n                [convert_value(x) for x in v]\n            )\n        elif isinstance(v, Enum):\n            return v.value\n        elif isinstance(v, float):\n            return f\"{v:{config.float_format}}\"\n        elif isinstance(v, FileModel) and v.filepath is not None:\n            return self._file_path_style_converter.convert_from_os_style(\n                v.filepath, save_settings.path_style\n            )\n        elif v is None:\n            return \"\"\n        else:\n            return str(v)\n\n    def _to_section(\n        self, config: INISerializerConfig, save_settings: ModelSaveSettings\n    ) -&gt; Section:\n        \"\"\"\n        Converts the model to an INI section.\n\n        Args:\n            config (INISerializerConfig): Configuration for serialization.\n            save_settings (ModelSaveSettings): Settings for saving the model.\n\n        Returns:\n            Section: The INI section representation of the model.\n        \"\"\"\n        props = []\n        for key, value in self:\n            if not self._should_be_serialized(key, value, save_settings):\n                continue\n\n            field_key = key\n            if key in self.__fields__:\n                key = self.__fields__[key].alias\n\n            prop = Property(\n                key=key,\n                value=self._convert_value(field_key, value, config, save_settings),\n                comment=getattr(self.comments, field_key, None),\n            )\n            props.append(prop)\n        return Section(header=self._header, content=props)\n\n    def _should_be_serialized(\n        self, key: str, value: Any, save_settings: ModelSaveSettings\n    ) -&gt; bool:\n        \"\"\"\n        Determines if a field should be serialized.\n\n        Args:\n            key (str): The field key.\n            value (Any): The field value.\n            save_settings (ModelSaveSettings): Settings for saving the model.\n\n        Returns:\n            bool: True if the field should be serialized; otherwise, False.\n        \"\"\"\n        if key in self._exclude_fields():\n            return False\n\n        if save_settings._exclude_unset and key not in self.__fields_set__:\n            return False\n\n        field = self.__fields__.get(key)\n        if not field:\n            return value is not None\n\n        field_type = field.type_\n        if self._is_union(field_type):\n            return value is not None or self._union_has_filemodel(field_type)\n\n        if self._is_list(field_type):\n            field_type = get_args(field_type)[0]\n\n        return self._value_is_not_none_or_type_is_filemodel(field_type, value)\n\n    @staticmethod\n    def _is_union(field_type: type) -&gt; bool:\n        \"\"\"\n        Checks if a type is a Union.\n\n        Args:\n            field_type (type): The type to check.\n\n        Returns:\n            bool: True if the type is a Union; otherwise, False.\n        \"\"\"\n        return get_origin(field_type) is Union\n\n    @staticmethod\n    def _union_has_filemodel(field_type: type) -&gt; bool:\n        \"\"\"\n        Checks if a Union type includes a FileModel subtype.\n\n        Args:\n            field_type (type): The type to check.\n\n        Returns:\n            bool: True if the Union includes a FileModel; otherwise, False.\n        \"\"\"\n        return any(\n            isclass(arg) and issubclass(arg, FileModel) for arg in get_args(field_type)\n        )\n\n    @staticmethod\n    def _is_list(field_type: type) -&gt; bool:\n        \"\"\"\n        Checks if a type is a list.\n\n        Args:\n            field_type (type): The type to check.\n\n        Returns:\n            bool: True if the type is a list; otherwise, False.\n        \"\"\"\n        return get_origin(field_type) is List\n\n    @staticmethod\n    def _value_is_not_none_or_type_is_filemodel(field_type: type, value: Any) -&gt; bool:\n        \"\"\"\n        Checks if a value is not None or if its type is FileModel.\n\n        Args:\n        field_type (type): The expected type of the field.\n        value (Any): The value to check.\n\n        Returns:\n            bool: True if the value is valid; otherwise, False.\n        \"\"\"\n        return value is not None or issubclass(field_type, FileModel)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Represents the comments associated with fields in an INIBasedModel.</p> Config <p>extra: Extra.allow     Allows dynamic fields for comments. arbitrary_types_allowed: bool     Indicates that only known types are allowed.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>class Comments(BaseModel, ABC):\n    \"\"\"\n    Represents the comments associated with fields in an INIBasedModel.\n\n    Attributes:\n        Arbitrary fields can be added dynamically to store comments.\n\n    Config:\n        extra: Extra.allow\n            Allows dynamic fields for comments.\n        arbitrary_types_allowed: bool\n            Indicates that only known types are allowed.\n    \"\"\"\n\n    class Config:\n        extra = Extra.allow\n        arbitrary_types_allowed = False\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.comments_matches_has_comments","title":"<code>comments_matches_has_comments(v)</code>","text":"<p>Validates the presence of comments if supported by the model.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Any</code> <p>The comments field value.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Validated comments field value.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@validator(\"comments\", always=True, allow_reuse=True)\ndef comments_matches_has_comments(cls, v):\n    \"\"\"\n    Validates the presence of comments if supported by the model.\n\n    Args:\n        v (Any): The comments field value.\n\n    Returns:\n        Any: Validated comments field value.\n    \"\"\"\n    if not cls._supports_comments() and v is not None:\n        logging.warning(f\"Dropped unsupported comments from {cls.__name__} init.\")\n        v = None\n    return v\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.get_list_delimiter","title":"<code>get_list_delimiter()</code>  <code>classmethod</code>","text":"<p>List delimiter string that will be used for serializing list field values for any IniBasedModel, if that field has no custom list delimiter.</p> <p>This function should be overridden by any subclass for a particular filetype that needs a specific/different list separator.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@classmethod\ndef get_list_delimiter(cls) -&gt; str:\n    \"\"\"List delimiter string that will be used for serializing\n    list field values for any IniBasedModel, **if** that field has\n    no custom list delimiter.\n\n    This function should be overridden by any subclass for a particular\n    filetype that needs a specific/different list separator.\n    \"\"\"\n    return \" \"\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.get_list_field_delimiter","title":"<code>get_list_field_delimiter(field_key)</code>  <code>classmethod</code>","text":"<p>List delimiter string that will be used for serializing the given field's value. The returned delimiter is either the field's custom list delimiter if that was specified using Field(.., delimiter=\"..\"), or the default list delimiter for the model class that this field belongs to.</p> <p>Parameters:</p> Name Type Description Default <code>field_key</code> <code>str</code> <p>the original field key (not its alias).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the delimiter string to be used for serializing the given field.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@classmethod\ndef get_list_field_delimiter(cls, field_key: str) -&gt; str:\n    \"\"\"List delimiter string that will be used for serializing\n    the given field's value.\n    The returned delimiter is either the field's custom list delimiter\n    if that was specified using Field(.., delimiter=\"..\"), or the\n    default list delimiter for the model class that this field belongs\n    to.\n\n    Args:\n        field_key (str): the original field key (not its alias).\n\n    Returns:\n        str: the delimiter string to be used for serializing the given field.\n    \"\"\"\n    delimiter = None\n    if (field := cls.__fields__.get(field_key)) and isinstance(field, ModelField):\n        delimiter = field.field_info.extra.get(\"delimiter\")\n    if not delimiter:\n        delimiter = cls.get_list_delimiter()\n\n    return delimiter\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.replace_fortran_scientific_notation_for_floats","title":"<code>replace_fortran_scientific_notation_for_floats(value, field)</code>","text":"<p>Converts FORTRAN-style scientific notation to standard notation for float fields.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The field value to process.</p> required <code>field</code> <code>Field</code> <p>The field being processed.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>The processed field value.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@validator(\"*\", pre=True, allow_reuse=True)\ndef replace_fortran_scientific_notation_for_floats(cls, value, field):\n    \"\"\"\n    Converts FORTRAN-style scientific notation to standard notation for float fields.\n\n    Args:\n        value (Any): The field value to process.\n        field (Field): The field being processed.\n\n    Returns:\n        Any: The processed field value.\n    \"\"\"\n    if field.type_ != float:\n        return value\n\n    return cls._replace_fortran_scientific_notation(value)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIBasedModel.validate","title":"<code>validate(value)</code>  <code>classmethod</code>","text":"<p>Validates a value as an instance of INIBasedModel.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to validate.</p> required <p>Returns:</p> Name Type Description <code>INIBasedModel</code> <code>INIBasedModel</code> <p>The validated instance.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>@classmethod\ndef validate(cls: Type[\"INIBasedModel\"], value: Any) -&gt; \"INIBasedModel\":\n    \"\"\"\n    Validates a value as an instance of INIBasedModel.\n\n    Args:\n        value (Any): The value to validate.\n\n    Returns:\n        INIBasedModel: The validated instance.\n    \"\"\"\n    if isinstance(value, Section):\n        value = value.flatten(\n            cls._duplicate_keys_as_list(), cls._supports_comments()\n        )\n\n    return super().validate(value)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.models.INIModel","title":"<code>INIModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>INI Model representation of a *.ini file.</p> <p>Typically subclasses will implement the various sorts of ini files, specifically for their fileType/contents. Child elements of this class associated with chapters/blocks in the ini file will be (sub)class of INIBasedModel.</p> Source code in <code>hydrolib/core/dflowfm/ini/models.py</code> <pre><code>class INIModel(ParsableFileModel):\n    \"\"\"INI Model representation of a *.ini file.\n\n    Typically subclasses will implement the various sorts of ini files,\n    specifically for their fileType/contents.\n    Child elements of this class associated with chapters/blocks in the\n    ini file will be (sub)class of INIBasedModel.\n    \"\"\"\n\n    serializer_config: INISerializerConfig = INISerializerConfig()\n\n    general: INIGeneral\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ini\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"fm\"\n\n    @classmethod\n    def _get_serializer(cls):\n        pass  # unused in favor of direct _serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return Parser.parse_as_dict\n\n    def _to_document(self, save_settings: ModelSaveSettings) -&gt; Document:\n        header = CommentBlock(lines=[f\"written by HYDROLIB-core {version}\"])\n        sections = []\n        for key, value in self:\n            if key in self._exclude_fields() or value is None:\n                continue\n            if save_settings._exclude_unset and key not in self.__fields_set__:\n                continue\n            if isinstance(value, list):\n                for v in value:\n                    sections.append(\n                        v._to_section(self.serializer_config, save_settings)\n                    )\n            else:\n                sections.append(\n                    value._to_section(self.serializer_config, save_settings)\n                )\n        return Document(header_comment=[header], sections=sections)\n\n    def _serialize(self, _: dict, save_settings: ModelSaveSettings) -&gt; None:\n        \"\"\"\n        Create a `Document` from the model and write it to the file.\n        \"\"\"\n        write_ini(\n            self._resolved_filepath,\n            self._to_document(save_settings),\n            config=self.serializer_config,\n        )\n</code></pre>"},{"location":"reference/ini/#parser","title":"Parser","text":""},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser","title":"<code>Parser</code>","text":"<p>Parser defines a generic Parser for Deltares ini files.</p> <p>The Parser can be configured with a ParserConfig object.</p> Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>class Parser:\n    \"\"\"Parser defines a generic Parser for Deltares ini files.\n\n    The Parser can be configured with a ParserConfig object.\n    \"\"\"\n\n    class _StateType(IntEnum):\n        NO_SECTION_FOUND = 0\n        PARSING_PROPERTIES = 1\n        PARSING_DATABLOCK = 2\n\n    def __init__(self, config: ParserConfig) -&gt; None:\n        \"\"\"Creates a new Parser configured with the provided config\n\n        Args:\n            config (ParserConfig): The configuration of this Parser\n        \"\"\"\n        self._config = config\n        self._document = Document()\n        self._current_section: Optional[_IntermediateSection] = None\n        self._current_header_block: Optional[_IntermediateCommentBlock] = None\n\n        self._state = self._StateType.NO_SECTION_FOUND\n        self._line_index = 0\n\n        # TODO add invalid blocks\n        self._feed_line: Dict[\n            Parser._StateType, List[Tuple[Callable[[str], bool], Callable[[str], None]]]\n        ] = {\n            Parser._StateType.NO_SECTION_FOUND: [\n                (self._is_comment, self._handle_header_comment),\n                (self._is_section_header, self._handle_next_section_header),\n            ],\n            Parser._StateType.PARSING_PROPERTIES: [\n                (self._is_comment, self._handle_section_comment),\n                (self._is_section_header, self._handle_next_section_header),\n                (self._is_property, self._handle_property),\n                (self._is_datarow, self._handle_new_datarow),\n            ],\n            Parser._StateType.PARSING_DATABLOCK: [\n                (self._is_section_header, self._handle_next_section_header),\n                (self._is_datarow, self._handle_datarow),\n            ],\n        }\n\n        self._handle_emptyline: Dict[Parser._StateType, Callable[[], None]] = {\n            self._StateType.NO_SECTION_FOUND: self._finish_current_header_block,\n            self._StateType.PARSING_PROPERTIES: self._noop,\n            self._StateType.PARSING_DATABLOCK: self._noop,\n        }\n\n    def feed_line(self, line: str) -&gt; None:\n        \"\"\"Parse the next line with this Parser.\n\n        Args:\n            line (str): The line to parse\n        \"\"\"\n        if not self._is_empty_line(line):\n            for is_line_type, handle_line_type in self._feed_line[self._state]:\n                if is_line_type(line):\n                    handle_line_type(line)\n                    break\n            else:\n                # handle exception\n                pass\n        else:\n            self._handle_emptyline[self._state]()\n\n        self._increment_line()\n\n    def finalize(self) -&gt; Document:\n        \"\"\"Finalize parsing and return the constructed Document.\n\n        Returns:\n            Document:\n                A Document describing the parsed ini file.\n        \"\"\"\n        # TODO handle invalid block\n        self._finish_current_header_block()\n        self._finalise_current_section()\n        return self._document\n\n    def _increment_line(self) -&gt; None:\n        self._line_index += 1\n\n    def _handle_next_section_header(self, line: str) -&gt; None:\n        self._finalise_current_section()\n        self._handle_new_section_header(line)\n\n        self._state = Parser._StateType.PARSING_PROPERTIES\n\n    def _handle_new_section_header(self, line: str) -&gt; None:\n        section_header = line.strip()[1:-1].strip()\n        self._current_section = _IntermediateSection(\n            header=section_header, start_line=self._line_index\n        )\n\n    def _finalise_current_section(self) -&gt; None:\n        if self._current_section is not None:\n            self._document.sections.append(self._current_section.finalize())\n\n    def _handle_header_comment(self, line: str) -&gt; None:\n        if self._current_header_block is None:\n            self._current_header_block = _IntermediateCommentBlock(\n                start_line=self._line_index\n            )\n\n        comment = self._convert_to_comment(line)\n        self._current_header_block.add_comment_line(comment)\n\n    def _handle_section_comment(self, line: str) -&gt; None:\n        comment = self._convert_to_comment(line)\n        self._current_section.add_comment(comment, self._line_index)  # type: ignore\n\n    def _handle_property(self, line: str) -&gt; None:\n        key, valuepart = self._retrieve_key_value(line)\n        if valuepart is not None:\n            comment, value = self._retrieve_property_comment(valuepart.strip())\n        else:\n            comment, value = None, None\n\n        prop = Property(key=key, value=value, comment=comment)\n        self._current_section.add_property(prop)  # type: ignore\n\n    def _handle_new_datarow(self, line: str) -&gt; None:\n        self._handle_datarow(line)\n        self._state = Parser._StateType.PARSING_DATABLOCK\n\n    def _handle_datarow(self, line: str) -&gt; None:\n        self._current_section.add_datarow(line.split())  # type: ignore\n\n    def _retrieve_property_comment(self, line: str) -&gt; Tuple[Optional[str], str]:\n        \"\"\"Retrieve the comment and value part from the valuestring of a key-value pair.\n\n        The comment retrieval is complicated by the fact that in the Deltares-INI\n        dialect, the comment delimiter '#' plays a double role: it may also be used\n        to quote string values (for example if the contain spaces).\n\n        Example lines that are supported:\n        key = valueAndNoComment\n        key = valueA  # and a simple comment\n        key = #valueA with possible spaces#\n        key = #valueA#  # and a simple comment\n        key = #valueA# # and a complicated comment with hashes #1 example\n        key = value # and a complicated comment with hashes #2.\n\n        Keywords arguments:\n            line (str) -- the partial string of the line containing both value and\n                possibly a comment at the end. Note that the \"key =\" part must already\n                have been split off, for example by _retrieve_key_value\n\n        Returns:\n            Tuple with the comment and string value, respectively. If no comment is\n            present, the first tuple element is None.\n        \"\"\"\n\n        if self._config.parse_comments and self._config.comment_delimiter in line:\n            line = line.strip()\n            parts = line.split(self._config.comment_delimiter)\n            numhash = line.count(self._config.comment_delimiter)\n            if numhash == 1:\n                # normal value, simple comment: \"key =  somevalue # and a comment \"\n                comment = parts[-1]\n                value = parts[0]\n            elif line.startswith(self._config.comment_delimiter):\n                # hashed value, possible with comment: \"key = #somevalue# ...\"\n                comment = (\n                    self._config.comment_delimiter.join(parts[3:])\n                    if numhash &gt;= 3\n                    else \"\"\n                )\n\n                value = self._config.comment_delimiter.join(parts[0:3])\n            else:\n                # normal value, comment with maybe more hashes: \"key = somevalue #This is comment #2, or two \"\n                comment = self._config.comment_delimiter.join(parts[1:])\n                value = parts[0]\n        else:\n            comment = \"\"\n            value = line\n\n        return (\n            comment if len(comment := comment.strip()) &gt; 0 else None,\n            value if len(value := value.strip()) &gt; 0 else None,\n        )\n\n    def _retrieve_key_value(self, line: str) -&gt; Tuple[str, Optional[str]]:\n        if \"=\" in line:\n            key, value = line.split(\"=\", 1)\n            return key.strip(), value if len(value := value.strip()) &gt; 0 else None\n        else:\n            # if no = exists, due to the previous check we know it will just be a\n            # single value\n            return line, None\n\n    def _finish_current_header_block(self) -&gt; None:\n        if self._current_header_block is not None:\n            self._document.header_comment.append(self._current_header_block.finalize())\n            self._current_header_block = None\n\n    def _noop(self, *_, **__) -&gt; None:\n        # no operation\n        pass\n\n    def _is_empty_line(self, line: str) -&gt; bool:\n        return len(line.strip()) == 0\n\n    def _is_comment(self, line: str) -&gt; bool:\n        return line.strip().startswith(self._config.comment_delimiter)\n\n    def _convert_to_comment(self, line: str) -&gt; str:\n        return line.strip()[1:].strip()\n\n    def _is_section_header(self, line: str) -&gt; bool:\n        # a header is defined as \"[ any-value ]\"\n        stripped = line.strip()\n        return stripped.startswith(\"[\") and stripped.endswith(\"]\")\n\n    def _is_property(self, line: str) -&gt; bool:\n        # we assume that we already checked wether it is a comment or\n        # a section header.\n        return self._config.allow_only_keywords or \"=\" in line\n\n    def _is_datarow(self, _: str) -&gt; bool:\n        # we assume that we already checked whether it is either a comment,\n        # section header or a property\n        return self._config.parse_datablocks\n\n    @classmethod\n    def parse_as_dict(cls, filepath: Path, config: ParserConfig = None) -&gt; dict:\n        \"\"\"\n        Parses an INI file without a specific model type and returns it as a dictionary.\n\n        Args:\n            filepath (Path): File path to the INI-format file.\n            config (ParserConfig, optional): Parser configuration to use. Defaults to None.\n\n        Returns:\n            dict: Representation of the parsed INI-file.\n        \"\"\"\n        return cls.parse(filepath, config).flatten()\n\n    @classmethod\n    def parse(cls, filepath: Path, config: ParserConfig = None) -&gt; Document:\n        \"\"\"\n        Parses an INI file without a specific model type and returns it as a Document.\n\n        Args:\n            filepath (Path): File path to the INI-format file.\n            config (ParserConfig, optional): Parser configuration to use. Defaults to None.\n\n        Returns:\n            Document: Representation of the parsed INI-file.\n        \"\"\"\n        if not config:\n            config = ParserConfig()\n        parser = cls(config)\n\n        with filepath.open(encoding=\"utf8\") as f:\n            for line in f:\n                parser.feed_line(line)\n\n        return parser.finalize()\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser.__init__","title":"<code>__init__(config)</code>","text":"<p>Creates a new Parser configured with the provided config</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ParserConfig</code> <p>The configuration of this Parser</p> required Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>def __init__(self, config: ParserConfig) -&gt; None:\n    \"\"\"Creates a new Parser configured with the provided config\n\n    Args:\n        config (ParserConfig): The configuration of this Parser\n    \"\"\"\n    self._config = config\n    self._document = Document()\n    self._current_section: Optional[_IntermediateSection] = None\n    self._current_header_block: Optional[_IntermediateCommentBlock] = None\n\n    self._state = self._StateType.NO_SECTION_FOUND\n    self._line_index = 0\n\n    # TODO add invalid blocks\n    self._feed_line: Dict[\n        Parser._StateType, List[Tuple[Callable[[str], bool], Callable[[str], None]]]\n    ] = {\n        Parser._StateType.NO_SECTION_FOUND: [\n            (self._is_comment, self._handle_header_comment),\n            (self._is_section_header, self._handle_next_section_header),\n        ],\n        Parser._StateType.PARSING_PROPERTIES: [\n            (self._is_comment, self._handle_section_comment),\n            (self._is_section_header, self._handle_next_section_header),\n            (self._is_property, self._handle_property),\n            (self._is_datarow, self._handle_new_datarow),\n        ],\n        Parser._StateType.PARSING_DATABLOCK: [\n            (self._is_section_header, self._handle_next_section_header),\n            (self._is_datarow, self._handle_datarow),\n        ],\n    }\n\n    self._handle_emptyline: Dict[Parser._StateType, Callable[[], None]] = {\n        self._StateType.NO_SECTION_FOUND: self._finish_current_header_block,\n        self._StateType.PARSING_PROPERTIES: self._noop,\n        self._StateType.PARSING_DATABLOCK: self._noop,\n    }\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser.feed_line","title":"<code>feed_line(line)</code>","text":"<p>Parse the next line with this Parser.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The line to parse</p> required Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>def feed_line(self, line: str) -&gt; None:\n    \"\"\"Parse the next line with this Parser.\n\n    Args:\n        line (str): The line to parse\n    \"\"\"\n    if not self._is_empty_line(line):\n        for is_line_type, handle_line_type in self._feed_line[self._state]:\n            if is_line_type(line):\n                handle_line_type(line)\n                break\n        else:\n            # handle exception\n            pass\n    else:\n        self._handle_emptyline[self._state]()\n\n    self._increment_line()\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser.finalize","title":"<code>finalize()</code>","text":"<p>Finalize parsing and return the constructed Document.</p> <p>Returns:</p> Name Type Description <code>Document</code> <code>Document</code> <p>A Document describing the parsed ini file.</p> Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>def finalize(self) -&gt; Document:\n    \"\"\"Finalize parsing and return the constructed Document.\n\n    Returns:\n        Document:\n            A Document describing the parsed ini file.\n    \"\"\"\n    # TODO handle invalid block\n    self._finish_current_header_block()\n    self._finalise_current_section()\n    return self._document\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser.parse","title":"<code>parse(filepath, config=None)</code>  <code>classmethod</code>","text":"<p>Parses an INI file without a specific model type and returns it as a Document.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>File path to the INI-format file.</p> required <code>config</code> <code>ParserConfig</code> <p>Parser configuration to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Document</code> <code>Document</code> <p>Representation of the parsed INI-file.</p> Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>@classmethod\ndef parse(cls, filepath: Path, config: ParserConfig = None) -&gt; Document:\n    \"\"\"\n    Parses an INI file without a specific model type and returns it as a Document.\n\n    Args:\n        filepath (Path): File path to the INI-format file.\n        config (ParserConfig, optional): Parser configuration to use. Defaults to None.\n\n    Returns:\n        Document: Representation of the parsed INI-file.\n    \"\"\"\n    if not config:\n        config = ParserConfig()\n    parser = cls(config)\n\n    with filepath.open(encoding=\"utf8\") as f:\n        for line in f:\n            parser.feed_line(line)\n\n    return parser.finalize()\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.Parser.parse_as_dict","title":"<code>parse_as_dict(filepath, config=None)</code>  <code>classmethod</code>","text":"<p>Parses an INI file without a specific model type and returns it as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>File path to the INI-format file.</p> required <code>config</code> <code>ParserConfig</code> <p>Parser configuration to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Representation of the parsed INI-file.</p> Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>@classmethod\ndef parse_as_dict(cls, filepath: Path, config: ParserConfig = None) -&gt; dict:\n    \"\"\"\n    Parses an INI file without a specific model type and returns it as a dictionary.\n\n    Args:\n        filepath (Path): File path to the INI-format file.\n        config (ParserConfig, optional): Parser configuration to use. Defaults to None.\n\n    Returns:\n        dict: Representation of the parsed INI-file.\n    \"\"\"\n    return cls.parse(filepath, config).flatten()\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.parser.ParserConfig","title":"<code>ParserConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>ParserConfig defines the configuration options of the Parser</p> <p>Note that we cannot set both allow_only_keywords and parse_datablocks to True because we cannot distinguish between datablocks and key only properties. As such this will lead to a validation error.</p> <p>Attributes:</p> Name Type Description <code>allow_only_keywords</code> <code>bool</code> <p>Whether to allow properties with only keys (no '=' or value). Defaults to False.</p> <code>parse_datablocks</code> <code>bool</code> <p>Whether to allow parsing of datablocks at the bottom of sections. Defaults to False.</p> <code>parse_comments</code> <code>bool</code> <p>Whether we allow parsing of comments defined with the comment_delimeter. Defaults to True.</p> <code>comment_delimiter</code> <code>str</code> <p>The character or sequence of character used to define a comment. Defaults to '#'.</p> Source code in <code>hydrolib/core/dflowfm/ini/parser.py</code> <pre><code>class ParserConfig(BaseModel):\n    \"\"\"ParserConfig defines the configuration options of the Parser\n\n    Note that we cannot set both allow_only_keywords and parse_datablocks to True\n    because we cannot distinguish between datablocks and key only properties. As\n    such this will lead to a validation error.\n\n    Attributes:\n        allow_only_keywords (bool):\n            Whether to allow properties with only keys (no '=' or value).\n            Defaults to False.\n        parse_datablocks (bool):\n            Whether to allow parsing of datablocks at the bottom of sections.\n            Defaults to False.\n        parse_comments (bool):\n            Whether we allow parsing of comments defined with the comment_delimeter.\n            Defaults to True.\n        comment_delimiter (str):\n            The character or sequence of character used to define a comment.\n            Defaults to '#'.\n    \"\"\"\n\n    allow_only_keywords: bool = False\n    parse_datablocks: bool = False\n    parse_comments: bool = True\n    comment_delimiter: str = \"#\"\n\n    @validator(\"parse_datablocks\")\n    def allow_only_keywods_and_parse_datablocks_leads_should_not_both_be_true(\n        cls, parse_datablocks, values\n    ):\n        # if both allow_only_keywords and parse_datablocks is true, we cannot\n        # distinguish between the two, and the parsing will not recognise either\n        # properly\n        if (\n            parse_datablocks\n            and \"allow_only_keywords\" in values\n            and values[\"allow_only_keywords\"]\n        ):\n            raise ValueError(\n                \"Both parse_datablocks and allow_only_keywords should not be both True.\"\n            )\n        return parse_datablocks\n</code></pre>"},{"location":"reference/ini/#serializer","title":"Serializer","text":""},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.DataBlockINIBasedSerializerConfig","title":"<code>DataBlockINIBasedSerializerConfig</code>","text":"<p>               Bases: <code>INISerializerConfig</code></p> <p>Class that holds the configuration settings for INI files with data blocks serialization.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>class DataBlockINIBasedSerializerConfig(INISerializerConfig):\n    \"\"\"Class that holds the configuration settings for INI files with data blocks serialization.\"\"\"\n\n    float_format_datablock: str = \"\"\n    \"\"\"str: The string format that will be used for float serialization of the datablock. If empty, the original number will be serialized. Defaults to an empty string.\n\n    Examples:\n        Input value = 123.456\n\n        Format    | Output          | Description\n        -------------------------------------------------------------------------------------------------------------------------------------\n        \".0f\"     | 123             | Format float with 0 decimal places.\n        \"f\"       | 123.456000      | Format float with default (=6) decimal places.\n        \".2f\"     | 123.46          | Format float with 2 decimal places.\n        \"+.1f\"    | +123.5          | Format float with 1 decimal place with a + or  sign.\n        \"e\"       | 1.234560e+02    | Format scientific notation with the letter 'e' with default (=6) decimal places.\n        \"E\"       | 1.234560E+02    | Format scientific notation with the letter 'E' with default (=6) decimal places.\n        \".3e\"     | 1.235e+02       | Format scientific notation with the letter 'e' with 3 decimal places.\n        \"&lt;15\"     | 123.456         | Left aligned in space with width 15\n        \"^15.0f\"  |       123       | Center aligned in space with width 15 with 0 decimal places.\n        \"&gt;15.1e\"  |         1.2e+02 | Right aligned in space with width 15 with scientific notation with 1 decimal place.\n        \"*&gt;15.1f\" | **********123.5 | Right aligned in space with width 15 with 1 decimal place and fill empty space with *\n        \"%\"       | 12345.600000%   | Format percentage with default (=6) decimal places.     \n        \".3%\"     | 12345.600%      | Format percentage with 3 decimal places.  \n\n        More information: https://docs.python.org/3/library/string.html#format-specification-mini-language\n    \"\"\"\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.DataBlockINIBasedSerializerConfig.float_format_datablock","title":"<code>float_format_datablock = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: The string format that will be used for float serialization of the datablock. If empty, the original number will be serialized. Defaults to an empty string.</p> <p>Examples:</p> <p>Input value = 123.456</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.DataBlockINIBasedSerializerConfig.float_format_datablock--format-output-description","title":"Format    | Output          | Description","text":"<p>\".0f\"     | 123             | Format float with 0 decimal places. \"f\"       | 123.456000      | Format float with default (=6) decimal places. \".2f\"     | 123.46          | Format float with 2 decimal places. \"+.1f\"    | +123.5          | Format float with 1 decimal place with a + or  sign. \"e\"       | 1.234560e+02    | Format scientific notation with the letter 'e' with default (=6) decimal places. \"E\"       | 1.234560E+02    | Format scientific notation with the letter 'E' with default (=6) decimal places. \".3e\"     | 1.235e+02       | Format scientific notation with the letter 'e' with 3 decimal places. \"&lt;15\"     | 123.456         | Left aligned in space with width 15 \"^15.0f\"  |       123       | Center aligned in space with width 15 with 0 decimal places. \"&gt;15.1e\"  |         1.2e+02 | Right aligned in space with width 15 with scientific notation with 1 decimal place. \"&gt;15.1f\" | ***123.5 | Right aligned in space with width 15 with 1 decimal place and fill empty space with * \"%\"       | 12345.600000%   | Format percentage with default (=6) decimal places.    \".3%\"     | 12345.600%      | Format percentage with 3 decimal places.  </p> <p>More information: https://docs.python.org/3/library/string.html#format-specification-mini-language</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.INISerializerConfig","title":"<code>INISerializerConfig</code>","text":"<p>               Bases: <code>SerializerConfig</code></p> <p>SerializerConfig defines the configuration options of the Serializer</p> <p>Attributes:</p> Name Type Description <code>section_indent</code> <code>int</code> <p>The number of spaces with which whole sections should be indented. Defaults to 0.</p> <code>property_indent</code> <code>int</code> <p>The number of spaces with which properties should be indented relative to the section header (i.e. the full indent equals the section_indent plus property_indent). Defaults to 4.</p> <code>datablock_indent</code> <code>int</code> <p>The number of spaces with which datablock rows are indented relative to the section header (i.e. the full indent equals the section_indent plus datablock_indent). Defaults to 8.</p> <code>datablock_spacing</code> <code>int</code> <p>The number of spaces between datablock columns. Note that there might be additional offset to ensure . is lined out. Defaults to 2.</p> <code>comment_delimiter</code> <code>str</code> <p>The character used to delimit comments. Defaults to '#'.</p> <code>skip_empty_properties</code> <code>bool</code> <p>Whether or not to skip properties with a value that is empty or None. Defaults to True.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>class INISerializerConfig(SerializerConfig):\n    \"\"\"SerializerConfig defines the configuration options of the Serializer\n\n    Attributes:\n        section_indent (int):\n            The number of spaces with which whole sections should be indented.\n            Defaults to 0.\n        property_indent (int):\n            The number of spaces with which properties should be indented relative to\n            the section header (i.e. the full indent equals the section_indent plus\n            property_indent). Defaults to 4.\n        datablock_indent (int):\n            The number of spaces with which datablock rows are indented relative to\n            the section header (i.e. the full indent equals the section_indent plus\n            datablock_indent). Defaults to 8.\n        datablock_spacing (int):\n            The number of spaces between datablock columns. Note that there might be\n            additional offset to ensure . is lined out. Defaults to 2.\n        comment_delimiter (str):\n            The character used to delimit comments. Defaults to '#'.\n        skip_empty_properties (bool):\n            Whether or not to skip properties with a value that is empty or None. Defaults to True.\n    \"\"\"\n\n    section_indent: int = 0\n    property_indent: int = 0\n    datablock_indent: int = 8\n    datablock_spacing: int = 2\n    comment_delimiter: str = \"#\"\n    skip_empty_properties: bool = True\n\n    @property\n    def total_property_indent(self) -&gt; int:\n        \"\"\"The combined property indentation, i.e. section_indent + property_indent\"\"\"\n        return self.section_indent + self.property_indent\n\n    @property\n    def total_datablock_indent(self) -&gt; int:\n        \"\"\"The combined datablock indentation, i.e. section_indent + datablock_indent\"\"\"\n        return self.section_indent + self.datablock_indent\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.INISerializerConfig.total_datablock_indent","title":"<code>total_datablock_indent</code>  <code>property</code>","text":"<p>The combined datablock indentation, i.e. section_indent + datablock_indent</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.INISerializerConfig.total_property_indent","title":"<code>total_property_indent</code>  <code>property</code>","text":"<p>The combined property indentation, i.e. section_indent + property_indent</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.MaxLengths","title":"<code>MaxLengths</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>MaxLengths defines the maxmimum lengths of the parts of a section</p> <p>Attributes:</p> Name Type Description <code>key</code> <code>int</code> <p>The maximum length of all the keys of the properties within a section. If no properties are present it should be 0.</p> <code>value</code> <code>int</code> <p>The maximum length of all the non None values of the properties within a section. If no properties are present, or all values are None, it should be 0.</p> <code>datablock</code> <code>Optional[Sequence[int]]</code> <p>The maximum length of the values of each column of the Datablock. If no datablock is present it defaults to None.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>class MaxLengths(BaseModel):\n    \"\"\"MaxLengths defines the maxmimum lengths of the parts of a section\n\n    Attributes:\n        key (int):\n            The maximum length of all the keys of the properties within a section.\n            If no properties are present it should be 0.\n        value (int):\n            The maximum length of all the non None values of the properties within a\n            section. If no properties are present, or all values are None, it should\n            be 0.\n        datablock (Optional[Sequence[int]]):\n            The maximum length of the values of each column of the Datablock.\n            If no datablock is present it defaults to None.\n    \"\"\"\n\n    key: int\n    value: int\n    datablock: Optional[Sequence[int]] = None\n\n    @classmethod\n    def from_section(cls, section: Section) -&gt; \"MaxLengths\":\n        \"\"\"Generate a MaxLengths instance from the given Section\n\n        Args:\n            section (Section): The section of which the MaxLengths are calculated\n\n        Returns:\n            MaxLengths: The MaxLengths corresponding with the provided section\n        \"\"\"\n        properties = list(p for p in section.content if isinstance(p, Property))\n\n        keys = (prop.key for prop in properties)\n        values = (prop.value for prop in properties if prop.value is not None)\n\n        max_key_length = max((len(k) for k in keys), default=0)\n        max_value_length = max((len(v) for v in values), default=0)\n        max_datablock_lengths = MaxLengths._of_datablock(section.datablock)\n\n        return cls(\n            key=max_key_length,\n            value=max_value_length,\n            datablock=max_datablock_lengths,\n        )\n\n    @staticmethod\n    def _of_datablock(datablock: Optional[Datablock]) -&gt; Optional[Sequence[int]]:\n        if datablock is None or len(datablock) &lt; 1:\n            return None\n\n        datablock_columns = map(list, zip(*datablock))\n        datablock_column_lengths = (map(len, column) for column in datablock_columns)  # type: ignore\n        max_lengths = (max(column) for column in datablock_column_lengths)\n\n        return tuple(max_lengths)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.MaxLengths.from_section","title":"<code>from_section(section)</code>  <code>classmethod</code>","text":"<p>Generate a MaxLengths instance from the given Section</p> <p>Parameters:</p> Name Type Description Default <code>section</code> <code>Section</code> <p>The section of which the MaxLengths are calculated</p> required <p>Returns:</p> Name Type Description <code>MaxLengths</code> <code>MaxLengths</code> <p>The MaxLengths corresponding with the provided section</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>@classmethod\ndef from_section(cls, section: Section) -&gt; \"MaxLengths\":\n    \"\"\"Generate a MaxLengths instance from the given Section\n\n    Args:\n        section (Section): The section of which the MaxLengths are calculated\n\n    Returns:\n        MaxLengths: The MaxLengths corresponding with the provided section\n    \"\"\"\n    properties = list(p for p in section.content if isinstance(p, Property))\n\n    keys = (prop.key for prop in properties)\n    values = (prop.value for prop in properties if prop.value is not None)\n\n    max_key_length = max((len(k) for k in keys), default=0)\n    max_value_length = max((len(v) for v in values), default=0)\n    max_datablock_lengths = MaxLengths._of_datablock(section.datablock)\n\n    return cls(\n        key=max_key_length,\n        value=max_value_length,\n        datablock=max_datablock_lengths,\n    )\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.SectionSerializer","title":"<code>SectionSerializer</code>","text":"<p>SectionSerializer provides the serialize method to serialize a Section</p> <p>The entrypoint of this method is the serialize method, which will construct an actual instance and serializes the Section with it.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>class SectionSerializer:\n    \"\"\"SectionSerializer provides the serialize method to serialize a Section\n\n    The entrypoint of this method is the serialize method, which will construct\n    an actual instance and serializes the Section with it.\n    \"\"\"\n\n    def __init__(self, config: INISerializerConfig, max_length: MaxLengths):\n        \"\"\"Create a new SectionSerializer\n\n        Args:\n            config (SerializerConfig): The config describing the serialization options\n            max_length (MaxLengths): The max lengths of the section being serialized\n        \"\"\"\n        self._config = config\n        self._max_length = max_length\n\n    @classmethod\n    def serialize(cls, section: Section, config: INISerializerConfig) -&gt; Lines:\n        \"\"\"Serialize the provided section with the given config\n\n        Args:\n            section (Section): The section to serialize\n            config (SerializerConfig): The config describing the serialization options\n\n        Returns:\n            Lines: The iterable lines of the serialized section\n        \"\"\"\n        serializer = cls(config, MaxLengths.from_section(section))\n        return serializer._serialize_section(section)\n\n    @property\n    def config(self) -&gt; INISerializerConfig:\n        \"\"\"The SerializerConfig used while serializing the section.\"\"\"\n        return self._config\n\n    @property\n    def max_length(self) -&gt; MaxLengths:\n        \"\"\"The MaxLengths of the Section being serialized by this SectionSerializer.\"\"\"\n        return self._max_length\n\n    def _serialize_section(self, section: Section) -&gt; Lines:\n        header_iterable = self._serialize_section_header(section.header)\n        properties = self._serialize_content(section.content)\n        datablock = self._serialize_datablock(section.datablock)\n\n        return chain(header_iterable, properties, datablock)\n\n    def _serialize_section_header(self, section_header: str) -&gt; Lines:\n        indent = \" \" * (self.config.section_indent)\n        yield f\"{indent}[{section_header}]\"\n\n    def _serialize_content(self, content: Iterable[ContentElement]) -&gt; Lines:\n        elements = (self._serialize_content_element(elem) for elem in content)\n        return chain.from_iterable(elements)\n\n    def _serialize_content_element(self, elem: ContentElement) -&gt; Lines:\n        if isinstance(elem, Property):\n            return self._serialize_property(elem)\n        else:\n            indent = self.config.total_property_indent\n            delimiter = self.config.comment_delimiter\n            return _serialize_comment_block(elem, delimiter, indent)\n\n    def _serialize_property(self, property: Property) -&gt; Lines:\n        if self.config.skip_empty_properties and str_is_empty_or_none(property.value):\n            return\n\n        indent = \" \" * (self._config.total_property_indent)\n        key_ws = _get_offset_whitespace(property.key, self.max_length.key)\n        key = f\"{property.key}{key_ws} = \"\n\n        value_ws = _get_offset_whitespace(property.value, self.max_length.value)\n\n        if property.value is not None:\n            value = f\"{property.value}{value_ws}\"\n        else:\n            value = value_ws\n\n        comment = (\n            f\" # {property.comment}\"\n            if not str_is_empty_or_none(property.comment)\n            else \"\"\n        )\n\n        yield f\"{indent}{key}{value}{comment}\".rstrip()\n\n    def _serialize_datablock(self, datablock: Optional[Datablock]) -&gt; Lines:\n        if datablock is None or self.max_length.datablock is None:\n            return []\n\n        indent = \" \" * self._config.total_datablock_indent\n        return (self._serialize_row(row, indent) for row in datablock)\n\n    def _serialize_row(self, row: DatablockRow, indent: str) -&gt; str:\n        elem_spacing = \" \" * self.config.datablock_spacing\n        elems = (self._serialize_row_element(elem, i) for elem, i in zip(row, count()))\n\n        return indent + elem_spacing.join(elems).rstrip()\n\n    def _serialize_row_element(self, elem: str, index: int) -&gt; str:\n        max_length = self.max_length.datablock[index]  # type: ignore\n        whitespace = _get_offset_whitespace(elem, max_length)\n        return elem + whitespace\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.SectionSerializer.config","title":"<code>config</code>  <code>property</code>","text":"<p>The SerializerConfig used while serializing the section.</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.SectionSerializer.max_length","title":"<code>max_length</code>  <code>property</code>","text":"<p>The MaxLengths of the Section being serialized by this SectionSerializer.</p>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.SectionSerializer.__init__","title":"<code>__init__(config, max_length)</code>","text":"<p>Create a new SectionSerializer</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SerializerConfig</code> <p>The config describing the serialization options</p> required <code>max_length</code> <code>MaxLengths</code> <p>The max lengths of the section being serialized</p> required Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>def __init__(self, config: INISerializerConfig, max_length: MaxLengths):\n    \"\"\"Create a new SectionSerializer\n\n    Args:\n        config (SerializerConfig): The config describing the serialization options\n        max_length (MaxLengths): The max lengths of the section being serialized\n    \"\"\"\n    self._config = config\n    self._max_length = max_length\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.SectionSerializer.serialize","title":"<code>serialize(section, config)</code>  <code>classmethod</code>","text":"<p>Serialize the provided section with the given config</p> <p>Parameters:</p> Name Type Description Default <code>section</code> <code>Section</code> <p>The section to serialize</p> required <code>config</code> <code>SerializerConfig</code> <p>The config describing the serialization options</p> required <p>Returns:</p> Name Type Description <code>Lines</code> <code>Lines</code> <p>The iterable lines of the serialized section</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>@classmethod\ndef serialize(cls, section: Section, config: INISerializerConfig) -&gt; Lines:\n    \"\"\"Serialize the provided section with the given config\n\n    Args:\n        section (Section): The section to serialize\n        config (SerializerConfig): The config describing the serialization options\n\n    Returns:\n        Lines: The iterable lines of the serialized section\n    \"\"\"\n    serializer = cls(config, MaxLengths.from_section(section))\n    return serializer._serialize_section(section)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.Serializer","title":"<code>Serializer</code>","text":"<p>Serializer serializes Document to its corresponding lines.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>class Serializer:\n    \"\"\"Serializer serializes Document to its corresponding lines.\"\"\"\n\n    def __init__(self, config: INISerializerConfig):\n        \"\"\"Creates a new Serializer with the provided configuration.\n\n        Args:\n            config (SerializerConfig): The configuration of this Serializer.\n        \"\"\"\n        self._config = config\n\n    def serialize(self, document: Document) -&gt; Lines:\n        \"\"\"Serialize the provided document into an iterable of lines.\n\n        Args:\n            document (Document): The Document to serialize.\n\n        Returns:\n            Lines: An iterable returning each line of the serialized Document.\n        \"\"\"\n        header_iterable = self._serialize_document_header(document.header_comment)\n\n        serialize_section = lambda s: SectionSerializer.serialize(s, self._config)\n        sections = (serialize_section(section) for section in document.sections)\n        sections_with_spacing = Serializer._interweave(sections, [\"\"])\n        sections_iterable = chain.from_iterable(sections_with_spacing)\n\n        return chain(header_iterable, sections_iterable)\n\n    def _serialize_document_header(self, header: Iterable[CommentBlock]) -&gt; Lines:\n        delimiter = self._config.comment_delimiter\n        serialize = lambda cb: _serialize_comment_block(cb, delimiter)\n        blocks = (serialize(block) for block in header)\n        blocks_with_spacing = Serializer._interweave(blocks, [\"\"])\n\n        return chain.from_iterable(blocks_with_spacing)\n\n    @staticmethod\n    def _interweave(iterable: Iterable, val: Any) -&gt; Iterable:\n        # Interweave the provided iterable with the provided value:\n        # iterable_element, val, iterable_element, val, ...\n\n        # Note that this will interweave with val without making copies\n        # as such it is the same object being interweaved.\n        return chain.from_iterable(zip(iterable, repeat(val)))\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.Serializer.__init__","title":"<code>__init__(config)</code>","text":"<p>Creates a new Serializer with the provided configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SerializerConfig</code> <p>The configuration of this Serializer.</p> required Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>def __init__(self, config: INISerializerConfig):\n    \"\"\"Creates a new Serializer with the provided configuration.\n\n    Args:\n        config (SerializerConfig): The configuration of this Serializer.\n    \"\"\"\n    self._config = config\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.Serializer.serialize","title":"<code>serialize(document)</code>","text":"<p>Serialize the provided document into an iterable of lines.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>Document</code> <p>The Document to serialize.</p> required <p>Returns:</p> Name Type Description <code>Lines</code> <code>Lines</code> <p>An iterable returning each line of the serialized Document.</p> Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>def serialize(self, document: Document) -&gt; Lines:\n    \"\"\"Serialize the provided document into an iterable of lines.\n\n    Args:\n        document (Document): The Document to serialize.\n\n    Returns:\n        Lines: An iterable returning each line of the serialized Document.\n    \"\"\"\n    header_iterable = self._serialize_document_header(document.header_comment)\n\n    serialize_section = lambda s: SectionSerializer.serialize(s, self._config)\n    sections = (serialize_section(section) for section in document.sections)\n    sections_with_spacing = Serializer._interweave(sections, [\"\"])\n    sections_iterable = chain.from_iterable(sections_with_spacing)\n\n    return chain(header_iterable, sections_iterable)\n</code></pre>"},{"location":"reference/ini/#hydrolib.core.dflowfm.ini.serializer.write_ini","title":"<code>write_ini(path, document, config)</code>","text":"<p>Write the provided document to the specified path</p> <p>If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to which the document should be written.</p> required <code>document</code> <code>Document</code> <p>The document to serialize to the specified path.</p> required <code>config</code> <code>INISerializerConfig</code> <p>The configuration settings for the serializer.</p> required Source code in <code>hydrolib/core/dflowfm/ini/serializer.py</code> <pre><code>def write_ini(path: Path, document: Document, config: INISerializerConfig) -&gt; None:\n    \"\"\"Write the provided document to the specified path\n\n    If the provided path already exists, it will be overwritten. If the parent folder\n    do not exist, they will be created.\n\n    Args:\n        path (Path): The path to which the document should be written.\n        document (Document): The document to serialize to the specified path.\n        config (INISerializerConfig): The configuration settings for the serializer.\n    \"\"\"\n\n    serializer = Serializer(config)\n\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with path.open(\"w\", encoding=\"utf8\") as f:\n\n        for line in serializer.serialize(document):\n            f.write(line + \"\\n\")\n</code></pre>"},{"location":"reference/base/api/","title":"API","text":"<p>Much of HYDROLIB-core's classes that represent input data are based on <code>BaseModel</code> and <code>FileModel</code>. These build upon the pydantic package for data validation.</p>"},{"location":"reference/base/api/#basemodel-and-filemodel","title":"BaseModel and FileModel","text":"<p>Here we define our Pydantic <code>BaseModel</code> with custom settings, as well as a <code>FileModel</code> that inherits from a <code>BaseModel</code> but also represents a file on disk.</p>"},{"location":"reference/base/api/#hydrolib.core.base.models.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class BaseModel(PydanticBaseModel):\n    class Config:\n        arbitrary_types_allowed = True\n        validate_assignment = True\n        use_enum_values = True\n        extra = \"forbid\"  # will throw errors so we can fix our models\n        allow_population_by_field_name = True\n        alias_generator = to_key\n\n    def __init__(self, **data: Any) -&gt; None:\n        \"\"\"Initialize a BaseModel with the provided data.\n\n        Raises:\n            ValidationError: A validation error when the data is invalid.\n        \"\"\"\n        try:\n            super().__init__(**data)\n        except ValidationError as e:\n\n            # Give a special message for faulty list input\n            for re in e.raw_errors:\n                if (\n                    hasattr(re, \"_loc\")\n                    and hasattr(re.exc, \"msg_template\")\n                    and isinstance(data.get(to_key(re._loc)), list)\n                ):\n                    re.exc.msg_template += (\n                        f\". The key {re._loc} might be duplicated in the input file.\"\n                    )\n\n            # Update error with specific model location name\n            identifier = self._get_identifier(data)\n            if identifier is None:\n                raise e\n            else:\n                # If there is an identifier, include this in the ValidationError messages.\n                raise ValidationError([ErrorWrapper(e, loc=identifier)], self.__class__)\n\n    def is_file_link(self) -&gt; bool:\n        \"\"\"Generic attribute for models backed by a file.\"\"\"\n        return False\n\n    def is_intermediate_link(self) -&gt; bool:\n        \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\"\n        return self.is_file_link()\n\n    def show_tree(self, indent=0):\n        \"\"\"Recursive print function for showing a tree of a model.\"\"\"\n        angle = \"\u221f\" if indent &gt; 0 else \"\"\n\n        # Only print if we're backed by a file\n        if self.is_file_link():\n            print(\" \" * indent * 2, angle, self)\n\n        # Otherwise we recurse through the fields of a model\n        for _, value in self:\n            # Handle lists of items\n            if not isinstance(value, list):\n                value = [value]\n            for v in value:\n                if hasattr(v, \"is_intermediate_link\") and v.is_intermediate_link():\n                    # If the field is only an intermediate, print the name only\n                    if not v.is_file_link():\n                        print(\" \" * (indent * 2 + 2), angle, v.__class__.__name__)\n                    v.show_tree(indent + 1)\n\n    def _apply_recurse(self, f, *args, **kwargs):\n        # Could we use this function for `show_tree`?\n        for _, value in self:\n            # Handle lists of items\n            if not isinstance(value, list):\n                value = [value]\n            for v in value:\n                if hasattr(v, \"is_intermediate_link\") and v.is_intermediate_link():\n                    v._apply_recurse(f, *args, **kwargs)\n\n        # Run self as last, so we can make use of the nested updates\n        if self.is_file_link():\n            getattr(self, f)(*args, **kwargs)\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        \"\"\"Get the identifier for this model.\n\n        Args:\n            data (dict): The data from which to retrieve the identifier\n\n        Returns:\n            str: The identifier or None.\n        \"\"\"\n        return None\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.BaseModel.__init__","title":"<code>__init__(**data)</code>","text":"<p>Initialize a BaseModel with the provided data.</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>A validation error when the data is invalid.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def __init__(self, **data: Any) -&gt; None:\n    \"\"\"Initialize a BaseModel with the provided data.\n\n    Raises:\n        ValidationError: A validation error when the data is invalid.\n    \"\"\"\n    try:\n        super().__init__(**data)\n    except ValidationError as e:\n\n        # Give a special message for faulty list input\n        for re in e.raw_errors:\n            if (\n                hasattr(re, \"_loc\")\n                and hasattr(re.exc, \"msg_template\")\n                and isinstance(data.get(to_key(re._loc)), list)\n            ):\n                re.exc.msg_template += (\n                    f\". The key {re._loc} might be duplicated in the input file.\"\n                )\n\n        # Update error with specific model location name\n        identifier = self._get_identifier(data)\n        if identifier is None:\n            raise e\n        else:\n            # If there is an identifier, include this in the ValidationError messages.\n            raise ValidationError([ErrorWrapper(e, loc=identifier)], self.__class__)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.BaseModel.is_file_link","title":"<code>is_file_link()</code>","text":"<p>Generic attribute for models backed by a file.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def is_file_link(self) -&gt; bool:\n    \"\"\"Generic attribute for models backed by a file.\"\"\"\n    return False\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.BaseModel.is_intermediate_link","title":"<code>is_intermediate_link()</code>","text":"<p>Generic attribute for models that have children fields that could contain files.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def is_intermediate_link(self) -&gt; bool:\n    \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\"\n    return self.is_file_link()\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.BaseModel.show_tree","title":"<code>show_tree(indent=0)</code>","text":"<p>Recursive print function for showing a tree of a model.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def show_tree(self, indent=0):\n    \"\"\"Recursive print function for showing a tree of a model.\"\"\"\n    angle = \"\u221f\" if indent &gt; 0 else \"\"\n\n    # Only print if we're backed by a file\n    if self.is_file_link():\n        print(\" \" * indent * 2, angle, self)\n\n    # Otherwise we recurse through the fields of a model\n    for _, value in self:\n        # Handle lists of items\n        if not isinstance(value, list):\n            value = [value]\n        for v in value:\n            if hasattr(v, \"is_intermediate_link\") and v.is_intermediate_link():\n                # If the field is only an intermediate, print the name only\n                if not v.is_file_link():\n                    print(\" \" * (indent * 2 + 2), angle, v.__class__.__name__)\n                v.show_tree(indent + 1)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.DiskOnlyFileModel","title":"<code>DiskOnlyFileModel</code>","text":"<p>               Bases: <code>FileModel</code></p> <p>DiskOnlyFileModel provides a stub implementation for file based models which are not explicitly implemented within hydrolib.core.</p> <p>It implements the FileModel with a void parser and serializer, and a save method which copies the file associated with the FileModel to a new location if it exists.</p> <p>We further explicitly assume that when the filepath is None, no file will be written.</p> <p>Actual file model implementations should not inherit from the DiskOnlyFileModel and instead inherit directly from FileModel.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class DiskOnlyFileModel(FileModel):\n    \"\"\"DiskOnlyFileModel provides a stub implementation for file based\n    models which are not explicitly implemented within hydrolib.core.\n\n    It implements the FileModel with a void parser and serializer, and a\n    save method which copies the file associated with the FileModel\n    to a new location if it exists.\n\n    We further explicitly assume that when the filepath is None, no\n    file will be written.\n\n    Actual file model implementations *should not* inherit from the\n    DiskOnlyFileModel and instead inherit directly from FileModel.\n    \"\"\"\n\n    _source_file_path: Optional[Path] = PrivateAttr(default=None)\n\n    def _post_init_load(self) -&gt; None:\n        # After initialisation we retrieve the _resolved_filepath\n        # this should correspond with the actual absolute path of the\n        # underlying file. Only after saving this path will be updated.\n        super()._post_init_load()\n        self._source_file_path = self._resolved_filepath\n\n    def _load(self, filepath: Path) -&gt; Dict:\n        # We de not load any additional data, as such we return an empty dict.\n        return dict()\n\n    def _save(self, save_settings: ModelSaveSettings) -&gt; None:\n        # The target_file_path contains the new path to write to, while the\n        # _source_file_path contains the original data. If these are not the\n        # same we copy the file and update the underlying source path.\n        target_file_path = self._resolved_filepath\n        if self._can_copy_to(target_file_path):\n            target_file_path.parent.mkdir(parents=True, exist_ok=True)  # type: ignore[arg-type]\n            shutil.copy(self._source_file_path, target_file_path)  # type: ignore[arg-type]\n        self._source_file_path = target_file_path\n\n    def _can_copy_to(self, target_file_path: Optional[Path]) -&gt; bool:\n        return (\n            self._source_file_path is not None\n            and target_file_path is not None\n            and self._source_file_path != target_file_path\n            and self._source_file_path.exists()\n            and self._source_file_path.is_file()\n        )\n\n    @classmethod\n    def _generate_name(cls) -&gt; Optional[Path]:\n        # There is no common name for DiskOnlyFileModel, instead we\n        # do not generate names and skip None filepaths.\n        return None\n\n    def is_intermediate_link(self) -&gt; bool:\n        # If the filepath is not None, there is an underlying file, and as such we need\n        # to traverse it.\n        return self.filepath is not None\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel","title":"<code>FileModel</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base class to represent models with a file representation.</p> <p>It therefore always has a <code>filepath</code> and if it is given on initilization, it will parse that file. The filepath can be relative, in which case the paths are expected to be resolved relative to some root model. If a path is absolute, this path will always be used, regardless of a root parent.</p> <p>When saving a model, if the current filepath is relative, the last resolved absolute path will be used. If the model has just been read, the</p> <p>This class extends the <code>validate</code> option of Pydantic, so when when a Path is given to a field with type <code>FileModel</code>, it doesn't error, but actually initializes the <code>FileModel</code>.</p> <p>Attributes:</p> Name Type Description <code>filepath</code> <code>Optional[Path]</code> <p>The path of this FileModel. This path can be either absolute or relative. If it is a relative path, it is assumed to be resolved from some root model.</p> <code>save_location</code> <code>Path</code> <p>A readonly property corresponding with the (current) save location of this FileModel. If read from a file or after saving recursively or after calling synchronize_filepath, this value will be updated to its new state. If made from memory and filepath is not set, it will correspond with cwd / filename.extension</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class FileModel(BaseModel, ABC):\n    \"\"\"Base class to represent models with a file representation.\n\n    It therefore always has a `filepath` and if it is given on\n    initilization, it will parse that file. The filepath can be\n    relative, in which case the paths are expected to be resolved\n    relative to some root model. If a path is absolute, this path\n    will always be used, regardless of a root parent.\n\n    When saving a model, if the current filepath is relative, the\n    last resolved absolute path will be used. If the model has just\n    been read, the\n\n    This class extends the `validate` option of Pydantic,\n    so when when a Path is given to a field with type `FileModel`,\n    it doesn't error, but actually initializes the `FileModel`.\n\n    Attributes:\n        filepath (Optional[Path]):\n            The path of this FileModel. This path can be either absolute or relative.\n            If it is a relative path, it is assumed to be resolved from some root\n            model.\n        save_location (Path):\n            A readonly property corresponding with the (current) save location of this\n            FileModel. If read from a file or after saving recursively or\n            after calling synchronize_filepath, this value will be updated to its new\n            state. If made from memory and filepath is not set, it will correspond with\n            cwd / filename.extension\n    \"\"\"\n\n    __slots__ = [\"__weakref__\"]\n    # Use WeakValueDictionary to keep track of file paths with their respective parsed file models.\n    _file_models_cache: WeakValueDictionary = WeakValueDictionary()\n    filepath: Optional[Path] = None\n    # Absolute anchor is used to resolve the save location when the filepath is relative.\n    _absolute_anchor_path: Path = PrivateAttr(default_factory=Path.cwd)\n\n    def __new__(cls, filepath: Optional[PathOrStr] = None, *args, **kwargs):\n        \"\"\"Create a new model.\n        If the file at the provided file path was already parsed, this instance is returned.\n\n        Args:\n            filepath (Optional[PathOrStr], optional): The file path to the file. Defaults to None.\n\n        Returns:\n            FileModel: A file model.\n        \"\"\"\n        filepath = FileModel._change_to_path(filepath)\n        with file_load_context() as context:\n            if (file_model := context.retrieve_model(filepath)) is not None:\n                if not context.is_content_changed(filepath):\n                    cls._has_been_loaded_from_cache = True\n                    return file_model\n\n            cls._has_been_loaded_from_cache = False\n            return super().__new__(cls)\n\n    def __init__(\n        self,\n        filepath: Optional[PathOrStr] = None,\n        resolve_casing: bool = False,\n        recurse: bool = True,\n        path_style: Optional[str] = None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"Create a new FileModel from the given filepath.\n\n        If no filepath is provided, the model is initialized as an empty\n        model with default values.\n        If the filepath is provided, it is read from disk.\n\n        Args:\n            filepath (Optional[PathOrStr], optional): The file path. Defaults to None.\n            resolve_casing (bool, optional): Whether or not to resolve the file name references so that they match the case with what is on disk. Defaults to False.\n            recurse (bool, optional): Whether or not to recursively load the model. Defaults to True.\n            path_style (Optional[str], optional): Which path style is used in the loaded files. Defaults to the path style that matches the current operating system. Options: 'unix', 'windows'.\n\n        Raises:\n            ValueError: When an unsupported path style is passed.\n        \"\"\"\n        if self._has_been_loaded_from_cache:\n            return\n\n        if not filepath:\n            super().__init__(*args, **kwargs)\n            return\n\n        filepath = FileModel._change_to_path(filepath)\n        path_style = path_style_validator.validate(path_style)\n\n        with file_load_context() as context:\n            context.initialize_load_settings(recurse, resolve_casing, path_style)\n\n            filepath = context.convert_path_style(filepath)\n\n            if not FileModel._should_load_model(context):\n                super().__init__(*args, **kwargs)\n                self.filepath = filepath\n                return\n\n            self._absolute_anchor_path = context.get_current_parent()\n            loading_path = context.resolve(filepath)\n            loading_path = context.resolve_casing(loading_path)\n            if context.load_settings.resolve_casing:\n                filepath = self._get_updated_file_path(filepath, loading_path)\n\n            logger.info(f\"Loading data from {filepath}\")\n\n            data = self._load(loading_path)\n            context.register_model(filepath, self)\n            data[\"filepath\"] = filepath\n            kwargs.update(data)\n\n            # Note: the relative mode needs to be obtained from the data directly\n            # because self._relative_mode has not been resolved yet (this is done as\n            # part of the __init__), however during the __init__ we need to already\n            # have pushed the new parent. As such we cannot move this call later.\n            relative_mode = self._get_relative_mode_from_data(data)\n            context.push_new_parent(filepath.parent, relative_mode)\n\n            super().__init__(*args, **kwargs)\n            self._post_init_load()\n\n            context.pop_last_parent()\n\n    @classmethod\n    def _should_load_model(cls, context: FileLoadContext) -&gt; bool:\n        \"\"\"Determines whether the file model should be loaded or not.\n        A file model should be loaded when either all models should be loaded recursively,\n        or when no file model has been loaded yet.\n\n        Returns:\n            bool: Whether or not the file model should be loaded or not.\n        \"\"\"\n        return context.load_settings.recurse or context.cache_is_empty()\n\n    def _post_init_load(self) -&gt; None:\n        \"\"\"\n        _post_init_load provides a hook into the __init__ of the FileModel which can be\n        used in subclasses for logic that requires the FileModel FileLoadContext.\n\n        It is guaranteed to be called after the pydantic model is, with the FileLoadContext\n        relative to this FileModel being loaded.\n        \"\"\"\n        pass\n\n    @property\n    def _resolved_filepath(self) -&gt; Optional[Path]:\n        if self.filepath is None:\n            return None\n\n        with file_load_context() as context:\n            return context.resolve(self.filepath)\n\n    @property\n    def save_location(self) -&gt; Optional[Path]:\n        \"\"\"Get the current save location which will be used when calling `save()`\n\n        This value can be None if the filepath is None and no name can be generated.\n\n        Returns:\n            Path: The location at which this model will be saved.\n        \"\"\"\n        filepath = self.filepath or self._generate_name()\n\n        if filepath is None:\n            return None\n        elif filepath.is_absolute():\n            return filepath\n        else:\n            return self._absolute_anchor_path / filepath\n\n    def is_file_link(self) -&gt; bool:\n        return True\n\n    def _get_updated_file_path(self, file_path: Path, loading_path: Path) -&gt; Path:\n        \"\"\"Update the file path with the resolved casing from the loading path.\n        Logs an information message if a file path is updated.\n\n        For example, given:\n            file_path = \"To/A/File.txt\"\n            loading_path = \"D:/path/to/a/file.txt\"\n\n        Then the result will be: \"to/a/file.txt\"\n\n        Args:\n            file_path (Path): The file path.\n            loading_path (Path): The resolved loading path.\n\n        Returns:\n            Path: The updated file path.\n        \"\"\"\n\n        updated_file_parts = loading_path.parts[-len(file_path.parts) :]  # noqa: E203\n        updated_file_path = Path(*updated_file_parts)\n\n        if str(updated_file_path) != str(file_path):\n            logger.info(\n                f\"Updating file reference from {file_path.name} to {updated_file_path}\"\n            )\n\n        return updated_file_path\n\n    @classmethod\n    def validate(cls: Type[\"FileModel\"], value: Any):\n        # Enable initialization with a Path.\n        if isinstance(value, (Path, str)):\n            # Pydantic Model init requires a dict\n            value = {\"filepath\": Path(value)}\n        elif value is None:\n            return None\n        elif not isinstance(value, cls) and not isinstance(value, dict):\n            raise ValueError(\n                f\"Expected {cls.__name__} or dict, got {type(value).__name__}\"\n            )\n        return super().validate(value)\n\n    def save(\n        self,\n        filepath: Optional[Path] = None,\n        recurse: bool = False,\n        path_style: Optional[str] = None,\n        exclude_unset: bool = False,\n    ) -&gt; None:\n        \"\"\"Save the model to disk.\n\n        If recurse is set to True, all of the child FileModels will be saved as well.\n        Relative child models are stored relative to this Model, according to the\n        model file hierarchy specified with the respective filepaths.\n        Absolute paths will be written to their respective locations. Note that this\n        will overwrite any existing files that are stored in this location.\n\n        Note that if recurse is set to True, the save_location properties of the\n        children are updated to their respective new locations.\n\n        If filepath it is specified, the filepath of this FileModel is set to the\n        specified path before the save operation is executed. If none is specified\n        it will use the current filepath.\n\n        If the used filepath is relative, it will be stored at the current\n        save_location. If you only want to save a child model of some root model, it is\n        recommended to first call synchronize_filepaths on the root model, to ensure\n        the child model's save_location is correctly determined.\n\n        Args:\n            filepath (Optional[Path], optional):\n                The file path at which this model is saved. If None is specified\n                it defaults to the filepath currently stored in the filemodel.\n                Defaults to None.\n            recurse (bool, optional):\n                Whether to save all children of this FileModel (when set to True),\n                or only save this model (when set to False). Defaults to False.\n            path_style (Optional[str], optional):\n                With which file path style to save the model. File references will\n                be written with the specified path style. Defaults to the path style\n                used by the current operating system. Options: 'unix', 'windows'.\n            exclude_unset (bool, optional):\n                Whether or not to exclude unset values when saving the model.\n                Defaults to False.\n\n        Raises:\n            ValueError: When an unsupported path style is passed.\n        \"\"\"\n        if filepath is not None:\n            self.filepath = filepath\n\n        path_style = path_style_validator.validate(path_style)\n        save_settings = ModelSaveSettings(\n            path_style=path_style, exclude_unset=exclude_unset\n        )\n\n        # Handle save\n        with file_load_context() as context:\n            context.push_new_parent(self._absolute_anchor_path, self._relative_mode)\n\n            if recurse:\n                self._save_tree(context, save_settings)\n            else:\n                self._save_instance(save_settings)\n\n    def _save_instance(self, save_settings: ModelSaveSettings) -&gt; None:\n        if self.filepath is None:\n            self.filepath = self._generate_name()\n        self._save(save_settings)\n\n    def _save_tree(\n        self, context: FileLoadContext, save_settings: ModelSaveSettings\n    ) -&gt; None:\n        # Ensure all names are generated prior to saving\n        def execute_generate_name(\n            model: BaseModel, acc: FileLoadContext\n        ) -&gt; FileLoadContext:\n            if isinstance(model, FileModel) and model.filepath is None:\n                model.filepath = model._generate_name()\n            return acc\n\n        name_traverser = ModelTreeTraverser[FileLoadContext](\n            should_traverse=_should_traverse,\n            should_execute=_should_execute,\n            post_traverse_func=execute_generate_name,\n        )\n\n        name_traverser.traverse(self, context)\n\n        def save_pre(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n            if isinstance(model, FileModel):\n                acc.push_new_parent(model.filepath.parent, model._relative_mode)  # type: ignore[arg-type]\n            return acc\n\n        def save_post(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n            if isinstance(model, FileModel):\n                acc.pop_last_parent()\n                model._absolute_anchor_path = acc.get_current_parent()\n                model._save(save_settings)\n            return acc\n\n        save_traverser = ModelTreeTraverser[FileLoadContext](\n            should_traverse=_should_traverse,\n            should_execute=_should_execute,\n            pre_traverse_func=save_pre,\n            post_traverse_func=save_post,\n        )\n        save_traverser.traverse(self, context)\n\n    def synchronize_filepaths(self) -&gt; None:\n        \"\"\"Synchronize the save_location properties of all child models respective to\n        this FileModel's save_location.\n        \"\"\"\n\n        def sync_pre(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n            if isinstance(model, FileModel):\n                acc.push_new_parent(model.filepath.parent, model._relative_mode)  # type: ignore[arg-type]\n            return acc\n\n        def sync_post(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n            if isinstance(model, FileModel):\n                acc.pop_last_parent()\n                model._absolute_anchor_path = acc.get_current_parent()\n            return acc\n\n        traverser = ModelTreeTraverser[FileLoadContext](\n            should_traverse=_should_traverse,\n            should_execute=_should_execute,\n            pre_traverse_func=sync_pre,\n            post_traverse_func=sync_post,\n        )\n\n        with file_load_context() as context:\n            context.push_new_parent(self._absolute_anchor_path, self._relative_mode)\n            traverser.traverse(self, context)\n\n    @property\n    def _relative_mode(self) -&gt; ResolveRelativeMode:\n        \"\"\"Get the ResolveRelativeMode of this FileModel.\n\n        Returns:\n            ResolveRelativeMode: The ResolveRelativeMode of this FileModel\n        \"\"\"\n        return ResolveRelativeMode.ToParent\n\n    @classmethod\n    def _get_relative_mode_from_data(cls, data: Dict[str, Any]) -&gt; ResolveRelativeMode:\n        \"\"\"Gets the ResolveRelativeMode of this FileModel based on the provided data.\n\n        Note that by default, data is not used, and FileModels are always relative to\n        the parent. In exceptional cases, the relative mode can be dependent on the\n        data (i.e. the unvalidated/parsed dictionary fed into the pydantic basemodel).\n        As such the data is provided for such classes where the relative mode is\n        dependent on the state (e.g. the [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]).\n\n        Args:\n            data (Dict[str, Any]):\n                The unvalidated/parsed data which is fed to the pydantic base model,\n                used to determine the ResolveRelativeMode.\n\n        Returns:\n            ResolveRelativeMode: The ResolveRelativeMode of this FileModel\n        \"\"\"\n        return ResolveRelativeMode.ToParent\n\n    @abstractclassmethod\n    def _generate_name(cls) -&gt; Optional[Path]:\n        \"\"\"Generate a (default) name for this FileModel.\n\n        Note that if _generate_name in theory can return a None value,\n        if this is possible in the specific implementation, _save should\n        be able to handle filepaths set to None.\n\n        Returns:\n            Optional[Path]:\n                a relative path with the default name of the model.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _save(self, save_settings: ModelSaveSettings) -&gt; None:\n        \"\"\"Save this instance to disk.\n\n        This method needs to be implemented by any class deriving from\n        FileModel, and is used in both the _save_instance and _save_tree\n        methods.\n\n        Args:\n            save_settings (ModelSaveSettings): The model save settings.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _load(self, filepath: Path) -&gt; Dict:\n        \"\"\"Load the data at filepath and returns it as a dictionary.\n\n        If a derived FileModel does not load data from disk, this should\n        return an empty dictionary.\n\n        Args:\n            filepath (Path): Path to the data to load.\n\n        Returns:\n            Dict: The data stored at filepath\n        \"\"\"\n        raise NotImplementedError()\n\n    def __str__(self) -&gt; str:\n        return str(self.filepath if self.filepath else \"\")\n\n    @staticmethod\n    def _change_to_path(filepath):\n        if filepath is None:\n            return filepath\n        elif isinstance(filepath, Path):\n            return filepath\n        else:\n            return Path(filepath)\n\n    @validator(\"filepath\")\n    def _conform_filepath_to_pathlib(cls, value):\n        return FileModel._change_to_path(value)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel.save_location","title":"<code>save_location</code>  <code>property</code>","text":"<p>Get the current save location which will be used when calling <code>save()</code></p> <p>This value can be None if the filepath is None and no name can be generated.</p> <p>Returns:</p> Name Type Description <code>Path</code> <code>Optional[Path]</code> <p>The location at which this model will be saved.</p>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel.__init__","title":"<code>__init__(filepath=None, resolve_casing=False, recurse=True, path_style=None, *args, **kwargs)</code>","text":"<p>Create a new FileModel from the given filepath.</p> <p>If no filepath is provided, the model is initialized as an empty model with default values. If the filepath is provided, it is read from disk.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[PathOrStr]</code> <p>The file path. Defaults to None.</p> <code>None</code> <code>resolve_casing</code> <code>bool</code> <p>Whether or not to resolve the file name references so that they match the case with what is on disk. Defaults to False.</p> <code>False</code> <code>recurse</code> <code>bool</code> <p>Whether or not to recursively load the model. Defaults to True.</p> <code>True</code> <code>path_style</code> <code>Optional[str]</code> <p>Which path style is used in the loaded files. Defaults to the path style that matches the current operating system. Options: 'unix', 'windows'.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When an unsupported path style is passed.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def __init__(\n    self,\n    filepath: Optional[PathOrStr] = None,\n    resolve_casing: bool = False,\n    recurse: bool = True,\n    path_style: Optional[str] = None,\n    *args,\n    **kwargs,\n):\n    \"\"\"Create a new FileModel from the given filepath.\n\n    If no filepath is provided, the model is initialized as an empty\n    model with default values.\n    If the filepath is provided, it is read from disk.\n\n    Args:\n        filepath (Optional[PathOrStr], optional): The file path. Defaults to None.\n        resolve_casing (bool, optional): Whether or not to resolve the file name references so that they match the case with what is on disk. Defaults to False.\n        recurse (bool, optional): Whether or not to recursively load the model. Defaults to True.\n        path_style (Optional[str], optional): Which path style is used in the loaded files. Defaults to the path style that matches the current operating system. Options: 'unix', 'windows'.\n\n    Raises:\n        ValueError: When an unsupported path style is passed.\n    \"\"\"\n    if self._has_been_loaded_from_cache:\n        return\n\n    if not filepath:\n        super().__init__(*args, **kwargs)\n        return\n\n    filepath = FileModel._change_to_path(filepath)\n    path_style = path_style_validator.validate(path_style)\n\n    with file_load_context() as context:\n        context.initialize_load_settings(recurse, resolve_casing, path_style)\n\n        filepath = context.convert_path_style(filepath)\n\n        if not FileModel._should_load_model(context):\n            super().__init__(*args, **kwargs)\n            self.filepath = filepath\n            return\n\n        self._absolute_anchor_path = context.get_current_parent()\n        loading_path = context.resolve(filepath)\n        loading_path = context.resolve_casing(loading_path)\n        if context.load_settings.resolve_casing:\n            filepath = self._get_updated_file_path(filepath, loading_path)\n\n        logger.info(f\"Loading data from {filepath}\")\n\n        data = self._load(loading_path)\n        context.register_model(filepath, self)\n        data[\"filepath\"] = filepath\n        kwargs.update(data)\n\n        # Note: the relative mode needs to be obtained from the data directly\n        # because self._relative_mode has not been resolved yet (this is done as\n        # part of the __init__), however during the __init__ we need to already\n        # have pushed the new parent. As such we cannot move this call later.\n        relative_mode = self._get_relative_mode_from_data(data)\n        context.push_new_parent(filepath.parent, relative_mode)\n\n        super().__init__(*args, **kwargs)\n        self._post_init_load()\n\n        context.pop_last_parent()\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel.__new__","title":"<code>__new__(filepath=None, *args, **kwargs)</code>","text":"<p>Create a new model. If the file at the provided file path was already parsed, this instance is returned.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[PathOrStr]</code> <p>The file path to the file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>FileModel</code> <p>A file model.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def __new__(cls, filepath: Optional[PathOrStr] = None, *args, **kwargs):\n    \"\"\"Create a new model.\n    If the file at the provided file path was already parsed, this instance is returned.\n\n    Args:\n        filepath (Optional[PathOrStr], optional): The file path to the file. Defaults to None.\n\n    Returns:\n        FileModel: A file model.\n    \"\"\"\n    filepath = FileModel._change_to_path(filepath)\n    with file_load_context() as context:\n        if (file_model := context.retrieve_model(filepath)) is not None:\n            if not context.is_content_changed(filepath):\n                cls._has_been_loaded_from_cache = True\n                return file_model\n\n        cls._has_been_loaded_from_cache = False\n        return super().__new__(cls)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel.save","title":"<code>save(filepath=None, recurse=False, path_style=None, exclude_unset=False)</code>","text":"<p>Save the model to disk.</p> <p>If recurse is set to True, all of the child FileModels will be saved as well. Relative child models are stored relative to this Model, according to the model file hierarchy specified with the respective filepaths. Absolute paths will be written to their respective locations. Note that this will overwrite any existing files that are stored in this location.</p> <p>Note that if recurse is set to True, the save_location properties of the children are updated to their respective new locations.</p> <p>If filepath it is specified, the filepath of this FileModel is set to the specified path before the save operation is executed. If none is specified it will use the current filepath.</p> <p>If the used filepath is relative, it will be stored at the current save_location. If you only want to save a child model of some root model, it is recommended to first call synchronize_filepaths on the root model, to ensure the child model's save_location is correctly determined.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[Path]</code> <p>The file path at which this model is saved. If None is specified it defaults to the filepath currently stored in the filemodel. Defaults to None.</p> <code>None</code> <code>recurse</code> <code>bool</code> <p>Whether to save all children of this FileModel (when set to True), or only save this model (when set to False). Defaults to False.</p> <code>False</code> <code>path_style</code> <code>Optional[str]</code> <p>With which file path style to save the model. File references will be written with the specified path style. Defaults to the path style used by the current operating system. Options: 'unix', 'windows'.</p> <code>None</code> <code>exclude_unset</code> <code>bool</code> <p>Whether or not to exclude unset values when saving the model. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When an unsupported path style is passed.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def save(\n    self,\n    filepath: Optional[Path] = None,\n    recurse: bool = False,\n    path_style: Optional[str] = None,\n    exclude_unset: bool = False,\n) -&gt; None:\n    \"\"\"Save the model to disk.\n\n    If recurse is set to True, all of the child FileModels will be saved as well.\n    Relative child models are stored relative to this Model, according to the\n    model file hierarchy specified with the respective filepaths.\n    Absolute paths will be written to their respective locations. Note that this\n    will overwrite any existing files that are stored in this location.\n\n    Note that if recurse is set to True, the save_location properties of the\n    children are updated to their respective new locations.\n\n    If filepath it is specified, the filepath of this FileModel is set to the\n    specified path before the save operation is executed. If none is specified\n    it will use the current filepath.\n\n    If the used filepath is relative, it will be stored at the current\n    save_location. If you only want to save a child model of some root model, it is\n    recommended to first call synchronize_filepaths on the root model, to ensure\n    the child model's save_location is correctly determined.\n\n    Args:\n        filepath (Optional[Path], optional):\n            The file path at which this model is saved. If None is specified\n            it defaults to the filepath currently stored in the filemodel.\n            Defaults to None.\n        recurse (bool, optional):\n            Whether to save all children of this FileModel (when set to True),\n            or only save this model (when set to False). Defaults to False.\n        path_style (Optional[str], optional):\n            With which file path style to save the model. File references will\n            be written with the specified path style. Defaults to the path style\n            used by the current operating system. Options: 'unix', 'windows'.\n        exclude_unset (bool, optional):\n            Whether or not to exclude unset values when saving the model.\n            Defaults to False.\n\n    Raises:\n        ValueError: When an unsupported path style is passed.\n    \"\"\"\n    if filepath is not None:\n        self.filepath = filepath\n\n    path_style = path_style_validator.validate(path_style)\n    save_settings = ModelSaveSettings(\n        path_style=path_style, exclude_unset=exclude_unset\n    )\n\n    # Handle save\n    with file_load_context() as context:\n        context.push_new_parent(self._absolute_anchor_path, self._relative_mode)\n\n        if recurse:\n            self._save_tree(context, save_settings)\n        else:\n            self._save_instance(save_settings)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.FileModel.synchronize_filepaths","title":"<code>synchronize_filepaths()</code>","text":"<p>Synchronize the save_location properties of all child models respective to this FileModel's save_location.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def synchronize_filepaths(self) -&gt; None:\n    \"\"\"Synchronize the save_location properties of all child models respective to\n    this FileModel's save_location.\n    \"\"\"\n\n    def sync_pre(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n        if isinstance(model, FileModel):\n            acc.push_new_parent(model.filepath.parent, model._relative_mode)  # type: ignore[arg-type]\n        return acc\n\n    def sync_post(model: BaseModel, acc: FileLoadContext) -&gt; FileLoadContext:\n        if isinstance(model, FileModel):\n            acc.pop_last_parent()\n            model._absolute_anchor_path = acc.get_current_parent()\n        return acc\n\n    traverser = ModelTreeTraverser[FileLoadContext](\n        should_traverse=_should_traverse,\n        should_execute=_should_execute,\n        pre_traverse_func=sync_pre,\n        post_traverse_func=sync_post,\n    )\n\n    with file_load_context() as context:\n        context.push_new_parent(self._absolute_anchor_path, self._relative_mode)\n        traverser.traverse(self, context)\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelSaveSettings","title":"<code>ModelSaveSettings</code>","text":"<p>A class that holds the global settings for model saving.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class ModelSaveSettings:\n    \"\"\"A class that holds the global settings for model saving.\"\"\"\n\n    _os_path_style = get_path_style_for_current_operating_system()\n\n    def __init__(\n        self, path_style: Optional[PathStyle] = None, exclude_unset: bool = False\n    ) -&gt; None:\n        \"\"\"Initializes a new instance of the ModelSaveSettings class.\n\n        Args:\n            path_style (Optional[PathStyle], optional): Which file path style to use when saving the model. Defaults to the path style that matches the current operating system.\n            exclude_unset (bool, optional): Whether or not to exclude unset values when saving the model. Defaults to False.\n        \"\"\"\n\n        if path_style is None:\n            path_style = self._os_path_style\n\n        self._path_style = path_style\n\n        self._exclude_unset = exclude_unset\n\n    @property\n    def path_style(self) -&gt; PathStyle:\n        \"\"\"Gets the path style setting.\n\n        Returns:\n            PathStyle: Which path style is used to save the files.\n        \"\"\"\n        return self._path_style\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelSaveSettings.path_style","title":"<code>path_style</code>  <code>property</code>","text":"<p>Gets the path style setting.</p> <p>Returns:</p> Name Type Description <code>PathStyle</code> <code>PathStyle</code> <p>Which path style is used to save the files.</p>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelSaveSettings.__init__","title":"<code>__init__(path_style=None, exclude_unset=False)</code>","text":"<p>Initializes a new instance of the ModelSaveSettings class.</p> <p>Parameters:</p> Name Type Description Default <code>path_style</code> <code>Optional[PathStyle]</code> <p>Which file path style to use when saving the model. Defaults to the path style that matches the current operating system.</p> <code>None</code> <code>exclude_unset</code> <code>bool</code> <p>Whether or not to exclude unset values when saving the model. Defaults to False.</p> <code>False</code> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def __init__(\n    self, path_style: Optional[PathStyle] = None, exclude_unset: bool = False\n) -&gt; None:\n    \"\"\"Initializes a new instance of the ModelSaveSettings class.\n\n    Args:\n        path_style (Optional[PathStyle], optional): Which file path style to use when saving the model. Defaults to the path style that matches the current operating system.\n        exclude_unset (bool, optional): Whether or not to exclude unset values when saving the model. Defaults to False.\n    \"\"\"\n\n    if path_style is None:\n        path_style = self._os_path_style\n\n    self._path_style = path_style\n\n    self._exclude_unset = exclude_unset\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelTreeTraverser","title":"<code>ModelTreeTraverser</code>","text":"<p>               Bases: <code>Generic[TAcc]</code></p> <p>ModelTreeTraverser is responsible for traversing a ModelTree using the provided functions.</p> <p>The ModelTreeTraverser will only traverse BaseModel and derived objects. Type parameter TAcc defines the type of Accumulator to be used.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class ModelTreeTraverser(Generic[TAcc]):\n    \"\"\"ModelTreeTraverser is responsible for traversing a ModelTree using the provided\n    functions.\n\n    The ModelTreeTraverser will only traverse BaseModel and derived objects.\n    Type parameter TAcc defines the type of Accumulator to be used.\n    \"\"\"\n\n    def __init__(\n        self,\n        should_traverse: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n        should_execute: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n        pre_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n        post_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n    ):\n        \"\"\"Create a new ModelTreeTraverser with the given functions.\n\n        If a predicate it is not defined, it is assumed to always be true, i.e. we will\n        always traverse to the next node, or always execute the traverse functions.\n\n        If a traverse function is not defined, it will be skipped.\n\n        The traverse functions share an accumulator, i.e. the accumulator argument\n        is passed through all evaluated traverse functions. It is expected that the\n        traverse function return the (potentially) changed accumulator.\n\n        Args:\n            should_traverse (Optional[Callable[[BaseModel, TAcc], bool]], optional):\n                Function to evaluate whether to traverse to the provided BaseModel. Defaults to None.\n            should_execute (Optional[Callable[[BaseModel, TAcc], bool]], optional):\n                Function to evaluate whether to execute the traverse functions for the\n                provided BaseModel. Defaults to None.\n            pre_traverse_func (Callable[[BaseModel, TAcc], TAcc], optional):\n                Traverse function executed before we traverse into the next BaseModel,\n                i.e. top-down traversal. Defaults to None.\n            post_traverse_func (Callable[[BaseModel, TAcc], TAcc], optional):\n                Traverse function executed after we traverse into the next BaseModel,\n                i.e. bottom-up traversal. Defaults to None.\n        \"\"\"\n        self._should_traverse_func = should_traverse\n        self._should_execute_func = should_execute\n        self._pre_traverse_func = pre_traverse_func\n        self._post_traverse_func = post_traverse_func\n\n    def _should_execute(self, model: BaseModel, acc: TAcc) -&gt; bool:\n        return self._should_execute_func is None or self._should_execute_func(\n            model, acc\n        )\n\n    def _should_execute_pre(self, model: BaseModel, acc: TAcc) -&gt; bool:\n        return self._pre_traverse_func is not None and self._should_execute(model, acc)\n\n    def _should_execute_post(self, model: BaseModel, acc: TAcc) -&gt; bool:\n        return self._post_traverse_func is not None and self._should_execute(model, acc)\n\n    def _should_traverse(self, value: Any, acc: TAcc) -&gt; bool:\n        return isinstance(value, BaseModel) and (\n            self._should_traverse_func is None or self._should_traverse_func(value, acc)\n        )\n\n    def traverse(self, model: BaseModel, acc: TAcc) -&gt; TAcc:\n        \"\"\"Traverse the model tree of BaseModels including the model as the root, with\n        the provided state of the acc and return the final accumulator.\n\n        The actual executed functions as well as the predicates defining whether these\n        functions should be executed for this model as well as whether child BaseModel\n        objects should be traversed are provided in the constructor of the\n        ModelTreeTraverser.\n\n        The final accumulator is returned.\n\n        Args:\n            model (BaseModel):\n                The root model in which the traversal of the model tree starts.\n            acc (TAcc):\n                The current accumulator.\n\n        Returns:\n            TAcc: The accumulator after the traversal of the model tree.\n        \"\"\"\n        if self._should_execute_pre(model, acc):\n            acc = self._pre_traverse_func(model, acc)  # type: ignore[arg-type]\n\n        for _, value in model:\n            if not isinstance(value, list):\n                value = [value]\n\n            for v in value:\n                if self._should_traverse(v, acc):\n                    acc = self.traverse(v, acc)\n\n        if self._should_execute_post(model, acc):\n            acc = self._post_traverse_func(model, acc)  # type: ignore[arg-type]\n\n        return acc\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelTreeTraverser.__init__","title":"<code>__init__(should_traverse=None, should_execute=None, pre_traverse_func=None, post_traverse_func=None)</code>","text":"<p>Create a new ModelTreeTraverser with the given functions.</p> <p>If a predicate it is not defined, it is assumed to always be true, i.e. we will always traverse to the next node, or always execute the traverse functions.</p> <p>If a traverse function is not defined, it will be skipped.</p> <p>The traverse functions share an accumulator, i.e. the accumulator argument is passed through all evaluated traverse functions. It is expected that the traverse function return the (potentially) changed accumulator.</p> <p>Parameters:</p> Name Type Description Default <code>should_traverse</code> <code>Optional[Callable[[BaseModel, TAcc], bool]]</code> <p>Function to evaluate whether to traverse to the provided BaseModel. Defaults to None.</p> <code>None</code> <code>should_execute</code> <code>Optional[Callable[[BaseModel, TAcc], bool]]</code> <p>Function to evaluate whether to execute the traverse functions for the provided BaseModel. Defaults to None.</p> <code>None</code> <code>pre_traverse_func</code> <code>Callable[[BaseModel, TAcc], TAcc]</code> <p>Traverse function executed before we traverse into the next BaseModel, i.e. top-down traversal. Defaults to None.</p> <code>None</code> <code>post_traverse_func</code> <code>Callable[[BaseModel, TAcc], TAcc]</code> <p>Traverse function executed after we traverse into the next BaseModel, i.e. bottom-up traversal. Defaults to None.</p> <code>None</code> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def __init__(\n    self,\n    should_traverse: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n    should_execute: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n    pre_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n    post_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n):\n    \"\"\"Create a new ModelTreeTraverser with the given functions.\n\n    If a predicate it is not defined, it is assumed to always be true, i.e. we will\n    always traverse to the next node, or always execute the traverse functions.\n\n    If a traverse function is not defined, it will be skipped.\n\n    The traverse functions share an accumulator, i.e. the accumulator argument\n    is passed through all evaluated traverse functions. It is expected that the\n    traverse function return the (potentially) changed accumulator.\n\n    Args:\n        should_traverse (Optional[Callable[[BaseModel, TAcc], bool]], optional):\n            Function to evaluate whether to traverse to the provided BaseModel. Defaults to None.\n        should_execute (Optional[Callable[[BaseModel, TAcc], bool]], optional):\n            Function to evaluate whether to execute the traverse functions for the\n            provided BaseModel. Defaults to None.\n        pre_traverse_func (Callable[[BaseModel, TAcc], TAcc], optional):\n            Traverse function executed before we traverse into the next BaseModel,\n            i.e. top-down traversal. Defaults to None.\n        post_traverse_func (Callable[[BaseModel, TAcc], TAcc], optional):\n            Traverse function executed after we traverse into the next BaseModel,\n            i.e. bottom-up traversal. Defaults to None.\n    \"\"\"\n    self._should_traverse_func = should_traverse\n    self._should_execute_func = should_execute\n    self._pre_traverse_func = pre_traverse_func\n    self._post_traverse_func = post_traverse_func\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ModelTreeTraverser.traverse","title":"<code>traverse(model, acc)</code>","text":"<p>Traverse the model tree of BaseModels including the model as the root, with the provided state of the acc and return the final accumulator.</p> <p>The actual executed functions as well as the predicates defining whether these functions should be executed for this model as well as whether child BaseModel objects should be traversed are provided in the constructor of the ModelTreeTraverser.</p> <p>The final accumulator is returned.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The root model in which the traversal of the model tree starts.</p> required <code>acc</code> <code>TAcc</code> <p>The current accumulator.</p> required <p>Returns:</p> Name Type Description <code>TAcc</code> <code>TAcc</code> <p>The accumulator after the traversal of the model tree.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def traverse(self, model: BaseModel, acc: TAcc) -&gt; TAcc:\n    \"\"\"Traverse the model tree of BaseModels including the model as the root, with\n    the provided state of the acc and return the final accumulator.\n\n    The actual executed functions as well as the predicates defining whether these\n    functions should be executed for this model as well as whether child BaseModel\n    objects should be traversed are provided in the constructor of the\n    ModelTreeTraverser.\n\n    The final accumulator is returned.\n\n    Args:\n        model (BaseModel):\n            The root model in which the traversal of the model tree starts.\n        acc (TAcc):\n            The current accumulator.\n\n    Returns:\n        TAcc: The accumulator after the traversal of the model tree.\n    \"\"\"\n    if self._should_execute_pre(model, acc):\n        acc = self._pre_traverse_func(model, acc)  # type: ignore[arg-type]\n\n    for _, value in model:\n        if not isinstance(value, list):\n            value = [value]\n\n        for v in value:\n            if self._should_traverse(v, acc):\n                acc = self.traverse(v, acc)\n\n    if self._should_execute_post(model, acc):\n        acc = self._post_traverse_func(model, acc)  # type: ignore[arg-type]\n\n    return acc\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.ParsableFileModel","title":"<code>ParsableFileModel</code>","text":"<p>               Bases: <code>FileModel</code></p> <p>ParsableFileModel defines a FileModel which can be parsed and serialized with a serializer .</p> <p>Each ParsableFileModel has a default _filename and _ext, which are used to generate the file name of any instance where the filepath is not (yet) set.</p> <p>Children of the ParsableFileModel are expected to implement a serializer function which takes a Path and Dict and writes the ParsableFileModel to disk, and a parser function which takes a Path and outputs a Dict.</p> <p>If more complicated solutions are required, a ParsableFileModel child can also opt to overwrite the _serialize and _parse methods, to skip the _get_serializer and _get_parser methods respectively.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class ParsableFileModel(FileModel):\n    \"\"\"ParsableFileModel defines a FileModel which can be parsed\n    and serialized with a serializer .\n\n    Each ParsableFileModel has a default _filename and _ext,\n    which are used to generate the file name of any instance where\n    the filepath is not (yet) set.\n\n    Children of the ParsableFileModel are expected to implement a\n    serializer function which takes a Path and Dict and writes the\n    ParsableFileModel to disk, and a parser function which takes\n    a Path and outputs a Dict.\n\n    If more complicated solutions are required, a ParsableFileModel\n    child can also opt to overwrite the _serialize and _parse methods,\n    to skip the _get_serializer and _get_parser methods respectively.\n    \"\"\"\n\n    serializer_config: SerializerConfig = SerializerConfig()\n\n    def _load(self, filepath: Path) -&gt; Dict:\n        # Make this lazy in some cases so it doesn't become slow\n        if filepath.is_file():\n            return self._parse(filepath)\n        else:\n            raise ValueError(f\"File: `{filepath}` not found, skipped parsing.\")\n\n    def _save(self, save_settings: ModelSaveSettings) -&gt; None:\n        \"\"\"Save the data of this FileModel.\n\n        _save provides a hook for child models to overwrite the save behaviour as\n        called during the tree traversal.\n\n        Args:\n            save_settings (ModelSaveSettings): The model save settings.\n        \"\"\"\n        self._serialize(self.dict(), save_settings)\n\n    def _serialize(self, data: dict, save_settings: ModelSaveSettings) -&gt; None:\n        \"\"\"Serializes the data to file. Should not be called directly, only through `_save`.\n\n        Args:\n            save_settings (ModelSaveSettings): The model save settings.\n        \"\"\"\n        path = self._resolved_filepath\n        if path is None:\n            # Do we need to add a warning / exception here\n            return\n\n        path.parent.mkdir(parents=True, exist_ok=True)\n        self._get_serializer()(path, data, self.serializer_config, save_settings)\n\n    def dict(self, *args, **kwargs):\n        kwargs[\"exclude\"] = self._exclude_fields()\n        return super().dict(*args, **kwargs)\n\n    @classmethod\n    def _exclude_fields(cls) -&gt; Set[str]:\n        \"\"\"A set containing the field names that should not be serialized.\"\"\"\n        return {\"filepath\", \"serializer_config\"}\n\n    @classmethod\n    def _parse(cls, path: Path) -&gt; Dict:\n        return cls._get_parser()(path)\n\n    @classmethod\n    def _generate_name(cls) -&gt; Path:\n        name, ext = cls._filename(), cls._ext()\n        return Path(f\"{name}{ext}\")\n\n    @abstractclassmethod\n    def _filename(cls) -&gt; str:\n        return \"test\"\n\n    @abstractclassmethod\n    def _ext(cls) -&gt; str:\n        return \".test\"\n\n    @abstractclassmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return DummySerializer.serialize\n\n    @abstractclassmethod\n    def _get_parser(cls) -&gt; Callable[[Path], Dict]:\n        return DummmyParser.parse\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        filepath = data.get(\"filepath\")\n        if filepath:\n            return filepath.name\n        return None\n\n    @staticmethod\n    def _get_quantity_unit(quantities_names: List[str]) -&gt; List[str]:\n        \"\"\"\n        Maps each quantity in the input list to a specific unit based on its content.\n\n        Args:\n            quantities_names (list of str): A list of strings to be checked for specific keywords.\n\n        Returns:\n            list of str: A list of corresponding units for each input string.\n\n        Examples:\n            ```python\n            &gt;&gt;&gt; quantities_names = [\"discharge\", \"waterlevel\", \"salinity\", \"temperature\"]\n            &gt;&gt;&gt; ParsableFileModel._get_quantity_unit(quantities_names)\n            ['m3/s', 'm', '1e-3', 'degC']\n\n            ```\n        \"\"\"\n        # Define the mapping of keywords to units\n        unit_mapping = {\n            \"discharge\": \"m3/s\",\n            \"waterlevel\": \"m\",\n            \"salinity\": \"1e-3\",\n            \"temperature\": \"degC\",\n        }\n\n        # Generate the list of units based on the mapping\n        units = []\n        for string in quantities_names:\n            for keyword, unit in unit_mapping.items():\n                if keyword in string.lower():\n                    units.append(unit)\n                    break\n            else:\n                # Append \"-\" if no keywords match\n                units.append(\"-\")\n\n        return units\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.SerializerConfig","title":"<code>SerializerConfig</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Class that holds the configuration settings for serialization.</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>class SerializerConfig(BaseModel, ABC):\n    \"\"\"Class that holds the configuration settings for serialization.\"\"\"\n\n    float_format: str = \"\"\n    \"\"\"str: The string format that will be used for float serialization. If empty, the original number will be serialized. Defaults to an empty string.\n\n        Examples:\n            Input value = 123.456\n\n            Format    | Output          | Description\n            -------------------------------------------------------------------------------------------------------------------------------------\n            \".0f\"     | 123             | Format float with 0 decimal places.\n            \"f\"       | 123.456000      | Format float with default (=6) decimal places.\n            \".2f\"     | 123.46          | Format float with 2 decimal places.\n            \"+.1f\"    | +123.5          | Format float with 1 decimal place with a + or  sign.\n            \"e\"       | 1.234560e+02    | Format scientific notation with the letter 'e' with default (=6) decimal places.\n            \"E\"       | 1.234560E+02    | Format scientific notation with the letter 'E' with default (=6) decimal places.\n            \".3e\"     | 1.235e+02       | Format scientific notation with the letter 'e' with 3 decimal places.\n            \"&lt;15\"     | 123.456         | Left aligned in space with width 15\n            \"^15.0f\"  |       123       | Center aligned in space with width 15 with 0 decimal places.\n            \"&gt;15.1e\"  |         1.2e+02 | Right aligned in space with width 15 with scientific notation with 1 decimal place.\n            \"*&gt;15.1f\" | **********123.5 | Right aligned in space with width 15 with 1 decimal place and fill empty space with *\n            \"%\"       | 12345.600000%   | Format percentage with default (=6) decimal places.\n            \".3%\"     | 12345.600%      | Format percentage with 3 decimal places.\n\n            More information: https://docs.python.org/3/library/string.html#format-specification-mini-language\n        \"\"\"\n</code></pre>"},{"location":"reference/base/api/#hydrolib.core.base.models.SerializerConfig.float_format","title":"<code>float_format = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: The string format that will be used for float serialization. If empty, the original number will be serialized. Defaults to an empty string.</p> <p>Examples:</p> <p>Input value = 123.456</p>"},{"location":"reference/base/api/#hydrolib.core.base.models.SerializerConfig.float_format--format-output-description","title":"Format    | Output          | Description","text":"<p>\".0f\"     | 123             | Format float with 0 decimal places. \"f\"       | 123.456000      | Format float with default (=6) decimal places. \".2f\"     | 123.46          | Format float with 2 decimal places. \"+.1f\"    | +123.5          | Format float with 1 decimal place with a + or  sign. \"e\"       | 1.234560e+02    | Format scientific notation with the letter 'e' with default (=6) decimal places. \"E\"       | 1.234560E+02    | Format scientific notation with the letter 'E' with default (=6) decimal places. \".3e\"     | 1.235e+02       | Format scientific notation with the letter 'e' with 3 decimal places. \"&lt;15\"     | 123.456         | Left aligned in space with width 15 \"^15.0f\"  |       123       | Center aligned in space with width 15 with 0 decimal places. \"&gt;15.1e\"  |         1.2e+02 | Right aligned in space with width 15 with scientific notation with 1 decimal place. \"&gt;15.1f\" | ***123.5 | Right aligned in space with width 15 with 1 decimal place and fill empty space with * \"%\"       | 12345.600000%   | Format percentage with default (=6) decimal places. \".3%\"     | 12345.600%      | Format percentage with 3 decimal places.</p> <p>More information: https://docs.python.org/3/library/string.html#format-specification-mini-language</p>"},{"location":"reference/base/api/#hydrolib.core.base.models.validator_set_default_disk_only_file_model_when_none","title":"<code>validator_set_default_disk_only_file_model_when_none()</code>","text":"<p>Validator to ensure a default empty DiskOnlyFileModel is created when the corresponding field is initialized with None.</p> <p>Returns:</p> Name Type Description <code>classmethod</code> <code>classmethod</code> <p>Validator to adjust None values to empty DiskOnlyFileModel objects</p> Source code in <code>hydrolib/core/base/models.py</code> <pre><code>def validator_set_default_disk_only_file_model_when_none() -&gt; classmethod:\n    \"\"\"Validator to ensure a default empty DiskOnlyFileModel is created\n    when the corresponding field is initialized with None.\n\n    Returns:\n        classmethod: Validator to adjust None values to empty DiskOnlyFileModel objects\n    \"\"\"\n\n    def adjust_none(v: Any, field: \"ModelField\") -&gt; Any:\n        if field.type_ is DiskOnlyFileModel and v is None:\n            return {\"filepath\": None}\n        return v\n\n    return validator(\"*\", allow_reuse=True, pre=True)(adjust_none)\n</code></pre>"},{"location":"reference/base/base/","title":"Base Module","text":""},{"location":"reference/base/base/#overview","title":"Overview","text":"<p>The <code>hydrolib.core.base</code> module provides the foundational classes and utilities for the HYDROLIB-core library. This module handles file management, model representation, parsing, serialization, and various utility functions that are used throughout the library.</p>"},{"location":"reference/base/base/#module-structure","title":"Module Structure","text":"<p>The <code>hydrolib.core.base</code> module consists of the following files:</p> <ol> <li><code>file_manager.py</code> - Handles file management operations</li> <li><code>models.py</code> - Provides base model classes for data representation</li> <li><code>parser.py</code> - Contains base classes for parsing files</li> <li><code>serializer.py</code> - Contains base classes for serializing models to files</li> <li><code>utils.py</code> - Provides utility functions and classes</li> </ol>"},{"location":"reference/base/base/#class-diagrams","title":"Class Diagrams","text":""},{"location":"reference/base/base/#ascii-class-diagram","title":"ASCII Class Diagram","text":"<pre><code>+------------------+     +------------------+     +------------------+\n| PydanticBaseModel|     | FileLoadContext  |     | BaseParser       |\n+------------------+     +------------------+     +------------------+\n        ^                        |                        ^\n        |                        |                        |\n+------------------+     +------------------+     +------------------+\n| BaseModel        |&lt;----| FileModel        |     | DummmyParser     |\n+------------------+     +------------------+     +------------------+\n                                ^\n                                |\n                +---------------+---------------+\n                |                               |\n    +------------------+               +------------------+\n    | ParsableFileModel|               | DiskOnlyFileModel|\n    +------------------+               +------------------+\n</code></pre>"},{"location":"reference/base/base/#mermaid-class-diagram","title":"Mermaid Class Diagram","text":"<pre><code>classDiagram\n    PydanticBaseModel &lt;|-- BaseModel\n    BaseModel &lt;|-- FileModel\n    FileModel &lt;|-- ParsableFileModel\n    FileModel &lt;|-- DiskOnlyFileModel\n    BaseModel &lt;-- ModelTreeTraverser\n    FileModel --&gt; FileLoadContext\n    BaseParser &lt;|-- DummmyParser\n    ParsableFileModel --&gt; DummmyParser\n    ParsableFileModel --&gt; DummySerializer\n\n    class PydanticBaseModel {\n        +Config\n    }\n\n    class BaseModel {\n        +Config\n        +__init__(**data)\n        +is_file_link()\n        +is_intermediate_link()\n        +show_tree(indent)\n        +_apply_recurse(f, *args, **kwargs)\n        +_get_identifier(data)\n    }\n\n    class FileModel {\n        +__new__(filepath, *args, **kwargs)\n        +__init__(filepath, resolve_casing, recurse, path_style, *args, **kwargs)\n        +_should_load_model(context)\n        +_post_init_load()\n        +_resolved_filepath()\n        +save_location()\n        +is_file_link()\n        +_get_updated_file_path(file_path, loading_path)\n        +validate(value)\n        +save(filepath, recurse, path_style, exclude_unset)\n        +_save_instance(save_settings)\n        +_save_tree(context, save_settings)\n        +synchronize_filepaths()\n        +_relative_mode()\n        +_get_relative_mode_from_data(data)\n        +_generate_name()\n        +_save(save_settings)\n        +_load(filepath)\n        +__str__()\n    }\n\n    class ParsableFileModel {\n        +_load(filepath)\n        +_save(save_settings)\n        +_serialize(data, save_settings)\n        +dict(*args, **kwargs)\n        +_exclude_fields()\n        +_parse(path)\n        +_generate_name()\n        +_filename()\n        +_ext()\n        +_get_serializer()\n        +_get_parser()\n        +_get_identifier(data)\n        +_get_quantity_unit(quantities_names)\n    }\n\n    class DiskOnlyFileModel {\n        +_post_init_load()\n        +_load(filepath)\n        +_save(save_settings)\n        +_can_copy_to(target_file_path)\n        +_generate_name()\n        +is_intermediate_link()\n    }\n\n    class ModelTreeTraverser {\n        +__init__(should_traverse, should_execute, pre_traverse_func, post_traverse_func)\n        +_should_execute(model, acc)\n        +_should_execute_pre(model, acc)\n        +_should_execute_post(model, acc)\n        +_should_traverse(value, acc)\n        +traverse(model, acc)\n    }\n\n    class FileLoadContext {\n        +__init__()\n        +initialize_load_settings(recurse, resolve_casing, path_style)\n        +load_settings()\n        +retrieve_model(path)\n        +register_model(path, model)\n        +cache_is_empty()\n        +get_current_parent()\n        +resolve(path)\n        +push_new_parent(parent_path, relative_mode)\n        +pop_last_parent()\n        +resolve_casing(file_path)\n        +convert_path_style(file_path)\n        +is_content_changed(path)\n    }\n\n    class BaseParser {\n        +_read_header_comments(lines)\n        +_raise_error_if_contains_comment(line, line_index)\n    }\n\n    class DummmyParser {\n        +parse(filepath)\n    }\n\n    class DummySerializer {\n        +serialize(path, data, config, save_settings)\n    }</code></pre>"},{"location":"reference/base/base/#module-details","title":"Module Details","text":""},{"location":"reference/base/base/#file_managerpy","title":"file_manager.py","text":"<p>The <code>file_manager.py</code> module provides classes and functions for managing file operations, including path resolution, caching, and loading contexts.</p>"},{"location":"reference/base/base/#key-classes","title":"Key Classes","text":"<ol> <li>ResolveRelativeMode - An enumeration for specifying how relative paths should be resolved:</li> <li><code>ANCHOR</code> - Resolve relative to the anchor path</li> <li> <p><code>DIRECT_PARENT</code> - Resolve relative to the direct parent path</p> </li> <li> <p>FilePathResolver - Handles resolving file paths:</p> </li> <li><code>resolve(path)</code> - Resolves a path using the current context</li> <li><code>push_new_parent(parent_path, relative_mode)</code> - Adds a new parent path to the resolution stack</li> <li> <p><code>pop_last_parent()</code> - Removes the last parent path from the resolution stack</p> </li> <li> <p>PathStyleValidator - Validates path styles:</p> </li> <li> <p><code>validate(path_style)</code> - Validates that a path style is supported</p> </li> <li> <p>ModelLoadSettings - Settings for model loading:</p> </li> <li><code>recurse()</code> - Whether to recursively load referenced models</li> <li><code>resolve_casing()</code> - Whether to resolve file casing</li> <li> <p><code>path_style()</code> - The path style to use</p> </li> <li> <p>CachedFileModel - Represents a cached file model:</p> </li> <li><code>model()</code> - The cached model</li> <li> <p><code>checksum()</code> - The checksum of the file when it was cached</p> </li> <li> <p>FileModelCache - Manages caching of file models:</p> </li> <li><code>retrieve_model(path)</code> - Retrieves a model from the cache</li> <li><code>register_model(path, model)</code> - Registers a model in the cache</li> <li> <p><code>has_changed(path)</code> - Checks if a file has changed since it was cached</p> </li> <li> <p>FileCasingResolver - Resolves file casing issues:</p> </li> <li> <p><code>resolve(path)</code> - Resolves the correct casing for a file path</p> </li> <li> <p>FileLoadContext - Provides context for file loading operations:</p> </li> <li><code>initialize_load_settings(recurse, resolve_casing, path_style)</code> - Initializes load settings</li> <li><code>retrieve_model(path)</code> - Retrieves a model from the cache</li> <li><code>register_model(path, model)</code> - Registers a model in the cache</li> <li><code>resolve(path)</code> - Resolves a path using the current context</li> <li><code>resolve_casing(file_path)</code> - Resolves the correct casing for a file path</li> <li><code>convert_path_style(file_path)</code> - Converts a file path to the specified style</li> </ol>"},{"location":"reference/base/base/#modelspy","title":"models.py","text":"<p>The <code>models.py</code> module provides base model classes for data representation, including file-based models.</p>"},{"location":"reference/base/base/#key-classes_1","title":"Key Classes","text":"<ol> <li>BaseModel - Base class for all models, extending Pydantic's BaseModel:</li> <li><code>is_file_link()</code> - Checks if the model is a file link</li> <li><code>is_intermediate_link()</code> - Checks if the model is an intermediate link</li> <li><code>show_tree(indent)</code> - Displays the model tree</li> <li> <p><code>_apply_recurse(f, *args, **kwargs)</code> - Applies a function recursively to the model tree</p> </li> <li> <p>ModelTreeTraverser - Traverses model trees with customizable behavior:</p> </li> <li> <p><code>traverse(model, acc)</code> - Traverses a model tree, applying functions pre and post traversal</p> </li> <li> <p>ModelSaveSettings - Settings for model saving:</p> </li> <li> <p><code>path_style()</code> - The path style to use for saving</p> </li> <li> <p>FileModel - Abstract base class for models that are loaded from/saved to files:</p> </li> <li><code>save(filepath, recurse, path_style, exclude_unset)</code> - Saves the model to a file</li> <li><code>_save_tree(context, save_settings)</code> - Saves the model tree</li> <li><code>synchronize_filepaths()</code> - Synchronizes file paths in the model tree</li> <li> <p><code>_load(filepath)</code> - Loads the model from a file</p> </li> <li> <p>SerializerConfig - Configuration for serializers</p> </li> <li> <p>ParsableFileModel - File model that can be parsed and serialized:</p> </li> <li><code>_load(filepath)</code> - Loads the model from a file using a parser</li> <li><code>_save(save_settings)</code> - Saves the model to a file using a serializer</li> <li><code>_serialize(data, save_settings)</code> - Serializes the model data</li> <li> <p><code>_parse(path)</code> - Parses a file into model data</p> </li> <li> <p>DiskOnlyFileModel - File model that only exists on disk:</p> </li> <li><code>_load(filepath)</code> - Loads the model from a file (no-op)</li> <li><code>_save(save_settings)</code> - Saves the model to a file (copies the file)</li> </ol>"},{"location":"reference/base/base/#parserpy","title":"parser.py","text":"<p>The <code>parser.py</code> module provides base classes for parsing files.</p>"},{"location":"reference/base/base/#key-classes_2","title":"Key Classes","text":"<ol> <li>BaseParser - Base class for parsers with utility methods:</li> <li><code>_read_header_comments(lines)</code> - Reads header comments from a list of lines</li> <li> <p><code>_raise_error_if_contains_comment(line, line_index)</code> - Raises an error if a line contains comments outside the header</p> </li> <li> <p>DummmyParser - A simple dummy parser implementation:</p> </li> <li><code>parse(filepath)</code> - Parses a file and returns an empty dictionary</li> </ol>"},{"location":"reference/base/base/#serializerpy","title":"serializer.py","text":"<p>The <code>serializer.py</code> module provides base classes for serializing models to files.</p>"},{"location":"reference/base/base/#key-classes_3","title":"Key Classes","text":"<ol> <li>DummySerializer - A simple dummy serializer implementation:</li> <li><code>serialize(path, data, config, save_settings)</code> - Serializes data to a file</li> </ol>"},{"location":"reference/base/base/#utilspy","title":"utils.py","text":"<p>The <code>utils.py</code> module provides utility functions and classes used throughout the library.</p>"},{"location":"reference/base/base/#key-functions","title":"Key Functions","text":"<ol> <li><code>to_key(string)</code> - Converts a string to a key format</li> <li><code>to_list(item)</code> - Converts an item to a list</li> <li><code>str_is_empty_or_none(str_field)</code> - Checks if a string is empty or None</li> <li><code>get_str_len(str_field)</code> - Gets the length of a string, handling None</li> <li><code>get_substring_between(source, start, end)</code> - Extracts a substring between two markers</li> <li><code>operator_str(operator_func)</code> - Converts an operator function to a string representation</li> <li><code>get_operating_system()</code> - Determines the current operating system</li> <li><code>get_path_style_for_current_operating_system()</code> - Gets the path style for the current OS</li> </ol>"},{"location":"reference/base/base/#key-classes_4","title":"Key Classes","text":"<ol> <li>OperatingSystem - Enum for different operating systems:</li> <li><code>WINDOWS</code></li> <li><code>LINUX</code></li> <li> <p><code>MACOS</code></p> </li> <li> <p>PathStyle - Enum for different path styles:</p> </li> <li><code>WINDOWS</code></li> <li> <p><code>POSIX</code></p> </li> <li> <p>FilePathStyleConverter - Converts file paths between different styles:</p> </li> <li><code>convert_to_os_style(file_path, source_path_style)</code> - Converts a file path to the OS style</li> <li> <p><code>convert_from_os_style(file_path, target_path_style)</code> - Converts a file path from the OS style</p> </li> <li> <p>FileChecksumCalculator - Calculates checksums for files:</p> </li> <li> <p><code>calculate_checksum(filepath)</code> - Calculates a checksum for a file</p> </li> <li> <p>FortranUtils - Utilities for handling Fortran-specific formats:</p> </li> <li><code>replace_fortran_scientific_notation(value)</code> - Replaces Fortran scientific notation</li> </ol>"},{"location":"reference/base/base/#workflow-diagrams","title":"Workflow Diagrams","text":""},{"location":"reference/base/base/#file-loading-process","title":"File Loading Process","text":""},{"location":"reference/base/base/#participants","title":"Participants","text":"<ul> <li>Client: The user or system that creates a <code>FileModel</code> instance.</li> <li>FileModel: The main model object to be loaded or parsed.</li> <li>FileLoadContext: Manages loading context and coordinates with the cache.</li> <li>FileModelCache: Stores and retrieves models to reduce redundant loading.</li> <li>Parser: Parses file content when needed.</li> </ul>"},{"location":"reference/base/base/#sequence-steps","title":"Sequence Steps","text":""},{"location":"reference/base/base/#1-initialization","title":"1. Initialization","text":"<pre><code>Client -&gt; FileModel: __init__(filepath)\n</code></pre> <ul> <li>The client creates an instance of <code>FileModel</code> with a given file path.</li> </ul>"},{"location":"reference/base/base/#2-load-settings-and-attempt-retrieval","title":"2. Load Settings and Attempt Retrieval","text":"<pre><code>FileModel -&gt; FileLoadContext: initialize_load_settings()\nFileModel -&gt; FileLoadContext: retrieve_model(filepath)\nFileLoadContext -&gt; FileModelCache: retrieve_model(filepath)\n</code></pre> <ul> <li>The <code>FileModel</code> sets up the loading context.</li> <li>It then tries to retrieve the model from the <code>FileModelCache</code> via the <code>FileLoadContext</code>.</li> </ul>"},{"location":"reference/base/base/#3-cache-handling","title":"3. Cache Handling","text":""},{"location":"reference/base/base/#if-the-model-is-cached-and-unchanged","title":"If the model is cached and unchanged:","text":"<pre><code>FileModelCache --&gt; FileLoadContext: cached_model\nFileLoadContext --&gt; FileModel: cached_model\n</code></pre> <ul> <li>Cached model is reused.</li> </ul>"},{"location":"reference/base/base/#if-the-model-is-not-cached-or-has-changed","title":"If the model is not cached or has changed:","text":"<pre><code>FileLoadContext --&gt; FileModel: None\nFileModel -&gt; FileModel: _load(filepath)\n</code></pre> <ul> <li>The model is reloaded from disk.</li> </ul>"},{"location":"reference/base/base/#4-file-parsing-conditional","title":"4. File Parsing (Conditional)","text":""},{"location":"reference/base/base/#if-the-model-is-a-parsablefilemodel","title":"If the model is a <code>ParsableFileModel</code>:","text":"<pre><code>FileModel -&gt; Parser: parse(filepath)\nParser --&gt; FileModel: parsed_data\n</code></pre> <ul> <li>Parsing is performed by the <code>Parser</code>.</li> </ul>"},{"location":"reference/base/base/#if-the-model-is-a-diskonlyfilemodel","title":"If the model is a <code>DiskOnlyFileModel</code>:","text":"<pre><code>Note over FileModel: No parsing needed\n</code></pre> <ul> <li>No parsing is required.</li> </ul>"},{"location":"reference/base/base/#5-registering-the-model","title":"5. Registering the Model","text":"<pre><code>FileModel -&gt; FileLoadContext: register_model(filepath, self)\nFileLoadContext -&gt; FileModelCache: register_model(filepath, model)\n</code></pre> <ul> <li>The loaded model is registered into the cache.</li> </ul>"},{"location":"reference/base/base/#6-post-initialization","title":"6. Post Initialization","text":"<pre><code>FileModel -&gt; FileModel: _post_init_load()\nFileModel --&gt; Client: model_instance\n</code></pre> <ul> <li>Final loading steps are performed.</li> <li>The model is returned to the client.</li> </ul>"},{"location":"reference/base/base/#summary","title":"Summary","text":"<p>This diagram represents:</p> <ul> <li>Lazy loading of models.</li> <li>Efficient reuse through caching.</li> <li>Conditional parsing for performance.</li> <li>Separation of concerns across components.</li> </ul> <pre><code>sequenceDiagram\n    participant Client\n    participant FileModel\n    participant FileLoadContext\n    participant FileModelCache\n    participant Parser\n\n    Client-&gt;&gt;FileModel: __init__(filepath)\n    FileModel-&gt;&gt;FileLoadContext: initialize_load_settings()\n    FileModel-&gt;&gt;FileLoadContext: retrieve_model(filepath)\n    FileLoadContext-&gt;&gt;FileModelCache: retrieve_model(filepath)\n    alt Model in cache and not changed\n        FileModelCache--&gt;&gt;FileLoadContext: cached_model\n        FileLoadContext--&gt;&gt;FileModel: cached_model\n    else Model not in cache or changed\n        FileLoadContext--&gt;&gt;FileModel: None\n        FileModel-&gt;&gt;FileModel: _load(filepath)\n        alt ParsableFileModel\n            FileModel-&gt;&gt;Parser: parse(filepath)\n            Parser--&gt;&gt;FileModel: parsed_data\n        else DiskOnlyFileModel\n            Note over FileModel: No parsing needed\n        end\n        FileModel-&gt;&gt;FileLoadContext: register_model(filepath, self)\n        FileLoadContext-&gt;&gt;FileModelCache: register_model(filepath, model)\n    end\n    FileModel-&gt;&gt;FileModel: _post_init_load()\n    FileModel--&gt;&gt;Client: model_instance</code></pre>"},{"location":"reference/base/base/#file-saving-process","title":"File Saving Process","text":""},{"location":"reference/base/base/#participants_1","title":"Participants","text":"<ul> <li>Client: The user or system that calls <code>save()</code> on a <code>FileModel</code> instance.</li> <li>FileModel: The object responsible for managing and saving model data.</li> <li>FileLoadContext: Provides contextual information needed during save operations.</li> <li>Serializer: Handles the actual serialization of data to disk.</li> </ul>"},{"location":"reference/base/base/#sequence-steps_1","title":"Sequence Steps","text":""},{"location":"reference/base/base/#1-saving-triggered","title":"1. Saving Triggered","text":"<pre><code>Client -&gt; FileModel: save(filepath, recurse)\n</code></pre> <ul> <li>The client initiates the save process.</li> </ul>"},{"location":"reference/base/base/#2-prepare-to-save","title":"2. Prepare to Save","text":"<pre><code>FileModel -&gt; FileModel: _save_tree(context, save_settings)\n</code></pre> <ul> <li>Internal method <code>_save_tree</code> is called with the context and settings.</li> </ul>"},{"location":"reference/base/base/#3-saving-each-model","title":"3. Saving Each Model","text":"<pre><code>loop For each model in tree\n    FileModel -&gt; FileModel: _save_instance(save_settings)\n</code></pre> <ul> <li>Each model in the save tree is saved individually.</li> </ul>"},{"location":"reference/base/base/#if-the-model-is-a-parsablefilemodel_1","title":"If the model is a <code>ParsableFileModel</code>:","text":"<pre><code>FileModel -&gt; FileModel: _serialize(data, save_settings)\nFileModel -&gt; Serializer: serialize(path, data, config, save_settings)\n</code></pre> <ul> <li>Data is serialized using internal logic and then saved via the <code>Serializer</code>.</li> </ul>"},{"location":"reference/base/base/#if-the-model-is-a-diskonlyfilemodel_1","title":"If the model is a <code>DiskOnlyFileModel</code>:","text":"<pre><code>FileModel -&gt; FileModel: _can_copy_to(target_file_path)\n</code></pre> <ul> <li>Checks whether the model file can be copied directly.</li> </ul>"},{"location":"reference/base/base/#if-the-file-can-be-copied","title":"If the file can be copied:","text":"<pre><code>FileModel -&gt; FileModel: shutil.copy2(source, target)\n</code></pre> <ul> <li>The file is copied using <code>shutil.copy2()</code>.</li> </ul>"},{"location":"reference/base/base/#4-completion","title":"4. Completion","text":"<pre><code>FileModel --&gt; Client: None\n</code></pre> <ul> <li>The save operation completes and control returns to the client.</li> </ul>"},{"location":"reference/base/base/#summary_1","title":"Summary","text":"<p>This diagram represents:</p> <ul> <li>Recursive saving of model trees.</li> <li>Dynamic behavior depending on model type.</li> <li>Use of serializers for parsable models.</li> <li>Direct file operations for disk-only models.</li> </ul> <pre><code>sequenceDiagram\n    participant Client\n    participant FileModel\n    participant FileLoadContext\n    participant Serializer\n\n    Client-&gt;&gt;FileModel: save(filepath, recurse)\n    FileModel-&gt;&gt;FileModel: _save_tree(context, save_settings)\n    loop For each model in tree\n        FileModel-&gt;&gt;FileModel: _save_instance(save_settings)\n        alt ParsableFileModel\n            FileModel-&gt;&gt;FileModel: _serialize(data, save_settings)\n            FileModel-&gt;&gt;Serializer: serialize(path, data, config, save_settings)\n        else DiskOnlyFileModel\n            FileModel-&gt;&gt;FileModel: _can_copy_to(target_file_path)\n            alt Can copy\n                FileModel-&gt;&gt;FileModel: shutil.copy2(source, target)\n            end\n        end\n    end\n    FileModel--&gt;&gt;Client: None</code></pre>"},{"location":"reference/base/base/#model-tree-traversal","title":"Model Tree Traversal","text":"<pre><code>flowchart TD\n    A[Start Traversal] --&gt; B{Should Traverse?}\n    B --&gt;|Yes| C[Pre-Traverse Function]\n    B --&gt;|No| J[Return Accumulator]\n    C --&gt; D[Process Model]\n    D --&gt; E[Get Child Models]\n    E --&gt; F{More Children?}\n    F --&gt;|Yes| G[Traverse Child]\n    G --&gt; F\n    F --&gt;|No| H[Post-Traverse Function]\n    H --&gt; J</code></pre>"},{"location":"reference/base/base/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/base/base/#loading-a-model-from-a-file","title":"Loading a Model from a File","text":"<pre><code>from hydrolib.core.base.models import ParsableFileModel\nfrom pathlib import Path\n\nclass MyModel(ParsableFileModel):\n    # Define model fields here\n\n    @classmethod\n    def _get_parser(cls):\n        # Return a parser for this model\n        return MyParser()\n\n    @classmethod\n    def _get_serializer(cls):\n        # Return a serializer for this model\n        return MySerializer()\n\n# Load a model from a file\nmodel = MyModel(filepath=Path(\"path/to/file.ext\"))\n</code></pre>"},{"location":"reference/base/base/#saving-a-model-to-a-file","title":"Saving a Model to a File","text":"<pre><code># Save a model to a file\nmodel.save(filepath=Path(\"path/to/output.ext\"), recurse=True)\n</code></pre>"},{"location":"reference/base/base/#traversing-a-model-tree","title":"Traversing a Model Tree","text":"<pre><code>from hydrolib.core.base.models import ModelTreeTraverser\n\n# Define a function to execute on each model\ndef process_model(model, accumulator):\n    # Process the model\n    return accumulator\n\n# Create a traverser\ntraverser = ModelTreeTraverser(\n    pre_traverse_func=process_model,\n    post_traverse_func=None\n)\n\n# Traverse the model tree\nresult = traverser.traverse(model, initial_accumulator)\n</code></pre>"},{"location":"reference/base/base/#conclusion","title":"Conclusion","text":"<p>The <code>hydrolib.core.base</code> module provides the foundation for the HYDROLIB-core library, with a focus on file-based models that can be loaded, parsed, and saved. The module's design allows for flexible handling of different file formats and model structures, with support for caching, path resolution, and tree traversal.</p>"},{"location":"reference/base/model-tree-traverser/","title":"ModelTreeTraverser","text":""},{"location":"reference/base/model-tree-traverser/#overview","title":"Overview","text":"<p>The <code>ModelTreeTraverser</code> is a powerful utility class in HYDROLIB-core that enables traversal of a model tree consisting of <code>BaseModel</code> objects. It provides a flexible way to execute custom functions during traversal, with control over which models to traverse and which functions to execute.</p> <p>The traverser is designed to be generic, allowing for different types of accumulator objects to be passed through the traversal process. This accumulator can be used to collect information, build output values, or maintain state during traversal.</p>"},{"location":"reference/base/model-tree-traverser/#class-definition","title":"Class Definition","text":"<pre><code>class ModelTreeTraverser(Generic[TAcc]):\n    def __init__(\n        self,\n        should_traverse: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n        should_execute: Optional[Callable[[BaseModel, TAcc], bool]] = None,\n        pre_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n        post_traverse_func: Optional[Callable[[BaseModel, TAcc], TAcc]] = None,\n    ):\n        # ...\n</code></pre> <p>Where: - <code>TAcc</code> is a generic type parameter representing the accumulator type - <code>should_traverse</code> is a function that determines whether to traverse to a given model - <code>should_execute</code> is a function that determines whether to execute the traverse functions for a given model - <code>pre_traverse_func</code> is a function executed before traversing into child models (top-down) - <code>post_traverse_func</code> is a function executed after traversing into child models (bottom-up)</p>"},{"location":"reference/base/model-tree-traverser/#key-features","title":"Key Features","text":""},{"location":"reference/base/model-tree-traverser/#generic-accumulator","title":"Generic Accumulator","text":"<p>The <code>ModelTreeTraverser</code> uses a generic type parameter <code>TAcc</code> to define the type of accumulator that will be passed through the traversal. This allows for flexibility in what data is collected or maintained during traversal.</p>"},{"location":"reference/base/model-tree-traverser/#customizable-traversal-behavior","title":"Customizable Traversal Behavior","text":"<p>The traversal behavior can be customized through two predicate functions:</p> <ol> <li><code>should_traverse</code>: Determines whether to traverse to a given model. If not provided, all <code>BaseModel</code> objects will be traversed.</li> <li><code>should_execute</code>: Determines whether to execute the traverse functions for a given model. If not provided, traverse functions will be executed for all models.</li> </ol>"},{"location":"reference/base/model-tree-traverser/#pre-and-post-traversal-functions","title":"Pre and Post Traversal Functions","text":"<p>The traverser supports two types of traversal functions:</p> <ol> <li><code>pre_traverse_func</code>: Executed before traversing into child models, enabling top-down traversal.</li> <li><code>post_traverse_func</code>: Executed after traversing into child models, enabling bottom-up traversal.</li> </ol> <p>Both functions receive the current model and accumulator as arguments and should return the (potentially modified) accumulator.</p>"},{"location":"reference/base/model-tree-traverser/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/base/model-tree-traverser/#basic-usage","title":"Basic Usage","text":"<pre><code>from hydrolib.core.basemodel import ModelTreeTraverser, BaseModel\n\n\n# Create a simple accumulator to count models\ndef count_models(model: BaseModel, count: int) -&gt; int:\n    return count + 1\n\n# Create a traverser that counts all models\ntraverser = ModelTreeTraverser[int](\n    post_traverse_func=count_models,\n)\n\n# Start traversal with an initial count of 0\ntotal_models = traverser.traverse(root_model, 0)\nprint(f\"Total models: {total_models}\")\n</code></pre>"},{"location":"reference/base/model-tree-traverser/#filtering-models","title":"Filtering Models","text":"<pre><code>from hydrolib.core.basemodel import ModelTreeTraverser, BaseModel, FileModel\n\n\n# Only traverse FileModel objects\ndef is_file_model(model: BaseModel, acc: list) -&gt; bool:\n    return isinstance(model, FileModel)\n\n# Collect all FileModel objects\ndef collect_file_model(model: BaseModel, models: list) -&gt; list:\n    models.append(model)\n    return models\n\n# Create a traverser that collects only FileModel objects\ntraverser = ModelTreeTraverser[list](\n    should_traverse=is_file_model,\n    should_execute=is_file_model,\n    post_traverse_func=collect_file_model,\n)\n\n# Start traversal with an empty list\nfile_models = traverser.traverse(root_model, [])\n</code></pre>"},{"location":"reference/base/model-tree-traverser/#complex-traversal-with-state","title":"Complex Traversal with State","text":"<pre><code>from hydrolib.core.basemodel import ModelTreeTraverser, BaseModel, FileModel\n\n\n# Define an accumulator type with state\nclass TraversalState:\n\n    def __init__(self):\n        self.depth = 0\n        self.results = {}\n\n# Pre-traversal function that increases depth\ndef enter_model(model: BaseModel, state: TraversalState) -&gt; TraversalState:\n    state.depth += 1\n    return state\n\n# Post-traversal function that decreases depth and records information\ndef exit_model(model: BaseModel, state: TraversalState) -&gt; TraversalState:\n    if isinstance(model, FileModel) and model.filepath is not None:\n        state.results[str(model.filepath)] = {\n            \"depth\": state.depth,\n            \"type\": type(model).__name__,\n        }\n    state.depth -= 1\n    return state\n\n# Create a traverser with both pre and post functions\ntraverser = ModelTreeTraverser[TraversalState](\n    pre_traverse_func=enter_model,\n    post_traverse_func=exit_model,\n)\n\n# Start traversal with a new state object\nstate = TraversalState()\nfinal_state = traverser.traverse(root_model, state)\n\n# Access the collected results\nfor path, info in final_state.results.items():\n    print(f\"{path}: {info['type']} at depth {info['depth']}\")\n</code></pre>"},{"location":"reference/base/model-tree-traverser/#common-use-cases-in-hydrolib-core","title":"Common Use Cases in HYDROLIB-core","text":"<p>The <code>ModelTreeTraverser</code> is used in several key areas of HYDROLIB-core:</p> <ol> <li>Generating Names: Ensuring all models in a tree have valid file paths before saving.</li> <li>Saving Models: Traversing the model tree to save each model to disk.</li> <li>Synchronizing File Paths: Updating the save locations of child models when a parent model's path changes.</li> </ol>"},{"location":"reference/base/model-tree-traverser/#implementation-details","title":"Implementation Details","text":""},{"location":"reference/base/model-tree-traverser/#traversal-algorithm","title":"Traversal Algorithm","text":"<p>The traversal algorithm is a depth-first search that:</p> <ol> <li>Optionally executes the pre-traverse function on the current model</li> <li>Iterates through all attributes of the current model</li> <li>For each attribute that is a BaseModel or a list containing BaseModels, recursively traverses those models if the should_traverse predicate allows it</li> <li>Optionally executes the post-traverse function on the current model after all children have been traversed</li> </ol>"},{"location":"reference/base/model-tree-traverser/#handling-lists-and-nested-structures","title":"Handling Lists and Nested Structures","text":"<p>The traverser automatically handles both direct BaseModel attributes and lists containing BaseModel objects. This allows it to work with the complex nested structures common in HYDROLIB-core models.</p>"},{"location":"reference/base/model-tree-traverser/#best-practices","title":"Best Practices","text":"<ol> <li>Keep Traverse Functions Pure: Traverse functions should primarily modify the accumulator, not the models themselves, to maintain predictable behavior.</li> <li>Use Type Hints: Always specify the accumulator type parameter to ensure type safety.</li> <li>Consider Performance: For large model trees, be selective about which models to traverse using the should_traverse predicate.</li> <li>Handle Errors Gracefully: Traverse functions should handle potential errors to prevent traversal from being interrupted.</li> </ol>"},{"location":"reference/models/crosssection/","title":"Cross section files","text":"<p>The crosssection module provides the specific logic for accessing cross section files (location and definition) for a D-Flow FM model. Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>The cross section files are represented by the classes below.</p>"},{"location":"reference/models/crosssection/#model","title":"Model","text":"<p>Cross section models for D-Flow FM.</p>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CircleCrsDef","title":"<code>CircleCrsDef</code>","text":"<p>               Bases: <code>CrossSectionDefinition</code></p> <p>CircleCrsDef.</p> <p>Crosssection definition with <code>type=circle</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the circle input as described in UM Sec.C.16.1.1.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CircleCrsDef(CrossSectionDefinition):\n    \"\"\"CircleCrsDef.\n\n    Crosssection definition with `type=circle`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the circle input as described in\n    [UM Sec.C.16.1.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.1).\n    \"\"\"\n\n    class Comments(CrossSectionDefinition.Comments):\n        \"\"\"Comments for the CircleCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\"Cross section type; must read circle\")\n\n        diameter: Optional[str] = Field(\"Internal diameter of the circle [m].\")\n        frictionid: Optional[str] = Field(\n            frictionid_description,\n            alias=\"frictionId\",\n        )\n        frictiontype: Optional[str] = Field(\n            frictiontype_description,\n            alias=\"frictionType\",\n        )\n        frictionvalue: Optional[str] = Field(\n            frictionvalue_description,\n            alias=\"frictionValue\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"circle\"] = Field(\"circle\")\n    diameter: float\n    frictionid: Optional[str] = Field(alias=\"frictionId\")\n    frictiontype: Optional[FrictionType] = Field(alias=\"frictionType\")\n    frictionvalue: Optional[float] = Field(alias=\"frictionValue\")\n\n    _friction_validator = CrossSectionDefinition._get_friction_root_validator(\n        \"frictionid\", \"frictiontype\", \"frictionvalue\"\n    )\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CircleCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the CircleCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(CrossSectionDefinition.Comments):\n    \"\"\"Comments for the CircleCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\"Cross section type; must read circle\")\n\n    diameter: Optional[str] = Field(\"Internal diameter of the circle [m].\")\n    frictionid: Optional[str] = Field(\n        frictionid_description,\n        alias=\"frictionId\",\n    )\n    frictiontype: Optional[str] = Field(\n        frictiontype_description,\n        alias=\"frictionType\",\n    )\n    frictionvalue: Optional[str] = Field(\n        frictionvalue_description,\n        alias=\"frictionValue\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossDefGeneral","title":"<code>CrossDefGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The crosssection definition file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossDefGeneral(INIGeneral):\n    \"\"\"The crosssection definition file's `[General]` section with file meta data.\"\"\"\n\n    fileversion: str = Field(\"3.00\", alias=\"fileVersion\")\n    filetype: Literal[\"crossDef\"] = Field(\"crossDef\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossDefModel","title":"<code>CrossDefModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall crosssection definition model that contains the contents of one crossdef file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.crossdeffile</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>CrossdefGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>definition</code> <code>List[CrossSectionDefinition]</code> <p>List of <code>[Definition]</code> blocks for all cross sections.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossDefModel(INIModel):\n    \"\"\"\n    The overall crosssection definition model that contains the contents of one crossdef file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile`.\n\n    Attributes:\n        general (CrossdefGeneral): `[General]` block with file metadata.\n        definition (List[CrossSectionDefinition]): List of `[Definition]` blocks for all cross sections.\n    \"\"\"\n\n    general: CrossDefGeneral = CrossDefGeneral()\n    definition: List[CrossSectionDefinition] = []\n\n    _make_list = make_list_validator(\"definition\")\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"crsdef\"\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossLocGeneral","title":"<code>CrossLocGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The crosssection location file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossLocGeneral(INIGeneral):\n    \"\"\"The crosssection location file's `[General]` section with file meta data.\"\"\"\n\n    fileversion: str = Field(\"3.00\", alias=\"fileVersion\")\n    filetype: Literal[\"crossLoc\"] = Field(\"crossLoc\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossLocModel","title":"<code>CrossLocModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall crosssection location model that contains the contents of one crossloc file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.crosslocfile</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>CrossLocGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>crosssection</code> <code>List[CrossSection]</code> <p>List of <code>[CrossSection]</code> blocks for all cross-section locations, The crosssection attribute also accepts single cross section.</p> <p>Examples:</p> <ul> <li> <p>Create the read <code>CrossLocModel</code> class from file. <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.crosssection.models import CrossLocModel\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; path = Path(\"examples/data/crsloc.ini\")\n&gt;&gt;&gt; crossloc_model = CrossLocModel(path)\n&gt;&gt;&gt; print(len(crossloc_model.crosssection))\n2\n&gt;&gt;&gt; print(crossloc_model.crosssection[0])\ncomments=Comments(id=None, branchid=None, chainage=None, x='x-coordinate of the location of the cross section.', y='y-coordinate of the location of the cross section.', shift=None, definitionid=None) id='Channel1_50.000' branchid='Channel1' chainage=50.0 x=None y=None shift=1.0 definitionid='Prof1'\n</code></pre></p> </li> <li> <p>Create the <code>CrossLocModel</code> class by providing values for the <code>crosssection</code> attribute. <pre><code>&gt;&gt;&gt; data = {\n...    \"id\": 99,\n...    \"branchId\": 9,\n...    \"chainage\": 403,\n...    \"shift\": 0.0,\n...    \"definitionId\": 99\n... }\n&gt;&gt;&gt; cross_section = CrossSection(**data)\n&gt;&gt;&gt; crossloc = CrossLocModel(crosssection=cross_section)\n&gt;&gt;&gt; type(crossloc.crosssection)\n&lt;class 'list'&gt;\n&gt;&gt;&gt; len(crossloc.crosssection)\n1\n</code></pre></p> </li> <li> <p>Create the <code>CrossLocModel</code> class by providing values as a dictionary. <pre><code>&gt;&gt;&gt; data = {\n...     \"crosssection\": {\n...         \"id\": 99,\n...         \"branchId\": 9,\n...         \"chainage\": 403.089709,\n...         \"shift\": 0.0,\n...         \"definitionId\": 99,\n...     }\n... }\n&gt;&gt;&gt; crossloc = CrossLocModel(**data)\n&gt;&gt;&gt; print(crossloc.crosssection)\n[CrossSection(comments=Comments(id='Unique cross-section location id.', branchid='Branch on which the cross section is located.', chainage='Chainage on the branch (m).', x='x-coordinate of the location of the cross section.', y='y-coordinate of the location of the cross section.', shift='Vertical shift of the cross section definition [m]. Defined positive upwards.', definitionid='Id of cross section definition.'), id='99', branchid='9', chainage=403.089709, x=None, y=None, shift=0.0, definitionid='99')]\n</code></pre></p> </li> </ul> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossLocModel(INIModel):\n    \"\"\"The overall crosssection location model that contains the contents of one crossloc file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crosslocfile`.\n\n    Attributes:\n        general (CrossLocGeneral):\n            `[General]` block with file metadata.\n        crosssection (List[CrossSection]):\n            List of `[CrossSection]` blocks for all cross-section locations, The crosssection attribute also accepts\n            single cross section.\n\n    Examples:\n        - Create the read `CrossLocModel` class from file.\n        ```python\n        &gt;&gt;&gt; from hydrolib.core.dflowfm.crosssection.models import CrossLocModel\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; path = Path(\"examples/data/crsloc.ini\")\n        &gt;&gt;&gt; crossloc_model = CrossLocModel(path)\n        &gt;&gt;&gt; print(len(crossloc_model.crosssection))\n        2\n        &gt;&gt;&gt; print(crossloc_model.crosssection[0])\n        comments=Comments(id=None, branchid=None, chainage=None, x='x-coordinate of the location of the cross section.', y='y-coordinate of the location of the cross section.', shift=None, definitionid=None) id='Channel1_50.000' branchid='Channel1' chainage=50.0 x=None y=None shift=1.0 definitionid='Prof1'\n\n        ```\n\n        - Create the `CrossLocModel` class by providing values for the `crosssection` attribute.\n        ```python\n        &gt;&gt;&gt; data = {\n        ...    \"id\": 99,\n        ...    \"branchId\": 9,\n        ...    \"chainage\": 403,\n        ...    \"shift\": 0.0,\n        ...    \"definitionId\": 99\n        ... }\n        &gt;&gt;&gt; cross_section = CrossSection(**data)\n        &gt;&gt;&gt; crossloc = CrossLocModel(crosssection=cross_section)\n        &gt;&gt;&gt; type(crossloc.crosssection)\n        &lt;class 'list'&gt;\n        &gt;&gt;&gt; len(crossloc.crosssection)\n        1\n\n        ```\n\n        - Create the `CrossLocModel` class by providing values as a dictionary.\n        ```python\n        &gt;&gt;&gt; data = {\n        ...     \"crosssection\": {\n        ...         \"id\": 99,\n        ...         \"branchId\": 9,\n        ...         \"chainage\": 403.089709,\n        ...         \"shift\": 0.0,\n        ...         \"definitionId\": 99,\n        ...     }\n        ... }\n        &gt;&gt;&gt; crossloc = CrossLocModel(**data)\n        &gt;&gt;&gt; print(crossloc.crosssection)\n        [CrossSection(comments=Comments(id='Unique cross-section location id.', branchid='Branch on which the cross section is located.', chainage='Chainage on the branch (m).', x='x-coordinate of the location of the cross section.', y='y-coordinate of the location of the cross section.', shift='Vertical shift of the cross section definition [m]. Defined positive upwards.', definitionid='Id of cross section definition.'), id='99', branchid='9', chainage=403.089709, x=None, y=None, shift=0.0, definitionid='99')]\n\n        ```\n    \"\"\"\n\n    general: CrossLocGeneral = CrossLocGeneral()\n    crosssection: List[CrossSection] = Field(default_factory=list)\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"crsloc\"\n\n    @validator(\"crosssection\", pre=True, always=True)\n    def ensure_crosssection_is_list(cls, v):\n        \"\"\"Converting the crosssection to a list if it is not already a list.\"\"\"\n        if isinstance(v, list):\n            return v\n        elif v is None:\n            return []\n        return [v]\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossLocModel.ensure_crosssection_is_list","title":"<code>ensure_crosssection_is_list(v)</code>","text":"<p>Converting the crosssection to a list if it is not already a list.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@validator(\"crosssection\", pre=True, always=True)\ndef ensure_crosssection_is_list(cls, v):\n    \"\"\"Converting the crosssection to a list if it is not already a list.\"\"\"\n    if isinstance(v, list):\n        return v\n    elif v is None:\n        return []\n    return [v]\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSection","title":"<code>CrossSection</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>Crosssection.</p> <p>A <code>[CrossSection]</code> block for use inside a crosssection location file, i.e., a CrossLocModel.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique cross-section location id.</p> <code>branchid</code> <code>str</code> <p>Branch on which the cross section is located.</p> <code>chainage</code> <code>str</code> <p>Chainage on the branch (m).</p> <code>x</code> <code>str</code> <p>x-coordinate of the location of the cross section.</p> <code>y</code> <code>str</code> <p>y-coordinate of the location of the cross section.</p> <code>shift</code> <code>float</code> <p>Vertical shift of the cross section definition [m]. Defined positive upwards.</p> <code>definitionid</code> <code>str</code> <p>Id of cross section definition.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossSection(INIBasedModel):\n    \"\"\"Crosssection.\n\n    A `[CrossSection]` block for use inside a crosssection location file,\n    i.e., a [CrossLocModel][hydrolib.core.dflowfm.crosssection.models.CrossLocModel].\n\n    Attributes:\n        id (str): Unique cross-section location id.\n        branchid (str, optional): Branch on which the cross section is located.\n        chainage (str, optional): Chainage on the branch (m).\n        x (str, optional): x-coordinate of the location of the cross section.\n        y (str, optional): y-coordinate of the location of the cross section.\n        shift (float, optional): Vertical shift of the cross section definition [m]. Defined positive upwards.\n        definitionid (str): Id of cross section definition.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        \"\"\"Comments for the CrossSection class.\"\"\"\n\n        id: Optional[str] = \"Unique cross-section location id.\"\n        branchid: Optional[str] = Field(\n            \"Branch on which the cross section is located.\", alias=\"branchId\"\n        )\n        chainage: Optional[str] = \"Chainage on the branch (m).\"\n\n        x: Optional[str] = Field(\n            \"x-coordinate of the location of the cross section.\",\n        )\n        y: Optional[str] = Field(\n            \"y-coordinate of the location of the cross section.\",\n        )\n        shift: Optional[str] = Field(\n            \"Vertical shift of the cross section definition [m]. Defined positive upwards.\",\n        )\n        definitionid: Optional[str] = Field(\n            \"Id of cross section definition.\", alias=\"definitionId\"\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"CrossSection\"] = \"CrossSection\"\n    id: str = Field(alias=\"id\")\n\n    branchid: Optional[str] = Field(None, alias=\"branchId\")\n    chainage: Optional[float] = Field(None)\n\n    x: Optional[float] = Field(None)\n    y: Optional[float] = Field(None)\n\n    shift: Optional[float] = Field(0.0)\n    definitionid: str = Field(alias=\"definitionId\")\n\n    @root_validator(allow_reuse=True)\n    def validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validate that the correct location specification is given.\"\"\"\n        return validate_location_specification(\n            values,\n            config=LocationValidationConfiguration(\n                validate_node=False,\n                validate_num_coordinates=False,\n                validate_location_type=False,\n            ),\n            fields=LocationValidationFieldNames(x_coordinates=\"x\", y_coordinates=\"y\"),\n        )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSection.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the CrossSection class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(INIBasedModel.Comments):\n    \"\"\"Comments for the CrossSection class.\"\"\"\n\n    id: Optional[str] = \"Unique cross-section location id.\"\n    branchid: Optional[str] = Field(\n        \"Branch on which the cross section is located.\", alias=\"branchId\"\n    )\n    chainage: Optional[str] = \"Chainage on the branch (m).\"\n\n    x: Optional[str] = Field(\n        \"x-coordinate of the location of the cross section.\",\n    )\n    y: Optional[str] = Field(\n        \"y-coordinate of the location of the cross section.\",\n    )\n    shift: Optional[str] = Field(\n        \"Vertical shift of the cross section definition [m]. Defined positive upwards.\",\n    )\n    definitionid: Optional[str] = Field(\n        \"Id of cross section definition.\", alias=\"definitionId\"\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSection.validate_that_location_specification_is_correct","title":"<code>validate_that_location_specification_is_correct(values)</code>","text":"<p>Validate that the correct location specification is given.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n    \"\"\"Validate that the correct location specification is given.\"\"\"\n    return validate_location_specification(\n        values,\n        config=LocationValidationConfiguration(\n            validate_node=False,\n            validate_num_coordinates=False,\n            validate_location_type=False,\n        ),\n        fields=LocationValidationFieldNames(x_coordinates=\"x\", y_coordinates=\"y\"),\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSectionDefinition","title":"<code>CrossSectionDefinition</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>CrossSectionDefinition.</p> <p>A <code>[Definition]</code> block for use inside a crosssection definition file, i.e., a CrossDefModel.</p> <p>This class is intended as an abstract class: various subclasses should define they actual types of crosssection definitions.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class CrossSectionDefinition(INIBasedModel):\n    \"\"\"CrossSectionDefinition.\n\n    A `[Definition]` block for use inside a crosssection definition file,\n    i.e., a [CrossDefModel][hydrolib.core.dflowfm.crosssection.models.CrossDefModel].\n\n    This class is intended as an abstract class: various subclasses should\n    define they actual types of crosssection definitions.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        \"\"\"Comments for the CrossSectionDefinition class.\"\"\"\n\n        id: Optional[str] = \"Unique cross-section definition id.\"\n        thalweg: Optional[str] = Field(\n            \"Transverse Y coordinate at which the cross section aligns with the branch (Keyword used by GUI only).\"\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Definition\"] = \"Definition\"\n\n    id: str = Field(alias=\"id\")\n    type: str = Field(alias=\"type\")\n    thalweg: Optional[float]\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"The CrossSectionDefinition does not currently support raising an error on unknown keywords.\"\"\"\n        return None\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\")\n\n    @classmethod\n    def _duplicate_keys_as_list(cls):\n        return True\n\n    @validator(\"type\", pre=True)\n    def _validate_type(cls, value):\n        return get_from_subclass_defaults(CrossSectionDefinition, \"type\", value)\n\n    @classmethod\n    def validate(cls, v):\n        \"\"\"Initialize subclass based on the `type` field.\n\n        This field is compared to each `type` field of the derived models of `CrossSectionDefinition`.\n        The derived model with an equal crosssection definition type will be initialized.\n\n        Raises:\n            ValueError: When the given type is not a known crosssection definition type.\n        \"\"\"\n        # should be replaced by discriminated unions once merged\n        # https://github.com/samuelcolvin/pydantic/pull/2336\n        if isinstance(v, dict):\n            for c in cls.__subclasses__():\n                if (\n                    c.__fields__.get(\"type\").default.lower()\n                    == v.get(\"type\", \"\").lower()\n                ):\n                    v = c(**v)\n                    break\n            else:\n                raise ValueError(\n                    f\"Type of {cls.__name__} with id={v.get('id', '')} and type={v.get('type', '')} is not recognized.\"\n                )\n        return super().validate(v)\n\n    @staticmethod\n    def _get_friction_root_validator(\n        frictionid_attr: str,\n        frictiontype_attr: str,\n        frictionvalue_attr: str,\n    ):\n        \"\"\"Get a root_validator for the friction specification.\n\n        Make a root_validator that verifies whether the crosssection definition (subclass)\n        has a valid friction specification.\n        Supposed to be embedded in subclasses for their friction fields.\n\n        Args:\n            frictionid_attr: name of the frictionid attribute in the subclass.\n            frictiontype_attr: name of the frictiontype attribute in the subclass.\n            frictionvalue_attr: name of the frictionvalue attribute in the subclass.\n\n        Returns:\n            root_validator: to be embedded in the subclass that needs it.\n        \"\"\"\n\n        def validate_friction_specification(cls, values):\n            \"\"\"Validate the friction specification.\n\n            The actual validator function.\n\n            Args:\n                cls: The subclass for which the root_validator is called.\n                values (dict): Dictionary of values to create a CrossSectionDefinition subclass.\n            \"\"\"\n            frictionid = values.get(frictionid_attr) or \"\"\n            frictiontype = values.get(frictiontype_attr) or \"\"\n            frictionvalue = values.get(frictionvalue_attr) or \"\"\n\n            if frictionid != \"\" and (frictiontype != \"\" or frictionvalue != \"\"):\n                raise ValueError(\n                    f\"Cross section has duplicate friction specification (both {frictionid_attr} and {frictiontype_attr}/{frictionvalue_attr}).\"\n                )\n\n            return values\n\n        return root_validator(allow_reuse=True)(validate_friction_specification)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSectionDefinition.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the CrossSectionDefinition class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(INIBasedModel.Comments):\n    \"\"\"Comments for the CrossSectionDefinition class.\"\"\"\n\n    id: Optional[str] = \"Unique cross-section definition id.\"\n    thalweg: Optional[str] = Field(\n        \"Transverse Y coordinate at which the cross section aligns with the branch (Keyword used by GUI only).\"\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.CrossSectionDefinition.validate","title":"<code>validate(v)</code>  <code>classmethod</code>","text":"<p>Initialize subclass based on the <code>type</code> field.</p> <p>This field is compared to each <code>type</code> field of the derived models of <code>CrossSectionDefinition</code>. The derived model with an equal crosssection definition type will be initialized.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the given type is not a known crosssection definition type.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@classmethod\ndef validate(cls, v):\n    \"\"\"Initialize subclass based on the `type` field.\n\n    This field is compared to each `type` field of the derived models of `CrossSectionDefinition`.\n    The derived model with an equal crosssection definition type will be initialized.\n\n    Raises:\n        ValueError: When the given type is not a known crosssection definition type.\n    \"\"\"\n    # should be replaced by discriminated unions once merged\n    # https://github.com/samuelcolvin/pydantic/pull/2336\n    if isinstance(v, dict):\n        for c in cls.__subclasses__():\n            if (\n                c.__fields__.get(\"type\").default.lower()\n                == v.get(\"type\", \"\").lower()\n            ):\n                v = c(**v)\n                break\n        else:\n            raise ValueError(\n                f\"Type of {cls.__name__} with id={v.get('id', '')} and type={v.get('type', '')} is not recognized.\"\n            )\n    return super().validate(v)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.RectangleCrsDef","title":"<code>RectangleCrsDef</code>","text":"<p>               Bases: <code>CrossSectionDefinition</code></p> <p>RectangleCrsDef.</p> <p>Crosssection definition with <code>type=rectangle</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the rectangle input as described in UM Sec.C.16.1.2.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class RectangleCrsDef(CrossSectionDefinition):\n    \"\"\"RectangleCrsDef.\n\n    Crosssection definition with `type=rectangle`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the rectangle input as described in\n    [UM Sec.C.16.1.2](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.2).\n    \"\"\"\n\n    class Comments(CrossSectionDefinition.Comments):\n        \"\"\"Comments for the RectangleCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\"Cross section type; must read rectangle\")\n        width: Optional[str] = Field(\"Width of the rectangle [m].\")\n        height: Optional[str] = Field(\"Height of the rectangle [m].\")\n        closed: Optional[str] = Field(\"no: Open channel, yes: Closed channel.\")\n        frictionid: Optional[str] = Field(\n            frictionid_description,\n            alias=\"frictionId\",\n        )\n        frictiontype: Optional[str] = Field(\n            frictiontype_description,\n            alias=\"frictionType\",\n        )\n        frictionvalue: Optional[str] = Field(\n            frictionvalue_description,\n            alias=\"frictionValue\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"rectangle\"] = Field(\"rectangle\")\n    width: float\n    height: float\n    closed: bool = Field(True)\n    frictionid: Optional[str] = Field(alias=\"frictionId\")\n    frictiontype: Optional[FrictionType] = Field(alias=\"frictionType\")\n    frictionvalue: Optional[float] = Field(alias=\"frictionValue\")\n\n    _friction_validator = CrossSectionDefinition._get_friction_root_validator(\n        \"frictionid\", \"frictiontype\", \"frictionvalue\"\n    )\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.RectangleCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the RectangleCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(CrossSectionDefinition.Comments):\n    \"\"\"Comments for the RectangleCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\"Cross section type; must read rectangle\")\n    width: Optional[str] = Field(\"Width of the rectangle [m].\")\n    height: Optional[str] = Field(\"Height of the rectangle [m].\")\n    closed: Optional[str] = Field(\"no: Open channel, yes: Closed channel.\")\n    frictionid: Optional[str] = Field(\n        frictionid_description,\n        alias=\"frictionId\",\n    )\n    frictiontype: Optional[str] = Field(\n        frictiontype_description,\n        alias=\"frictionType\",\n    )\n    frictionvalue: Optional[str] = Field(\n        frictionvalue_description,\n        alias=\"frictionValue\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.XYZCrsDef","title":"<code>XYZCrsDef</code>","text":"<p>               Bases: <code>YZCrsDef</code>, <code>CrossSectionDefinition</code></p> <p>XYZCrsDef.</p> <p>Crosssection definition with <code>type=xyz</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the xyz input as described in UM Sec.C.16.1.5.</p> <p>This class extends the YZCrsDef class with x-coordinates and an optional branchId field. Most other attributes are inherited, but the coordcount is overridden under the Pydantic alias \"xyzCount\".</p> <p>Attributes:</p> Name Type Description <code>yzcount</code> <code>Optional[int]</code> <p>dummy attribute that should not be set nor used. Only present to mask the inherited attribute from parent class YZCrsDef.</p> <code>xyzcount</code> <code>int</code> <p>Number of XYZ-coordinates. Always use this instead of yzcount.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class XYZCrsDef(YZCrsDef, CrossSectionDefinition):\n    \"\"\"XYZCrsDef.\n\n    Crosssection definition with `type=xyz`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the xyz input as described in\n    [UM Sec.C.16.1.5](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.5).\n\n    This class extends the YZCrsDef class with x-coordinates and an optional\n    branchId field. Most other attributes are inherited, but the coordcount\n    is overridden under the Pydantic alias \"xyzCount\".\n\n    Attributes:\n        yzcount (Optional[int]): dummy attribute that should not be set nor used.\n            Only present to mask the inherited attribute from parent class YZCrsDef.\n        xyzcount (int): Number of XYZ-coordinates. Always use this instead of yzcount.\n    \"\"\"\n\n    class Comments(YZCrsDef.Comments):\n        \"\"\"Comments for the XYZCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\"Cross section type; must read xyz\", alias=\"type\")\n        branchid: Optional[str] = Field(\n            \"Branch on which the cross section is located.\", alias=\"branchId\"\n        )\n        xyzcount: Optional[str] = Field(\"Number of XYZ-coordinates.\", alias=\"xyzCount\")\n        xCoordinates: Optional[str] = Field(\n            \"Space separated list of x-coordinates [m or degrees East].\",\n            alias=\"xCoordinates\",\n        )\n        yCoordinates: Optional[str] = Field(\n            \"Space separated list of y-coordinates [m or degrees North].\",\n            alias=\"yCoordinates\",\n        )\n        zCoordinates: Optional[str] = Field(\n            \"Space separated list of z-coordinates [m AD].\",\n            alias=\"zCoordinates\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"xyz\"] = Field(\"xyz\")\n    branchid: Optional[str] = Field(alias=\"branchId\")\n    yzcount: Optional[int] = Field(\n        alias=\"yzCount\"\n    )  # Trick to not inherit parent's yzcount required field.\n    xyzcount: int = Field(alias=\"xyzCount\")\n    xcoordinates: List[float] = Field(alias=\"xCoordinates\")\n\n    _split_to_list0 = get_split_string_on_delimiter_validator(\n        \"xcoordinates\",\n    )\n\n    @validator(\"xyzcount\")\n    @classmethod\n    def validate_xyzcount_without_yzcount(cls, field_value: int, values: dict) -&gt; int:\n        \"\"\"Validate the xyzcount field.\n\n        Validates whether this XYZCrsDef does have attribute xyzcount,\n        but not the parent class's yzcount.\n\n        Args:\n            field_value (Optional[Path]): Value given for xyzcount.\n            values (dict): Dictionary of values already validated.\n\n        Raises:\n            ValueError: When yzcount is present.\n\n        Returns:\n            int: The value given for xyzcount.\n        \"\"\"\n        # Retrieve the algorithm value (if not found use 0).\n        yzcount_value = values.get(\"yzcount\")\n        if field_value is not None and yzcount_value is not None:\n            # yzcount should not be set, when xyzcount is set.\n            raise ValueError(\n                f\"xyz cross section definition should not contain field yzCount (rather: xyzCount), current value: {yzcount_value}.\"\n            )\n        return field_value\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths_coordinates(cls, values):\n        \"\"\"Validate that the length of the xcoordinates, ycoordinates and zcoordinates field are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"xcoordinates\",\n            \"ycoordinates\",\n            \"zcoordinates\",\n            length_name=\"xyzcount\",\n        )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.XYZCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the XYZCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(YZCrsDef.Comments):\n    \"\"\"Comments for the XYZCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\"Cross section type; must read xyz\", alias=\"type\")\n    branchid: Optional[str] = Field(\n        \"Branch on which the cross section is located.\", alias=\"branchId\"\n    )\n    xyzcount: Optional[str] = Field(\"Number of XYZ-coordinates.\", alias=\"xyzCount\")\n    xCoordinates: Optional[str] = Field(\n        \"Space separated list of x-coordinates [m or degrees East].\",\n        alias=\"xCoordinates\",\n    )\n    yCoordinates: Optional[str] = Field(\n        \"Space separated list of y-coordinates [m or degrees North].\",\n        alias=\"yCoordinates\",\n    )\n    zCoordinates: Optional[str] = Field(\n        \"Space separated list of z-coordinates [m AD].\",\n        alias=\"zCoordinates\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.XYZCrsDef.check_list_lengths_coordinates","title":"<code>check_list_lengths_coordinates(values)</code>","text":"<p>Validate that the length of the xcoordinates, ycoordinates and zcoordinates field are as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths_coordinates(cls, values):\n    \"\"\"Validate that the length of the xcoordinates, ycoordinates and zcoordinates field are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"xcoordinates\",\n        \"ycoordinates\",\n        \"zcoordinates\",\n        length_name=\"xyzcount\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.XYZCrsDef.validate_xyzcount_without_yzcount","title":"<code>validate_xyzcount_without_yzcount(field_value, values)</code>  <code>classmethod</code>","text":"<p>Validate the xyzcount field.</p> <p>Validates whether this XYZCrsDef does have attribute xyzcount, but not the parent class's yzcount.</p> <p>Parameters:</p> Name Type Description Default <code>field_value</code> <code>Optional[Path]</code> <p>Value given for xyzcount.</p> required <code>values</code> <code>dict</code> <p>Dictionary of values already validated.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When yzcount is present.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The value given for xyzcount.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@validator(\"xyzcount\")\n@classmethod\ndef validate_xyzcount_without_yzcount(cls, field_value: int, values: dict) -&gt; int:\n    \"\"\"Validate the xyzcount field.\n\n    Validates whether this XYZCrsDef does have attribute xyzcount,\n    but not the parent class's yzcount.\n\n    Args:\n        field_value (Optional[Path]): Value given for xyzcount.\n        values (dict): Dictionary of values already validated.\n\n    Raises:\n        ValueError: When yzcount is present.\n\n    Returns:\n        int: The value given for xyzcount.\n    \"\"\"\n    # Retrieve the algorithm value (if not found use 0).\n    yzcount_value = values.get(\"yzcount\")\n    if field_value is not None and yzcount_value is not None:\n        # yzcount should not be set, when xyzcount is set.\n        raise ValueError(\n            f\"xyz cross section definition should not contain field yzCount (rather: xyzCount), current value: {yzcount_value}.\"\n        )\n    return field_value\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.YZCrsDef","title":"<code>YZCrsDef</code>","text":"<p>               Bases: <code>CrossSectionDefinition</code></p> <p>YZCrsDef.</p> <p>Crosssection definition with <code>type=yz</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the yz input as described in UM Sec.C.16.1.6.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class YZCrsDef(CrossSectionDefinition):\n    \"\"\"YZCrsDef.\n\n    Crosssection definition with `type=yz`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the yz input as described in\n    [UM Sec.C.16.1.6](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.6).\n    \"\"\"\n\n    class Comments(CrossSectionDefinition.Comments):\n        \"\"\"Comments for the YZCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\"Cross section type; must read yz\", alias=\"type\")\n        conveyance: Optional[str] = Field(\n            \"lumped: Lumped, segmented: Vertically segmented. Only the default lumped \"\n            + \"option is allowed if singleValuedZ = no. In the case of lumped conveyance, \"\n            + \"only a single uniform roughness for the whole cross section is allowed, \"\n            + \"i.e., sectionCount must equal 1.\",\n        )\n        yzcount: Optional[str] = Field(\"Number of YZ-coordinates.\", alias=\"yzCount\")\n        yCoordinates: Optional[str] = Field(\n            \"Space separated list of monotonic increasing y-coordinates [m].\",\n            alias=\"yCoordinates\",\n        )\n        zCoordinates: Optional[str] = Field(\n            \"Space separated list of single-valued z-coordinates [m AD].\",\n            alias=\"zCoordinates\",\n        )\n        sectioncount: Optional[str] = Field(\n            \"Number of roughness sections. If the lumped conveyance is selected then \"\n            + \"sectionCount must equal 1.\",\n            alias=\"sectionCount\",\n        )\n        frictionpositions: Optional[str] = Field(\n            \"Locations where the roughness sections start and end. Always one location more than \"\n            + \"sectionCount. The first value should equal 0 and the last value should equal the \"\n            + \"cross section length. Keyword may be skipped if sectionCount = 1.\",\n            alias=\"frictionPositions\",\n        )\n        frictionids: Optional[str] = Field(\n            \"Semicolon separated list of roughness variable names associated with the roughness \"\n            + \"sections. Either this parameter or frictionTypes should be specified. If neither \"\n            + 'parameter is specified, the frictionIds default to \"Main\", \"FloodPlain1\" '\n            + 'and \"FloodPlain2\".',\n            alias=\"frictionIds\",\n        )\n        frictiontypes: Optional[str] = Field(\n            \"Semicolon separated list of roughness types associated with the roughness sections. \"\n            + \"Either this parameter or frictionIds should be specified. Can be specified as a \"\n            + \"single value if all roughness sections use the same type.\",\n            alias=\"frictionTypes\",\n        )\n        frictionvalues: Optional[str] = Field(\n            \"Space separated list of roughness values; their meaning depends on the roughness \"\n            + \"types selected (only used if frictionTypes specified).\",\n            alias=\"frictionValues\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"yz\"] = Field(\"yz\")\n    singlevaluedz: Optional[bool] = Field(alias=\"singleValuedZ\")\n    yzcount: int = Field(alias=\"yzCount\")\n    ycoordinates: List[float] = Field(alias=\"yCoordinates\")\n    zcoordinates: List[float] = Field(alias=\"zCoordinates\")\n    conveyance: Optional[str] = Field(\"segmented\")\n    sectioncount: Optional[int] = Field(1, alias=\"sectionCount\")\n    frictionpositions: Optional[List[float]] = Field(alias=\"frictionPositions\")\n    frictionids: Optional[List[str]] = Field(alias=\"frictionIds\", delimiter=\";\")\n    frictiontypes: Optional[List[FrictionType]] = Field(\n        alias=\"frictionTypes\", delimiter=\";\"\n    )\n    frictionvalues: Optional[List[float]] = Field(alias=\"frictionValues\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"ycoordinates\",\n        \"zcoordinates\",\n        \"frictionpositions\",\n        \"frictionvalues\",\n        \"frictionids\",\n        \"frictiontypes\",\n    )\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths_coordinates(cls, values):\n        \"\"\"Validate that the length of the ycoordinates and zcoordinates fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"ycoordinates\",\n            \"zcoordinates\",\n            length_name=\"yzcount\",\n        )\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths_friction(cls, values):\n        \"\"\"Validate that the length of the frictionids, frictiontypes and frictionvalues field are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"frictionids\",\n            \"frictiontypes\",\n            \"frictionvalues\",\n            length_name=\"sectioncount\",\n        )\n\n    @root_validator(allow_reuse=True)\n    def check_list_length_frictionpositions(cls, values):\n        \"\"\"Validate that the length of the frictionpositions field is as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"frictionpositions\",\n            length_name=\"sectioncount\",\n            length_incr=1,  # 1 extra for frictionpositions\n        )\n\n    _friction_validator = CrossSectionDefinition._get_friction_root_validator(\n        \"frictionids\", \"frictiontypes\", \"frictionvalues\"\n    )\n    _frictiontype_validator = get_enum_validator(\"frictiontypes\", enum=FrictionType)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.YZCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the YZCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(CrossSectionDefinition.Comments):\n    \"\"\"Comments for the YZCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\"Cross section type; must read yz\", alias=\"type\")\n    conveyance: Optional[str] = Field(\n        \"lumped: Lumped, segmented: Vertically segmented. Only the default lumped \"\n        + \"option is allowed if singleValuedZ = no. In the case of lumped conveyance, \"\n        + \"only a single uniform roughness for the whole cross section is allowed, \"\n        + \"i.e., sectionCount must equal 1.\",\n    )\n    yzcount: Optional[str] = Field(\"Number of YZ-coordinates.\", alias=\"yzCount\")\n    yCoordinates: Optional[str] = Field(\n        \"Space separated list of monotonic increasing y-coordinates [m].\",\n        alias=\"yCoordinates\",\n    )\n    zCoordinates: Optional[str] = Field(\n        \"Space separated list of single-valued z-coordinates [m AD].\",\n        alias=\"zCoordinates\",\n    )\n    sectioncount: Optional[str] = Field(\n        \"Number of roughness sections. If the lumped conveyance is selected then \"\n        + \"sectionCount must equal 1.\",\n        alias=\"sectionCount\",\n    )\n    frictionpositions: Optional[str] = Field(\n        \"Locations where the roughness sections start and end. Always one location more than \"\n        + \"sectionCount. The first value should equal 0 and the last value should equal the \"\n        + \"cross section length. Keyword may be skipped if sectionCount = 1.\",\n        alias=\"frictionPositions\",\n    )\n    frictionids: Optional[str] = Field(\n        \"Semicolon separated list of roughness variable names associated with the roughness \"\n        + \"sections. Either this parameter or frictionTypes should be specified. If neither \"\n        + 'parameter is specified, the frictionIds default to \"Main\", \"FloodPlain1\" '\n        + 'and \"FloodPlain2\".',\n        alias=\"frictionIds\",\n    )\n    frictiontypes: Optional[str] = Field(\n        \"Semicolon separated list of roughness types associated with the roughness sections. \"\n        + \"Either this parameter or frictionIds should be specified. Can be specified as a \"\n        + \"single value if all roughness sections use the same type.\",\n        alias=\"frictionTypes\",\n    )\n    frictionvalues: Optional[str] = Field(\n        \"Space separated list of roughness values; their meaning depends on the roughness \"\n        + \"types selected (only used if frictionTypes specified).\",\n        alias=\"frictionValues\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.YZCrsDef.check_list_length_frictionpositions","title":"<code>check_list_length_frictionpositions(values)</code>","text":"<p>Validate that the length of the frictionpositions field is as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_length_frictionpositions(cls, values):\n    \"\"\"Validate that the length of the frictionpositions field is as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"frictionpositions\",\n        length_name=\"sectioncount\",\n        length_incr=1,  # 1 extra for frictionpositions\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.YZCrsDef.check_list_lengths_coordinates","title":"<code>check_list_lengths_coordinates(values)</code>","text":"<p>Validate that the length of the ycoordinates and zcoordinates fields are as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths_coordinates(cls, values):\n    \"\"\"Validate that the length of the ycoordinates and zcoordinates fields are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"ycoordinates\",\n        \"zcoordinates\",\n        length_name=\"yzcount\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.YZCrsDef.check_list_lengths_friction","title":"<code>check_list_lengths_friction(values)</code>","text":"<p>Validate that the length of the frictionids, frictiontypes and frictionvalues field are as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths_friction(cls, values):\n    \"\"\"Validate that the length of the frictionids, frictiontypes and frictionvalues field are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"frictionids\",\n        \"frictiontypes\",\n        \"frictionvalues\",\n        length_name=\"sectioncount\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWCrsDef","title":"<code>ZWCrsDef</code>","text":"<p>               Bases: <code>CrossSectionDefinition</code></p> <p>ZWCrsDef.</p> <p>Crosssection definition with <code>type=zw</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the zw input as described in UM Sec.C.16.1.4.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class ZWCrsDef(CrossSectionDefinition):\n    \"\"\"ZWCrsDef.\n\n    Crosssection definition with `type=zw`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the zw input as described in\n    [UM Sec.C.16.1.4](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.4).\n    \"\"\"\n\n    class Comments(CrossSectionDefinition.Comments):\n        \"\"\"Comments for the ZWCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\"Cross section type; must read zw\", alias=\"type\")\n        # NOTE: Field \"template\" deliberately ignored for now.\n        numlevels: Optional[str] = Field(\n            \"Number of levels in the table.\", alias=\"numLevels\"\n        )\n        levels: Optional[str] = Field(\n            \"Space separated list of monotonic increasing heights/levels [m AD].\",\n            alias=\"levels\",\n        )\n        flowwidths: Optional[str] = Field(\n            \"Space separated list of flow widths at the selected heights [m)].\",\n            alias=\"flowWidths\",\n        )\n        totalwidths: Optional[str] = Field(\n            \"Space separated list of total widths at the selected heights [m]. \"\n            \"Equal to flowWidths if not specified. If specified, the totalWidths\"\n            \"should be larger than flowWidths.\",\n            alias=\"totalWidths\",\n        )\n        frictionid: Optional[str] = Field(\n            frictionid_description,\n            alias=\"frictionId\",\n        )\n        frictiontype: Optional[str] = Field(\n            frictiontype_description,\n            alias=\"frictionType\",\n        )\n        frictionvalue: Optional[str] = Field(\n            frictionvalue_description,\n            alias=\"frictionValue\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"zw\"] = Field(\"zw\")\n    numlevels: int = Field(alias=\"numLevels\")\n    levels: List[float]\n    flowwidths: List[float] = Field(alias=\"flowWidths\")\n    totalwidths: Optional[List[float]] = Field(alias=\"totalWidths\")\n    frictionid: Optional[str] = Field(alias=\"frictionId\")\n    frictiontype: Optional[FrictionType] = Field(alias=\"frictionType\")\n    frictionvalue: Optional[float] = Field(alias=\"frictionValue\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"levels\",\n        \"flowwidths\",\n        \"totalwidths\",\n    )\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths(cls, values):\n        \"\"\"Validate that the length of the levels, flowwidths and totalwidths fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"levels\",\n            \"flowwidths\",\n            \"totalwidths\",\n            length_name=\"numlevels\",\n        )\n\n    _friction_validator = CrossSectionDefinition._get_friction_root_validator(\n        \"frictionid\", \"frictiontype\", \"frictionvalue\"\n    )\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the ZWCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(CrossSectionDefinition.Comments):\n    \"\"\"Comments for the ZWCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\"Cross section type; must read zw\", alias=\"type\")\n    # NOTE: Field \"template\" deliberately ignored for now.\n    numlevels: Optional[str] = Field(\n        \"Number of levels in the table.\", alias=\"numLevels\"\n    )\n    levels: Optional[str] = Field(\n        \"Space separated list of monotonic increasing heights/levels [m AD].\",\n        alias=\"levels\",\n    )\n    flowwidths: Optional[str] = Field(\n        \"Space separated list of flow widths at the selected heights [m)].\",\n        alias=\"flowWidths\",\n    )\n    totalwidths: Optional[str] = Field(\n        \"Space separated list of total widths at the selected heights [m]. \"\n        \"Equal to flowWidths if not specified. If specified, the totalWidths\"\n        \"should be larger than flowWidths.\",\n        alias=\"totalWidths\",\n    )\n    frictionid: Optional[str] = Field(\n        frictionid_description,\n        alias=\"frictionId\",\n    )\n    frictiontype: Optional[str] = Field(\n        frictiontype_description,\n        alias=\"frictionType\",\n    )\n    frictionvalue: Optional[str] = Field(\n        frictionvalue_description,\n        alias=\"frictionValue\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWCrsDef.check_list_lengths","title":"<code>check_list_lengths(values)</code>","text":"<p>Validate that the length of the levels, flowwidths and totalwidths fields are as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths(cls, values):\n    \"\"\"Validate that the length of the levels, flowwidths and totalwidths fields are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"levels\",\n        \"flowwidths\",\n        \"totalwidths\",\n        length_name=\"numlevels\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWRiverCrsDef","title":"<code>ZWRiverCrsDef</code>","text":"<p>               Bases: <code>CrossSectionDefinition</code></p> <p>ZWRiverCrsDef.</p> <p>Crosssection definition with <code>type=zwRiver</code>, to be included in a crossdef file. Typically inside the definition list of a FMModel<code>.geometry.crossdeffile.definition[..]</code></p> <p>All lowercased attributes match with the zwRiver input as described in UM Sec.C.16.1.3.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class ZWRiverCrsDef(CrossSectionDefinition):\n    \"\"\"ZWRiverCrsDef.\n\n    Crosssection definition with `type=zwRiver`, to be included in a crossdef file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.crossdeffile.definition[..]`\n\n    All lowercased attributes match with the zwRiver input as described in\n    [UM Sec.C.16.1.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.16.1.3).\n    \"\"\"\n\n    class Comments(CrossSectionDefinition.Comments):\n        \"\"\"Comments for the ZWRiverCrsDef class.\"\"\"\n\n        type: Optional[str] = Field(\n            \"Cross section type; must read zwRiver\", alias=\"type\"\n        )\n        numlevels: Optional[str] = Field(\n            \"Number of levels in the table.\", alias=\"numLevels\"\n        )\n        levels: Optional[str] = Field(\n            \"Space separated list of monotonic increasing heights/levels [m AD].\",\n            alias=\"levels\",\n        )\n        flowwidths: Optional[str] = Field(\n            \"Space separated list of flow widths at the selected heights [m)].\",\n            alias=\"flowWidths\",\n        )\n        totalwidths: Optional[str] = Field(\n            \"Space separated list of total widths at the selected heights [m]. \"\n            \"Equal to flowWidths if not specified. If specified, the totalWidths\"\n            \"should be larger than flowWidths.\",\n            alias=\"totalWidths\",\n        )\n        leveecrestLevel: Optional[str] = Field(\n            \"Crest level of levee [m AD].\", alias=\"leveeCrestlevel\"\n        )\n        leveebaselevel: Optional[str] = Field(\n            \"Base level of levee [m AD].\", alias=\"leveeBaseLevel\"\n        )\n        leveeflowarea: Optional[str] = Field(\n            \"Flow area behind levee [m2].\", alias=\"leveeFlowArea\"\n        )\n        leveetotalarea: Optional[str] = Field(\n            \"Total area behind levee [m2].\", alias=\"leveeTotalArea\"\n        )\n        mainwidth: Optional[str] = Field(\n            \"Width of main section [m]. Default value: max(flowWidths).\",\n            alias=\"mainWidth\",\n        )\n        fp1width: Optional[str] = Field(\n            \"Width of floodplain 1 section [m]. Default value: max(flowWidths)-mainWidth\",\n            alias=\"fp1Width\",\n        )\n        fp2width: Optional[str] = Field(\n            \"Width of floodplain 2 section [m]. Default value: max(flowWidths)-mainWidth-fp1Width\",\n            alias=\"fp2Width\",\n        )\n        frictionids: Optional[str] = Field(\n            \"Semicolon separated list of roughness variable names associated with the roughness \"\n            \"sections. Either this parameter or frictionTypes should be specified. If neither \"\n            'parameter is specified, the frictionIds default to \"Main\", \"FloodPlain1\" '\n            'and \"FloodPlain2\".',\n            alias=\"frictionIds\",\n        )\n        frictiontypes: Optional[str] = Field(\n            \"Semicolon separated list of roughness types associated with the roughness sections. \"\n            \"Either this parameter or frictionIds should be specified. Can be specified as a \"\n            \"single value if all roughness sections use the same type.\",\n            alias=\"frictionTypes\",\n        )\n        frictionvalues: Optional[str] = Field(\n            \"Space separated list of roughness values; their meaning depends on the roughness \"\n            \"types selected (only used if frictionTypes specified).\",\n            alias=\"frictionValues\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"zwRiver\"] = Field(\"zwRiver\")\n    numlevels: int = Field(alias=\"numLevels\")\n    levels: List[float]\n    flowwidths: List[float] = Field(alias=\"flowWidths\")\n    totalwidths: Optional[List[float]] = Field(alias=\"totalWidths\")\n    leveecrestLevel: Optional[float] = Field(alias=\"leveeCrestlevel\")\n    leveebaselevel: Optional[float] = Field(alias=\"leveeBaseLevel\")\n    leveeflowarea: Optional[float] = Field(alias=\"leveeFlowArea\")\n    leveetotalrea: Optional[float] = Field(alias=\"leveeTotalArea\")\n    mainwidth: Optional[float] = Field(alias=\"mainWidth\")\n    fp1width: Optional[float] = Field(alias=\"fp1Width\")\n    fp2width: Optional[float] = Field(alias=\"fp2Width\")\n    frictionids: Optional[List[str]] = Field(alias=\"frictionIds\", delimiter=\";\")\n    frictiontypes: Optional[List[FrictionType]] = Field(\n        alias=\"frictionTypes\", delimiter=\";\"\n    )\n    frictionvalues: Optional[List[float]] = Field(alias=\"frictionValues\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"levels\",\n        \"flowwidths\",\n        \"totalwidths\",\n        \"frictionvalues\",\n        \"frictionids\",\n        \"frictiontypes\",\n    )\n\n    _friction_validator = CrossSectionDefinition._get_friction_root_validator(\n        \"frictionids\", \"frictiontypes\", \"frictionvalues\"\n    )\n    _frictiontype_validator = get_enum_validator(\"frictiontypes\", enum=FrictionType)\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths(cls, values):\n        \"\"\"Validate that the length of the levels, flowwidths and totalwidths fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"levels\",\n            \"flowwidths\",\n            \"totalwidths\",\n            length_name=\"numlevels\",\n        )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWRiverCrsDef.Comments","title":"<code>Comments</code>","text":"<p>               Bases: <code>Comments</code></p> <p>Comments for the ZWRiverCrsDef class.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>class Comments(CrossSectionDefinition.Comments):\n    \"\"\"Comments for the ZWRiverCrsDef class.\"\"\"\n\n    type: Optional[str] = Field(\n        \"Cross section type; must read zwRiver\", alias=\"type\"\n    )\n    numlevels: Optional[str] = Field(\n        \"Number of levels in the table.\", alias=\"numLevels\"\n    )\n    levels: Optional[str] = Field(\n        \"Space separated list of monotonic increasing heights/levels [m AD].\",\n        alias=\"levels\",\n    )\n    flowwidths: Optional[str] = Field(\n        \"Space separated list of flow widths at the selected heights [m)].\",\n        alias=\"flowWidths\",\n    )\n    totalwidths: Optional[str] = Field(\n        \"Space separated list of total widths at the selected heights [m]. \"\n        \"Equal to flowWidths if not specified. If specified, the totalWidths\"\n        \"should be larger than flowWidths.\",\n        alias=\"totalWidths\",\n    )\n    leveecrestLevel: Optional[str] = Field(\n        \"Crest level of levee [m AD].\", alias=\"leveeCrestlevel\"\n    )\n    leveebaselevel: Optional[str] = Field(\n        \"Base level of levee [m AD].\", alias=\"leveeBaseLevel\"\n    )\n    leveeflowarea: Optional[str] = Field(\n        \"Flow area behind levee [m2].\", alias=\"leveeFlowArea\"\n    )\n    leveetotalarea: Optional[str] = Field(\n        \"Total area behind levee [m2].\", alias=\"leveeTotalArea\"\n    )\n    mainwidth: Optional[str] = Field(\n        \"Width of main section [m]. Default value: max(flowWidths).\",\n        alias=\"mainWidth\",\n    )\n    fp1width: Optional[str] = Field(\n        \"Width of floodplain 1 section [m]. Default value: max(flowWidths)-mainWidth\",\n        alias=\"fp1Width\",\n    )\n    fp2width: Optional[str] = Field(\n        \"Width of floodplain 2 section [m]. Default value: max(flowWidths)-mainWidth-fp1Width\",\n        alias=\"fp2Width\",\n    )\n    frictionids: Optional[str] = Field(\n        \"Semicolon separated list of roughness variable names associated with the roughness \"\n        \"sections. Either this parameter or frictionTypes should be specified. If neither \"\n        'parameter is specified, the frictionIds default to \"Main\", \"FloodPlain1\" '\n        'and \"FloodPlain2\".',\n        alias=\"frictionIds\",\n    )\n    frictiontypes: Optional[str] = Field(\n        \"Semicolon separated list of roughness types associated with the roughness sections. \"\n        \"Either this parameter or frictionIds should be specified. Can be specified as a \"\n        \"single value if all roughness sections use the same type.\",\n        alias=\"frictionTypes\",\n    )\n    frictionvalues: Optional[str] = Field(\n        \"Space separated list of roughness values; their meaning depends on the roughness \"\n        \"types selected (only used if frictionTypes specified).\",\n        alias=\"frictionValues\",\n    )\n</code></pre>"},{"location":"reference/models/crosssection/#hydrolib.core.dflowfm.crosssection.models.ZWRiverCrsDef.check_list_lengths","title":"<code>check_list_lengths(values)</code>","text":"<p>Validate that the length of the levels, flowwidths and totalwidths fields are as expected.</p> Source code in <code>hydrolib/core/dflowfm/crosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths(cls, values):\n    \"\"\"Validate that the length of the levels, flowwidths and totalwidths fields are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"levels\",\n        \"flowwidths\",\n        \"totalwidths\",\n        length_name=\"numlevels\",\n    )\n</code></pre>"},{"location":"reference/models/dimr/","title":"DIMR xml files","text":"<p>The input to the Deltares Integrated Model Runner (DIMR) is a single XML file, represented by the classes below.</p>"},{"location":"reference/models/dimr/#model","title":"Model","text":"<p>Dimr models.</p>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Component","title":"<code>Component</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Specification of a BMI-compliant model component instance that will be executed by DIMR.</p> <p>Attributes:</p> Name Type Description <code>library</code> <code>str</code> <p>The library name of the compoment.</p> <code>name</code> <code>str</code> <p>The component name.</p> <code>workingDir</code> <code>Path</code> <p>The working directory.</p> <code>inputFile</code> <code>Path</code> <p>The name of the input file.</p> <code>process</code> <code>Optional[int]</code> <p>Number of subprocesses in the component.</p> <code>setting</code> <code>Optional[List[KeyValuePair]]</code> <p>A list of variables that are provided to the BMI model before initialization.</p> <code>parameter</code> <code>Optional[List[KeyValuePair]]</code> <p>A list of variables that are provided to the BMI model after initialization.</p> <code>mpiCommunicator</code> <code>Optional[str]</code> <p>The MPI communicator value.</p> <code>model</code> <code>Optional[FileModel]</code> <p>The model represented by this component.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Component(BaseModel, ABC):\n    \"\"\"\n    Specification of a BMI-compliant model component instance that will be executed by DIMR.\n\n    Attributes:\n        library: The library name of the compoment.\n        name: The component name.\n        workingDir: The working directory.\n        inputFile: The name of the input file.\n        process: Number of subprocesses in the component.\n        setting: A list of variables that are provided to the BMI model before initialization.\n        parameter: A list of variables that are provided to the BMI model after initialization.\n        mpiCommunicator: The MPI communicator value.\n        model: The model represented by this component.\n    \"\"\"\n\n    library: str\n    name: str\n    workingDir: Path\n    inputFile: Path\n    process: Optional[int]\n    setting: Optional[List[KeyValuePair]] = Field(default_factory=list)\n    parameter: Optional[List[KeyValuePair]] = Field(default_factory=list)\n    mpiCommunicator: Optional[str]\n\n    model: Optional[FileModel]\n\n    @property\n    def filepath(self):\n        return self.workingDir / self.inputFile\n\n    @abstractclassmethod\n    def get_model(cls) -&gt; Type[FileModel]:\n        raise NotImplementedError(\"Model not implemented yet.\")\n\n    @validator(\"setting\", \"parameter\", pre=True, allow_reuse=True)\n    def validate_setting(cls, v):\n        return to_list(v)\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n\n    def dict(self, *args, **kwargs):\n        # Exclude the FileModel from any DIMR serialization.\n        kwargs[\"exclude\"] = {\"model\"}\n        return super().dict(*args, **kwargs)\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.ComponentOrCouplerRef","title":"<code>ComponentOrCouplerRef</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Reference to a BMI-compliant model component instance.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the reference to a BMI-compliant model component instance.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class ComponentOrCouplerRef(BaseModel):\n    \"\"\"\n    Reference to a BMI-compliant model component instance.\n\n    Attributes:\n        name: Name of the reference to a BMI-compliant model component instance.\n    \"\"\"\n\n    name: str\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.ControlModel","title":"<code>ControlModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Control Model.</p> <p>Overrides to make sure that the control elements in the DIMR are parsed and serialized correctly.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class ControlModel(BaseModel):\n    \"\"\"Control Model.\n\n    Overrides to make sure that the control elements in the DIMR are parsed and serialized correctly.\n    \"\"\"\n\n    _type: str\n\n    def dict(self, *args, **kwargs):\n        \"\"\"Add control element prefixes for serialized data.\"\"\"\n        return {\n            str(self._type): super().dict(*args, **kwargs),\n        }\n\n    @classmethod\n    def validate(cls, v):\n        \"\"\"Remove control element prefixes from parsed data.\"\"\"\n        # should be replaced by discriminated unions once merged\n        # https://github.com/samuelcolvin/pydantic/pull/2336\n        if isinstance(v, dict) and len(v.keys()) == 1:\n            key = list(v.keys())[0]\n            v = v[key]\n        return super().validate(v)\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.ControlModel.dict","title":"<code>dict(*args, **kwargs)</code>","text":"<p>Add control element prefixes for serialized data.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>def dict(self, *args, **kwargs):\n    \"\"\"Add control element prefixes for serialized data.\"\"\"\n    return {\n        str(self._type): super().dict(*args, **kwargs),\n    }\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.ControlModel.validate","title":"<code>validate(v)</code>  <code>classmethod</code>","text":"<p>Remove control element prefixes from parsed data.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>@classmethod\ndef validate(cls, v):\n    \"\"\"Remove control element prefixes from parsed data.\"\"\"\n    # should be replaced by discriminated unions once merged\n    # https://github.com/samuelcolvin/pydantic/pull/2336\n    if isinstance(v, dict) and len(v.keys()) == 1:\n        key = list(v.keys())[0]\n        v = v[key]\n    return super().validate(v)\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.CoupledItem","title":"<code>CoupledItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification of an item that has to be exchanged.</p> <p>Attributes:</p> Name Type Description <code>sourceName</code> <code>str</code> <p>Name of the item at the source component.</p> <code>targetName</code> <code>str</code> <p>Name of the item at the target component.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class CoupledItem(BaseModel):\n    \"\"\"\n    Specification of an item that has to be exchanged.\n\n    Attributes:\n        sourceName: Name of the item at the source component.\n        targetName: Name of the item at the target component.\n    \"\"\"\n\n    sourceName: str\n    targetName: str\n\n    def is_intermediate_link(self) -&gt; bool:\n        # TODO set to True once we replace Paths with FileModels\n        return False\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Coupler","title":"<code>Coupler</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification of the coupling actions to be performed between two BMI-compliant model components.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the coupler.</p> <code>sourceComponent</code> <code>str</code> <p>The component that provides the data to has to be exchanged.</p> <code>targetComponent</code> <code>str</code> <p>The component that consumes the data to has to be exchanged.</p> <code>item</code> <code>List[CoupledItem]</code> <p>A list of items that have to be exchanged.</p> <code>logger</code> <code>Optional[Logger]</code> <p>Logger for logging the values that get exchanged.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Coupler(BaseModel):\n    \"\"\"\n    Specification of the coupling actions to be performed between two BMI-compliant model components.\n\n    Attributes:\n        name: The name of the coupler.\n        sourceComponent: The component that provides the data to has to be exchanged.\n        targetComponent: The component that consumes the data to has to be exchanged.\n        item: A list of items that have to be exchanged.\n        logger: Logger for logging the values that get exchanged.\n    \"\"\"\n\n    name: str\n    sourceComponent: str\n    targetComponent: str\n    item: List[CoupledItem] = Field(default_factory=list)\n    logger: Optional[Logger]\n\n    @validator(\"item\", pre=True)\n    def validate_item(cls, v):\n        return to_list(v)\n\n    def is_intermediate_link(self) -&gt; bool:\n        # TODO set to True once we replace Paths with FileModels\n        return False\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.DIMR","title":"<code>DIMR</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>DIMR model representation.</p> <p>Attributes:</p> Name Type Description <code>documentation</code> <code>Documentation</code> <p>File metadata.</p> <code>control</code> <code>List[Union[Start, Parallel]]</code> <p>The <code>&lt;control&gt;</code> element with a list of Start and Parallel sub-elements, which defines the (sequence of) program(s) to be run. May be empty while constructing, but must be non-empty when saving! Also, all referenced components must be present in <code>component</code> when saving. Similarly, all referenced couplers must be present in <code>coupler</code>.</p> <code>component</code> <code>List[Union[RRComponent, FMComponent, Component]]</code> <p>List of <code>&lt;component&gt;</code> elements that defines which programs can be used inside the <code>&lt;control&gt;</code> subelements. Must be non-empty when saving!</p> <code>coupler</code> <code>Optional[List[Coupler]]</code> <p>optional list of <code>&lt;coupler&gt;</code> elements that defines which couplers can be used inside the <code>&lt;parallel&gt;</code> elements under <code>&lt;control&gt;</code>.</p> <code>waitFile</code> <code>Optional[str]</code> <p>Optional waitfile name for debugging.</p> <code>global_settings</code> <code>Optional[GlobalSettings]</code> <p>Optional global DIMR settings.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class DIMR(ParsableFileModel):\n    \"\"\"DIMR model representation.\n\n    Attributes:\n        documentation (Documentation): File metadata.\n        control (List[Union[Start, Parallel]]): The `&lt;control&gt;` element with a list\n            of [Start][hydrolib.core.dimr.models.Start]\n            and [Parallel][hydrolib.core.dimr.models.Parallel] sub-elements,\n            which defines the (sequence of) program(s) to be run.\n            May be empty while constructing, but must be non-empty when saving!\n            Also, all referenced components must be present in `component` when\n            saving. Similarly, all referenced couplers must be present in `coupler`.\n        component (List[Union[RRComponent, FMComponent, Component]]): List of\n            `&lt;component&gt;` elements that defines which programs can be used inside\n            the `&lt;control&gt;` subelements. Must be non-empty when saving!\n        coupler (Optional[List[Coupler]]): optional list of `&lt;coupler&gt;` elements\n            that defines which couplers can be used inside the `&lt;parallel&gt;`\n            elements under `&lt;control&gt;`.\n        waitFile (Optional[str]): Optional waitfile name for debugging.\n        global_settings (Optional[GlobalSettings]): Optional global DIMR settings.\n    \"\"\"\n\n    documentation: Documentation = Documentation()\n    control: List[Union[Start, Parallel]] = Field(default_factory=list)\n    component: List[Union[RRComponent, FMComponent, Component]] = Field(\n        default_factory=list\n    )\n    coupler: Optional[List[Coupler]] = Field(default_factory=list)\n    waitFile: Optional[str]\n    global_settings: Optional[GlobalSettings]\n\n    @validator(\"component\", \"coupler\", \"control\", pre=True)\n    def validate_component(cls, v):\n        return to_list(v)\n\n    def dict(self, *args, **kwargs):\n        kwargs[\"exclude_none\"] = True\n        return super().dict(*args, **kwargs)\n\n    def _post_init_load(self) -&gt; None:\n        \"\"\"Load the component models of this DIMR model.\"\"\"\n        super()._post_init_load()\n\n        for comp in self.component:\n            try:\n                comp.model = comp.get_model()(filepath=comp.filepath)\n            except NotImplementedError:\n                pass\n\n    def _serialize(self, data: dict, save_settings: ModelSaveSettings) -&gt; None:\n        dimr_as_dict = self._update_dimr_dictonary_with_adjusted_fmcomponent_values(\n            data\n        )\n        super()._serialize(dimr_as_dict, save_settings)\n\n    def _update_dimr_dictonary_with_adjusted_fmcomponent_values(\n        self, dimr_as_dict: Dict\n    ):\n        fmcomponents = [\n            item for item in self.component if isinstance(item, FMComponent)\n        ]\n\n        list_of_fmcomponents_as_dict = self._get_list_of_updated_fm_components(\n            fmcomponents\n        )\n        dimr_as_dict = self._update_dimr_dictionary(\n            dimr_as_dict, list_of_fmcomponents_as_dict\n        )\n        return dimr_as_dict\n\n    def _update_dimr_dictionary(\n        self, dimr_as_dict: Dict, list_of_fm_components_as_dict: List[Dict]\n    ) -&gt; Dict:\n        if len(list_of_fm_components_as_dict) &gt; 0:\n            dimr_as_dict.update({\"component\": list_of_fm_components_as_dict})\n\n        return dimr_as_dict\n\n    def _get_list_of_updated_fm_components(\n        self, fmcomponents: List[FMComponent]\n    ) -&gt; List[Dict]:\n        list_of_fm_components_as_dict = []\n        for fmcomponent in fmcomponents:\n            if fmcomponent is None or fmcomponent.process is None:\n                continue\n\n            fmcomponent_process_value = \" \".join(\n                str(i) for i in range(fmcomponent.process)\n            )\n            fmcomponent_as_dict = self._update_component_dictonary(\n                fmcomponent, fmcomponent_process_value\n            )\n\n            list_of_fm_components_as_dict.append(fmcomponent_as_dict)\n\n        return list_of_fm_components_as_dict\n\n    def _update_component_dictonary(\n        self, fmcomponent: FMComponent, fmcomponent_process_value: str\n    ) -&gt; Dict:\n        fmcomponent_as_dict = fmcomponent.dict()\n        fmcomponent_as_dict.update({\"process\": fmcomponent_process_value})\n        return fmcomponent_as_dict\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".xml\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"dimr_config\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return DIMRSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return DIMRParser.parse\n\n    @classmethod\n    def _parse(cls, path: Path) -&gt; Dict:\n        data = super()._parse(path)\n        return cls._update_component(data)\n\n    @classmethod\n    def _update_component(cls, data: Dict) -&gt; Dict:\n        component = data.get(\"component\", None)\n\n        if not isinstance(component, Dict):\n            return data\n\n        process_value = component.get(\"process\", None)\n\n        if not isinstance(process_value, str):\n            return data\n\n        if cls._is_valid_process_string(process_value):\n            value_as_int = cls._parse_process(process_value)\n            component.update({\"process\": value_as_int})\n            data.update({\"component\": component})\n\n        return data\n\n    @classmethod\n    def _parse_process(cls, process_value: str) -&gt; int:\n        if \":\" in process_value:\n            semicolon_split_values = process_value.split(\":\")\n            start_value = int(semicolon_split_values[0])\n            end_value = int(semicolon_split_values[-1])\n            return end_value - start_value + 1\n\n        return len(process_value.split())\n\n    @classmethod\n    def _is_valid_process_string(cls, process_value: str) -&gt; bool:\n        if \":\" in process_value:\n            return cls._is_valid_process_with_semicolon_string(process_value)\n\n        return cls._is_valid_process_list_string(process_value)\n\n    @classmethod\n    def _is_valid_process_with_semicolon_string(cls, process_value: str) -&gt; bool:\n        semicolon_split_values = process_value.split(\":\")\n\n        if len(semicolon_split_values) != 2:\n            return False\n\n        last_value: str = semicolon_split_values[-1]\n        if last_value.isdigit():\n            return True\n\n        return False\n\n    @classmethod\n    def _is_valid_process_list_string(cls, process_value: str) -&gt; bool:\n        split_values = process_value.split()\n\n        if len(split_values) &lt; 1:\n            return False\n\n        if split_values[0] != \"0\":\n            return False\n\n        for value in split_values:\n            if not value.isdigit():\n                return False\n\n        return True\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Documentation","title":"<code>Documentation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information on the present DIMR configuration file.</p> <p>Attributes:</p> Name Type Description <code>fileVersion</code> <code>str</code> <p>The DIMR file version.</p> <code>createdBy</code> <code>str</code> <p>Creators of the DIMR file.</p> <code>creationDate</code> <code>datetime</code> <p>The creation date of the DIMR file.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Documentation(BaseModel):\n    \"\"\"\n    Information on the present DIMR configuration file.\n\n    Attributes:\n        fileVersion: The DIMR file version.\n        createdBy: Creators of the DIMR file.\n        creationDate: The creation date of the DIMR file.\n    \"\"\"\n\n    fileVersion: str = \"1.3\"\n    createdBy: str = f\"hydrolib-core {__version__}\"\n    creationDate: datetime = Field(default_factory=datetime.utcnow)\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.FMComponent","title":"<code>FMComponent</code>","text":"<p>               Bases: <code>Component</code></p> <p>Component to include the D-Flow FM program in a DIMR control flow.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class FMComponent(Component):\n    \"\"\"Component to include the D-Flow FM program in a DIMR control flow.\"\"\"\n\n    library: Literal[\"dflowfm\"] = \"dflowfm\"\n\n    @validator(\"process\", pre=True)\n    def validate_process(cls, value, values: dict) -&gt; Union[None, int]:\n        \"\"\"\n        Validation for the process Attribute.\n\n        args:\n            value : The value which is to be validated for process.\n            values : FMComponent used to retrieve the name of the component.\n\n        Returns:\n            int : The process as int, when given value is None, None is returned.\n\n        Raises:\n            ValueError : When value is set to 0 or negative.\n            ValueError : When value is not int or None.\n        \"\"\"\n        if value is None:\n            return value\n\n        if isinstance(value, int) and cls._is_valid_process_int(\n            value, values.get(\"name\")\n        ):\n            return value\n\n        raise ValueError(\n            f\"In component '{values.get('name')}', the keyword process '{value}', is incorrect.\"\n        )\n\n    @classmethod\n    def _is_valid_process_int(cls, value: int, name: str) -&gt; bool:\n        if value &gt; 0:\n            return True\n\n        raise ValueError(\n            f\"In component '{name}', the keyword process can not be 0 or negative, please specify value of 1 or greater.\"\n        )\n\n    @classmethod\n    def get_model(cls):\n        return FMModel\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.FMComponent.validate_process","title":"<code>validate_process(value, values)</code>","text":"<p>Validation for the process Attribute.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>The value which is to be validated for process.</p> required <code>values</code> <p>FMComponent used to retrieve the name of the component.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>Union[None, int]</code> <p>The process as int, when given value is None, None is returned.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When value is set to 0 or negative.</p> <code>ValueError</code> <p>When value is not int or None.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>@validator(\"process\", pre=True)\ndef validate_process(cls, value, values: dict) -&gt; Union[None, int]:\n    \"\"\"\n    Validation for the process Attribute.\n\n    args:\n        value : The value which is to be validated for process.\n        values : FMComponent used to retrieve the name of the component.\n\n    Returns:\n        int : The process as int, when given value is None, None is returned.\n\n    Raises:\n        ValueError : When value is set to 0 or negative.\n        ValueError : When value is not int or None.\n    \"\"\"\n    if value is None:\n        return value\n\n    if isinstance(value, int) and cls._is_valid_process_int(\n        value, values.get(\"name\")\n    ):\n        return value\n\n    raise ValueError(\n        f\"In component '{values.get('name')}', the keyword process '{value}', is incorrect.\"\n    )\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.GlobalSettings","title":"<code>GlobalSettings</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Global settings for the DIMR configuration.</p> <p>Attributes:</p> Name Type Description <code>logger_ncFormat</code> <code>int</code> <p>NetCDF format type for logging.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class GlobalSettings(BaseModel):\n    \"\"\"\n    Global settings for the DIMR configuration.\n\n    Attributes:\n        logger_ncFormat: NetCDF format type for logging.\n    \"\"\"\n\n    logger_ncFormat: int\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.KeyValuePair","title":"<code>KeyValuePair</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Key value pair to specify settings and parameters.</p> <p>Attributes:</p> Name Type Description <code>key</code> <code>str</code> <p>The key.</p> <code>value</code> <code>str</code> <p>The value.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class KeyValuePair(BaseModel):\n    \"\"\"Key value pair to specify settings and parameters.\n\n    Attributes:\n        key: The key.\n        value: The value.\n    \"\"\"\n\n    key: str\n    value: str\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Logger","title":"<code>Logger</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Logger.</p> <p>Used to log values to the specified file in workingdir for each timestep</p> <p>Attributes:</p> Name Type Description <code>workingDir</code> <code>Path</code> <p>Directory where the log file is written.</p> <code>outputFile</code> <code>Path</code> <p>Name of the log file.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Logger(BaseModel):\n    \"\"\"Logger.\n\n    Used to log values to the specified file in workingdir for each timestep\n\n    Attributes:\n        workingDir: Directory where the log file is written.\n        outputFile: Name of the log file.\n    \"\"\"\n\n    workingDir: Path\n    outputFile: Path\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Parallel","title":"<code>Parallel</code>","text":"<p>               Bases: <code>ControlModel</code></p> <p>Parallel control flow.</p> <p>Specification of a parallel control flow: one main component and a group of related components and couplers. Step wise execution order according to order in parallel control flow.</p> <p>Attributes:</p> Name Type Description <code>startGroup</code> <code>StartGroup</code> <p>Group of components and couplers to be executed.</p> <code>start</code> <code>ComponentOrCouplerRef</code> <p>Main component to be executed step wise (provides start time, end time and time step).</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Parallel(ControlModel):\n    \"\"\"Parallel control flow.\n\n    Specification of a parallel control flow: one main component and a group of related components and couplers.\n    Step wise execution order according to order in parallel control flow.\n\n    Attributes:\n        startGroup: Group of components and couplers to be executed.\n        start: Main component to be executed step wise (provides start time, end time and time step).\n    \"\"\"\n\n    _type: Literal[\"parallel\"] = \"parallel\"\n    startGroup: StartGroup\n    start: ComponentOrCouplerRef\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.RRComponent","title":"<code>RRComponent</code>","text":"<p>               Bases: <code>Component</code></p> <p>Component to include the RainfallRunoff program in a DIMR control flow.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class RRComponent(Component):\n    \"\"\"Component to include the RainfallRunoff program in a DIMR control flow.\"\"\"\n\n    library: Literal[\"rr_dll\"] = \"rr_dll\"\n\n    @classmethod\n    def get_model(cls):\n        return RainfallRunoffModel\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.Start","title":"<code>Start</code>","text":"<p>               Bases: <code>ControlModel</code></p> <p>Specification of a serial control flow: one main component.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the reference to a BMI-compliant model component instance</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class Start(ControlModel):\n    \"\"\"\n    Specification of a serial control flow: one main component.\n\n    Attributes:\n        name: Name of the reference to a BMI-compliant model component instance\n    \"\"\"\n\n    _type: Literal[\"start\"] = \"start\"\n    name: str\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.models.StartGroup","title":"<code>StartGroup</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification of model components and couplers to be executed with a certain frequency.</p> <p>Attributes:</p> Name Type Description <code>time</code> <code>str</code> <p>Time frame specification for the present group: start time, stop time and frequency.   Expressed in terms of the time frame of the main component.</p> <code>start</code> <code>List[ComponentOrCouplerRef]</code> <p>Ordered list of components to be executed.</p> <code>coupler</code> <code>List[ComponentOrCouplerRef]</code> <p>Oredered list of couplers to be executed.</p> Source code in <code>hydrolib/core/dimr/models.py</code> <pre><code>class StartGroup(BaseModel):\n    \"\"\"\n    Specification of model components and couplers to be executed with a certain frequency.\n\n    Attributes:\n        time: Time frame specification for the present group: start time, stop time and frequency.\n              Expressed in terms of the time frame of the main component.\n        start: Ordered list of components to be executed.\n        coupler: Oredered list of couplers to be executed.\n    \"\"\"\n\n    time: str\n    start: List[ComponentOrCouplerRef] = Field(default_factory=list)\n    coupler: List[ComponentOrCouplerRef] = Field(default_factory=list)\n\n    @validator(\"start\", \"coupler\", pre=True)\n    def validate_start(cls, v):\n        return to_list(v)\n</code></pre>"},{"location":"reference/models/dimr/#parser","title":"Parser","text":"<p>DIMR Parser.</p>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.parser.DIMRParser","title":"<code>DIMRParser</code>","text":"<p>A parser for DIMR xml files.</p> Source code in <code>hydrolib/core/dimr/parser.py</code> <pre><code>class DIMRParser:\n    \"\"\"A parser for DIMR xml files.\"\"\"\n\n    @staticmethod\n    def parse(path: Path) -&gt; dict:\n        \"\"\"Parses a DIMR file to a dictionary.\n\n        Args:\n            path (Path): Path to the DIMR configuration file.\n        \"\"\"\n        if not path.is_file():\n            warn(f\"File: `{path}` not found, skipped parsing.\")\n            return {}\n\n        parser = etree.XMLParser(\n            remove_comments=True, resolve_entities=False, no_network=True\n        )\n        root = etree.parse(str(path), parser=parser).getroot()\n\n        return DIMRParser._node_to_dictionary(root, True)\n\n    @staticmethod\n    def _node_to_dictionary(node: etree, ignore_attributes: bool = False):\n        \"\"\"Convert a node to a dictionary.\n\n        Convert an lxml.etree node tree recursively into a nested dictionary.\n        The node's attributes and child items will be added to it's dictionary.\n\n        Args:\n            node (etree):\n                The etree node\n            ignore_attributes (bool, Optional):\n                parameter; whether or not to skip the node's attributes. Default is False.\n        \"\"\"\n        result = {} if ignore_attributes else dict(node.attrib)\n\n        for child_node in node.iterchildren():\n\n            key = child_node.tag.split(\"}\")[1]\n\n            if child_node.text and child_node.text.strip():\n                value = child_node.text\n            else:\n                value = DIMRParser._node_to_dictionary(child_node)\n\n            if key in result:\n\n                if type(result[key]) is list:\n                    result[key].append(value)\n                else:\n                    first_value = result[key].copy()\n                    result[key] = [first_value, value]\n            else:\n                result[key] = value\n\n        return result\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.parser.DIMRParser.parse","title":"<code>parse(path)</code>  <code>staticmethod</code>","text":"<p>Parses a DIMR file to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the DIMR configuration file.</p> required Source code in <code>hydrolib/core/dimr/parser.py</code> <pre><code>@staticmethod\ndef parse(path: Path) -&gt; dict:\n    \"\"\"Parses a DIMR file to a dictionary.\n\n    Args:\n        path (Path): Path to the DIMR configuration file.\n    \"\"\"\n    if not path.is_file():\n        warn(f\"File: `{path}` not found, skipped parsing.\")\n        return {}\n\n    parser = etree.XMLParser(\n        remove_comments=True, resolve_entities=False, no_network=True\n    )\n    root = etree.parse(str(path), parser=parser).getroot()\n\n    return DIMRParser._node_to_dictionary(root, True)\n</code></pre>"},{"location":"reference/models/dimr/#serializer","title":"Serializer","text":"<p>DIMR Serializer.</p>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.serializer.DIMRSerializer","title":"<code>DIMRSerializer</code>","text":"<p>A serializer for DIMR files.</p> Source code in <code>hydrolib/core/dimr/serializer.py</code> <pre><code>class DIMRSerializer:\n    \"\"\"A serializer for DIMR files.\"\"\"\n\n    @staticmethod\n    def serialize(\n        path: Path,\n        data: dict,\n        config: SerializerConfig,\n        save_settings: ModelSaveSettings,\n    ):\n        \"\"\"Serializes the DIMR data to the file at the specified path.\n\n        Attributes:\n            path (Path): The path to the destination file.\n            data (Dict): The data to be serialized.\n            config (SerializerConfig): The serialization configuration.\n            save_settings (ModelSaveSettings): The model save settings.\n        \"\"\"\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        xmlns = \"http://schemas.deltares.nl/dimr\"\n        xsi = \"http://www.w3.org/2001/XMLSchema-instance\"\n        schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\"\n\n        attrib = {e.QName(xsi, \"schemaLocation\"): f\"{xmlns} {schema_location}\"}\n        namespaces = {None: xmlns, \"xsi\": xsi}\n\n        root = e.Element(\n            \"dimrConfig\",\n            attrib=attrib,\n            nsmap=namespaces,\n        )\n\n        path_style_converter = FilePathStyleConverter()\n        DIMRSerializer._build_tree(\n            root, data, config, save_settings, path_style_converter\n        )\n\n        to_string = minidom.parseString(e.tostring(root))\n        xml = to_string.toprettyxml(indent=\"  \", encoding=\"utf-8\")\n\n        with path.open(\"wb\") as f:\n            f.write(xml)\n\n    @staticmethod\n    def _build_tree(\n        root,\n        data: dict,\n        config: SerializerConfig,\n        save_settings: ModelSaveSettings,\n        path_style_converter: FilePathStyleConverter,\n    ):\n        name = data.pop(\"name\", None)\n        if name:\n            root.set(\"name\", name)\n\n        for key, val in data.items():\n            if isinstance(val, dict):\n                c = e.Element(key)\n                DIMRSerializer._build_tree(\n                    c, val, config, save_settings, path_style_converter\n                )\n                root.append(c)\n            elif isinstance(val, List):\n                for item in val:\n                    c = e.Element(key)\n                    DIMRSerializer._build_tree(\n                        c, item, config, save_settings, path_style_converter\n                    )\n                    root.append(c)\n            else:\n                c = e.Element(key)\n                if isinstance(val, datetime):\n                    c.text = val.isoformat(sep=\"T\", timespec=\"auto\")\n                elif isinstance(val, float):\n                    c.text = f\"{val:{config.float_format}}\"\n                elif isinstance(val, Path):\n                    c.text = path_style_converter.convert_from_os_style(\n                        val, save_settings.path_style\n                    )\n                else:\n                    c.text = str(val)\n                root.append(c)\n</code></pre>"},{"location":"reference/models/dimr/#hydrolib.core.dimr.serializer.DIMRSerializer.serialize","title":"<code>serialize(path, data, config, save_settings)</code>  <code>staticmethod</code>","text":"<p>Serializes the DIMR data to the file at the specified path.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>The path to the destination file.</p> <code>data</code> <code>Dict</code> <p>The data to be serialized.</p> <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> <code>save_settings</code> <code>ModelSaveSettings</code> <p>The model save settings.</p> Source code in <code>hydrolib/core/dimr/serializer.py</code> <pre><code>@staticmethod\ndef serialize(\n    path: Path,\n    data: dict,\n    config: SerializerConfig,\n    save_settings: ModelSaveSettings,\n):\n    \"\"\"Serializes the DIMR data to the file at the specified path.\n\n    Attributes:\n        path (Path): The path to the destination file.\n        data (Dict): The data to be serialized.\n        config (SerializerConfig): The serialization configuration.\n        save_settings (ModelSaveSettings): The model save settings.\n    \"\"\"\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    xmlns = \"http://schemas.deltares.nl/dimr\"\n    xsi = \"http://www.w3.org/2001/XMLSchema-instance\"\n    schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\"\n\n    attrib = {e.QName(xsi, \"schemaLocation\"): f\"{xmlns} {schema_location}\"}\n    namespaces = {None: xmlns, \"xsi\": xsi}\n\n    root = e.Element(\n        \"dimrConfig\",\n        attrib=attrib,\n        nsmap=namespaces,\n    )\n\n    path_style_converter = FilePathStyleConverter()\n    DIMRSerializer._build_tree(\n        root, data, config, save_settings, path_style_converter\n    )\n\n    to_string = minidom.parseString(e.tostring(root))\n    xml = to_string.toprettyxml(indent=\"  \", encoding=\"utf-8\")\n\n    with path.open(\"wb\") as f:\n        f.write(xml)\n</code></pre>"},{"location":"reference/models/ext/","title":"External forcings file","text":"<p>The external forcing .ext file contains the forcing data for a D-Flow FM model. This includes open boundaries, lateral discharges and meteorological forcings. The documentation below only concerns the 'new' format (<code>ExtForceFileNew</code> in the MDU file).</p>"},{"location":"reference/models/ext/#model","title":"Model","text":""},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Boundary","title":"<code>Boundary</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Boundary]</code> block for use inside an external forcings file, i.e., a ExtModel.</p> <p>All lowercased attributes match with the boundary input as described in UM Sec.C.5.2.1.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class Boundary(INIBasedModel):\n    \"\"\"\n    A `[Boundary]` block for use inside an external forcings file,\n    i.e., a [ExtModel][hydrolib.core.dflowfm.ext.models.ExtModel].\n\n    All lowercased attributes match with the boundary input as described in\n    [UM Sec.C.5.2.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.5.2.1).\n    \"\"\"\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Boundary\"] = \"Boundary\"\n    quantity: str = Field(alias=\"quantity\")\n    nodeid: Optional[str] = Field(alias=\"nodeId\")\n    locationfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"locationFile\"\n    )\n    forcingfile: Union[ForcingModel, List[ForcingModel]] = Field(alias=\"forcingFile\")\n    bndwidth1d: Optional[float] = Field(alias=\"bndWidth1D\")\n    bndbldepth: Optional[float] = Field(alias=\"bndBlDepth\")\n    returntime: Optional[float] = Field(alias=\"returnTime\")\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    @classmethod\n    def _is_valid_locationfile_data(\n        cls, elem: Union[None, str, Path, DiskOnlyFileModel]\n    ) -&gt; bool:\n        return isinstance(elem, Path) or (\n            isinstance(elem, DiskOnlyFileModel) and elem.filepath is not None\n        )\n\n    @root_validator\n    @classmethod\n    def check_nodeid_or_locationfile_present(cls, values: Dict):\n        \"\"\"\n        Verifies that either nodeid or locationfile properties have been set.\n\n        Args:\n            values (Dict): Dictionary with values already validated.\n\n        Raises:\n            ValueError: When none of the values are present.\n\n        Returns:\n            Dict: Validated dictionary of values for Boundary.\n        \"\"\"\n        node_id = values.get(\"nodeid\", None)\n        location_file = values.get(\"locationfile\", None)\n        if str_is_empty_or_none(node_id) and not cls._is_valid_locationfile_data(\n            location_file\n        ):\n            raise ValueError(\n                \"Either nodeId or locationFile fields should be specified.\"\n            )\n        return values\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        \"\"\"\n        Retrieves the identifier for a boundary, which is the nodeid\n\n        Args:\n            data (dict): Dictionary of values for this boundary.\n\n        Returns:\n            str: The nodeid value or None if not found.\n        \"\"\"\n        return data.get(\"nodeid\")\n\n    @property\n    def forcing(self) -&gt; Union[ForcingBase, None]:\n        \"\"\"Retrieves the corresponding forcing data for this boundary.\n\n        Returns:\n            ForcingBase: The corresponding forcing data. None when this boundary does not have a forcing file or when the data cannot be found.\n        \"\"\"\n        result = None\n        if self.forcingfile is not None:\n            for forcing in self.forcingfile.forcing:\n\n                if self.nodeid == forcing.name and any(\n                    quantity.quantity.startswith(self.quantity)\n                    for quantity in forcing.quantityunitpair\n                ):\n                    result = forcing\n                    break\n\n        return result\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Boundary.forcing","title":"<code>forcing</code>  <code>property</code>","text":"<p>Retrieves the corresponding forcing data for this boundary.</p> <p>Returns:</p> Name Type Description <code>ForcingBase</code> <code>Union[ForcingBase, None]</code> <p>The corresponding forcing data. None when this boundary does not have a forcing file or when the data cannot be found.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Boundary.check_nodeid_or_locationfile_present","title":"<code>check_nodeid_or_locationfile_present(values)</code>  <code>classmethod</code>","text":"<p>Verifies that either nodeid or locationfile properties have been set.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Dict</code> <p>Dictionary with values already validated.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When none of the values are present.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <p>Validated dictionary of values for Boundary.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>@root_validator\n@classmethod\ndef check_nodeid_or_locationfile_present(cls, values: Dict):\n    \"\"\"\n    Verifies that either nodeid or locationfile properties have been set.\n\n    Args:\n        values (Dict): Dictionary with values already validated.\n\n    Raises:\n        ValueError: When none of the values are present.\n\n    Returns:\n        Dict: Validated dictionary of values for Boundary.\n    \"\"\"\n    node_id = values.get(\"nodeid\", None)\n    location_file = values.get(\"locationfile\", None)\n    if str_is_empty_or_none(node_id) and not cls._is_valid_locationfile_data(\n        location_file\n    ):\n        raise ValueError(\n            \"Either nodeId or locationFile fields should be specified.\"\n        )\n    return values\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.BoundaryError","title":"<code>BoundaryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>BoundaryError.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class BoundaryError(Exception):\n    \"\"\"BoundaryError.\"\"\"\n\n    def __init__(self, error_message: str):\n        \"\"\"BoundaryError constructor.\"\"\"\n        print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.BoundaryError.__init__","title":"<code>__init__(error_message)</code>","text":"<p>BoundaryError constructor.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>def __init__(self, error_message: str):\n    \"\"\"BoundaryError constructor.\"\"\"\n    print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.ExtGeneral","title":"<code>ExtGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The external forcing file's <code>[General]</code> section with file meta-data.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class ExtGeneral(INIGeneral):\n    \"\"\"The external forcing file's `[General]` section with file meta-data.\"\"\"\n\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"2.01\", alias=\"fileVersion\")\n    filetype: Literal[\"extForce\"] = Field(\"extForce\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.ExtModel","title":"<code>ExtModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall external forcings model that contains the contents of one external forcings file (new format).</p> <p>This model is typically referenced under a FMModel<code>.external_forcing.extforcefilenew</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>ExtGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>boundary</code> <code>List[Boundary]</code> <p>List of <code>[Boundary]</code> blocks for all boundary conditions.</p> <code>lateral</code> <code>List[Lateral]</code> <p>List of <code>[Lateral]</code> blocks for all lateral discharges.</p> <code>sourcesink</code> <code>List[SourceSink]</code> <p>List of <code>[SourceSink]</code> blocks for all source/sink terms.</p> <code>meteo</code> <code>List[Meteo]</code> <p>List of <code>[Meteo]</code> blocks for all meteorological forcings.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class ExtModel(INIModel):\n    \"\"\"\n    The overall external forcings model that contains the contents of one external forcings file (new format).\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.external_forcing.extforcefilenew`.\n\n    Attributes:\n        general (ExtGeneral): `[General]` block with file metadata.\n        boundary (List[Boundary]): List of `[Boundary]` blocks for all boundary conditions.\n        lateral (List[Lateral]): List of `[Lateral]` blocks for all lateral discharges.\n        sourcesink (List[SourceSink]): List of `[SourceSink]` blocks for all source/sink terms.\n        meteo (List[Meteo]): List of `[Meteo]` blocks for all meteorological forcings.\n    \"\"\"\n\n    general: ExtGeneral = ExtGeneral()\n    boundary: List[Boundary] = Field(default_factory=list)\n    lateral: List[Lateral] = Field(default_factory=list)\n    sourcesink: List[SourceSink] = Field(default_factory=list)\n    meteo: List[Meteo] = Field(default_factory=list)\n    serializer_config: INISerializerConfig = INISerializerConfig(\n        section_indent=0, property_indent=0\n    )\n    _split_to_list = make_list_validator(\"boundary\", \"lateral\", \"meteo\", \"sourcesink\")\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ext\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"bnd\"\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.InitialFieldError","title":"<code>InitialFieldError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>InitialFieldError.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class InitialFieldError(Exception):\n    \"\"\"InitialFieldError.\"\"\"\n\n    def __init__(self, error_message: str):\n        \"\"\"InitialFieldError constructor.\"\"\"\n        print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.InitialFieldError.__init__","title":"<code>__init__(error_message)</code>","text":"<p>InitialFieldError constructor.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>def __init__(self, error_message: str):\n    \"\"\"InitialFieldError constructor.\"\"\"\n    print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Lateral","title":"<code>Lateral</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Lateral]</code> block for use inside an external forcings file, i.e., a ExtModel.</p> <p>All lowercased attributes match with the lateral input as described in UM Sec.C.5.2.2.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class Lateral(INIBasedModel):\n    \"\"\"\n    A `[Lateral]` block for use inside an external forcings file,\n    i.e., a [ExtModel][hydrolib.core.dflowfm.ext.models.ExtModel].\n\n    All lowercased attributes match with the lateral input as described in\n    [UM Sec.C.5.2.2](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.5.2.2).\n    \"\"\"\n\n    _header: Literal[\"Lateral\"] = \"Lateral\"\n    id: str = Field(alias=\"id\")\n    name: str = Field(\"\", alias=\"name\")\n    locationtype: Optional[str] = Field(alias=\"locationType\")\n    nodeid: Optional[str] = Field(alias=\"nodeId\")\n    branchid: Optional[str] = Field(alias=\"branchId\")\n    chainage: Optional[float] = Field(alias=\"chainage\")\n    numcoordinates: Optional[int] = Field(alias=\"numCoordinates\")\n    xcoordinates: Optional[List[float]] = Field(alias=\"xCoordinates\")\n    ycoordinates: Optional[List[float]] = Field(alias=\"yCoordinates\")\n    discharge: ForcingData = Field(alias=\"discharge\")\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"xcoordinates\", \"ycoordinates\"\n    )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the correct location specification is given.\"\"\"\n        return validate_location_specification(\n            values, config=LocationValidationConfiguration(minimum_num_coordinates=1)\n        )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\") or data.get(\"name\")\n\n    @validator(\"locationtype\")\n    @classmethod\n    def validate_location_type(cls, v: str) -&gt; str:\n        \"\"\"\n        Method to validate whether the specified location type is correct.\n\n        Args:\n            v (str): Given value for the locationtype field.\n\n        Raises:\n            ValueError: When the value given for locationtype is unknown.\n\n        Returns:\n            str: Validated locationtype string.\n        \"\"\"\n        possible_values = [\"1d\", \"2d\", \"all\"]\n        if v.lower() not in possible_values:\n            raise ValueError(\n                \"Value given ({}) not accepted, should be one of: {}\".format(\n                    v, \", \".join(possible_values)\n                )\n            )\n        return v\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Lateral.validate_location_type","title":"<code>validate_location_type(v)</code>  <code>classmethod</code>","text":"<p>Method to validate whether the specified location type is correct.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>Given value for the locationtype field.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the value given for locationtype is unknown.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Validated locationtype string.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>@validator(\"locationtype\")\n@classmethod\ndef validate_location_type(cls, v: str) -&gt; str:\n    \"\"\"\n    Method to validate whether the specified location type is correct.\n\n    Args:\n        v (str): Given value for the locationtype field.\n\n    Raises:\n        ValueError: When the value given for locationtype is unknown.\n\n    Returns:\n        str: Validated locationtype string.\n    \"\"\"\n    possible_values = [\"1d\", \"2d\", \"all\"]\n    if v.lower() not in possible_values:\n        raise ValueError(\n            \"Value given ({}) not accepted, should be one of: {}\".format(\n                v, \", \".join(possible_values)\n            )\n        )\n    return v\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Lateral.validate_that_location_specification_is_correct","title":"<code>validate_that_location_specification_is_correct(values)</code>","text":"<p>Validates that the correct location specification is given.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n    \"\"\"Validates that the correct location specification is given.\"\"\"\n    return validate_location_specification(\n        values, config=LocationValidationConfiguration(minimum_num_coordinates=1)\n    )\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.Meteo","title":"<code>Meteo</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Meteo]</code> block for use inside an external forcings file, i.e., a ExtModel.</p> <p>All lowercased attributes match with the meteo input as described in UM Sec.C.5.2.3.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class Meteo(INIBasedModel):\n    \"\"\"\n    A `[Meteo]` block for use inside an external forcings file,\n    i.e., a [ExtModel][hydrolib.core.dflowfm.ext.models.ExtModel].\n\n    All lowercased attributes match with the meteo input as described in\n    [UM Sec.C.5.2.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.5.2.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        quantity: Optional[str] = Field(\n            \"Name of the quantity. See UM Section C.5.3\", alias=\"quantity\"\n        )\n        forcingfile: Optional[str] = Field(\n            \"Name of file containing the forcing for this meteo quantity.\",\n            alias=\"forcingFile\",\n        )\n        forcingfiletype: Optional[str] = Field(\n            \"Type of forcingFile.\", alias=\"forcingFileType\"\n        )\n        forcingVariableName: Optional[str] = Field(\n            \"Variable name used in forcingfile associated with this forcing. See UM Section C.5.3\",\n            alias=\"forcingVariableName\",\n        )\n        targetmaskfile: Optional[str] = Field(\n            \"Name of &lt;*.pol&gt; file to be used as mask. Grid parts inside any polygon will receive the meteo forcing.\",\n            alias=\"targetMaskFile\",\n        )\n        targetmaskinvert: Optional[str] = Field(\n            \"Flag indicating whether the target mask should be inverted, i.e., outside of all polygons: no or yes.\",\n            alias=\"targetMaskInvert\",\n        )\n        interpolationmethod: Optional[str] = Field(\n            \"Type of (spatial) interpolation.\", alias=\"interpolationMethod\"\n        )\n        operand: Optional[str] = Field(\n            \"How this data is combined with previous data for the same quantity (if any).\",\n            alias=\"operand\",\n        )\n        extrapolationAllowed: Optional[str] = Field(\n            \"Optionally allow nearest neighbour extrapolation in space (0: no, 1: yes). Default off.\",\n            alias=\"extrapolationAllowed\",\n        )\n        extrapolationSearchRadius: Optional[str] = Field(\n            \"Maximum search radius for nearest neighbor extrapolation in space.\",\n            alias=\"extrapolationSearchRadius\",\n        )\n\n    comments: Comments = Comments()\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"\n        The Meteo does not currently support raising an error on unknown keywords.\n        \"\"\"\n        return None\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Meteo\"] = \"Meteo\"\n    quantity: str = Field(alias=\"quantity\")\n    forcingfile: Union[TimModel, ForcingModel, DiskOnlyFileModel] = Field(\n        alias=\"forcingFile\"\n    )\n    forcingVariableName: Optional[str] = Field(alias=\"forcingVariableName\")\n    forcingfiletype: MeteoForcingFileType = Field(alias=\"forcingFileType\")\n    targetmaskfile: Optional[PolyFile] = Field(None, alias=\"targetMaskFile\")\n    targetmaskinvert: Optional[bool] = Field(None, alias=\"targetMaskInvert\")\n    interpolationmethod: Optional[MeteoInterpolationMethod] = Field(\n        alias=\"interpolationMethod\"\n    )\n    operand: Optional[Operand] = Field(Operand.override.value, alias=\"operand\")\n    extrapolationAllowed: Optional[bool] = Field(alias=\"extrapolationAllowed\")\n    extrapolationSearchRadius: Optional[float] = Field(\n        alias=\"extrapolationSearchRadius\"\n    )\n    averagingType: Optional[int] = Field(alias=\"averagingType\")\n    averagingNumMin: Optional[float] = Field(alias=\"averagingNumMin\")\n    averagingPercentile: Optional[float] = Field(alias=\"averagingPercentile\")\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    forcingfiletype_validator = get_enum_validator(\n        \"forcingfiletype\", enum=MeteoForcingFileType\n    )\n    interpolationmethod_validator = get_enum_validator(\n        \"interpolationmethod\", enum=MeteoInterpolationMethod\n    )\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoError","title":"<code>MeteoError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>MeteoError.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class MeteoError(Exception):\n    \"\"\"MeteoError.\"\"\"\n\n    def __init__(self, error_message: str):\n        \"\"\"MeteoError constructor.\"\"\"\n        print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoError.__init__","title":"<code>__init__(error_message)</code>","text":"<p>MeteoError constructor.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>def __init__(self, error_message: str):\n    \"\"\"MeteoError constructor.\"\"\"\n    print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType","title":"<code>MeteoForcingFileType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the forcingFileType attribute in Meteo class.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class MeteoForcingFileType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the forcingFileType\n    attribute in Meteo class.\n    \"\"\"\n\n    bcascii = \"bcAscii\"\n    \"\"\"str: Space-uniform time series in &lt;*.bc&gt; file.\"\"\"\n\n    uniform = \"uniform\"\n    \"\"\"str: Space-uniform time series in &lt;*.tim&gt; file.\"\"\"\n\n    unimagdir = \"uniMagDir\"\n    \"\"\"str: Space-uniform wind magnitude+direction in &lt;*.tim&gt; file.\"\"\"\n\n    arcinfo = \"arcInfo\"\n    \"\"\"str: Space- and time-varying wind and pressure on an equidistant grid in &lt;*.amu/v/p&gt; files.\"\"\"\n\n    spiderweb = \"spiderweb\"\n    \"\"\"str: Space- and time-varying cyclone wind and pressure in &lt;*.spw&gt; files.\"\"\"\n\n    curvigrid = \"curviGrid\"\n    \"\"\"str: Space- and time-varying wind and pressure on a curvilinear grid in &lt;*.grd+*.amu/v/p&gt; files.\"\"\"\n\n    netcdf = \"netcdf\"\n    \"\"\"str: NetCDF, either with gridded data, or multiple station time series.\"\"\"\n\n    allowedvaluestext = \"Possible values: bcAscii, uniform, uniMagDir, arcInfo, spiderweb, curviGrid, netcdf.\"\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.arcinfo","title":"<code>arcinfo = 'arcInfo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space- and time-varying wind and pressure on an equidistant grid in &lt;*.amu/v/p&gt; files.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.bcascii","title":"<code>bcascii = 'bcAscii'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space-uniform time series in &lt;*.bc&gt; file.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.curvigrid","title":"<code>curvigrid = 'curviGrid'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space- and time-varying wind and pressure on a curvilinear grid in &lt;.grd+.amu/v/p&gt; files.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.netcdf","title":"<code>netcdf = 'netcdf'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: NetCDF, either with gridded data, or multiple station time series.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.spiderweb","title":"<code>spiderweb = 'spiderweb'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space- and time-varying cyclone wind and pressure in &lt;*.spw&gt; files.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.uniform","title":"<code>uniform = 'uniform'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space-uniform time series in &lt;*.tim&gt; file.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoForcingFileType.unimagdir","title":"<code>unimagdir = 'uniMagDir'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Space-uniform wind magnitude+direction in &lt;*.tim&gt; file.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoInterpolationMethod","title":"<code>MeteoInterpolationMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the interpolationMethod attribute in Meteo class.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class MeteoInterpolationMethod(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the interpolationMethod\n    attribute in Meteo class.\n    \"\"\"\n\n    nearestnb = \"nearestNb\"\n    \"\"\"str: Nearest-neighbour interpolation, only with station-data in forcingFileType=netcdf\"\"\"\n    linearSpaceTime = \"linearSpaceTime\"\n    \"\"\"str: Linear interpolation in space and time.\"\"\"\n    allowedvaluestext = \"Possible values: nearestNb, linearSpaceTime.\"\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoInterpolationMethod.linearSpaceTime","title":"<code>linearSpaceTime = 'linearSpaceTime'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Linear interpolation in space and time.</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.MeteoInterpolationMethod.nearestnb","title":"<code>nearestnb = 'nearestNb'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Nearest-neighbour interpolation, only with station-data in forcingFileType=netcdf</p>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.ParameterFieldError","title":"<code>ParameterFieldError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>ParameterFieldError.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class ParameterFieldError(Exception):\n    \"\"\"ParameterFieldError.\"\"\"\n\n    def __init__(self, error_message: str):\n        \"\"\"ParameterFieldError constructor.\"\"\"\n        print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.ParameterFieldError.__init__","title":"<code>__init__(error_message)</code>","text":"<p>ParameterFieldError constructor.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>def __init__(self, error_message: str):\n    \"\"\"ParameterFieldError constructor.\"\"\"\n    print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.SourceSink","title":"<code>SourceSink</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[SourceSink]</code> block for use inside an external forcings file, i.e., a ExtModel.</p> <p>All lowercased attributes match with the source-sink input as described in UM Sec.C.5.2.4.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class SourceSink(INIBasedModel):\n    \"\"\"\n    A `[SourceSink]` block for use inside an external forcings file,\n    i.e., a [ExtModel][hydrolib.core.dflowfm.ext.models.SourceSink].\n\n    All lowercased attributes match with the source-sink input as described in\n    [UM Sec.C.5.2.4](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.5.2.4).\n    \"\"\"\n\n    _header: Literal[\"SourceSink\"] = \"SourceSink\"\n    id: str = Field(alias=\"id\")\n    name: str = Field(\"\", alias=\"name\")\n    locationfile: Optional[DiskOnlyFileModel] = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"locationFile\"\n    )\n\n    numcoordinates: Optional[int] = Field(alias=\"numCoordinates\")\n    xcoordinates: Optional[List[float]] = Field(alias=\"xCoordinates\")\n    ycoordinates: Optional[List[float]] = Field(alias=\"yCoordinates\")\n\n    zsource: Optional[Union[float, List[float]]] = Field(alias=\"zSource\")\n    zsink: Optional[Union[float, List[float]]] = Field(alias=\"zSink\")\n    area: Optional[float] = Field(alias=\"Area\")\n\n    discharge: ForcingData = Field(alias=\"discharge\")\n    salinitydelta: Optional[ForcingData] = Field(alias=\"salinityDelta\")\n    temperaturedelta: Optional[ForcingData] = Field(alias=\"temperatureDelta\")\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    @classmethod\n    def _exclude_from_validation(cls, input_data: Optional[dict] = None) -&gt; Set:\n        fields = cls.__fields__\n        unknown_keywords = [\n            key\n            for key in input_data.keys()\n            if key not in fields\n            and key.startswith(SOURCE_SINKS_QUANTITIES_VALID_PREFIXES)\n        ]\n        return set(unknown_keywords)\n\n    class Config:\n        \"\"\"\n        Config class to tell Pydantic to accept fields not explicitly declared in the model.\n        \"\"\"\n\n        # Allow dynamic fields\n        extra = \"allow\"\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        # Add dynamic attributes for fields starting with 'tracer'\n        for key, value in data.items():\n            if isinstance(key, str) and key.startswith(\n                SOURCE_SINKS_QUANTITIES_VALID_PREFIXES\n            ):\n                setattr(self, key, value)\n\n    @root_validator(pre=True)\n    def validate_location_specification(cls, values):\n        \"\"\"\n        Ensures that either `locationfile` or a valid set of coordinates is provided.\n\n         This validation enforces that at least one of the following conditions is met:\n         1. `locationfile` is provided.\n         2. The combination of `numcoordinates`, `xcoordinates`, and `ycoordinates` is valid:\n             - `xcoordinates` and `ycoordinates` must be lists of equal length.\n             - The length of `xcoordinates` and `ycoordinates` must match `numcoordinates`.\n\n         Raises:\n             ValueError: If neither `locationfile` nor a valid coordinate set is provided.\n\n         Returns:\n             Dict: The validated input values.\n        \"\"\"\n        locationfile = values.get(\"locationfile\", values.get(\"locationFile\"))\n\n        numcoordinates = values.get(\"numcoordinates\", values.get(\"numCoordinates\"))\n        xcoordinates = values.get(\"xcoordinates\", values.get(\"xCoordinates\"))\n        ycoordinates = values.get(\"ycoordinates\", values.get(\"yCoordinates\"))\n\n        has_locationfile = locationfile is not None\n        has_coordinates = (\n            numcoordinates is not None\n            and xcoordinates is not None\n            and ycoordinates is not None\n            and len(xcoordinates) == len(ycoordinates) == numcoordinates\n        )\n\n        if not (has_locationfile or has_coordinates):\n            raise ValueError(\n                \"Either `locationFile` or the combination of `numCoordinates`, `xCoordinates`, and `yCoordinates` \"\n                f\"must be provided. for the SourceSink block `{values.get('id')}`.\"\n            )\n\n        return values\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.SourceSink.Config","title":"<code>Config</code>","text":"<p>Config class to tell Pydantic to accept fields not explicitly declared in the model.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class Config:\n    \"\"\"\n    Config class to tell Pydantic to accept fields not explicitly declared in the model.\n    \"\"\"\n\n    # Allow dynamic fields\n    extra = \"allow\"\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.SourceSink.validate_location_specification","title":"<code>validate_location_specification(values)</code>","text":"<p>Ensures that either <code>locationfile</code> or a valid set of coordinates is provided.</p> <p>This validation enforces that at least one of the following conditions is met:  1. <code>locationfile</code> is provided.  2. The combination of <code>numcoordinates</code>, <code>xcoordinates</code>, and <code>ycoordinates</code> is valid:      - <code>xcoordinates</code> and <code>ycoordinates</code> must be lists of equal length.      - The length of <code>xcoordinates</code> and <code>ycoordinates</code> must match <code>numcoordinates</code>.</p> <p>Raises:      ValueError: If neither <code>locationfile</code> nor a valid coordinate set is provided.</p> <p>Returns:      Dict: The validated input values.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>@root_validator(pre=True)\ndef validate_location_specification(cls, values):\n    \"\"\"\n    Ensures that either `locationfile` or a valid set of coordinates is provided.\n\n     This validation enforces that at least one of the following conditions is met:\n     1. `locationfile` is provided.\n     2. The combination of `numcoordinates`, `xcoordinates`, and `ycoordinates` is valid:\n         - `xcoordinates` and `ycoordinates` must be lists of equal length.\n         - The length of `xcoordinates` and `ycoordinates` must match `numcoordinates`.\n\n     Raises:\n         ValueError: If neither `locationfile` nor a valid coordinate set is provided.\n\n     Returns:\n         Dict: The validated input values.\n    \"\"\"\n    locationfile = values.get(\"locationfile\", values.get(\"locationFile\"))\n\n    numcoordinates = values.get(\"numcoordinates\", values.get(\"numCoordinates\"))\n    xcoordinates = values.get(\"xcoordinates\", values.get(\"xCoordinates\"))\n    ycoordinates = values.get(\"ycoordinates\", values.get(\"yCoordinates\"))\n\n    has_locationfile = locationfile is not None\n    has_coordinates = (\n        numcoordinates is not None\n        and xcoordinates is not None\n        and ycoordinates is not None\n        and len(xcoordinates) == len(ycoordinates) == numcoordinates\n    )\n\n    if not (has_locationfile or has_coordinates):\n        raise ValueError(\n            \"Either `locationFile` or the combination of `numCoordinates`, `xCoordinates`, and `yCoordinates` \"\n            f\"must be provided. for the SourceSink block `{values.get('id')}`.\"\n        )\n\n    return values\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.SourceSinkError","title":"<code>SourceSinkError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>SourceSinkError.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>class SourceSinkError(Exception):\n    \"\"\"SourceSinkError.\"\"\"\n\n    def __init__(self, error_message: str):\n        \"\"\"SourceSinkError constructor.\"\"\"\n        print(error_message)\n</code></pre>"},{"location":"reference/models/ext/#hydrolib.core.dflowfm.ext.models.SourceSinkError.__init__","title":"<code>__init__(error_message)</code>","text":"<p>SourceSinkError constructor.</p> Source code in <code>hydrolib/core/dflowfm/ext/models.py</code> <pre><code>def __init__(self, error_message: str):\n    \"\"\"SourceSinkError constructor.\"\"\"\n    print(error_message)\n</code></pre>"},{"location":"reference/models/extold/","title":"External forcings file","text":"<p>The external forcing .ext file contains the forcing data for a D-Flow FM model. This includes open boundaries, lateral discharges and meteorological forcings. The documentation below only concerns the 'old' format (<code>ExtForceFile</code> in the MDU file).</p>"},{"location":"reference/models/extold/#model","title":"Model","text":""},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity","title":"<code>ExtOldBoundaryQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldBoundaryQuantity(StrEnum):\n    # Boundary conditions\n    WaterLevelBnd = \"waterlevelbnd\"\n    \"\"\"Water level\"\"\"\n    NeumannBnd = \"neumannbnd\"\n    \"\"\"Water level gradient\"\"\"\n    RiemannBnd = \"riemannbnd\"\n    \"\"\"Riemann invariant\"\"\"\n    OutflowBnd = \"outflowbnd\"\n    \"\"\"Outflow\"\"\"\n    VelocityBnd = \"velocitybnd\"\n    \"\"\"Velocity\"\"\"\n    DischargeBnd = \"dischargebnd\"\n    \"\"\"Discharge\"\"\"\n    RiemannVelocityBnd = \"riemann_velocitybnd\"\n    \"\"\"Riemann invariant velocity\"\"\"\n    SalinityBnd = \"salinitybnd\"\n    \"\"\"Salinity\"\"\"\n    TemperatureBnd = \"temperaturebnd\"\n    \"\"\"Temperature\"\"\"\n    SedimentBnd = \"sedimentbnd\"\n    \"\"\"Suspended sediment\"\"\"\n    UXUYAdvectionVelocityBnd = \"uxuyadvectionvelocitybnd\"\n    \"\"\"ux-uy advection velocity\"\"\"\n    NormalVelocityBnd = \"normalvelocitybnd\"\n    \"\"\"Normal velocity\"\"\"\n    TangentialVelocityBnd = \"tangentialvelocitybnd\"\n    \"\"\"Tangential velocity\"\"\"\n    QhBnd = \"qhbnd\"\n    \"\"\"Discharge-water level dependency\"\"\"\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"Custom implementation for handling missing values.\n\n        the method parses any missing values and only allows the ones that start with \"initialtracer\".\n        \"\"\"\n        # Allow strings starting with \"tracer\"\n        if isinstance(value, str) and value.startswith(\n            BOUNDARY_CONDITION_QUANTITIES_VALID_PREFIXES\n        ):\n            new_member = str.__new__(cls, value)\n            new_member._value_ = value\n            return new_member\n        else:\n            raise ValueError(\n                f\"{value} is not a valid {cls.__name__} possible quantities are {', '.join(cls.__members__)}, \"\n                f\"and quantities that start with 'tracer'\"\n            )\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.DischargeBnd","title":"<code>DischargeBnd = 'dischargebnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discharge</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.NeumannBnd","title":"<code>NeumannBnd = 'neumannbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Water level gradient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.NormalVelocityBnd","title":"<code>NormalVelocityBnd = 'normalvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Normal velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.OutflowBnd","title":"<code>OutflowBnd = 'outflowbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Outflow</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.QhBnd","title":"<code>QhBnd = 'qhbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discharge-water level dependency</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.RiemannBnd","title":"<code>RiemannBnd = 'riemannbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Riemann invariant</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.RiemannVelocityBnd","title":"<code>RiemannVelocityBnd = 'riemann_velocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Riemann invariant velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.SalinityBnd","title":"<code>SalinityBnd = 'salinitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Salinity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.SedimentBnd","title":"<code>SedimentBnd = 'sedimentbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Suspended sediment</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.TangentialVelocityBnd","title":"<code>TangentialVelocityBnd = 'tangentialvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Tangential velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.TemperatureBnd","title":"<code>TemperatureBnd = 'temperaturebnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.UXUYAdvectionVelocityBnd","title":"<code>UXUYAdvectionVelocityBnd = 'uxuyadvectionvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ux-uy advection velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.VelocityBnd","title":"<code>VelocityBnd = 'velocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldBoundaryQuantity.WaterLevelBnd","title":"<code>WaterLevelBnd = 'waterlevelbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Water level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldExtrapolationMethod","title":"<code>ExtOldExtrapolationMethod</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the <code>extrapolation_method</code> attribute in the ExtOldForcing class.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldExtrapolationMethod(IntEnum):\n    \"\"\"Enum class containing the valid values for the `extrapolation_method` attribute\n    in the [ExtOldForcing][hydrolib.core.dflowfm.extold.models.ExtOldForcing] class.\n    \"\"\"\n\n    NoSpatialExtrapolation = 0\n    \"\"\"0. No spatial extrapolation.\"\"\"\n    SpatialExtrapolationOutsideOfSourceDataBoundingBox = 1\n    \"\"\"1. Do spatial extrapolation outside of source data bounding box.\"\"\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldExtrapolationMethod.NoSpatialExtrapolation","title":"<code>NoSpatialExtrapolation = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>No spatial extrapolation.</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldExtrapolationMethod.SpatialExtrapolationOutsideOfSourceDataBoundingBox","title":"<code>SpatialExtrapolationOutsideOfSourceDataBoundingBox = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Do spatial extrapolation outside of source data bounding box.</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType","title":"<code>ExtOldFileType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the <code>filetype</code> attribute in the ExtOldForcing class.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldFileType(IntEnum):\n    \"\"\"Enum class containing the valid values for the `filetype` attribute\n    in the [ExtOldForcing][hydrolib.core.dflowfm.extold.models.ExtOldForcing] class.\n    \"\"\"\n\n    TimeSeries = 1\n    \"\"\"1. Time series\"\"\"\n    TimeSeriesMagnitudeAndDirection = 2\n    \"\"\"2. Time series magnitude and direction\"\"\"\n    SpatiallyVaryingWindPressure = 3\n    \"\"\"3. Spatially varying wind and pressure\"\"\"\n    ArcInfo = 4\n    \"\"\"4. ArcInfo\"\"\"\n    SpiderWebData = 5\n    \"\"\"5. Spiderweb data (cyclones)\"\"\"\n    CurvilinearData = 6\n    \"\"\"6. Space-time data on curvilinear grid\"\"\"\n    Samples = 7\n    \"\"\"7. Samples\"\"\"\n    TriangulationMagnitudeAndDirection = 8\n    \"\"\"8. Triangulation magnitude and direction\"\"\"\n    Polyline = 9\n    \"\"\"9. Polyline (&lt;*.pli&gt;-file) with boundary signals on support points\"\"\"\n    InsidePolygon = 10\n    \"\"\"10. Polyfile (&lt;*.pol&gt;-file). Uniform value inside polygon for INITIAL fields\"\"\"\n    NetCDFGridData = 11\n    \"\"\"11. NetCDF grid data (e.g. meteo fields)\"\"\"\n    NetCDFWaveData = 14\n    \"\"\"14. NetCDF wave data\"\"\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.ArcInfo","title":"<code>ArcInfo = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>ArcInfo</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.CurvilinearData","title":"<code>CurvilinearData = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Space-time data on curvilinear grid</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.InsidePolygon","title":"<code>InsidePolygon = 10</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Polyfile (&lt;*.pol&gt;-file). Uniform value inside polygon for INITIAL fields</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.NetCDFGridData","title":"<code>NetCDFGridData = 11</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>NetCDF grid data (e.g. meteo fields)</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.NetCDFWaveData","title":"<code>NetCDFWaveData = 14</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>NetCDF wave data</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.Polyline","title":"<code>Polyline = 9</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Polyline (&lt;*.pli&gt;-file) with boundary signals on support points</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.Samples","title":"<code>Samples = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Samples</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.SpatiallyVaryingWindPressure","title":"<code>SpatiallyVaryingWindPressure = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Spatially varying wind and pressure</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.SpiderWebData","title":"<code>SpiderWebData = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Spiderweb data (cyclones)</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.TimeSeries","title":"<code>TimeSeries = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Time series</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.TimeSeriesMagnitudeAndDirection","title":"<code>TimeSeriesMagnitudeAndDirection = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Time series magnitude and direction</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldFileType.TriangulationMagnitudeAndDirection","title":"<code>TriangulationMagnitudeAndDirection = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Triangulation magnitude and direction</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing","title":"<code>ExtOldForcing</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class holding the external forcing values.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldForcing(BaseModel):\n    \"\"\"Class holding the external forcing values.\"\"\"\n\n    quantity: Union[ExtOldQuantity, str] = Field(alias=\"QUANTITY\")\n    \"\"\"Union[Quantity, str]: The name of the quantity.\"\"\"\n\n    filename: Union[PolyFile, TimModel, DiskOnlyFileModel] = Field(\n        None, alias=\"FILENAME\"\n    )\n    \"\"\"Union[PolyFile, TimModel, DiskOnlyFileModel]: The file associated to this forcing.\"\"\"\n\n    varname: Optional[str] = Field(None, alias=\"VARNAME\")\n    \"\"\"Optional[str]: The variable name used in `filename` associated with this forcing; some input files may contain multiple variables.\"\"\"\n\n    sourcemask: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"SOURCEMASK\"\n    )\n    \"\"\"DiskOnlyFileModel: The file containing a mask.\"\"\"\n\n    filetype: ExtOldFileType = Field(alias=\"FILETYPE\")\n    \"\"\"FileType: Indication of the file type.\n\n    Options:\n    1. Time series\n    2. Time series magnitude and direction\n    3. Spatially varying weather\n    4. ArcInfo\n    5. Spiderweb data (cyclones)\n    6. Curvilinear data\n    7. Samples (C.3)\n    8. Triangulation magnitude and direction\n    9. Polyline (&lt;*.pli&gt;-file, C.2)\n    11. NetCDF grid data (e.g. meteo fields)\n    14. NetCDF wave data\n    \"\"\"\n\n    method: ExtOldMethod = Field(alias=\"METHOD\")\n    \"\"\"ExtOldMethod: The method of interpolation.\n\n    Options:\n    1. Pass through (no interpolation)\n    2. Interpolate time and space\n    3. Interpolate time and space, save weights\n    4. Interpolate space\n    5. Interpolate time\n    6. Averaging space\n    7. Interpolate/Extrapolate time\n    \"\"\"\n\n    extrapolation_method: Optional[ExtOldExtrapolationMethod] = Field(\n        None, alias=\"EXTRAPOLATION_METHOD\"\n    )\n    \"\"\"Optional[ExtOldExtrapolationMethod]: The extrapolation method.\n\n    Options:\n    0. No spatial extrapolation.\n    1. Do spatial extrapolation outside of source data bounding box.\n    \"\"\"\n\n    maxsearchradius: Optional[float] = Field(None, alias=\"MAXSEARCHRADIUS\")\n    \"\"\"Optional[float]: Search radius (in m) for model grid points that lie outside of the source data bounding box.\"\"\"\n\n    operand: Operand = Field(alias=\"OPERAND\")\n    \"\"\"Operand: The operand to use for adding the provided values.\n\n    Options:\n    'O' Existing values are overwritten with the provided values.\n    'A' Provided values are used where existing values are missing.\n    '+' Existing values are summed with the provided values.\n    '*' Existing values are multiplied with the provided values.\n    'X' The maximum values of the existing values and provided values are used.\n    'N' The minimum values of the existing values and provided values are used.\n    \"\"\"\n\n    value: Optional[float] = Field(None, alias=\"VALUE\")\n    \"\"\"Optional[float]: Custom coefficients for transformation.\"\"\"\n\n    factor: Optional[float] = Field(None, alias=\"FACTOR\")\n    \"\"\"Optional[float]: The conversion factor.\"\"\"\n\n    ifrctyp: Optional[float] = Field(None, alias=\"IFRCTYP\")\n    \"\"\"Optional[float]: The friction type.\"\"\"\n\n    averagingtype: Optional[float] = Field(None, alias=\"AVERAGINGTYPE\")\n    \"\"\"Optional[float]: The averaging type.\"\"\"\n\n    relativesearchcellsize: Optional[float] = Field(\n        None, alias=\"RELATIVESEARCHCELLSIZE\"\n    )\n    \"\"\"Optional[float]: The relative search cell size for samples inside a cell.\"\"\"\n\n    extrapoltol: Optional[float] = Field(None, alias=\"EXTRAPOLTOL\")\n    \"\"\"Optional[float]: The extrapolation tolerance.\"\"\"\n\n    percentileminmax: Optional[float] = Field(None, alias=\"PERCENTILEMINMAX\")\n    \"\"\"Optional[float]: Changes the min/max operator to an average of the highest/lowest data points. The value sets the percentage of the total set that is to be included..\"\"\"\n\n    area: Optional[float] = Field(None, alias=\"AREA\")\n    \"\"\"Optional[float]: The area for sources and sinks.\"\"\"\n\n    nummin: Optional[int] = Field(None, alias=\"NUMMIN\")\n    \"\"\"Optional[int]: The minimum required number of source data points in each target cell.\"\"\"\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n\n    @validator(\"quantity\", pre=True)\n    def validate_quantity(cls, value):\n        if isinstance(value, ExtOldQuantity):\n            return value\n\n        def raise_error_tracer_name(quantity: ExtOldTracerQuantity):\n            raise ValueError(\n                f\"QUANTITY '{quantity}' should be appended with a tracer name.\"\n            )\n\n        if isinstance(value, ExtOldTracerQuantity):\n            raise_error_tracer_name(value)\n\n        value_str = str(value)\n        lower_value = value_str.lower()\n\n        for tracer_quantity in ExtOldTracerQuantity:\n            if lower_value.startswith(tracer_quantity):\n                n = len(tracer_quantity)\n                if n == len(value_str):\n                    raise_error_tracer_name(tracer_quantity)\n                return tracer_quantity + value_str[n:]\n\n        if lower_value in list(ExtOldQuantity):\n            return ExtOldQuantity(lower_value)\n\n        supported_value_str = \", \".join(([x.value for x in ExtOldQuantity]))\n        raise ValueError(\n            f\"QUANTITY '{value_str}' not supported. Supported values: {supported_value_str}\"\n        )\n\n    @validator(\"operand\", pre=True)\n    def validate_operand(cls, value):\n        if isinstance(value, Operand):\n            return value\n\n        if isinstance(value, str):\n\n            for operand in Operand:\n                if value.lower() == operand.value.lower():\n                    return operand\n\n            supported_value_str = \", \".join(([x.value for x in Operand]))\n            raise ValueError(\n                f\"OPERAND '{value}' not supported. Supported values: {supported_value_str}\"\n            )\n\n        return value\n\n    @root_validator(skip_on_failure=True)\n    def validate_forcing(cls, values):\n        class _Field:\n            def __init__(self, key: str) -&gt; None:\n                self.alias = cls.__fields__[key].alias\n                self.value = values[key]\n\n        def raise_error_only_allowed_when(\n            field: _Field, dependency: _Field, valid_dependency_value: str\n        ):\n            error = f\"{field.alias} only allowed when {dependency.alias} is {valid_dependency_value}\"\n            raise ValueError(error)\n\n        def only_allowed_when(\n            field: _Field, dependency: _Field, valid_dependency_value: Any\n        ):\n            \"\"\"This function checks if a particular field is allowed to have a value only when a dependency field has a specific value.\"\"\"\n\n            if field.value is None or dependency.value == valid_dependency_value:\n                return\n\n            raise_error_only_allowed_when(field, dependency, valid_dependency_value)\n\n        quantity = _Field(\"quantity\")\n        varname = _Field(\"varname\")\n        sourcemask = _Field(\"sourcemask\")\n        filetype = _Field(\"filetype\")\n        method = _Field(\"method\")\n        extrapolation_method = _Field(\"extrapolation_method\")\n        maxsearchradius = _Field(\"maxsearchradius\")\n        value = _Field(\"value\")\n        factor = _Field(\"factor\")\n        ifrctype = _Field(\"ifrctyp\")\n        averagingtype = _Field(\"averagingtype\")\n        relativesearchcellsize = _Field(\"relativesearchcellsize\")\n        extrapoltol = _Field(\"extrapoltol\")\n        percentileminmax = _Field(\"percentileminmax\")\n        area = _Field(\"area\")\n        nummin = _Field(\"nummin\")\n\n        only_allowed_when(varname, filetype, ExtOldFileType.NetCDFGridData)\n\n        if sourcemask.value.filepath is not None and filetype.value not in [\n            ExtOldFileType.ArcInfo,\n            ExtOldFileType.CurvilinearData,\n        ]:\n            raise_error_only_allowed_when(\n                sourcemask, filetype, valid_dependency_value=\"4 or 6\"\n            )\n\n        if (\n            extrapolation_method.value\n            == ExtOldExtrapolationMethod.SpatialExtrapolationOutsideOfSourceDataBoundingBox\n            and method.value != ExtOldMethod.InterpolateTimeAndSpaceSaveWeights\n            and method.value != ExtOldMethod.Obsolete\n        ):\n            error = f\"{extrapolation_method.alias} only allowed to be 1 when {method.alias} is 3\"\n            raise ValueError(error)\n\n        only_allowed_when(\n            maxsearchradius,\n            extrapolation_method,\n            ExtOldExtrapolationMethod.SpatialExtrapolationOutsideOfSourceDataBoundingBox,\n        )\n        only_allowed_when(value, method, ExtOldMethod.InterpolateSpace)\n\n        if factor.value is not None and not quantity.value.startswith(\n            ExtOldTracerQuantity.InitialTracer\n        ):\n            error = f\"{factor.alias} only allowed when {quantity.alias} starts with {ExtOldTracerQuantity.InitialTracer}\"\n            raise ValueError(error)\n\n        only_allowed_when(ifrctype, quantity, ExtOldQuantity.FrictionCoefficient)\n        only_allowed_when(averagingtype, method, ExtOldMethod.AveragingSpace)\n        only_allowed_when(relativesearchcellsize, method, ExtOldMethod.AveragingSpace)\n        only_allowed_when(extrapoltol, method, ExtOldMethod.InterpolateTime)\n        only_allowed_when(percentileminmax, method, ExtOldMethod.AveragingSpace)\n        only_allowed_when(\n            area, quantity, ExtOldQuantity.DischargeSalinityTemperatureSorSin\n        )\n        only_allowed_when(nummin, method, ExtOldMethod.AveragingSpace)\n\n        return values\n\n    @root_validator(pre=True)\n    def chooce_file_model(cls, values):\n        \"\"\"Root-level validator to the right class for the filename parameter based on the filetype.\n\n        The validator chooses the right class for the filename parameter based on the FileType_FileModel_mapping\n        dictionary.\n\n        FileType_FileModel_mapping = {\n            1: TimModel,\n            2: TimModel,\n            3: DiskOnlyFileModel,\n            4: DiskOnlyFileModel,\n            5: DiskOnlyFileModel,\n            6: DiskOnlyFileModel,\n            7: DiskOnlyFileModel,\n            8: DiskOnlyFileModel,\n            9: PolyFile,\n            10: PolyFile,\n            11: DiskOnlyFileModel,\n            12: DiskOnlyFileModel,\n        }\n        \"\"\"\n        # if the filetype and the filename are present in the values\n        if any(par in values for par in [\"filetype\", \"FILETYPE\"]) and any(\n            par in values for par in [\"filename\", \"FILENAME\"]\n        ):\n            file_type_var_name = \"filetype\" if \"filetype\" in values else \"FILETYPE\"\n            filename_var_name = \"filename\" if \"filename\" in values else \"FILENAME\"\n            file_type = values.get(file_type_var_name)\n            raw_path = values.get(filename_var_name)\n            model = FILETYPE_FILEMODEL_MAPPING.get(int(file_type))\n\n            values[filename_var_name] = model(raw_path)\n\n        return values\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.area","title":"<code>area = Field(None, alias='AREA')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The area for sources and sinks.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.averagingtype","title":"<code>averagingtype = Field(None, alias='AVERAGINGTYPE')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The averaging type.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.extrapolation_method","title":"<code>extrapolation_method = Field(None, alias='EXTRAPOLATION_METHOD')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[ExtOldExtrapolationMethod]: The extrapolation method.</p> <p>Options: 0. No spatial extrapolation. 1. Do spatial extrapolation outside of source data bounding box.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.extrapoltol","title":"<code>extrapoltol = Field(None, alias='EXTRAPOLTOL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The extrapolation tolerance.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.factor","title":"<code>factor = Field(None, alias='FACTOR')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The conversion factor.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.filename","title":"<code>filename = Field(None, alias='FILENAME')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Union[PolyFile, TimModel, DiskOnlyFileModel]: The file associated to this forcing.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.filetype","title":"<code>filetype = Field(alias='FILETYPE')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FileType: Indication of the file type.</p> <p>Options: 1. Time series 2. Time series magnitude and direction 3. Spatially varying weather 4. ArcInfo 5. Spiderweb data (cyclones) 6. Curvilinear data 7. Samples (C.3) 8. Triangulation magnitude and direction 9. Polyline (&lt;*.pli&gt;-file, C.2) 11. NetCDF grid data (e.g. meteo fields) 14. NetCDF wave data</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.ifrctyp","title":"<code>ifrctyp = Field(None, alias='IFRCTYP')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The friction type.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.maxsearchradius","title":"<code>maxsearchradius = Field(None, alias='MAXSEARCHRADIUS')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: Search radius (in m) for model grid points that lie outside of the source data bounding box.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.method","title":"<code>method = Field(alias='METHOD')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ExtOldMethod: The method of interpolation.</p> <p>Options: 1. Pass through (no interpolation) 2. Interpolate time and space 3. Interpolate time and space, save weights 4. Interpolate space 5. Interpolate time 6. Averaging space 7. Interpolate/Extrapolate time</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.nummin","title":"<code>nummin = Field(None, alias='NUMMIN')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[int]: The minimum required number of source data points in each target cell.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.operand","title":"<code>operand = Field(alias='OPERAND')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Operand: The operand to use for adding the provided values.</p> <p>Options: 'O' Existing values are overwritten with the provided values. 'A' Provided values are used where existing values are missing. '+' Existing values are summed with the provided values. '*' Existing values are multiplied with the provided values. 'X' The maximum values of the existing values and provided values are used. 'N' The minimum values of the existing values and provided values are used.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.percentileminmax","title":"<code>percentileminmax = Field(None, alias='PERCENTILEMINMAX')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: Changes the min/max operator to an average of the highest/lowest data points. The value sets the percentage of the total set that is to be included..</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.quantity","title":"<code>quantity = Field(alias='QUANTITY')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Union[Quantity, str]: The name of the quantity.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.relativesearchcellsize","title":"<code>relativesearchcellsize = Field(None, alias='RELATIVESEARCHCELLSIZE')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: The relative search cell size for samples inside a cell.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.sourcemask","title":"<code>sourcemask = Field(default_factory=lambda: DiskOnlyFileModel(None), alias='SOURCEMASK')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>DiskOnlyFileModel: The file containing a mask.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.value","title":"<code>value = Field(None, alias='VALUE')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[float]: Custom coefficients for transformation.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.varname","title":"<code>varname = Field(None, alias='VARNAME')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional[str]: The variable name used in <code>filename</code> associated with this forcing; some input files may contain multiple variables.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldForcing.chooce_file_model","title":"<code>chooce_file_model(values)</code>","text":"<p>Root-level validator to the right class for the filename parameter based on the filetype.</p> <p>The validator chooses the right class for the filename parameter based on the FileType_FileModel_mapping dictionary.</p> <p>FileType_FileModel_mapping = {     1: TimModel,     2: TimModel,     3: DiskOnlyFileModel,     4: DiskOnlyFileModel,     5: DiskOnlyFileModel,     6: DiskOnlyFileModel,     7: DiskOnlyFileModel,     8: DiskOnlyFileModel,     9: PolyFile,     10: PolyFile,     11: DiskOnlyFileModel,     12: DiskOnlyFileModel, }</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>@root_validator(pre=True)\ndef chooce_file_model(cls, values):\n    \"\"\"Root-level validator to the right class for the filename parameter based on the filetype.\n\n    The validator chooses the right class for the filename parameter based on the FileType_FileModel_mapping\n    dictionary.\n\n    FileType_FileModel_mapping = {\n        1: TimModel,\n        2: TimModel,\n        3: DiskOnlyFileModel,\n        4: DiskOnlyFileModel,\n        5: DiskOnlyFileModel,\n        6: DiskOnlyFileModel,\n        7: DiskOnlyFileModel,\n        8: DiskOnlyFileModel,\n        9: PolyFile,\n        10: PolyFile,\n        11: DiskOnlyFileModel,\n        12: DiskOnlyFileModel,\n    }\n    \"\"\"\n    # if the filetype and the filename are present in the values\n    if any(par in values for par in [\"filetype\", \"FILETYPE\"]) and any(\n        par in values for par in [\"filename\", \"FILENAME\"]\n    ):\n        file_type_var_name = \"filetype\" if \"filetype\" in values else \"FILETYPE\"\n        filename_var_name = \"filename\" if \"filename\" in values else \"FILENAME\"\n        file_type = values.get(file_type_var_name)\n        raw_path = values.get(filename_var_name)\n        model = FILETYPE_FILEMODEL_MAPPING.get(int(file_type))\n\n        values[filename_var_name] = model(raw_path)\n\n    return values\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldInitialConditionQuantity","title":"<code>ExtOldInitialConditionQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> Initial Condition quantities <p>initialwaterlevel, initialsalinity, initialsalinitytop, initialtemperature, initialverticaltemperatureprofile, initialverticalsalinityprofile, initialvelocityx, initialvelocityy, initialvelocity</p> <p>If there is a missing quantity that is mentioned in the \"Accepted quantity names\" section of the user manual Sec.C.5.3. and Sec.D.3. please open and issue in github.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldInitialConditionQuantity(StrEnum):\n    \"\"\"\n    Initial Condition quantities:\n        initialwaterlevel, initialsalinity, initialsalinitytop, initialtemperature,\n        initialverticaltemperatureprofile, initialverticalsalinityprofile, initialvelocityx,\n        initialvelocityy, initialvelocity\n\n    If there is a missing quantity that is mentioned in the \"Accepted quantity names\" section of the user manual\n    [Sec.C.5.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.5.3).\n    and [Sec.D.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.D.3).\n    please open and issue in github.\n    \"\"\"\n\n    # Initial Condition fields\n    BedLevel = \"bedlevel\"\n    BedLevel1D = \"bedlevel1D\"\n    BedLevel2D = \"bedlevel2D\"\n\n    InitialWaterLevel = \"initialwaterlevel\"\n    InitialWaterLevel1D = \"initialwaterlevel1d\"\n    InitialWaterLevel2D = \"initialwaterlevel2d\"\n\n    InitialSalinity = \"initialsalinity\"\n    InitialSalinityTop = \"initialsalinitytop\"\n    InitialSalinityBot = \"initialsalinitybot\"\n    InitialVerticalSalinityProfile = \"initialverticalsalinityprofile\"\n\n    InitialTemperature = \"initialtemperature\"\n    InitialVerticalTemperatureProfile = \"initialverticaltemperatureprofile\"\n\n    initialUnsaturatedZoneThickness = \"initialunsaturatedzonethickness\"\n    InitialVelocityX = \"initialvelocityx\"\n    InitialVelocityY = \"initialvelocityy\"\n    InitialVelocity = \"initialvelocity\"\n    InitialWaqBot = \"initialwaqbot\"\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"Custom implementation for handling missing values.\n\n        the method parses any missing values and only allows the ones that start with \"initialtracer\".\n        \"\"\"\n        # Allow strings starting with \"tracer\"\n        if isinstance(value, str) and value.startswith(\n            INITIAL_CONDITION_QUANTITIES_VALID_PREFIXES\n        ):\n            new_member = str.__new__(cls, value)\n            new_member._value_ = value\n            return new_member\n        else:\n            raise ValueError(\n                f\"{value} is not a valid {cls.__name__} possible quantities are {', '.join(cls.__members__)}, \"\n                f\"and quantities that start with 'tracer'\"\n            )\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity","title":"<code>ExtOldMeteoQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldMeteoQuantity(StrEnum):\n\n    # Meteorological fields\n    WindX = \"windx\"\n    \"\"\"Wind x component\"\"\"\n    WindY = \"windy\"\n    \"\"\"Wind y component\"\"\"\n    WindXY = \"windxy\"\n    \"\"\"Wind vector\"\"\"\n    AirPressureWindXWindY = \"airpressure_windx_windy\"\n    \"\"\"Atmospheric pressure and wind components\"\"\"\n    AirPressureWindXWindYCharnock = \"airpressure_windx_windy_charnock\"\n    \"Atmospheric pressure and wind components Charnock\"\n    AtmosphericPressure = \"atmosphericpressure\"\n    \"\"\"Atmospheric pressure\"\"\"\n    Rainfall = \"rainfall\"\n    \"\"\"Precipitation\"\"\"\n    RainfallRate = \"rainfall_rate\"\n    \"\"\"Precipitation\"\"\"\n    HumidityAirTemperatureCloudiness = \"humidity_airtemperature_cloudiness\"\n    \"\"\"Combined heat flux terms\"\"\"\n    HumidityAirTemperatureCloudinessSolarRadiation = (\n        \"humidity_airtemperature_cloudiness_solarradiation\"\n    )\n    \"\"\"Combined heat flux terms\"\"\"\n    DewPointAirTemperatureCloudiness = \"dewpoint_airtemperature_cloudiness\"\n    \"\"\"Dew point air temperature cloudiness\"\"\"\n    LongWaveRadiation = \"longwaveradiation\"\n    \"\"\"Long wave radiation\"\"\"\n    SolarRadiation = \"solarradiation\"\n    \"\"\"Solar radiation\"\"\"\n    NudgeSalinityTemperature = \"nudge_salinity_temperature\"\n    \"\"\"Nudging salinity and temperature\"\"\"\n    AirPressure = \"airpressure\"\n    \"\"\"AirPressure\"\"\"\n    StressX = \"stressx\"\n    \"\"\"eastward wind stress\"\"\"\n    StressY = \"stressy\"\n    \"\"\"northward wind stress\"\"\"\n    AirTemperature = \"airtemperature\"\n    \"\"\"AirTemperature\"\"\"\n    Cloudiness = \"cloudiness\"\n    \"\"\"Cloudiness, or cloud cover (fraction)\"\"\"\n    Humidity = \"humidity\"\n    \"\"\"Humidity\"\"\"\n    StressXY = \"stressxy\"\n    \"\"\"eastward and northward wind stress\"\"\"\n    AirpressureStressXStressY = \"airpressure_stressx_stressy\"\n    \"\"\"Airpressure, eastward and northward wind stress\"\"\"\n    WindSpeed = \"wind_speed\"\n    \"\"\"WindSpeed\"\"\"\n    WindFromDirection = \"wind_from_direction\"\n    \"\"\"WindFromDirection\"\"\"\n    DewpointAirTemperatureCloudinessSolarradiation = (\n        \"dewpoint_airtemperature_cloudiness_solarradiation\"\n    )\n    \"\"\"Dewpoint temperature, air temperature, cloudiness, solarradiation\"\"\"\n    AirDensity = \"airdensity\"\n    \"\"\"Air density\"\"\"\n    Charnock = \"charnock\"\n    \"\"\"Charnock coefficient\"\"\"\n    Dewpoint = \"dewpoint\"\n    \"\"\"Dewpoint temperature\"\"\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirDensity","title":"<code>AirDensity = 'airdensity'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Air density</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirPressure","title":"<code>AirPressure = 'airpressure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>AirPressure</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirPressureWindXWindY","title":"<code>AirPressureWindXWindY = 'airpressure_windx_windy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure and wind components</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirPressureWindXWindYCharnock","title":"<code>AirPressureWindXWindYCharnock = 'airpressure_windx_windy_charnock'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure and wind components Charnock</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirTemperature","title":"<code>AirTemperature = 'airtemperature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>AirTemperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AirpressureStressXStressY","title":"<code>AirpressureStressXStressY = 'airpressure_stressx_stressy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Airpressure, eastward and northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.AtmosphericPressure","title":"<code>AtmosphericPressure = 'atmosphericpressure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.Charnock","title":"<code>Charnock = 'charnock'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Charnock coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.Cloudiness","title":"<code>Cloudiness = 'cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Cloudiness, or cloud cover (fraction)</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.DewPointAirTemperatureCloudiness","title":"<code>DewPointAirTemperatureCloudiness = 'dewpoint_airtemperature_cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dew point air temperature cloudiness</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.Dewpoint","title":"<code>Dewpoint = 'dewpoint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dewpoint temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.DewpointAirTemperatureCloudinessSolarradiation","title":"<code>DewpointAirTemperatureCloudinessSolarradiation = 'dewpoint_airtemperature_cloudiness_solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dewpoint temperature, air temperature, cloudiness, solarradiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.Humidity","title":"<code>Humidity = 'humidity'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Humidity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.HumidityAirTemperatureCloudiness","title":"<code>HumidityAirTemperatureCloudiness = 'humidity_airtemperature_cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Combined heat flux terms</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.HumidityAirTemperatureCloudinessSolarRadiation","title":"<code>HumidityAirTemperatureCloudinessSolarRadiation = 'humidity_airtemperature_cloudiness_solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Combined heat flux terms</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.LongWaveRadiation","title":"<code>LongWaveRadiation = 'longwaveradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Long wave radiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.NudgeSalinityTemperature","title":"<code>NudgeSalinityTemperature = 'nudge_salinity_temperature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Nudging salinity and temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.Rainfall","title":"<code>Rainfall = 'rainfall'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Precipitation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.RainfallRate","title":"<code>RainfallRate = 'rainfall_rate'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Precipitation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.SolarRadiation","title":"<code>SolarRadiation = 'solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Solar radiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.StressX","title":"<code>StressX = 'stressx'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>eastward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.StressXY","title":"<code>StressXY = 'stressxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>eastward and northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.StressY","title":"<code>StressY = 'stressy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.WindFromDirection","title":"<code>WindFromDirection = 'wind_from_direction'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>WindFromDirection</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.WindSpeed","title":"<code>WindSpeed = 'wind_speed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>WindSpeed</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.WindX","title":"<code>WindX = 'windx'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind x component</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.WindXY","title":"<code>WindXY = 'windxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind vector</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMeteoQuantity.WindY","title":"<code>WindY = 'windy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind y component</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod","title":"<code>ExtOldMethod</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the <code>method</code> attribute in the ExtOldForcing class.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldMethod(IntEnum):\n    \"\"\"Enum class containing the valid values for the `method` attribute\n    in the [ExtOldForcing][hydrolib.core.dflowfm.extold.models.ExtOldForcing] class.\n    \"\"\"\n\n    PassThrough = 1\n    \"\"\"1. Pass through (no interpolation)\"\"\"\n    InterpolateTimeAndSpace = 2\n    \"\"\"2. Interpolate time and space\"\"\"\n    InterpolateTimeAndSpaceSaveWeights = 3\n    \"\"\"3. Interpolate time and space, save weights\"\"\"\n    InterpolateSpace = 4\n    \"\"\"4. Interpolate space\"\"\"\n    InterpolateTime = 5\n    \"\"\"5. Interpolate time\"\"\"\n    AveragingSpace = 6\n    \"\"\"6. Averaging in space\"\"\"\n    InterpolateExtrapolateTime = 7\n    \"\"\"7. Interpolate/Extrapolate time\"\"\"\n    Obsolete = 11\n    \"\"\"11. METHOD=11 is obsolete; use METHOD=3 and EXTRAPOLATION_METHOD=1\"\"\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.AveragingSpace","title":"<code>AveragingSpace = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Averaging in space</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.InterpolateExtrapolateTime","title":"<code>InterpolateExtrapolateTime = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Interpolate/Extrapolate time</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.InterpolateSpace","title":"<code>InterpolateSpace = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Interpolate space</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.InterpolateTime","title":"<code>InterpolateTime = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Interpolate time</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.InterpolateTimeAndSpace","title":"<code>InterpolateTimeAndSpace = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Interpolate time and space</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.InterpolateTimeAndSpaceSaveWeights","title":"<code>InterpolateTimeAndSpaceSaveWeights = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Interpolate time and space, save weights</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.Obsolete","title":"<code>Obsolete = 11</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>METHOD=11 is obsolete; use METHOD=3 and EXTRAPOLATION_METHOD=1</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldMethod.PassThrough","title":"<code>PassThrough = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<ol> <li>Pass through (no interpolation)</li> </ol>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldModel","title":"<code>ExtOldModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>The overall external forcings model that contains the contents of one external forcings file (old format).</p> <p>This model is typically referenced under a FMModel<code>.external_forcing.extforcefile</code>.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldModel(ParsableFileModel):\n    \"\"\"\n    The overall external forcings model that contains the contents of one external forcings file (old format).\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.external_forcing.extforcefile`.\n    \"\"\"\n\n    comment: List[str] = Field(default=HEADER.splitlines()[1:])\n    \"\"\"List[str]: The comments in the header of the external forcing file.\"\"\"\n    forcing: List[ExtOldForcing] = Field(default_factory=list)\n    \"\"\"List[ExtOldForcing]: The external forcing/QUANTITY blocks in the external forcing file.\"\"\"\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ext\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"externalforcings\"\n\n    def dict(self, *args, **kwargs):\n        return dict(comment=self.comment, forcing=[dict(f) for f in self.forcing])\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return Serializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable[[Path], Dict]:\n        return Parser.parse\n\n    @property\n    def quantities(self) -&gt; List[str]:\n        \"\"\"List all the quantities in the external forcings file.\"\"\"\n        return [forcing.quantity for forcing in self.forcing]\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldModel.comment","title":"<code>comment = Field(default=HEADER.splitlines()[1:])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[str]: The comments in the header of the external forcing file.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldModel.forcing","title":"<code>forcing = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[ExtOldForcing]: The external forcing/QUANTITY blocks in the external forcing file.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldModel.quantities","title":"<code>quantities</code>  <code>property</code>","text":"<p>List all the quantities in the external forcings file.</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldParametersQuantity","title":"<code>ExtOldParametersQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the Spatial parameter category of the external forcings.</p> <p>for more details check D-Flow FM User Manual 1D2D, Chapter D.3.1, Table D.2 https://content.oss.deltares.nl/delft3d/D-Flow_FM_User_Manual_1D2D.pdf</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldParametersQuantity(StrEnum):\n    \"\"\"Enum class containing the valid values for the Spatial parameter category\n    of the external forcings.\n\n    for more details check D-Flow FM User Manual 1D2D, Chapter D.3.1, Table D.2\n    https://content.oss.deltares.nl/delft3d/D-Flow_FM_User_Manual_1D2D.pdf\n    \"\"\"\n\n    FrictionCoefficient = \"frictioncoefficient\"\n    HorizontalEddyViscosityCoefficient = \"horizontaleddyviscositycoefficient\"\n    HorizontalEddyDiffusivityCoefficient = \"horizontaleddydiffusivitycoefficient\"\n    AdvectionType = \"advectiontype\"\n    InfiltrationCapacity = \"infiltrationcapacity\"\n    BedRockSurfaceElevation = \"bedrock_surface_elevation\"\n    WaveDirection = \"wavedirection\"\n    XWaveForce = \"xwaveforce\"\n    YWaveForce = \"ywaveforce\"\n    WavePeriod = \"waveperiod\"\n    WaveSignificantHeight = \"wavesignificantheight\"\n    InternalTidesFrictionCoefficient = \"internaltidesfrictioncoefficient\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity","title":"<code>ExtOldQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the boundary conditions category of the external forcings.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldQuantity(StrEnum):\n    \"\"\"Enum class containing the valid values for the boundary conditions category\n    of the external forcings.\n    \"\"\"\n\n    # Boundary conditions\n    WaterLevelBnd = \"waterlevelbnd\"\n    \"\"\"Water level\"\"\"\n    NeumannBnd = \"neumannbnd\"\n    \"\"\"Water level gradient\"\"\"\n    RiemannBnd = \"riemannbnd\"\n    \"\"\"Riemann invariant\"\"\"\n    OutflowBnd = \"outflowbnd\"\n    \"\"\"Outflow\"\"\"\n    VelocityBnd = \"velocitybnd\"\n    \"\"\"Velocity\"\"\"\n    DischargeBnd = \"dischargebnd\"\n    \"\"\"Discharge\"\"\"\n    RiemannVelocityBnd = \"riemann_velocitybnd\"\n    \"\"\"Riemann invariant velocity\"\"\"\n    SalinityBnd = \"salinitybnd\"\n    \"\"\"Salinity\"\"\"\n    TemperatureBnd = \"temperaturebnd\"\n    \"\"\"Temperature\"\"\"\n    SedimentBnd = \"sedimentbnd\"\n    \"\"\"Suspended sediment\"\"\"\n    UXUYAdvectionVelocityBnd = \"uxuyadvectionvelocitybnd\"\n    \"\"\"ux-uy advection velocity\"\"\"\n    NormalVelocityBnd = \"normalvelocitybnd\"\n    \"\"\"Normal velocity\"\"\"\n    TangentialVelocityBnd = \"tangentialvelocitybnd\"\n    \"\"\"Tangentional velocity\"\"\"\n    QhBnd = \"qhbnd\"\n    \"\"\"Discharge-water level dependency\"\"\"\n\n    # Meteorological fields\n    WindX = \"windx\"\n    \"\"\"Wind x component\"\"\"\n    WindY = \"windy\"\n    \"\"\"Wind y component\"\"\"\n    WindXY = \"windxy\"\n    \"\"\"Wind vector\"\"\"\n    AirPressureWindXWindY = \"airpressure_windx_windy\"\n    \"\"\"Atmospheric pressure and wind components\"\"\"\n    AirPressureWindXWindYCharnock = \"airpressure_windx_windy_charnock\"\n    \"Atmospheric pressure and wind components Charnock\"\n    AtmosphericPressure = \"atmosphericpressure\"\n    \"\"\"Atmospheric pressure\"\"\"\n    Rainfall = \"rainfall\"\n    \"\"\"Precipitation\"\"\"\n    RainfallRate = \"rainfall_rate\"\n    \"\"\"Precipitation\"\"\"\n    HumidityAirTemperatureCloudiness = \"humidity_airtemperature_cloudiness\"\n    \"\"\"Combined heat flux terms\"\"\"\n    HumidityAirTemperatureCloudinessSolarRadiation = (\n        \"humidity_airtemperature_cloudiness_solarradiation\"\n    )\n    \"\"\"Combined heat flux terms\"\"\"\n    DewPointAirTemperatureCloudiness = \"dewpoint_airtemperature_cloudiness\"\n    \"\"\"Dew point air temperature cloudiness\"\"\"\n    LongWaveRadiation = \"longwaveradiation\"\n    \"\"\"Long wave radiation\"\"\"\n    SolarRadiation = \"solarradiation\"\n    \"\"\"Solar radiation\"\"\"\n    DischargeSalinityTemperatureSorSin = \"discharge_salinity_temperature_sorsin\"\n    \"\"\"Discharge, salinity temperature source-sinks\"\"\"\n    NudgeSalinityTemperature = \"nudge_salinity_temperature\"\n    \"\"\"Nudging salinity and temperature\"\"\"\n    AirPressure = \"airpressure\"\n    \"\"\"AirPressure\"\"\"\n    StressX = \"stressx\"\n    \"\"\"eastward wind stress\"\"\"\n    StressY = \"stressy\"\n    \"\"\"northward wind stress\"\"\"\n    AirTemperature = \"airtemperature\"\n    \"\"\"AirTemperature\"\"\"\n    Cloudiness = \"cloudiness\"\n    \"\"\"Cloudiness, or cloud cover (fraction)\"\"\"\n    Humidity = \"humidity\"\n    \"\"\"Humidity\"\"\"\n    StressXY = \"stressxy\"\n    \"\"\"eastward and northward wind stress\"\"\"\n    AirpressureStressXStressY = \"airpressure_stressx_stressy\"\n    \"\"\"Airpressure, eastward and northward wind stress\"\"\"\n    WindSpeed = \"wind_speed\"\n    \"\"\"WindSpeed\"\"\"\n    WindFromDirection = \"wind_from_direction\"\n    \"\"\"WindFromDirection\"\"\"\n    DewpointAirTemperatureCloudinessSolarradiation = (\n        \"dewpoint_airtemperature_cloudiness_solarradiation\"\n    )\n    \"\"\"Dewpoint temperature, air temperature, cloudiness, solarradiation\"\"\"\n    AirDensity = \"airdensity\"\n    \"\"\"Air density\"\"\"\n    Charnock = \"charnock\"\n    \"\"\"Charnock coefficient\"\"\"\n    Dewpoint = \"dewpoint\"\n    \"\"\"Dewpoint temperature\"\"\"\n\n    # Structure parameters\n    Pump = \"pump\"\n    \"\"\"Pump capacity\"\"\"\n    DamLevel = \"damlevel\"\n    \"\"\"Dam level\"\"\"\n    GateLowerEdgeLevel = \"gateloweredgelevel\"\n    \"\"\"Gate lower edge level\"\"\"\n    GeneralStructure = \"generalstructure\"\n    \"\"\"General structure\"\"\"\n\n    # Initial fields\n    InitialWaterLevel = \"initialwaterlevel\"\n    \"\"\"Initial water level\"\"\"\n    InitialSalinity = \"initialsalinity\"\n    \"\"\"Initial salinity\"\"\"\n    InitialSalinityTop = \"initialsalinitytop\"\n    \"\"\"Initial salinity top layer\"\"\"\n    InitialTemperature = \"initialtemperature\"\n    \"\"\"Initial temperature\"\"\"\n    InitialVerticalTemperatureProfile = \"initialverticaltemperatureprofile\"\n    \"\"\"Initial vertical temperature profile\"\"\"\n    InitialVerticalSalinityProfile = \"initialverticalsalinityprofile\"\n    \"\"\"Initial vertical salinity profile\"\"\"\n    BedLevel = \"bedlevel\"\n    \"\"\"Bed level\"\"\"\n\n    # Spatial physical properties\n    FrictionCoefficient = \"frictioncoefficient\"\n    \"\"\"Friction coefficient\"\"\"\n    HorizontalEddyViscosityCoefficient = \"horizontaleddyviscositycoefficient\"\n    \"\"\"Horizontal eddy viscosity coefficient\"\"\"\n    InternalTidesFrictionCoefficient = \"internaltidesfrictioncoefficient\"\n    \"\"\"Internal tides friction coefficient\"\"\"\n    HorizontalEddyDiffusivityCoefficient = \"horizontaleddydiffusivitycoefficient\"\n    \"\"\"Horizontal eddy diffusivity coefficient\"\"\"\n    AdvectionType = \"advectiontype\"\n    \"\"\"Type of advection scheme\"\"\"\n    IBotLevType = \"ibotlevtype\"\n    BedRockSurfaceElevation = \"bedrock_surface_elevation\"\n    \"\"\"Type of bed-level handling\"\"\"\n\n    # Miscellaneous\n    ShiptXY = \"shiptxy\"\n    \"\"\"shiptxy\"\"\"\n    MovingStationXY = \"movingstationxy\"\n    \"\"\"Moving observation point for output (time, x, y)\"\"\"\n    WaveSignificantHeight = \"wavesignificantheight\"\n    \"\"\"Wave significant height\"\"\"\n    WavePeriod = \"waveperiod\"\n    \"\"\"Wave period\"\"\"\n    WaveDirection = \"wavedirection\"\n    XWaveForce = \"xwaveforce\"\n    YWaveForce = \"ywaveforce\"\n\n    InitialVelocityX = \"initialvelocityx\"\n    InitialVelocityY = \"initialvelocityy\"\n    InitialVelocity = \"initialvelocity\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AdvectionType","title":"<code>AdvectionType = 'advectiontype'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of advection scheme</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirDensity","title":"<code>AirDensity = 'airdensity'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Air density</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirPressure","title":"<code>AirPressure = 'airpressure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>AirPressure</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirPressureWindXWindY","title":"<code>AirPressureWindXWindY = 'airpressure_windx_windy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure and wind components</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirPressureWindXWindYCharnock","title":"<code>AirPressureWindXWindYCharnock = 'airpressure_windx_windy_charnock'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure and wind components Charnock</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirTemperature","title":"<code>AirTemperature = 'airtemperature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>AirTemperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AirpressureStressXStressY","title":"<code>AirpressureStressXStressY = 'airpressure_stressx_stressy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Airpressure, eastward and northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.AtmosphericPressure","title":"<code>AtmosphericPressure = 'atmosphericpressure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Atmospheric pressure</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.BedLevel","title":"<code>BedLevel = 'bedlevel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Bed level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.BedRockSurfaceElevation","title":"<code>BedRockSurfaceElevation = 'bedrock_surface_elevation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of bed-level handling</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Charnock","title":"<code>Charnock = 'charnock'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Charnock coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Cloudiness","title":"<code>Cloudiness = 'cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Cloudiness, or cloud cover (fraction)</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.DamLevel","title":"<code>DamLevel = 'damlevel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dam level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.DewPointAirTemperatureCloudiness","title":"<code>DewPointAirTemperatureCloudiness = 'dewpoint_airtemperature_cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dew point air temperature cloudiness</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Dewpoint","title":"<code>Dewpoint = 'dewpoint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dewpoint temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.DewpointAirTemperatureCloudinessSolarradiation","title":"<code>DewpointAirTemperatureCloudinessSolarradiation = 'dewpoint_airtemperature_cloudiness_solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Dewpoint temperature, air temperature, cloudiness, solarradiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.DischargeBnd","title":"<code>DischargeBnd = 'dischargebnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discharge</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.DischargeSalinityTemperatureSorSin","title":"<code>DischargeSalinityTemperatureSorSin = 'discharge_salinity_temperature_sorsin'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discharge, salinity temperature source-sinks</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.FrictionCoefficient","title":"<code>FrictionCoefficient = 'frictioncoefficient'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Friction coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.GateLowerEdgeLevel","title":"<code>GateLowerEdgeLevel = 'gateloweredgelevel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Gate lower edge level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.GeneralStructure","title":"<code>GeneralStructure = 'generalstructure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>General structure</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.HorizontalEddyDiffusivityCoefficient","title":"<code>HorizontalEddyDiffusivityCoefficient = 'horizontaleddydiffusivitycoefficient'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Horizontal eddy diffusivity coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.HorizontalEddyViscosityCoefficient","title":"<code>HorizontalEddyViscosityCoefficient = 'horizontaleddyviscositycoefficient'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Horizontal eddy viscosity coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Humidity","title":"<code>Humidity = 'humidity'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Humidity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.HumidityAirTemperatureCloudiness","title":"<code>HumidityAirTemperatureCloudiness = 'humidity_airtemperature_cloudiness'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Combined heat flux terms</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.HumidityAirTemperatureCloudinessSolarRadiation","title":"<code>HumidityAirTemperatureCloudinessSolarRadiation = 'humidity_airtemperature_cloudiness_solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Combined heat flux terms</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialSalinity","title":"<code>InitialSalinity = 'initialsalinity'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial salinity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialSalinityTop","title":"<code>InitialSalinityTop = 'initialsalinitytop'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial salinity top layer</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialTemperature","title":"<code>InitialTemperature = 'initialtemperature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialVerticalSalinityProfile","title":"<code>InitialVerticalSalinityProfile = 'initialverticalsalinityprofile'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial vertical salinity profile</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialVerticalTemperatureProfile","title":"<code>InitialVerticalTemperatureProfile = 'initialverticaltemperatureprofile'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial vertical temperature profile</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InitialWaterLevel","title":"<code>InitialWaterLevel = 'initialwaterlevel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial water level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.InternalTidesFrictionCoefficient","title":"<code>InternalTidesFrictionCoefficient = 'internaltidesfrictioncoefficient'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Internal tides friction coefficient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.LongWaveRadiation","title":"<code>LongWaveRadiation = 'longwaveradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Long wave radiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.MovingStationXY","title":"<code>MovingStationXY = 'movingstationxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Moving observation point for output (time, x, y)</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.NeumannBnd","title":"<code>NeumannBnd = 'neumannbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Water level gradient</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.NormalVelocityBnd","title":"<code>NormalVelocityBnd = 'normalvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Normal velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.NudgeSalinityTemperature","title":"<code>NudgeSalinityTemperature = 'nudge_salinity_temperature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Nudging salinity and temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.OutflowBnd","title":"<code>OutflowBnd = 'outflowbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Outflow</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Pump","title":"<code>Pump = 'pump'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Pump capacity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.QhBnd","title":"<code>QhBnd = 'qhbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discharge-water level dependency</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.Rainfall","title":"<code>Rainfall = 'rainfall'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Precipitation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.RainfallRate","title":"<code>RainfallRate = 'rainfall_rate'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Precipitation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.RiemannBnd","title":"<code>RiemannBnd = 'riemannbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Riemann invariant</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.RiemannVelocityBnd","title":"<code>RiemannVelocityBnd = 'riemann_velocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Riemann invariant velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.SalinityBnd","title":"<code>SalinityBnd = 'salinitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Salinity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.SedimentBnd","title":"<code>SedimentBnd = 'sedimentbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Suspended sediment</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.ShiptXY","title":"<code>ShiptXY = 'shiptxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>shiptxy</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.SolarRadiation","title":"<code>SolarRadiation = 'solarradiation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Solar radiation</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.StressX","title":"<code>StressX = 'stressx'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>eastward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.StressXY","title":"<code>StressXY = 'stressxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>eastward and northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.StressY","title":"<code>StressY = 'stressy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>northward wind stress</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.TangentialVelocityBnd","title":"<code>TangentialVelocityBnd = 'tangentialvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Tangentional velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.TemperatureBnd","title":"<code>TemperatureBnd = 'temperaturebnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Temperature</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.UXUYAdvectionVelocityBnd","title":"<code>UXUYAdvectionVelocityBnd = 'uxuyadvectionvelocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ux-uy advection velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.VelocityBnd","title":"<code>VelocityBnd = 'velocitybnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Velocity</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WaterLevelBnd","title":"<code>WaterLevelBnd = 'waterlevelbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Water level</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WavePeriod","title":"<code>WavePeriod = 'waveperiod'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wave period</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WaveSignificantHeight","title":"<code>WaveSignificantHeight = 'wavesignificantheight'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wave significant height</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WindFromDirection","title":"<code>WindFromDirection = 'wind_from_direction'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>WindFromDirection</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WindSpeed","title":"<code>WindSpeed = 'wind_speed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>WindSpeed</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WindX","title":"<code>WindX = 'windx'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind x component</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WindXY","title":"<code>WindXY = 'windxy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind vector</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldQuantity.WindY","title":"<code>WindY = 'windy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Wind y component</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldSourcesSinks","title":"<code>ExtOldSourcesSinks</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Source and sink quantities</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldSourcesSinks(StrEnum):\n    \"\"\"Source and sink quantities\"\"\"\n\n    DischargeSalinityTemperatureSorSin = \"discharge_salinity_temperature_sorsin\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldTracerQuantity","title":"<code>ExtOldTracerQuantity</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the boundary conditions category of the external forcings that are specific to tracers.</p> Source code in <code>hydrolib/core/dflowfm/extold/models.py</code> <pre><code>class ExtOldTracerQuantity(StrEnum):\n    \"\"\"Enum class containing the valid values for the boundary conditions category\n    of the external forcings that are specific to tracers.\n    \"\"\"\n\n    TracerBnd = \"tracerbnd\"\n    \"\"\"User-defined tracer\"\"\"\n    InitialTracer = \"initialtracer\"\n    \"\"\"Initial tracer\"\"\"\n    SedFracBnd = \"sedfracbnd\"\n</code></pre>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldTracerQuantity.InitialTracer","title":"<code>InitialTracer = 'initialtracer'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial tracer</p>"},{"location":"reference/models/extold/#hydrolib.core.dflowfm.extold.models.ExtOldTracerQuantity.TracerBnd","title":"<code>TracerBnd = 'tracerbnd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>User-defined tracer</p>"},{"location":"reference/models/forcing/","title":"Forcings .bc file","text":"<p>The forcings .bc files contain forcing data for point locations, for example time series input for a boundary condition. Various quantities and function types are supported.</p> <p>The forcings file is represented by the classes below.</p> <pre><code>classDiagram\n    class VerticalInterpolation {\n        &lt;&lt;Enum&gt;&gt;\n        +linear: str\n        +log: str\n        +block: str\n    }\n\n    class VerticalPositionType {\n        &lt;&lt;Enum&gt;&gt;\n        +percentage_bed: str\n        +z_bed: str\n        +z_datum: str\n        +z_surf: str\n    }\n\n    class TimeInterpolation {\n        &lt;&lt;Enum&gt;&gt;\n        +linear: str\n        +block_from: str\n        +block_to: str\n    }\n\n    class QuantityUnitPair {\n        +quantity: str\n        +unit: str\n        +vertpositionindex: Optional[int]\n        +_to_properties()\n    }\n\n    class VectorQuantityUnitPairs {\n        +vectorname: str\n        +elementname: List[str]\n        +quantityunitpair: List[QuantityUnitPair]\n        +_validate_quantity_element_names()\n        +_to_vectordefinition_string()\n        +_to_properties()\n    }\n\n    class ScalarOrVectorQUP {\n        &lt;&lt;Union&gt;&gt;\n        +QuantityUnitPair\n        +VectorQuantityUnitPairs\n    }\n\n    class ForcingBase {\n        +name: str\n        +function: str\n        +quantityunitpair: List[ScalarOrVectorQUP]\n        +_exclude_fields()\n        +_supports_comments()\n        +_duplicate_keys_as_list()\n        +_validate_quantityunitpair()\n        +_set_function()\n        +validate()\n        +_get_identifier()\n        +_to_section()\n    }\n\n    class VectorForcingBase {\n        +validate_and_update_quantityunitpairs()\n        +_process_vectordefinition_or_check_quantityunitpairs()\n        +_validate_vectordefinition_and_update_quantityunitpairs()\n        +_find_and_pack_vector_qups()\n        +_validate_vectorlength()\n        +get_number_of_repetitions()\n    }\n\n    class TimeSeries {\n        +function: str\n        +timeinterpolation: TimeInterpolation\n        +offset: float\n        +factor: float\n        +rename_keys()\n    }\n\n    class Harmonic {\n        +function: str\n        +factor: float\n    }\n\n    class HarmonicCorrection {\n        +function: str\n    }\n\n    class Astronomic {\n        +function: str\n        +factor: float\n    }\n\n    class AstronomicCorrection {\n        +function: str\n    }\n\n    class T3D {\n        +function: str\n        +offset: float\n        +factor: float\n        +vertpositions: List[float]\n        +vertinterpolation: VerticalInterpolation\n        +vertpositiontype: VerticalPositionType\n        +timeinterpolation: TimeInterpolation\n        +rename_keys()\n    }\n\n    class QHTable {\n        +function: str\n    }\n\n    class Constant {\n        +function: str\n        +offset: float\n        +factor: float\n    }\n\n    class ForcingGeneral {\n        +fileversion: str\n        +filetype: str\n    }\n\n    class RealTime {\n        &lt;&lt;Enum&gt;&gt;\n        +realtime: str\n    }\n\n    class ForcingData {\n        &lt;&lt;Union&gt;&gt;\n        +float\n        +RealTime\n        +ForcingModel\n    }\n\n    ScalarOrVectorQUP --&gt; QuantityUnitPair\n    ScalarOrVectorQUP --&gt; VectorQuantityUnitPairs\n    ScalarOrVectorQUP --&gt; ForcingBase\n    VerticalInterpolation --&gt; ForcingBase\n    VerticalPositionType --&gt; T3D\n    TimeInterpolation --&gt; ForcingBase\n    VectorForcingBase --&gt; TimeSeries\n    ForcingBase --&gt; Harmonic\n    ForcingBase --&gt; HarmonicCorrection\n    ForcingBase --&gt; Astronomic\n    ForcingBase --&gt; AstronomicCorrection\n    ForcingBase --&gt; QHTable\n    ForcingBase --&gt; Constant\n    QuantityUnitPair --&gt; VectorQuantityUnitPairs\n    ForcingBase &lt;|-- VectorForcingBase\n    VectorForcingBase --&gt; T3D\n    ForcingBase --&gt; ForcingGeneral\n    RealTime --&gt; ForcingData\n    ForcingModel --&gt; ForcingData\n</code></pre>"},{"location":"reference/models/forcing/#model","title":"Model","text":"<p>Representation of a .bc file in various classes.</p> <p>Most relevant classes are:</p> <ul> <li>ForcingModel: toplevel class containing the whole .bc file contents.</li> <li>ForcingBase subclasses: containing the actual data columns, for example:     TimeSeries, HarmonicComponent, AstronomicComponent, HarmonicCorrection,     AstronomicCorrection, Constant, T3D.</li> </ul>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingData","title":"<code>ForcingData = Union[float, RealTime, ForcingModel]</code>  <code>module-attribute</code>","text":"<p>Data type that selects from three different types of forcing data: *   a scalar float constant *   \"realtime\" keyword, indicating externally controlled. *   A ForcingModel coming from a .bc file.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Astronomic","title":"<code>Astronomic</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with astronomic components data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class Astronomic(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with astronomic components data.\"\"\"\n\n    function: Literal[\"astronomic\"] = \"astronomic\"\n\n    factor: float = Field(1.0, alias=\"factor\")\n    \"\"\"float: All values in the table are multiplied with the factor. Defaults to 1.0.\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Astronomic.factor","title":"<code>factor = Field(1.0, alias='factor')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are multiplied with the factor. Defaults to 1.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.AstronomicCorrection","title":"<code>AstronomicCorrection</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with astronomic components correction data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class AstronomicCorrection(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with astronomic components correction data.\"\"\"\n\n    function: Literal[\"astronomic-correction\"] = \"astronomic-correction\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Constant","title":"<code>Constant</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with constant value data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class Constant(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with constant value data.\"\"\"\n\n    function: Literal[\"constant\"] = \"constant\"\n\n    offset: float = Field(0.0, alias=\"offset\")\n    \"\"\"float: All values in the table are increased by the offset (after multiplication by factor). Defaults to 0.0.\"\"\"\n\n    factor: float = Field(1.0, alias=\"factor\")\n    \"\"\"float: All values in the table are multiplied with the factor. Defaults to 1.0.\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Constant.factor","title":"<code>factor = Field(1.0, alias='factor')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are multiplied with the factor. Defaults to 1.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Constant.offset","title":"<code>offset = Field(0.0, alias='offset')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are increased by the offset (after multiplication by factor). Defaults to 0.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingBase","title":"<code>ForcingBase</code>","text":"<p>               Bases: <code>DataBlockINIBasedModel</code></p> <p>The base class of a single [Forcing] block in a .bc forcings file.</p> <p>The <code>ForcingBase</code> class is used as the foundational model for various types of forcing data blocks, such as TimeSeries, Harmonic, Astronomic, and others. It includes functionality for handling structured data, validating input, and serializing the forcing data.</p> <p>This model is referenced under a ForcingModel<code>.forcing[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier that specifies the location for this forcing data.</p> <code>function</code> <code>str</code> <p>Specifies the function type of the data in the associated data block.</p> <code>quantityunitpair</code> <code>List[ScalarOrVectorQUP]</code> <p>List of header lines for one or more quantities and their units. These describe the columns in the associated data block.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The unique name identifying this forcing block.</p> required <code>function</code> <code>str</code> <p>The function type specifying the behavior of the forcing block. Possible values are timeseries, harmonic, astronomic, harmonic-correction, astronomic-correction, t3d, constant, qhtable.</p> required <code>quantityunitpair</code> <code>List[ScalarOrVectorQUP]</code> <p>The quantities and units associated with the data block.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>quantity</code> or <code>unit</code> fields are missing or mismatched.</p> <code>ValueError</code> <p>If the <code>function</code> field contains an unrecognized type.</p> See Also <p>DataBlockINIBasedModel: Parent class for handling data blocks in INI files. QuantityUnitPair: Represents a single quantity and its unit. VectorQuantityUnitPairs: Handles vector quantities in the data block.</p> <p>Examples:</p> <p>Create a simple forcing block:</p> <pre><code>```python\n&gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingBase, QuantityUnitPair\n&gt;&gt;&gt; forcing = ForcingBase(\n...     name=\"Location1\",\n...     function=\"timeseries\",\n...     quantityunitpair=[QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")]\n... )\n&gt;&gt;&gt; print(forcing.name)\nLocation1\n&gt;&gt;&gt; print(forcing.function)\ntimeseries\n\n```\n</code></pre> <p>Handle vector quantities:</p> <pre><code>```python\n&gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import VectorQuantityUnitPairs\n&gt;&gt;&gt; forcing = ForcingBase(\n...     name=\"Location2\",\n...     function=\"vector\",\n...     quantityunitpair=[\n...         VectorQuantityUnitPairs(\n...             vectorname=\"velocity\",\n...             elementname=[\"u\", \"v\"],\n...             quantityunitpair=[\n...                 QuantityUnitPair(quantity=\"u\", unit=\"m/s\"),\n...                 QuantityUnitPair(quantity=\"v\", unit=\"m/s\")\n...             ]\n...         )\n...     ]\n... )\n&gt;&gt;&gt; print(forcing.quantityunitpair[0].vectorname)\nvelocity\n\n```\n</code></pre> Notes <ul> <li>The <code>ForcingBase</code> class is typically subclassed to provide specific behavior for different forcing types.</li> <li>It includes robust validation mechanisms to ensure consistency between quantities and units.</li> </ul> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class ForcingBase(DataBlockINIBasedModel):\n    \"\"\"\n    The base class of a single [Forcing] block in a .bc forcings file.\n\n    The `ForcingBase` class is used as the foundational model for various types\n    of forcing data blocks, such as TimeSeries, Harmonic, Astronomic, and others.\n    It includes functionality for handling structured data, validating input,\n    and serializing the forcing data.\n\n    This model is referenced under a [ForcingModel][hydrolib.core.dflowfm.bc.models.ForcingModel]`.forcing[..]`.\n\n    Attributes:\n        name (str):\n            Unique identifier that specifies the location for this forcing data.\n        function (str):\n            Specifies the function type of the data in the associated data block.\n        quantityunitpair (List[ScalarOrVectorQUP]):\n            List of header lines for one or more quantities and their units.\n            These describe the columns in the associated data block.\n\n    Args:\n        name (str):\n            The unique name identifying this forcing block.\n        function (str):\n            The function type specifying the behavior of the forcing block.\n            Possible values are timeseries, harmonic, astronomic, harmonic-correction, astronomic-correction, t3d,\n            constant, qhtable.\n        quantityunitpair (List[ScalarOrVectorQUP]):\n            The quantities and units associated with the data block.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If `quantity` or `unit` fields are missing or mismatched.\n        ValueError: If the `function` field contains an unrecognized type.\n\n    See Also:\n        DataBlockINIBasedModel: Parent class for handling data blocks in INI files.\n        QuantityUnitPair: Represents a single quantity and its unit.\n        VectorQuantityUnitPairs: Handles vector quantities in the data block.\n\n    Examples:\n        Create a simple forcing block:\n\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingBase, QuantityUnitPair\n            &gt;&gt;&gt; forcing = ForcingBase(\n            ...     name=\"Location1\",\n            ...     function=\"timeseries\",\n            ...     quantityunitpair=[QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")]\n            ... )\n            &gt;&gt;&gt; print(forcing.name)\n            Location1\n            &gt;&gt;&gt; print(forcing.function)\n            timeseries\n\n            ```\n\n        Handle vector quantities:\n\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import VectorQuantityUnitPairs\n            &gt;&gt;&gt; forcing = ForcingBase(\n            ...     name=\"Location2\",\n            ...     function=\"vector\",\n            ...     quantityunitpair=[\n            ...         VectorQuantityUnitPairs(\n            ...             vectorname=\"velocity\",\n            ...             elementname=[\"u\", \"v\"],\n            ...             quantityunitpair=[\n            ...                 QuantityUnitPair(quantity=\"u\", unit=\"m/s\"),\n            ...                 QuantityUnitPair(quantity=\"v\", unit=\"m/s\")\n            ...             ]\n            ...         )\n            ...     ]\n            ... )\n            &gt;&gt;&gt; print(forcing.quantityunitpair[0].vectorname)\n            velocity\n\n            ```\n\n    Notes:\n        - The `ForcingBase` class is typically subclassed to provide specific behavior for different forcing types.\n        - It includes robust validation mechanisms to ensure consistency between quantities and units.\n    \"\"\"\n\n    _header: Literal[\"Forcing\"] = \"Forcing\"\n    name: str = Field(alias=\"name\")\n    \"\"\"str: Unique identifier that identifies the location for this forcing data.\"\"\"\n\n    function: str = Field(alias=\"function\")\n    \"\"\"str: Function type of the data in the actual datablock.\"\"\"\n\n    quantityunitpair: List[ScalarOrVectorQUP]\n    \"\"\"List[ScalarOrVectorQUP]: List of header lines for one or more quantities and their unit. Describes the columns in the actual datablock.\"\"\"\n\n    def _exclude_fields(self) -&gt; Set:\n        return {\"quantityunitpair\"}.union(super()._exclude_fields())\n\n    @classmethod\n    def _supports_comments(cls):\n        return True\n\n    @classmethod\n    def _duplicate_keys_as_list(cls):\n        return True\n\n    @root_validator(pre=True)\n    def _validate_quantityunitpair(cls, values):\n        quantityunitpairkey = \"quantityunitpair\"\n\n        if values.get(quantityunitpairkey) is not None:\n            return values\n\n        quantities = values.get(\"quantity\")\n        if quantities is None:\n            raise ValueError(\"quantity is not provided\")\n        units = values.get(\"unit\")\n        if units is None:\n            raise ValueError(\"unit is not provided\")\n\n        if isinstance(quantities, str) and isinstance(units, str):\n            values[quantityunitpairkey] = [\n                QuantityUnitPair(quantity=quantities, unit=units)\n            ]\n            return values\n\n        if isinstance(quantities, list) and isinstance(units, list):\n            if len(quantities) != len(units):\n                raise ValueError(\n                    \"Number of quantities should be equal to number of units\"\n                )\n\n            values[quantityunitpairkey] = [\n                QuantityUnitPair(quantity=quantity, unit=unit)\n                for quantity, unit in zip(quantities, units)\n            ]\n            return values\n\n        raise ValueError(\"Number of quantities should be equal to number of units\")\n\n    @validator(\"function\", pre=True)\n    def _set_function(cls, value):\n        return get_from_subclass_defaults(ForcingBase, \"function\", value)\n\n    @classmethod\n    def validate(cls, v):\n        \"\"\"Try to initialize subclass based on the `function` field.\n        This field is compared to each `function` field of the derived models of `ForcingBase`\n        or models derived from derived models.\n        The derived model with an equal function type will be initialized.\n\n        Raises:\n            ValueError: When the given type is not a known structure type.\n        \"\"\"\n\n        # should be replaced by discriminated unions once merged\n        # https://github.com/samuelcolvin/pydantic/pull/2336\n        if isinstance(v, dict):\n            function_string = v.get(\"function\", \"\").lower()\n            function_type = get_type_based_on_subclass_default_value(\n                cls, \"function\", function_string\n            )\n\n            if function_type is not None:\n                return function_type(**v)\n\n            else:\n                raise ValueError(\n                    f\"Function of {cls.__name__} with name={v.get('name', '')} and function={v.get('function', '')} is not recognized.\"\n                )\n        return v\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n\n    def _to_section(\n        self,\n        config: DataBlockINIBasedSerializerConfig,\n        save_settings: ModelSaveSettings,\n    ) -&gt; Section:\n        section = super()._to_section(config, save_settings)\n\n        for quantity in self.quantityunitpair:\n            for prop in quantity._to_properties():\n                section.content.append(prop)\n\n        return section\n\n    class Config:\n        extra = Extra.ignore\n\n    def __repr__(self) -&gt; str:\n        data = dict(self)\n        data[\"datablock\"] = \"&lt;omitted&gt;\"\n        representable = BaseModel.construct(**data)\n        return str(representable)\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingBase.function","title":"<code>function = Field(alias='function')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Function type of the data in the actual datablock.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingBase.name","title":"<code>name = Field(alias='name')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Unique identifier that identifies the location for this forcing data.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingBase.quantityunitpair","title":"<code>quantityunitpair</code>  <code>instance-attribute</code>","text":"<p>List[ScalarOrVectorQUP]: List of header lines for one or more quantities and their unit. Describes the columns in the actual datablock.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingBase.validate","title":"<code>validate(v)</code>  <code>classmethod</code>","text":"<p>Try to initialize subclass based on the <code>function</code> field. This field is compared to each <code>function</code> field of the derived models of <code>ForcingBase</code> or models derived from derived models. The derived model with an equal function type will be initialized.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the given type is not a known structure type.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@classmethod\ndef validate(cls, v):\n    \"\"\"Try to initialize subclass based on the `function` field.\n    This field is compared to each `function` field of the derived models of `ForcingBase`\n    or models derived from derived models.\n    The derived model with an equal function type will be initialized.\n\n    Raises:\n        ValueError: When the given type is not a known structure type.\n    \"\"\"\n\n    # should be replaced by discriminated unions once merged\n    # https://github.com/samuelcolvin/pydantic/pull/2336\n    if isinstance(v, dict):\n        function_string = v.get(\"function\", \"\").lower()\n        function_type = get_type_based_on_subclass_default_value(\n            cls, \"function\", function_string\n        )\n\n        if function_type is not None:\n            return function_type(**v)\n\n        else:\n            raise ValueError(\n                f\"Function of {cls.__name__} with name={v.get('name', '')} and function={v.get('function', '')} is not recognized.\"\n            )\n    return v\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingGeneral","title":"<code>ForcingGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p><code>[General]</code> section with .bc file metadata.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class ForcingGeneral(INIGeneral):\n    \"\"\"`[General]` section with .bc file metadata.\"\"\"\n\n    fileversion: str = Field(\"1.01\", alias=\"fileVersion\")\n    \"\"\"str: The file version.\"\"\"\n\n    filetype: Literal[\"boundConds\"] = Field(\"boundConds\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingGeneral.fileversion","title":"<code>fileversion = Field('1.01', alias='fileVersion')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: The file version.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingModel","title":"<code>ForcingModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall model that contains the contents of one .bc forcings file.</p> <p>The <code>ForcingModel</code> class is the top-level model that aggregates metadata and multiple <code>[Forcing]</code> blocks. It provides functionality for parsing, serializing, and managing data within a .bc file.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>ForcingGeneral</code> <p>The <code>[General]</code> block containing metadata such as file version and type.</p> <code>forcing</code> <code>List[ForcingBase]</code> <p>A list of <code>[Forcing]</code> blocks representing the different forcings defined in the file.</p> <code>serializer_config</code> <code>DataBlockINIBasedSerializerConfig</code> <p>Configuration for serialization of the .bc file.</p> <p>Parameters:</p> Name Type Description Default <code>general</code> <code>ForcingGeneral</code> <p>Metadata for the file. Defaults to an instance of <code>ForcingGeneral</code>.</p> required <code>forcing</code> <code>(List[ForcingBase], optional, Defaults is [])</code> <p>A list of forcing definitions.</p> required <code>serializer_config</code> <code>DataBlockINIBasedSerializerConfig</code> <p>Serialization settings. Default to a predefined configuration.</p> required See Also <p>ForcingBase: Represents individual forcing blocks within the file. ForcingGeneral: Metadata model for the <code>[General]</code> section.</p> <p>Examples:</p> <p>Create a simple ForcingModel:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingModel, ForcingBase, ForcingGeneral, QuantityUnitPair\n&gt;&gt;&gt; forcing_block = ForcingBase(\n...     name=\"Location1\",\n...     function=\"timeseries\",\n...     quantityunitpair=[\n...         QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")\n...     ]\n... )\n&gt;&gt;&gt; model = ForcingModel(\n...     general=ForcingGeneral(fileversion=\"1.01\", filetype=\"boundConds\"),\n...     forcing=[forcing_block]\n... )\n&gt;&gt;&gt; print(model.general.fileversion)\n1.01\n&gt;&gt;&gt; model.save(filepath=\"tests/data/output.bc\") # doctest: +SKIP\n</code></pre></p> <p>Parse a .bc file:     <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; filepath = Path(\"tests/data/reference/bc/test.bc\")\n&gt;&gt;&gt; parsed_model = ForcingModel.parse(filepath)\n&gt;&gt;&gt; print(parsed_model.keys())\ndict_keys(['general', 'forcing'])\n&gt;&gt;&gt; print(len(parsed_model[\"forcing\"]))\n6\n&gt;&gt;&gt; print(parsed_model[\"forcing\"][0]) # doctest: +SKIP\n{'_header': 'Forcing',\n 'datablock': [['0.0000', '1.2300'],\n  ['60.0000', '2.3400'],\n  ['120.0000', '3.4500']],\n 'name': 'boundary_timeseries',\n 'function': 'timeseries',\n 'timeinterpolation': 'block-To',\n 'offset': '1.230',\n 'factor': '2.340',\n 'quantity': ['time', 'dischargebnd'],\n 'unit': ['minutes since 2015-01-01 00:00:00', 'm\u00b3/s']}\n</code></pre></p> <p>Serialize a ForcingModel:     <pre><code>&gt;&gt;&gt; save_path = Path(\"output.bc\")\n&gt;&gt;&gt; model.save(filepath=save_path) # doctest: +SKIP\n&gt;&gt;&gt; print(save_path.exists()) # doctest: +SKIP\nTrue\n</code></pre></p> <p>Create a ForcingModel from a dictionary:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingModel\n&gt;&gt;&gt; forcing_blocks_list = [\n...     {\n...         '_header': 'Forcing',\n...         'datablock': [\n...             ['0.0000', '1.2300'],\n...             ['60.0000', '2.3400'],\n...             ['120.0000', '3.4500']\n...         ],\n...         'name': 'boundary_timeseries',\n...         'function': 'timeseries',\n...         'timeinterpolation': 'block-To',\n...         'offset': '1.230',\n...         'factor': '2.340',\n...         'quantity': ['time', 'dischargebnd'],\n...         'unit': ['minutes since 2015-01-01 00:00:00', 'm\u00b3/s']\n...     }\n... ]\n&gt;&gt;&gt; model_dict = {\n...     \"forcing\": forcing_blocks_list,\n...     \"general\": {\"fileVersion\": \"1.01\", \"fileType\": \"boundConds\"}\n... }\n&gt;&gt;&gt; model = ForcingModel(**model_dict)\n&gt;&gt;&gt; print(len(model.forcing))\n1\n&gt;&gt;&gt; type(model.forcing[0])\n&lt;class 'hydrolib.core.dflowfm.bc.models.TimeSeries'&gt;\n&gt;&gt;&gt; print(model.general.fileversion)\n1.01\n</code></pre></p> <p>Example .bc file content:     <pre><code># written by HYDROLIB-core 0.3.0\n\n[General]\nfileVersion = 1.01\nfileType    = boundConds\n\n[Forcing]\nname               = boundary_timeseries\nfunction           = timeseries\nTime Interpolation = block-To\noffset             = 1.23\nfactor             = 2.34\nquantity           = time\nunit               = minutes since 2015-01-01 00:00:00\nquantity           = dischargebnd\nunit               = m\u00b3/s\n0.0      1.23\n60.0     2.34\n120.0    3.45\n</code></pre></p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class ForcingModel(INIModel):\n    \"\"\"\n    The overall model that contains the contents of one .bc forcings file.\n\n    The `ForcingModel` class is the top-level model that aggregates metadata\n    and multiple `[Forcing]` blocks. It provides functionality for parsing,\n    serializing, and managing data within a .bc file.\n\n    Attributes:\n        general (ForcingGeneral):\n            The `[General]` block containing metadata such as file version and type.\n        forcing (List[ForcingBase]):\n            A list of `[Forcing]` blocks representing the different forcings defined\n            in the file.\n        serializer_config (DataBlockINIBasedSerializerConfig):\n            Configuration for serialization of the .bc file.\n\n    Args:\n        general (ForcingGeneral, optional):\n            Metadata for the file. Defaults to an instance of `ForcingGeneral`.\n        forcing (List[ForcingBase], optional, Defaults is []):\n            A list of forcing definitions.\n        serializer_config (DataBlockINIBasedSerializerConfig, optional):\n            Serialization settings. Default to a predefined configuration.\n\n    See Also:\n        ForcingBase: Represents individual forcing blocks within the file.\n        ForcingGeneral: Metadata model for the `[General]` section.\n\n    Examples:\n        Create a simple ForcingModel:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingModel, ForcingBase, ForcingGeneral, QuantityUnitPair\n            &gt;&gt;&gt; forcing_block = ForcingBase(\n            ...     name=\"Location1\",\n            ...     function=\"timeseries\",\n            ...     quantityunitpair=[\n            ...         QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")\n            ...     ]\n            ... )\n            &gt;&gt;&gt; model = ForcingModel(\n            ...     general=ForcingGeneral(fileversion=\"1.01\", filetype=\"boundConds\"),\n            ...     forcing=[forcing_block]\n            ... )\n            &gt;&gt;&gt; print(model.general.fileversion)\n            1.01\n            &gt;&gt;&gt; model.save(filepath=\"tests/data/output.bc\") # doctest: +SKIP\n            ```\n\n        Parse a .bc file:\n            ```python\n            &gt;&gt;&gt; from pathlib import Path\n            &gt;&gt;&gt; filepath = Path(\"tests/data/reference/bc/test.bc\")\n            &gt;&gt;&gt; parsed_model = ForcingModel.parse(filepath)\n            &gt;&gt;&gt; print(parsed_model.keys())\n            dict_keys(['general', 'forcing'])\n            &gt;&gt;&gt; print(len(parsed_model[\"forcing\"]))\n            6\n            &gt;&gt;&gt; print(parsed_model[\"forcing\"][0]) # doctest: +SKIP\n            {'_header': 'Forcing',\n             'datablock': [['0.0000', '1.2300'],\n              ['60.0000', '2.3400'],\n              ['120.0000', '3.4500']],\n             'name': 'boundary_timeseries',\n             'function': 'timeseries',\n             'timeinterpolation': 'block-To',\n             'offset': '1.230',\n             'factor': '2.340',\n             'quantity': ['time', 'dischargebnd'],\n             'unit': ['minutes since 2015-01-01 00:00:00', 'm\u00b3/s']}\n            ```\n\n        Serialize a ForcingModel:\n            ```python\n            &gt;&gt;&gt; save_path = Path(\"output.bc\")\n            &gt;&gt;&gt; model.save(filepath=save_path) # doctest: +SKIP\n            &gt;&gt;&gt; print(save_path.exists()) # doctest: +SKIP\n            True\n            ```\n\n        Create a ForcingModel from a dictionary:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import ForcingModel\n            &gt;&gt;&gt; forcing_blocks_list = [\n            ...     {\n            ...         '_header': 'Forcing',\n            ...         'datablock': [\n            ...             ['0.0000', '1.2300'],\n            ...             ['60.0000', '2.3400'],\n            ...             ['120.0000', '3.4500']\n            ...         ],\n            ...         'name': 'boundary_timeseries',\n            ...         'function': 'timeseries',\n            ...         'timeinterpolation': 'block-To',\n            ...         'offset': '1.230',\n            ...         'factor': '2.340',\n            ...         'quantity': ['time', 'dischargebnd'],\n            ...         'unit': ['minutes since 2015-01-01 00:00:00', 'm\u00b3/s']\n            ...     }\n            ... ]\n            &gt;&gt;&gt; model_dict = {\n            ...     \"forcing\": forcing_blocks_list,\n            ...     \"general\": {\"fileVersion\": \"1.01\", \"fileType\": \"boundConds\"}\n            ... }\n            &gt;&gt;&gt; model = ForcingModel(**model_dict)\n            &gt;&gt;&gt; print(len(model.forcing))\n            1\n            &gt;&gt;&gt; type(model.forcing[0])\n            &lt;class 'hydrolib.core.dflowfm.bc.models.TimeSeries'&gt;\n            &gt;&gt;&gt; print(model.general.fileversion)\n            1.01\n\n            ```\n\n    Example .bc file content:\n        ```.bc\n        # written by HYDROLIB-core 0.3.0\n\n        [General]\n        fileVersion = 1.01\n        fileType    = boundConds\n\n        [Forcing]\n        name               = boundary_timeseries\n        function           = timeseries\n        Time Interpolation = block-To\n        offset             = 1.23\n        factor             = 2.34\n        quantity           = time\n        unit               = minutes since 2015-01-01 00:00:00\n        quantity           = dischargebnd\n        unit               = m\u00b3/s\n        0.0      1.23\n        60.0     2.34\n        120.0    3.45\n        ```\n    \"\"\"\n\n    general: ForcingGeneral = ForcingGeneral()\n    \"\"\"ForcingGeneral: `[General]` block with file metadata.\"\"\"\n\n    forcing: List[ForcingBase] = Field(default_factory=list)\n    \"\"\"List[ForcingBase]: List of `[Forcing]` blocks for all forcing\n    definitions in a single .bc file. Actual data is stored in\n    forcing[..].datablock from [hydrolib.core.dflowfm.ini.models.DataBlockINIBasedModel.datablock].\"\"\"\n\n    _split_to_list = make_list_validator(\"forcing\")\n\n    serializer_config: DataBlockINIBasedSerializerConfig = (\n        DataBlockINIBasedSerializerConfig(\n            section_indent=0, property_indent=0, datablock_indent=0\n        )\n    )\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        \"\"\"\n        Get the file extension for .bc files.\n\n        Returns:\n            str: The file extension, \".bc\".\n        \"\"\"\n        return \".bc\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        \"\"\"\n        Get the default filename for .bc files.\n\n        Returns:\n            str: The default filename, \"boundaryconditions\".\n        \"\"\"\n        return \"boundaryconditions\"\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        \"\"\"\n        Retrieve the parser for .bc files.\n\n        Returns:\n            Callable: The parser function.\n        \"\"\"\n        return cls.parse\n\n    @classmethod\n    def parse(cls, filepath: Path) -&gt; Dict[str, Any]:\n        \"\"\"\n        Parse a .bc file and create an instance of `ForcingModel`.\n\n        Args:\n            filepath (Path): The path to the .bc file.\n\n        Returns:\n            ForcingModel: The parsed model instance.\n        \"\"\"\n        # It's odd to have to disable parsing something as comments\n        # but also need to pass it to the *flattener*.\n        # This method now only supports per model settings, not per section.\n        parser = Parser(ParserConfig(parse_datablocks=True, parse_comments=False))\n\n        with filepath.open(encoding=\"utf8\") as f:\n            for line in f:\n                parser.feed_line(line)\n\n        return parser.finalize().flatten(True, False)\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingModel.forcing","title":"<code>forcing = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[ForcingBase]: List of <code>[Forcing]</code> blocks for all forcing definitions in a single .bc file. Actual data is stored in forcing[..].datablock from [hydrolib.core.dflowfm.ini.models.DataBlockINIBasedModel.datablock].</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingModel.general","title":"<code>general = ForcingGeneral()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ForcingGeneral: <code>[General]</code> block with file metadata.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.ForcingModel.parse","title":"<code>parse(filepath)</code>  <code>classmethod</code>","text":"<p>Parse a .bc file and create an instance of <code>ForcingModel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>The path to the .bc file.</p> required <p>Returns:</p> Name Type Description <code>ForcingModel</code> <code>Dict[str, Any]</code> <p>The parsed model instance.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@classmethod\ndef parse(cls, filepath: Path) -&gt; Dict[str, Any]:\n    \"\"\"\n    Parse a .bc file and create an instance of `ForcingModel`.\n\n    Args:\n        filepath (Path): The path to the .bc file.\n\n    Returns:\n        ForcingModel: The parsed model instance.\n    \"\"\"\n    # It's odd to have to disable parsing something as comments\n    # but also need to pass it to the *flattener*.\n    # This method now only supports per model settings, not per section.\n    parser = Parser(ParserConfig(parse_datablocks=True, parse_comments=False))\n\n    with filepath.open(encoding=\"utf8\") as f:\n        for line in f:\n            parser.feed_line(line)\n\n    return parser.finalize().flatten(True, False)\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Harmonic","title":"<code>Harmonic</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with harmonic components data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class Harmonic(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with harmonic components data.\"\"\"\n\n    function: Literal[\"harmonic\"] = \"harmonic\"\n\n    factor: float = Field(1.0, alias=\"factor\")\n    \"\"\"float: All values in the table are multiplied with the factor. Defaults to 1.0.\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.Harmonic.factor","title":"<code>factor = Field(1.0, alias='factor')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are multiplied with the factor. Defaults to 1.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.HarmonicCorrection","title":"<code>HarmonicCorrection</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with harmonic components correction data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class HarmonicCorrection(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with harmonic components correction data.\"\"\"\n\n    function: Literal[\"harmonic-correction\"] = \"harmonic-correction\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.QHTable","title":"<code>QHTable</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with Q-h table data.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class QHTable(ForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with Q-h table data.\"\"\"\n\n    function: Literal[\"qhtable\"] = \"qhtable\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.QuantityUnitPair","title":"<code>QuantityUnitPair</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A .bc file header lines tuple containing a quantity name, its unit and optionally a vertical position index.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class QuantityUnitPair(BaseModel):\n    \"\"\"A .bc file header lines tuple containing a quantity name, its unit and optionally a vertical position index.\"\"\"\n\n    quantity: str\n    \"\"\"str: Name of quantity.\"\"\"\n\n    unit: str\n    \"\"\"str: Unit of quantity.\"\"\"\n\n    vertpositionindex: Optional[int] = Field(alias=\"vertPositionIndex\")\n    \"\"\"int (optional): This is a (one-based) index into the verticalposition-specification, assigning a vertical position to the quantity (t3D-blocks only).\"\"\"\n\n    def _to_properties(self):\n        \"\"\"Generator function that yields the ini Property objects for a single\n        QuantityUnitPair object.\"\"\"\n        yield Property(key=\"quantity\", value=self.quantity)\n        yield Property(key=\"unit\", value=self.unit)\n        if self.vertpositionindex is not None:\n            yield Property(key=\"vertPositionIndex\", value=self.vertpositionindex)\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.QuantityUnitPair.quantity","title":"<code>quantity</code>  <code>instance-attribute</code>","text":"<p>str: Name of quantity.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.QuantityUnitPair.unit","title":"<code>unit</code>  <code>instance-attribute</code>","text":"<p>str: Unit of quantity.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.QuantityUnitPair.vertpositionindex","title":"<code>vertpositionindex = Field(alias='vertPositionIndex')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>int (optional): This is a (one-based) index into the verticalposition-specification, assigning a vertical position to the quantity (t3D-blocks only).</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.RealTime","title":"<code>RealTime</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid value for the \"realtime\" reserved keyword for real-time controlled forcing data, e.g., for hydraulic structures.</p> <p>This class is used inside the ForcingData Union, to force detection of the realtime keyword, prior to considering it a filename.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class RealTime(StrEnum):\n    \"\"\"\n    Enum class containing the valid value for the \"realtime\" reserved\n    keyword for real-time controlled forcing data, e.g., for hydraulic\n    structures.\n\n    This class is used inside the ForcingData Union, to force detection\n    of the realtime keyword, prior to considering it a filename.\n    \"\"\"\n\n    realtime = \"realtime\"\n    \"\"\"str: Realtime data source, externally provided\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.RealTime.realtime","title":"<code>realtime = 'realtime'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Realtime data source, externally provided</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.T3D","title":"<code>T3D</code>","text":"<p>               Bases: <code>VectorForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with 3D timeseries data.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>float</code> <p>default is 0.0 All values in the table are increased by the offset (after multiplication by factor).</p> required <code>factor</code> <code>float</code> <p>default is 1.0 all values in the table are multiplied with the factor.</p> required <code>vertpositions</code> <code>List[float]</code> <p>The specification of the vertical positions.</p> required <code>vertinterpolation</code> <code>VerticalInterpolation</code> <p>default is linear The type of vertical interpolation.</p> required <code>vertpositiontype</code> <code>VerticalPositionType</code> <p>The vertical position type of the verticalpositions values.</p> required <code>timeinterpolation</code> <code>TimeInterpolation</code> <p>default is linear The type of time interpolation.</p> required <p>Examples:</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class T3D(VectorForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with 3D timeseries data.\n\n    Args:\n        offset (float): default is 0.0\n            All values in the table are increased by the offset (after multiplication by factor).\n        factor (float): default is 1.0\n            all values in the table are multiplied with the factor.\n        vertpositions (List[float]):\n            The specification of the vertical positions.\n        vertinterpolation (VerticalInterpolation): default is linear\n            The type of vertical interpolation.\n        vertpositiontype (VerticalPositionType):\n            The vertical position type of the verticalpositions values.\n        timeinterpolation (TimeInterpolation): default is linear\n            The type of time interpolation.\n\n    Examples:\n\n    \"\"\"\n\n    function: Literal[\"t3d\"] = \"t3d\"\n    offset: float = Field(0.0, alias=\"offset\")\n    factor: float = Field(1.0, alias=\"factor\")\n    vertpositions: List[float] = Field(alias=\"vertPositions\")\n    vertinterpolation: VerticalInterpolation = Field(\n        VerticalInterpolation.linear, alias=\"vertInterpolation\"\n    )\n    vertpositiontype: VerticalPositionType = Field(alias=\"vertPositionType\")\n    timeinterpolation: TimeInterpolation = Field(\n        TimeInterpolation.linear, alias=\"timeInterpolation\"\n    )\n\n    _keys_to_rename = {\n        \"timeinterpolation\": [\"time_interpolation\"],\n        \"vertpositions\": [\"vertical_position_specification\"],\n        \"vertinterpolation\": [\"vertical_interpolation\"],\n        \"vertpositiontype\": [\"vertical_position_type\"],\n        \"vertpositionindex\": [\"vertical_position\"],\n    }\n\n    @root_validator(allow_reuse=True, pre=True)\n    def rename_keys(cls, values: Dict) -&gt; Dict:\n        \"\"\"Renames some old keywords to the currently supported keywords.\"\"\"\n        return rename_keys_for_backwards_compatibility(values, cls._keys_to_rename)\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"vertpositions\",\n    )\n\n    _verticalinterpolation_validator = get_enum_validator(\n        \"vertinterpolation\", enum=VerticalInterpolation\n    )\n    _verticalpositiontype_validator = get_enum_validator(\n        \"vertpositiontype\",\n        enum=VerticalPositionType,\n        alternative_enum_values={\n            VerticalPositionType.percentage_bed: [\"percentage from bed\"],\n        },\n    )\n    _timeinterpolation_validator = get_enum_validator(\n        \"timeinterpolation\", enum=TimeInterpolation\n    )\n\n    @classmethod\n    def get_number_of_repetitions(cls, values: Dict) -&gt; int:\n        verticalpositions = values.get(\"vertpositions\")\n        # Since the renaming root validator may not have been run yet, in this\n        # method we explicitly check old keywords for backwards compatibility:\n        if verticalpositions is None:\n            # try to get the value from any of the older keywords\n            for old_keyword in cls._keys_to_rename[\"vertpositions\"]:\n                verticalpositions = values.get(old_keyword)\n                if verticalpositions is not None:\n                    break\n\n        if verticalpositions is None:\n            raise ValueError(\"vertPositions is not provided\")\n\n        number_of_verticalpositions = (\n            len(verticalpositions)\n            if isinstance(verticalpositions, List)\n            else len(verticalpositions.split())\n        )\n\n        return number_of_verticalpositions\n\n    @root_validator(pre=True)\n    def _validate_quantityunitpairs(cls, values: Dict) -&gt; Dict:\n        quantityunitpairs = values[\"quantityunitpair\"]\n\n        T3D._validate_that_first_unit_is_time_and_has_no_verticalposition(\n            quantityunitpairs\n        )\n\n        number_of_verticalpositions = cls.get_number_of_repetitions(values)\n\n        verticalpositionindexes = values.get(\"vertpositionindex\")\n        if verticalpositionindexes is None:\n            T3D._validate_that_all_quantityunitpairs_have_valid_verticalpositionindex(\n                quantityunitpairs[1:], number_of_verticalpositions\n            )\n        else:\n            T3D._validate_verticalpositionindexes_and_update_quantityunitpairs(\n                verticalpositionindexes,\n                number_of_verticalpositions,\n                quantityunitpairs,\n            )\n\n        return values\n\n    @staticmethod\n    def _validate_that_first_unit_is_time_and_has_no_verticalposition(\n        quantityunitpairs: List[QuantityUnitPair],\n    ) -&gt; None:\n        if quantityunitpairs[0].quantity.lower() != \"time\":\n            raise ValueError(\"First quantity should be `time`\")\n        if quantityunitpairs[0].vertpositionindex is not None:\n            raise ValueError(\"`time` quantity cannot have vertical position index\")\n\n    @staticmethod\n    def _validate_that_all_quantityunitpairs_have_valid_verticalpositionindex(\n        quantityunitpairs: List[ScalarOrVectorQUP], maximum_verticalpositionindex: int\n    ) -&gt; None:\n        for quantityunitpair in quantityunitpairs:\n            if isinstance(quantityunitpair, VectorQuantityUnitPairs):\n                return T3D._validate_that_all_quantityunitpairs_have_valid_verticalpositionindex(\n                    quantityunitpair.quantityunitpair, maximum_verticalpositionindex\n                )\n\n            verticalpositionindex = quantityunitpair.vertpositionindex\n\n            if not T3D._is_valid_verticalpositionindex(\n                verticalpositionindex, maximum_verticalpositionindex\n            ):\n                raise ValueError(\n                    f\"Vertical position index should be between 1 and {maximum_verticalpositionindex}, but {verticalpositionindex} was given\"\n                )\n\n    @staticmethod\n    def _validate_verticalpositionindexes_and_update_quantityunitpairs(\n        verticalpositionindexes: List[int],\n        number_of_verticalpositions: int,\n        quantityunitpairs: List[ScalarOrVectorQUP],\n    ) -&gt; None:\n        if verticalpositionindexes is None:\n            raise ValueError(\"vertPositionIndex is not provided\")\n\n        T3D._validate_that_verticalpositionindexes_are_valid(\n            verticalpositionindexes, number_of_verticalpositions\n        )\n\n        T3D._add_verticalpositionindex_to_quantityunitpairs(\n            quantityunitpairs[1:], verticalpositionindexes\n        )\n\n    @staticmethod\n    def _validate_that_verticalpositionindexes_are_valid(\n        verticalpositionindexes: List[int], number_of_vertical_positions: int\n    ) -&gt; None:\n        for verticalpositionindexstring in verticalpositionindexes:\n            verticalpositionindex = (\n                int(verticalpositionindexstring)\n                if verticalpositionindexstring\n                else None\n            )\n            if not T3D._is_valid_verticalpositionindex(\n                verticalpositionindex, number_of_vertical_positions\n            ):\n                raise ValueError(\n                    f\"Vertical position index should be between 1 and {number_of_vertical_positions}\"\n                )\n\n    @staticmethod\n    def _is_valid_verticalpositionindex(\n        verticalpositionindex: int, number_of_vertical_positions: int\n    ) -&gt; bool:\n        one_based_index_offset = 1\n\n        return (\n            verticalpositionindex is not None\n            and verticalpositionindex &gt;= one_based_index_offset\n            and verticalpositionindex &lt;= number_of_vertical_positions\n        )\n\n    @staticmethod\n    def _add_verticalpositionindex_to_quantityunitpairs(\n        quantityunitpairs: List[ScalarOrVectorQUP], verticalpositionindexes: List[int]\n    ) -&gt; None:\n        i = 0\n\n        for quanityunitpair in quantityunitpairs:\n            if i &gt;= len(verticalpositionindexes):\n                raise ValueError(\n                    \"Number of vertical position indexes should be equal to the number of quantities/units - 1\"\n                )\n\n            if isinstance(quanityunitpair, VectorQuantityUnitPairs):\n                for qup in quanityunitpair.quantityunitpair:\n                    qup.vertpositionindex = verticalpositionindexes[i]\n                    i = i + 1\n            else:\n                quanityunitpair.vertpositionindex = verticalpositionindexes[i]\n                i = i + 1\n\n        if i != len(verticalpositionindexes):\n            raise ValueError(\n                \"Number of vertical position indexes should be equal to the number of quantities/units - 1\"\n            )\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.T3D.rename_keys","title":"<code>rename_keys(values)</code>","text":"<p>Renames some old keywords to the currently supported keywords.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@root_validator(allow_reuse=True, pre=True)\ndef rename_keys(cls, values: Dict) -&gt; Dict:\n    \"\"\"Renames some old keywords to the currently supported keywords.\"\"\"\n    return rename_keys_for_backwards_compatibility(values, cls._keys_to_rename)\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeInterpolation","title":"<code>TimeInterpolation</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the time interpolation.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class TimeInterpolation(StrEnum):\n    \"\"\"Enum class containing the valid values for the time interpolation.\"\"\"\n\n    linear = \"linear\"\n    \"\"\"str: Linear interpolation between times.\"\"\"\n\n    block_from = \"block-From\"\n    \"\"\"str: Equal to that at the start of the time interval (latest specified time value).\"\"\"\n\n    block_to = \"block-To\"\n    \"\"\"str: Equal to that at the end of the time interval (upcoming specified time value).\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeInterpolation.block_from","title":"<code>block_from = 'block-From'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Equal to that at the start of the time interval (latest specified time value).</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeInterpolation.block_to","title":"<code>block_to = 'block-To'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Equal to that at the end of the time interval (upcoming specified time value).</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeInterpolation.linear","title":"<code>linear = 'linear'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Linear interpolation between times.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeSeries","title":"<code>TimeSeries</code>","text":"<p>               Bases: <code>VectorForcingBase</code></p> <p>Subclass for a .bc file [Forcing] block with timeseries data.</p> <p>Attributes:</p> Name Type Description <code>function</code> <code>Literal['timeseries']</code> <p>Specifies that this is a timeseries forcing block. Defaults to \"timeseries\".</p> <code>timeinterpolation</code> <code>TimeInterpolation</code> <p>The type of time interpolation, such as \"linear\", \"block-From\", or \"block-To\".</p> <code>offset</code> <code>float</code> <p>All values in the table are increased by the offset (after multiplication by factor). Defaults to 0.0.</p> <code>factor</code> <code>float</code> <p>All values in the table are multiplied by the factor. Defaults to 1.0.</p> <p>Methods:     rename_keys(cls, values: Dict) -&gt; Dict:         Renames old keywords to currently supported keywords for backward compatibility.</p> <p>Examples:</p> <p>One quantity: <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import TimeSeries\n&gt;&gt;&gt; timeseries = TimeSeries(\n...     name=\"Boundary1\",\n...     function=\"timeseries\",\n...     timeinterpolation=\"block-From\",\n...     offset=1.23,\n...     factor=2.34,\n...     quantityunitpair=[\n...         QuantityUnitPair(quantity=\"time\", unit=\"minutes since 2015-01-01 00:00:00\"),\n...         QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")\n...    ],\n...     datablock=[[\"0\", \"10\"], [\"1.0\", \"20\"], [\"2.0\", \"30\"]]\n... )\n</code></pre> the forcing will look as follows: <pre><code>[Forcing]\n    name              = Boundary1\n    timeinterpolation = block-From\n    function          = timeseries\n    quantity          = time\n    unit              = minutes since 2001-01-01\n    quantity          = waterlevel\n    unit              = m\n    offset            = 1.23\n    factor            = 2.34\n    0 10\n    1 20\n    2 30\n</code></pre> Two quantities:</p> <pre><code>&gt;&gt;&gt; timeseries = TimeSeries(\n...     name=\"Boundary1\",\n...     function=\"timeseries\",\n...     timeinterpolation=\"block-From\",\n...     offset=1.23,\n...     factor=2.34,\n...     quantityunitpair=[\n...         QuantityUnitPair(quantity=\"time\", unit=\"minutes since 2015-01-01 00:00:00\"),\n...         QuantityUnitPair(quantity=\"dischargebnd\", unit=\"m\u00b3/s\"),\n...         QuantityUnitPair(quantity=\"waterlevelbnd\", unit=\"m\")\n...     ],\n...    datablock=[[\"0\", \"50\", \"4.0\"], [\"1\", \"60\", \"5.0\"], [\"2\", \"70\", \"6.0\"]]\n... )\n</code></pre> <p><pre><code>the forcing will look as follows:\n</code></pre> [Forcing]     name              = Boundary1     timeinterpolation = block-From     function          = timeseries     quantity          = time     unit              = minutes since 2015-01-01 00:00:00     quantity          = dischargebnd     unit              = m\u00b3/s     quantity          = waterlevelbnd     unit              = m     offset            = 1.23     factor            = 2.34     0 50 4.0     1 60 5.0     2 70 6.0 ```</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class TimeSeries(VectorForcingBase):\n    \"\"\"Subclass for a .bc file [Forcing] block with timeseries data.\n\n    Attributes:\n        function (Literal[\"timeseries\"]):\n            Specifies that this is a timeseries forcing block. Defaults to \"timeseries\".\n        timeinterpolation (TimeInterpolation):\n            The type of time interpolation, such as \"linear\", \"block-From\", or \"block-To\".\n        offset (float):\n            All values in the table are increased by the offset (after multiplication by factor).\n            Defaults to 0.0.\n        factor (float):\n            All values in the table are multiplied by the factor. Defaults to 1.0.\n\n     Methods:\n        rename_keys(cls, values: Dict) -&gt; Dict:\n            Renames old keywords to currently supported keywords for backward compatibility.\n\n    Examples:\n        One quantity:\n        ```python\n        &gt;&gt;&gt; from hydrolib.core.dflowfm.bc.models import TimeSeries\n        &gt;&gt;&gt; timeseries = TimeSeries(\n        ...     name=\"Boundary1\",\n        ...     function=\"timeseries\",\n        ...     timeinterpolation=\"block-From\",\n        ...     offset=1.23,\n        ...     factor=2.34,\n        ...     quantityunitpair=[\n        ...         QuantityUnitPair(quantity=\"time\", unit=\"minutes since 2015-01-01 00:00:00\"),\n        ...         QuantityUnitPair(quantity=\"waterlevel\", unit=\"m\")\n        ...    ],\n        ...     datablock=[[\"0\", \"10\"], [\"1.0\", \"20\"], [\"2.0\", \"30\"]]\n        ... )\n\n        ```\n        the forcing will look as follows:\n        ```\n        [Forcing]\n            name              = Boundary1\n            timeinterpolation = block-From\n            function          = timeseries\n            quantity          = time\n            unit              = minutes since 2001-01-01\n            quantity          = waterlevel\n            unit              = m\n            offset            = 1.23\n            factor            = 2.34\n            0 10\n            1 20\n            2 30\n        ```\n        Two quantities:\n        &gt;&gt;&gt; timeseries = TimeSeries(\n        ...     name=\"Boundary1\",\n        ...     function=\"timeseries\",\n        ...     timeinterpolation=\"block-From\",\n        ...     offset=1.23,\n        ...     factor=2.34,\n        ...     quantityunitpair=[\n        ...         QuantityUnitPair(quantity=\"time\", unit=\"minutes since 2015-01-01 00:00:00\"),\n        ...         QuantityUnitPair(quantity=\"dischargebnd\", unit=\"m\u00b3/s\"),\n        ...         QuantityUnitPair(quantity=\"waterlevelbnd\", unit=\"m\")\n        ...     ],\n        ...    datablock=[[\"0\", \"50\", \"4.0\"], [\"1\", \"60\", \"5.0\"], [\"2\", \"70\", \"6.0\"]]\n        ... )\n\n        ```\n        the forcing will look as follows:\n        ```\n        [Forcing]\n            name              = Boundary1\n            timeinterpolation = block-From\n            function          = timeseries\n            quantity          = time\n            unit              = minutes since 2015-01-01 00:00:00\n            quantity          = dischargebnd\n            unit              = m\u00b3/s\n            quantity          = waterlevelbnd\n            unit              = m\n            offset            = 1.23\n            factor            = 2.34\n            0 50 4.0\n            1 60 5.0\n            2 70 6.0\n        ```\n    \"\"\"\n\n    function: Literal[\"timeseries\"] = \"timeseries\"\n\n    timeinterpolation: TimeInterpolation = Field(alias=\"timeInterpolation\")\n    \"\"\"TimeInterpolation: The type of time interpolation.\"\"\"\n\n    offset: float = Field(0.0, alias=\"offset\")\n    \"\"\"float: All values in the table are increased by the offset (after multiplication by factor). Defaults to 0.0.\"\"\"\n\n    factor: float = Field(1.0, alias=\"factor\")\n    \"\"\"float: All values in the table are multiplied with the factor. Defaults to 1.0.\"\"\"\n\n    _timeinterpolation_validator = get_enum_validator(\n        \"timeinterpolation\", enum=TimeInterpolation\n    )\n\n    @root_validator(allow_reuse=True, pre=True)\n    def rename_keys(cls, values: Dict) -&gt; Dict:\n        \"\"\"Renames some old keywords to the currently supported keywords.\"\"\"\n        return rename_keys_for_backwards_compatibility(\n            values,\n            {\n                \"timeinterpolation\": [\"time_interpolation\"],\n            },\n        )\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeSeries.factor","title":"<code>factor = Field(1.0, alias='factor')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are multiplied with the factor. Defaults to 1.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeSeries.offset","title":"<code>offset = Field(0.0, alias='offset')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>float: All values in the table are increased by the offset (after multiplication by factor). Defaults to 0.0.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeSeries.timeinterpolation","title":"<code>timeinterpolation = Field(alias='timeInterpolation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>TimeInterpolation: The type of time interpolation.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.TimeSeries.rename_keys","title":"<code>rename_keys(values)</code>","text":"<p>Renames some old keywords to the currently supported keywords.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@root_validator(allow_reuse=True, pre=True)\ndef rename_keys(cls, values: Dict) -&gt; Dict:\n    \"\"\"Renames some old keywords to the currently supported keywords.\"\"\"\n    return rename_keys_for_backwards_compatibility(\n        values,\n        {\n            \"timeinterpolation\": [\"time_interpolation\"],\n        },\n    )\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorForcingBase","title":"<code>VectorForcingBase</code>","text":"<p>               Bases: <code>ForcingBase</code></p> <p>The base class of a single [Forcing] block that supports vectors in a .bc forcings file.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class VectorForcingBase(ForcingBase):\n    \"\"\"\n    The base class of a single [Forcing] block that supports vectors in a .bc forcings file.\n    \"\"\"\n\n    @root_validator(pre=True)\n    def validate_and_update_quantityunitpairs(cls, values: Dict) -&gt; Dict:\n        \"\"\"\n        Validates and, if required, updates vector quantity unit pairs.\n\n        Args:\n            values (Dict): Dictionary of values to be used to validate or\n            update vector quantity unit pairs.\n\n        Raises:\n            ValueError: When a quantity unit pair is found in a vector where it does not belong.\n            ValueError: When the number of quantity unit pairs in a vectors is not as expected.\n\n        Returns:\n            Dict: Dictionary of validates values.\n        \"\"\"\n        quantityunitpairs = values[\"quantityunitpair\"]\n        vector = values.get(\"vector\")\n        number_of_element_repetitions = cls.get_number_of_repetitions(values)\n\n        VectorForcingBase._process_vectordefinition_or_check_quantityunitpairs(\n            vector, quantityunitpairs, number_of_element_repetitions\n        )\n\n        return values\n\n    @staticmethod\n    def _process_vectordefinition_or_check_quantityunitpairs(\n        vectordefs: Optional[List[str]],\n        quantityunitpairs: List[ScalarOrVectorQUP],\n        number_of_element_repetitions: int,\n    ) -&gt; None:\n        \"\"\"\n        Processes the given vector definition header lines from a .bc file\n        or, if absent, checks whether the existing VectorQuantityUnitPairs\n        objects already have the correct vector length.\n\n        Args:\n            vectordefs (List[str]): List of vector definition values, e.g.,\n                [\"vectorname:comp1,comp2,..compN\", ...]\n            quantityunitpairs (List[ScalarOrVectorQUP]): list of already parsed\n                and constructed QuantityUnitPair objects, which may be modified\n                in place with some packed VectorQuantityUnitPairs objects.\n            number_of_element_repetitions (int, optional): Number of times each\n                vector element is expected to be present in the subsequent\n                Quantity lines. Typically used for 3D quantities, using the\n                number of vertical layers.\n        \"\"\"\n\n        if vectordefs is not None and not any(\n            map(lambda qup: isinstance(qup, VectorQuantityUnitPairs), quantityunitpairs)\n        ):\n            # Vector definition line still must be processed and VectorQUPs still created.\n            VectorForcingBase._validate_vectordefinition_and_update_quantityunitpairs(\n                vectordefs, quantityunitpairs, number_of_element_repetitions\n            )\n        else:\n            # VectorQUPs already present; directly validate their vector length.\n            for qup in quantityunitpairs:\n                if isinstance(qup, VectorQuantityUnitPairs):\n                    VectorForcingBase._validate_vectorlength(\n                        qup, number_of_element_repetitions\n                    )\n\n    @staticmethod\n    def _validate_vectordefinition_and_update_quantityunitpairs(\n        vectordefs: Optional[List[str]],\n        quantityunitpairs: List[ScalarOrVectorQUP],\n        number_of_element_repetitions: int,\n    ) -&gt; None:\n        \"\"\"\n        Validates the given vector definition header lines from a .bc file\n        for a ForcingBase subclass and updates the existing QuantityUnitPair list\n        by packing the vector elements into a VectorQuantityUnitPairs object\n        for each vector definition.\n\n        Args:\n            vectordefs (List[str]): List of vector definition values, e.g.,\n                [\"vectorname:comp1,comp2,..compN\", ...]\n            quantityunitpairs (List[ScalarOrVectorQUP]): list of already parsed\n                and constructed QuantityUnitPair objects, which will be modified\n                in place with some packed VectorQuantityUnitPairs objects.\n            number_of_element_repetitions (int, optional): Number of times each\n                vector element is expected to be present in the subsequent\n                Quantity lines. Typically used for 3D quantities, using the\n                number of vertical layers.\n        \"\"\"\n\n        if vectordefs is None:\n            return\n\n        vectordefs = to_list(vectordefs)\n\n        qup_iter = iter(quantityunitpairs)\n\n        # Start a new list, to only keep the scalar QUPs, and add newly\n        # created VectorQUPs.\n        quantityunitpairs_with_vectors = []\n\n        # If one quantity is \"time\", it must be the first one.\n        if quantityunitpairs[0].quantity == \"time\":\n            quantityunitpairs_with_vectors.append(quantityunitpairs[0])\n            _ = next(qup_iter)\n\n        # For each vector definition line, greedily find the quantity unit pairs\n        # that form the vector elements, and pack them into a single VectorQuantityUnitPairs oject.\n        for vectordef in vectordefs:\n            VectorForcingBase._find_and_pack_vector_qups(\n                number_of_element_repetitions,\n                qup_iter,\n                quantityunitpairs_with_vectors,\n                vectordef,\n            )\n\n        for remaining_qu_pair in qup_iter:\n            quantityunitpairs_with_vectors.append(remaining_qu_pair)\n\n        quantityunitpairs[:] = quantityunitpairs_with_vectors\n\n    @staticmethod\n    def _find_and_pack_vector_qups(\n        number_of_element_repetitions: int,\n        qup_iter: Iterator[ScalarOrVectorQUP],\n        quantityunitpairs_with_vectors: List[ScalarOrVectorQUP],\n        vectordef: str,\n    ):\n        vectorname, componentdefs = vectordef.split(\":\")\n        componentnames = re.split(r\"[, \\t]\", componentdefs)\n        n_components = len(componentnames)\n\n        vqu_pair = VectorQuantityUnitPairs(\n            vectorname=vectorname, elementname=componentnames, quantityunitpair=[]\n        )\n\n        n_rep = 0\n        for qu_pair in qup_iter:\n            if qu_pair.quantity in componentnames:\n                # This vector element found, store it.\n                vqu_pair.quantityunitpair.append(qu_pair)\n                n_rep += 1\n                if n_rep == n_components * number_of_element_repetitions:\n                    break\n            else:\n                # This quantity was no vector element being searched for\n                # so keep it as a regular (scalar) QuantityUnitPair.\n                quantityunitpairs_with_vectors.append(qu_pair)\n\n        if VectorForcingBase._validate_vectorlength(\n            vqu_pair, number_of_element_repetitions\n        ):\n            # This VectorQuantityUnitPairs is now complete; add it to result list.\n            quantityunitpairs_with_vectors.append(vqu_pair)\n\n    @staticmethod\n    def _validate_vectorlength(\n        vqu_pair: VectorQuantityUnitPairs,\n        number_of_element_repetitions,\n    ) -&gt; bool:\n        \"\"\"\n        Checks whether the number of QuantityUnitPairs in a vector quantity\n        matches exactly with number of vector elements in the definition and,\n        optionally, the number of vertical layers.\n\n        Args:\n            vqu_pair (VectorQuantityUnitPairs): the vector quantity object to be checked.\n            number_of_element_repetitions (int, optional): Number of times each\n                vector element is expected to be present in the subsequent\n                Quantity lines. Typically used for 3D quantities, using the\n                number of vertical layers.\n\n        Returns:\n            bool: True if vqu_pair is valid. False return value is hidden because\n                an exception will be raised.\n\n        Raises:\n            ValueError: If number of QuantityUnitPair objects in vqu_pair is not equal\n                to number of element names * number_of_element_repetitions.\n        \"\"\"\n\n        if not (\n            valid := len(vqu_pair.quantityunitpair)\n            == len(vqu_pair.elementname) * number_of_element_repetitions\n        ):\n            raise ValueError(\n                f\"Incorrect number of quantity unit pairs were found; should match the elements in vectordefinition for {vqu_pair.vectorname}\"\n                + (\n                    f\", and {number_of_element_repetitions} vertical layers\"\n                    if number_of_element_repetitions &gt; 1\n                    else \"\"\n                )\n                + \".\"\n            )\n\n        return valid\n\n    @validator(\"function\", pre=True)\n    def _set_function(cls, value):\n        return get_from_subclass_defaults(VectorForcingBase, \"function\", value)\n\n    @classmethod\n    def get_number_of_repetitions(cls, values: Dict) -&gt; int:\n        \"\"\"Gets the number of expected quantityunitpairs for each vector element. Defaults to 1.\"\"\"\n        return 1\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorForcingBase.get_number_of_repetitions","title":"<code>get_number_of_repetitions(values)</code>  <code>classmethod</code>","text":"<p>Gets the number of expected quantityunitpairs for each vector element. Defaults to 1.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@classmethod\ndef get_number_of_repetitions(cls, values: Dict) -&gt; int:\n    \"\"\"Gets the number of expected quantityunitpairs for each vector element. Defaults to 1.\"\"\"\n    return 1\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorForcingBase.validate_and_update_quantityunitpairs","title":"<code>validate_and_update_quantityunitpairs(values)</code>","text":"<p>Validates and, if required, updates vector quantity unit pairs.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Dict</code> <p>Dictionary of values to be used to validate or</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When a quantity unit pair is found in a vector where it does not belong.</p> <code>ValueError</code> <p>When the number of quantity unit pairs in a vectors is not as expected.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Dictionary of validates values.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>@root_validator(pre=True)\ndef validate_and_update_quantityunitpairs(cls, values: Dict) -&gt; Dict:\n    \"\"\"\n    Validates and, if required, updates vector quantity unit pairs.\n\n    Args:\n        values (Dict): Dictionary of values to be used to validate or\n        update vector quantity unit pairs.\n\n    Raises:\n        ValueError: When a quantity unit pair is found in a vector where it does not belong.\n        ValueError: When the number of quantity unit pairs in a vectors is not as expected.\n\n    Returns:\n        Dict: Dictionary of validates values.\n    \"\"\"\n    quantityunitpairs = values[\"quantityunitpair\"]\n    vector = values.get(\"vector\")\n    number_of_element_repetitions = cls.get_number_of_repetitions(values)\n\n    VectorForcingBase._process_vectordefinition_or_check_quantityunitpairs(\n        vector, quantityunitpairs, number_of_element_repetitions\n    )\n\n    return values\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorQuantityUnitPairs","title":"<code>VectorQuantityUnitPairs</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A subset of .bc file header lines containing a vector quantity definition, followed by all component quantity names, their unit and optionally their vertical position indexes.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class VectorQuantityUnitPairs(BaseModel):\n    \"\"\"A subset of .bc file header lines containing a vector quantity definition,\n    followed by all component quantity names, their unit and optionally their\n    vertical position indexes.\"\"\"\n\n    class Config:\n        validate_assignment = True\n\n    vectorname: str\n    \"\"\"str: Name of the vector quantity.\"\"\"\n\n    elementname: List[str]\n    \"\"\"List[str]: List of names of the vector component quantities.\"\"\"\n\n    quantityunitpair: List[QuantityUnitPair]\n    \"\"\"List[QuantityUnitPair]: List of QuantityUnitPair that define the vector components.\"\"\"\n\n    @root_validator\n    @classmethod\n    def _validate_quantity_element_names(cls, values: Dict):\n        for idx, name in enumerate(\n            [qup.quantity for qup in values[\"quantityunitpair\"]]\n        ):\n            if name not in values[\"elementname\"]:\n                raise ValueError(\n                    f\"quantityunitpair[{idx}], quantity '{name}' must be in vectordefinition's element names: '{VectorQuantityUnitPairs._to_vectordefinition_string(values['vectorname'], values['elementname'])}'.\"\n                )\n\n        return values\n\n    @staticmethod\n    def _to_vectordefinition_string(vectorname: str, elementname: List[str]):\n        return vectorname + \":\" + \",\".join(elementname)\n\n    def __str__(self) -&gt; str:\n        return VectorQuantityUnitPairs._to_vectordefinition_string(\n            self.vectorname, self.elementname\n        )\n\n    def _to_properties(self):\n        \"\"\"Generator function that yields the ini Property objects for a single\n        VectorQuantityUnitPairs object.\"\"\"\n        yield Property(key=\"vector\", value=str(self))\n\n        for qup in self.quantityunitpair:\n            for prop in qup._to_properties():\n                yield prop\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorQuantityUnitPairs.elementname","title":"<code>elementname</code>  <code>instance-attribute</code>","text":"<p>List[str]: List of names of the vector component quantities.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorQuantityUnitPairs.quantityunitpair","title":"<code>quantityunitpair</code>  <code>instance-attribute</code>","text":"<p>List[QuantityUnitPair]: List of QuantityUnitPair that define the vector components.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VectorQuantityUnitPairs.vectorname","title":"<code>vectorname</code>  <code>instance-attribute</code>","text":"<p>str: Name of the vector quantity.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalInterpolation","title":"<code>VerticalInterpolation</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the vertical position type, which defines what the numeric values for vertical position specification mean.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class VerticalInterpolation(StrEnum):\n    \"\"\"Enum class containing the valid values for the vertical position type,\n    which defines what the numeric values for vertical position specification mean.\n    \"\"\"\n\n    linear = \"linear\"\n    \"\"\"str: Linear interpolation between vertical positions.\"\"\"\n\n    log = \"log\"\n    \"\"\"str: Logarithmic interpolation between vertical positions (e.g. vertical velocity profiles).\"\"\"\n\n    block = \"block\"\n    \"\"\"str: Equal to the value at the directly lower specified vertical position.\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalInterpolation.block","title":"<code>block = 'block'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Equal to the value at the directly lower specified vertical position.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalInterpolation.linear","title":"<code>linear = 'linear'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Linear interpolation between vertical positions.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalInterpolation.log","title":"<code>log = 'log'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Logarithmic interpolation between vertical positions (e.g. vertical velocity profiles).</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalPositionType","title":"<code>VerticalPositionType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the vertical position type.</p> Source code in <code>hydrolib/core/dflowfm/bc/models.py</code> <pre><code>class VerticalPositionType(StrEnum):\n    \"\"\"Enum class containing the valid values for the vertical position type.\"\"\"\n\n    percentage_bed = \"percBed\"\n    \"\"\"str: Percentage with respect to the water depth from the bed upward.\"\"\"\n\n    z_bed = \"ZBed\"\n    \"\"\"str: Absolute distance from the bed upward.\"\"\"\n\n    z_datum = \"ZDatum\"\n    \"\"\"str: z-coordinate with respect to the reference level of the model.\"\"\"\n\n    z_surf = \"ZSurf\"\n    \"\"\"str: Absolute distance from the free surface downward.\"\"\"\n</code></pre>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalPositionType.percentage_bed","title":"<code>percentage_bed = 'percBed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Percentage with respect to the water depth from the bed upward.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalPositionType.z_bed","title":"<code>z_bed = 'ZBed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Absolute distance from the bed upward.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalPositionType.z_datum","title":"<code>z_datum = 'ZDatum'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: z-coordinate with respect to the reference level of the model.</p>"},{"location":"reference/models/forcing/#hydrolib.core.dflowfm.bc.models.VerticalPositionType.z_surf","title":"<code>z_surf = 'ZSurf'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Absolute distance from the free surface downward.</p>"},{"location":"reference/models/friction/","title":"Friction","text":""},{"location":"reference/models/friction/#1d-roughness-ini-files","title":"1D roughness .ini files","text":"<p>The friction module provides the specific logic for accessing friction/1D roughness files for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>A 1D roughness file is described by the classes below.</p>"},{"location":"reference/models/friction/#model","title":"Model","text":""},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictBranch","title":"<code>FrictBranch</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Branch]</code> block for use inside a friction file.</p> <p>Each block can define the roughness value(s) on a particular branch.</p> Source code in <code>hydrolib/core/dflowfm/friction/models.py</code> <pre><code>class FrictBranch(INIBasedModel):\n    \"\"\"A `[Branch]` block for use inside a friction file.\n\n    Each block can define the roughness value(s) on a particular branch.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        branchid: Optional[str] = Field(\"The name of the branch.\", alias=\"branchId\")\n        frictiontype: Optional[str] = Field(\n            \"The roughness type to be used on this branch.\", alias=\"frictionType\"\n        )\n        functiontype: Optional[str] = Field(\n            \"Function type for the calculation of the value. \"\n            + \"Possible values: constant, timeSeries, absDischarge, waterlevel.\",\n            alias=\"functionType\",\n        )\n        timeseriesid: Optional[str] = Field(\n            \"Refers to a data block in the &lt;*.bc&gt; frictionValuesFile. \"\n            + \"Only if functionType = timeSeries.\",\n            alias=\"timeSeriesId\",\n        )\n        numlevels: Optional[str] = Field(\n            \"Number of levels in table. Only if functionType is not constant.\",\n            alias=\"numLevels\",\n        )\n        levels: Optional[str] = Field(\n            \"Space separated list of discharge [m3/s] or water level [m AD] values. \"\n            + \"Only if functionType is absDischarge or waterLevel.\"\n        )\n        numlocations: Optional[str] = Field(\n            \"Number of locations on branch. The default 0 implies branch uniform values.\",\n            alias=\"numLocations\",\n        )\n        chainage: Optional[str] = Field(\n            \"Space separated list of locations on the branch [m]. Locations sorted by \"\n            + \"increasing chainage. The keyword must be specified if numLocations&gt;0.\"\n        )\n        frictionvalues: Optional[str] = Field(\n            \"numLevels lines containing space separated lists of roughness values: \"\n            + \"numLocations values per line. If the functionType is constant, then a \"\n            + \"single line is required. For a uniform roughness per branch \"\n            + \"(numLocations = 0) a single entry per line is required. The meaning \"\n            + \"of the values depends on the roughness type selected (see frictionType).\",\n            alias=\"frictionValues\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Branch\"] = \"Branch\"\n    branchid: str = Field(alias=\"branchId\")\n    frictiontype: FrictionType = Field(alias=\"frictionType\")\n    functiontype: Optional[str] = Field(\"constant\", alias=\"functionType\")\n    timeseriesid: Optional[str] = Field(alias=\"timeSeriesId\")\n    numlevels: Optional[PositiveInt] = Field(alias=\"numLevels\")\n    levels: Optional[List[float]]\n    numlocations: Optional[NonNegativeInt] = Field(0, alias=\"numLocations\")\n    chainage: Optional[List[float]]\n    frictionvalues: Optional[List[float]] = Field(\n        alias=\"frictionValues\"\n    )  # TODO: turn this into List[List[float]], see issue #143.\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"levels\",\n        \"chainage\",\n        \"frictionvalues\",\n    )\n\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"branchid\")\n\n    @validator(\"levels\", always=True)\n    @classmethod\n    def _validate_levels(cls, v, values):\n        if v is not None and (\n            values[\"numlevels\"] is None or len(v) != values[\"numlevels\"]\n        ):\n            raise ValueError(\n                f\"Number of values for levels should be equal to the numLevels value (branchId={values.get('branchid', '')}).\"\n            )\n\n        return v\n\n    @validator(\"chainage\", always=True)\n    @classmethod\n    def _validate_chainage(cls, v, values):\n        if v is not None and len(v) != values[\"numlocations\"]:\n            raise ValueError(\n                f\"Number of values for chainage should be equal to the numLocations value (branchId={values.get('branchid', '')}).\"\n            )\n\n        return v\n\n    @validator(\"frictionvalues\", always=True)\n    @classmethod\n    def _validate_frictionvalues(cls, v, values):\n        # number of values should be equal to numlocations*numlevels\n        numlevels = (\n            1\n            if (\n                \"numlevels\" not in values\n                or values[\"numlevels\"] is None\n                or values[\"numlevels\"] == 0\n            )\n            else values[\"numlevels\"]\n        )\n        numvals = max(1, values[\"numlocations\"]) * numlevels\n        if v is not None and len(v) != numvals:\n            raise ValueError(\n                f\"Number of values for frictionValues should be equal to the numLocations*numLevels value (branchId={values.get('branchid', '')}).\"\n            )\n\n        return v\n</code></pre>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictGeneral","title":"<code>FrictGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The friction file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/friction/models.py</code> <pre><code>class FrictGeneral(INIGeneral):\n    \"\"\"The friction file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'roughness'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n        frictionvaluesfile: Optional[str] = Field(\n            \"Name of &lt;*.bc&gt; file containing the timeseries with friction values. \"\n            + \"Only needed for functionType = timeSeries.\",\n            alias=\"frictionValuesFile\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"3.01\", alias=\"fileVersion\")\n    filetype: Literal[\"roughness\"] = Field(\"roughness\", alias=\"fileType\")\n    frictionvaluesfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"frictionValuesFile\"\n    )\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n</code></pre>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictGlobal","title":"<code>FrictGlobal</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Global]</code> block for use inside a friction file.</p> <p>Multiple of such blocks may be present to define multiple frictionId classes.</p> Source code in <code>hydrolib/core/dflowfm/friction/models.py</code> <pre><code>class FrictGlobal(INIBasedModel):\n    \"\"\"A `[Global]` block for use inside a friction file.\n\n    Multiple of such blocks may be present to define multiple frictionId classes.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        frictionid: Optional[str] = Field(\n            \"Name of the roughness variable.\", alias=\"frictionId\"\n        )\n        frictiontype: Optional[str] = Field(\n            \"The global roughness type for this variable, which is used \"\n            + \"if no branch specific roughness definition is given.\",\n            alias=\"frictionType\",\n        )\n        frictionvalue: Optional[str] = Field(\n            \"The global default value for this roughness variable.\",\n            alias=\"frictionValue\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Global\"] = \"Global\"\n    frictionid: str = Field(alias=\"frictionId\")\n    frictiontype: FrictionType = Field(alias=\"frictionType\")\n    frictionvalue: float = Field(alias=\"frictionValue\")\n\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"frictionid\")\n</code></pre>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionModel","title":"<code>FrictionModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall friction model that contains the contents of one friction file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.frictfile[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>FrictGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>global_</code> <code>List[FrictGlobal]</code> <p>Definitions of <code>[Global]</code> friction classes.</p> <code>branch</code> <code>List[FrictBranch]</code> <p>Definitions of <code>[Branch]</code> friction values.</p> Source code in <code>hydrolib/core/dflowfm/friction/models.py</code> <pre><code>class FrictionModel(INIModel):\n    \"\"\"\n    The overall friction model that contains the contents of one friction file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.frictfile[..]`.\n\n    Attributes:\n        general (FrictGeneral): `[General]` block with file metadata.\n        global_ (List[FrictGlobal]): Definitions of `[Global]` friction classes.\n        branch (List[FrictBranch]): Definitions of `[Branch]` friction values.\n    \"\"\"\n\n    general: FrictGeneral = FrictGeneral()\n    global_: List[FrictGlobal] = Field([], alias=\"global\")  # to circumvent built-in kw\n    branch: List[FrictBranch] = []\n\n    _split_to_list = make_list_validator(\n        \"global_\",\n        \"branch\",\n    )\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ini\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"roughness\"\n</code></pre>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType","title":"<code>FrictionType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the frictionType attribute in several subclasses of Structure/CrossSection/friction.models.</p> Source code in <code>hydrolib/core/dflowfm/friction/models.py</code> <pre><code>class FrictionType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the frictionType\n    attribute in several subclasses of Structure/CrossSection/friction.models.\n    \"\"\"\n\n    chezy = \"Chezy\"\n    \"\"\"str: Ch\u00e9zy C [m 1/2 /s]\"\"\"\n\n    manning = \"Manning\"\n    \"\"\"str: Manning n [s/m 1/3 ]\"\"\"\n\n    walllawnikuradse = \"wallLawNikuradse\"\n    \"\"\"str: Nikuradse k_n [m]\"\"\"\n\n    whitecolebrook = \"WhiteColebrook\"\n    \"\"\"str: Nikuradse k_n [m]\"\"\"\n\n    stricklernikuradse = \"StricklerNikuradse\"\n    \"\"\"str: Nikuradse k_n [m]\"\"\"\n\n    strickler = \"Strickler\"\n    \"\"\"str: Strickler k_s [m 1/3 /s]\"\"\"\n\n    debosbijkerk = \"deBosBijkerk\"\n    \"\"\"str: De Bos-Bijkerk \u03b3 [1/s]\"\"\"\n</code></pre>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.chezy","title":"<code>chezy = 'Chezy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Ch\u00e9zy C [m 1/2 /s]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.debosbijkerk","title":"<code>debosbijkerk = 'deBosBijkerk'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: De Bos-Bijkerk \u03b3 [1/s]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.manning","title":"<code>manning = 'Manning'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Manning n [s/m 1/3 ]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.strickler","title":"<code>strickler = 'Strickler'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Strickler k_s [m 1/3 /s]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.stricklernikuradse","title":"<code>stricklernikuradse = 'StricklerNikuradse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Nikuradse k_n [m]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.walllawnikuradse","title":"<code>walllawnikuradse = 'wallLawNikuradse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Nikuradse k_n [m]</p>"},{"location":"reference/models/friction/#hydrolib.core.dflowfm.friction.models.FrictionType.whitecolebrook","title":"<code>whitecolebrook = 'WhiteColebrook'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>str: Nikuradse k_n [m]</p>"},{"location":"reference/models/inifield/","title":"Initial and parameter field files","text":"<p>The inifield file contains the initial conditions and spatial parameter input fields for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>The inifield file is represented by the classes below.</p>"},{"location":"reference/models/inifield/#model","title":"Model","text":""},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.AbstractSpatialField","title":"<code>AbstractSpatialField</code>","text":"<p>               Bases: <code>INIBasedModel</code>, <code>ABC</code></p> <p>Abstract base class for <code>[Initial]</code> and <code>[Parameter]</code> block data in inifield files.</p> <p>Defines all common fields. Used via subclasses InitialField and ParameterField.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class AbstractSpatialField(INIBasedModel, ABC):\n    \"\"\"\n    Abstract base class for `[Initial]` and `[Parameter]` block data in\n    inifield files.\n\n    Defines all common fields. Used via subclasses InitialField and ParameterField.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        quantity: Optional[str] = Field(\n            \"Name of the quantity. See UM Table D.2.\", alias=\"quantity\"\n        )\n        datafile: Optional[str] = Field(\n            \"Name of file containing field data values.\", alias=\"dataFile\"\n        )\n        datafiletype: Optional[str] = Field(\"Type of dataFile.\", alias=\"dataFileType\")\n        interpolationmethod: Optional[str] = Field(\n            \"Type of (spatial) interpolation.\", alias=\"interpolationmethod\"\n        )\n        operand: Optional[str] = Field(\n            \"How this data is combined with previous data for the same quantity (if any).\",\n            alias=\"operand\",\n        )\n        averagingtype: Optional[str] = Field(\n            \"Type of averaging, if interpolationMethod=averaging .\",\n            alias=\"averagingtype\",\n        )\n        averagingrelsize: Optional[str] = Field(\n            \"Relative search cell size for averaging.\", alias=\"averagingrelsize\"\n        )\n        averagingnummin: Optional[str] = Field(\n            \"Minimum number of points in averaging. Must be \u2265 1.\",\n            alias=\"averagingnummin\",\n        )\n        averagingpercentile: Optional[str] = Field(\n            \"Percentile value for which data values to include in averaging. 0.0 means off.\",\n            alias=\"averagingpercentile\",\n        )\n        extrapolationmethod: Optional[str] = Field(\n            \"Option for (spatial) extrapolation.\", alias=\"extrapolationmethod\"\n        )\n        locationtype: Optional[str] = Field(\n            \"Target location of interpolation.\", alias=\"locationtype\"\n        )\n        value: Optional[str] = Field(\n            \"Only for dataFileType=polygon. The constant value to be set inside for all model points inside the polygon.\"\n        )\n\n    comments: Comments = Comments()\n\n    quantity: str = Field(alias=\"quantity\")\n    datafile: DiskOnlyFileModel = Field(alias=\"dataFile\")\n\n    datafiletype: DataFileType = Field(alias=\"dataFileType\")\n    interpolationmethod: Optional[InterpolationMethod] = Field(\n        alias=\"interpolationMethod\"\n    )\n    operand: Optional[Operand] = Field(Operand.override.value, alias=\"operand\")\n    averagingtype: Optional[AveragingType] = Field(\n        AveragingType.mean.value, alias=\"averagingType\"\n    )\n    averagingrelsize: Optional[NonNegativeFloat] = Field(1.01, alias=\"averagingRelSize\")\n    averagingnummin: Optional[PositiveInt] = Field(1, alias=\"averagingNumMin\")\n    averagingpercentile: Optional[NonNegativeFloat] = Field(\n        0, alias=\"averagingPercentile\"\n    )\n    extrapolationmethod: Optional[bool] = Field(False, alias=\"extrapolationMethod\")\n    locationtype: Optional[LocationType] = Field(\n        LocationType.all.value, alias=\"locationType\"\n    )\n    value: Optional[float] = Field(alias=\"value\")\n\n    datafiletype_validator = get_enum_validator(\"datafiletype\", enum=DataFileType)\n    interpolationmethod_validator = get_enum_validator(\n        \"interpolationmethod\", enum=InterpolationMethod\n    )\n    operand_validator = get_enum_validator(\"operand\", enum=Operand)\n    averagingtype_validator = get_enum_validator(\"averagingtype\", enum=AveragingType)\n    locationtype_validator = get_enum_validator(\"locationtype\", enum=LocationType)\n\n    @root_validator(allow_reuse=True)\n    def validate_that_value_is_present_for_polygons(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the value is provided when dealing with polygons.\"\"\"\n        return validate_required_fields(\n            values,\n            \"value\",\n            conditional_field_name=\"datafiletype\",\n            conditional_value=DataFileType.polygon,\n        )\n\n    @validator(\"value\", always=True)\n    @classmethod\n    def _validate_value_and_filetype(cls, v, values: dict):\n        if v is not None and values.get(\"datafiletype\") != DataFileType.polygon:\n            raise ValueError(\n                f\"When value={v} is given, dataFileType={DataFileType.polygon} is required.\"\n            )\n\n        return v\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.AbstractSpatialField.validate_that_value_is_present_for_polygons","title":"<code>validate_that_value_is_present_for_polygons(values)</code>","text":"<p>Validates that the value is provided when dealing with polygons.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_value_is_present_for_polygons(cls, values: Dict) -&gt; Dict:\n    \"\"\"Validates that the value is provided when dealing with polygons.\"\"\"\n    return validate_required_fields(\n        values,\n        \"value\",\n        conditional_field_name=\"datafiletype\",\n        conditional_value=DataFileType.polygon,\n    )\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.AveragingType","title":"<code>AveragingType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the averagingType attribute in several subclasses of AbstractIniField.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class AveragingType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the averagingType\n    attribute in several subclasses of AbstractIniField.\n    \"\"\"\n\n    mean = \"mean\"  # simple average\n    nearestnb = \"nearestNb\"  # nearest neighbour value\n    max = \"max\"  # highest\n    min = \"min\"  # lowest\n    invdist = \"invDist\"  # inverse-weighted distance average\n    minabs = \"minAbs\"  # smallest absolute value\n\n    allowedvaluestext = \"Possible values: mean, nearestNb, max, min, invDist, minAbs.\"\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.DataFileType","title":"<code>DataFileType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the dataFileType attribute in several subclasses of AbstractIniField.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class DataFileType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the dataFileType\n    attribute in several subclasses of AbstractIniField.\n    \"\"\"\n\n    arcinfo = \"arcinfo\"\n    geotiff = \"GeoTIFF\"\n    sample = \"sample\"\n    onedfield = \"1dField\"\n    polygon = \"polygon\"\n    uniform = \"uniform\"\n    netcdf = \"netcdf\"\n\n    allowedvaluestext = \"Possible values: arcinfo, GeoTIFF, sample, 1dField, polygon.\"\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.IniFieldGeneral","title":"<code>IniFieldGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The initial field file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class IniFieldGeneral(INIGeneral):\n    \"\"\"The initial field file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'iniField'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"iniField\"] = Field(\"iniField\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.IniFieldModel","title":"<code>IniFieldModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall inifield model that contains the contents of one initial field and parameter file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.inifieldfile[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>IniFieldGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>initial</code> <code>List[InitialField]</code> <p>List of <code>[Initial]</code> blocks with initial condition definitions.</p> <code>parameter</code> <code>List[ParameterField]</code> <p>List of <code>[Parameter]</code> blocks with spatial parameter definitions.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class IniFieldModel(INIModel):\n    \"\"\"\n    The overall inifield model that contains the contents of one initial field and parameter file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.inifieldfile[..]`.\n\n    Attributes:\n        general (IniFieldGeneral): `[General]` block with file metadata.\n        initial (List[InitialField]): List of `[Initial]` blocks with initial condition definitions.\n        parameter (List[ParameterField]): List of `[Parameter]` blocks with spatial parameter definitions.\n    \"\"\"\n\n    general: IniFieldGeneral = IniFieldGeneral()\n    initial: List[InitialField] = Field(default_factory=list)\n    parameter: List[ParameterField] = Field(default_factory=list)\n\n    _split_to_list = make_list_validator(\"initial\", \"parameter\")\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ini\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"fieldFile\"\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.InitialField","title":"<code>InitialField</code>","text":"<p>               Bases: <code>AbstractSpatialField</code></p> <p>Initial condition field definition, represents an <code>[Initial]</code> block in an inifield file. Typically inside the definition list of a FMModel<code>.geometry.inifieldfile.initial[..]</code></p> <p>All lowercased attributes match with the initial field input as described in UM Sec.D.2.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class InitialField(AbstractSpatialField):\n    \"\"\"\n    Initial condition field definition, represents an `[Initial]` block in\n    an inifield file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.inifieldfile.initial[..]`\n\n    All lowercased attributes match with the initial field input as described in\n    [UM Sec.D.2](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.D.2).\n    \"\"\"\n\n    _header: Literal[\"Initial\"] = \"Initial\"\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.InterpolationMethod","title":"<code>InterpolationMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the interpolationMethod attribute in several subclasses of AbstractIniField.</p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class InterpolationMethod(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the interpolationMethod\n    attribute in several subclasses of AbstractIniField.\n    \"\"\"\n\n    constant = \"constant\"  # only with dataFileType=polygon .\n    triangulation = \"triangulation\"  # Delaunay triangulation+linear interpolation.\n    averaging = \"averaging\"  # grid cell averaging.\n    linear_space_time = \"linearSpaceTime\"  # linear interpolation in space and time.\n\n    allowedvaluestext = \"Possible values: constant, triangulation, averaging.\"\n</code></pre>"},{"location":"reference/models/inifield/#hydrolib.core.dflowfm.inifield.models.ParameterField","title":"<code>ParameterField</code>","text":"<p>               Bases: <code>AbstractSpatialField</code></p> <p>Parameter field definition, represents a <code>[Parameter]</code> block in an inifield file. Typically inside the definition list of a FMModel<code>.geometry.inifieldfile.parameter[..]</code></p> Source code in <code>hydrolib/core/dflowfm/inifield/models.py</code> <pre><code>class ParameterField(AbstractSpatialField):\n    \"\"\"\n    Parameter field definition, represents a `[Parameter]` block in\n    an inifield file.\n    Typically inside the definition list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.inifieldfile.parameter[..]`\n    \"\"\"\n\n    _header: Literal[\"Parameter\"] = \"Parameter\"\n</code></pre>"},{"location":"reference/models/mdu/","title":"MDU file","text":"<p>The MDU file is the main input file for D-Flow FM. It is represented by the classes below.</p>"},{"location":"reference/models/mdu/#model","title":"Model","text":""},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.AutoStartOption","title":"<code>AutoStartOption</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the AutoStart attribute in the General class.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class AutoStartOption(IntEnum):\n    \"\"\"\n    Enum class containing the valid values for the AutoStart\n    attribute in the [General][hydrolib.core.dflowfm.mdu.models.General] class.\n    \"\"\"\n\n    no = 0\n    autostart = 1\n    autostartstop = 2\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Calibration","title":"<code>Calibration</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Calibration]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.calibration</code>.</p> <p>All lowercased attributes match with the [Calibration] input as described in UM Sec.A.3.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Calibration(INIBasedModel):\n    \"\"\"\n    The `[Calibration]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.calibration`.\n\n    All lowercased attributes match with the [Calibration] input as described in\n    [UM Sec.A.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        usecalibration: Optional[str] = Field(\n            \"Activate calibration factor friction multiplier (0: no, 1: yes).\",\n            alias=\"UseCalibration\",\n        )\n        definitionfile: Optional[str] = Field(\n            \"File (*.cld) containing calibration definitions.\",\n            alias=\"DefinitionFile\",\n        )\n        areafile: Optional[str] = Field(\n            \"File (*.cll) containing area distribution of calibration definitions.\",\n            alias=\"AreaFile\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Calibration\"] = \"Calibration\"\n    usecalibration: bool = Field(False, alias=\"UseCalibration\")\n    definitionfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"DefinitionFile\"\n    )\n    areafile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"AreaFile\"\n    )\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.ExternalForcing","title":"<code>ExternalForcing</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[External Forcing]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.external_forcing</code>.</p> <p>All lowercased attributes match with the [External Forcing] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class ExternalForcing(INIBasedModel):\n    \"\"\"\n    The `[External Forcing]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.external_forcing`.\n\n    All lowercased attributes match with the [External Forcing] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        extforcefile: Optional[str] = Field(\n            \"Old format for external forcings file *.ext, link with tim/cmp-format boundary conditions specification.\",\n            alias=\"extForceFile\",\n        )\n        extforcefilenew: Optional[str] = Field(\n            \"New format for external forcings file *.ext, link with bcformat boundary conditions specification.\",\n            alias=\"extForceFileNew\",\n        )\n        rainfall: Optional[str] = Field(\n            \"Include rainfall, (0=no, 1=yes).\", alias=\"rainfall\"\n        )\n        qext: Optional[str] = Field(\n            \"Include user Qin/out, externally provided, (0=no, 1=yes).\", alias=\"qExt\"\n        )\n        evaporation: Optional[str] = Field(\n            \"Include evaporation in water balance, (0=no, 1=yes).\", alias=\"evaporation\"\n        )\n        windext: Optional[str] = Field(\n            \"Include wind, externally provided, (0=no, 1=reserved for EC, 2=yes).\",\n            alias=\"windExt\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"External Forcing\"] = \"External Forcing\"\n    extforcefile: Optional[ExtOldModel] = Field(None, alias=\"extForceFile\")\n    extforcefilenew: Optional[ExtModel] = Field(None, alias=\"extForceFileNew\")\n    rainfall: Optional[bool] = Field(None, alias=\"rainfall\")\n    qext: Optional[bool] = Field(None, alias=\"qExt\")\n    evaporation: Optional[bool] = Field(None, alias=\"evaporation\")\n    windext: Optional[int] = Field(None, alias=\"windExt\")\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.FMModel","title":"<code>FMModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall FM model that contains the contents of the toplevel MDU file.</p> <p>All lowercased attributes match with the supported \"[section]\"s as described in UM Sec.A.</p> <p>Each of these class attributes refers to an underlying model class for that particular section.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class FMModel(INIModel):\n    \"\"\"\n    The overall FM model that contains the contents of the toplevel MDU file.\n\n    All lowercased attributes match with the supported \"[section]\"s as described in\n    [UM Sec.A](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#appendix.A).\n\n    Each of these class attributes refers to an underlying model class for that particular section.\n    \"\"\"\n\n    general: General = Field(default_factory=General)\n    geometry: Geometry = Field(default_factory=Geometry)\n    volumetables: VolumeTables = Field(default_factory=VolumeTables)\n    numerics: Numerics = Field(default_factory=Numerics)\n    physics: Physics = Field(default_factory=Physics)\n    sediment: Sediment = Field(default_factory=Sediment)\n    wind: Wind = Field(default_factory=Wind)\n    waves: Optional[Waves] = None\n    time: Time = Field(default_factory=Time)\n    restart: Restart = Field(default_factory=Restart)\n    external_forcing: ExternalForcing = Field(default_factory=ExternalForcing)\n    hydrology: Hydrology = Field(default_factory=Hydrology)\n    trachytopes: Trachytopes = Field(default_factory=Trachytopes)\n    output: Output = Field(default_factory=Output)\n    calibration: Optional[Calibration] = Field(None)\n    grw: Optional[GroundWater] = Field(None)\n    processes: Optional[Processes] = Field(None)\n    particles: Optional[Particles] = Field(None)\n    veg: Optional[Vegetation] = Field(None)\n\n    serializer_config: INISerializerConfig = INISerializerConfig(\n        skip_empty_properties=False\n    )\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".mdu\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"fm\"\n\n    @FileModel._relative_mode.getter\n    def _relative_mode(self) -&gt; ResolveRelativeMode:\n        # This method overrides the _relative_mode property of the FileModel:\n        # The FMModel has a \"special\" feature which determines how relative filepaths\n        # should be resolved. When the field \"pathsRelativeToParent\" is set to False\n        # all relative paths should be resolved in respect to the parent directory of\n        # the mdu file. As such we need to explicitly set the resolve mode to ToAnchor\n        # when this attribute is set.\n\n        if not hasattr(self, \"general\") or self.general is None:\n            return ResolveRelativeMode.ToParent\n\n        if self.general.pathsrelativetoparent:\n            return ResolveRelativeMode.ToParent\n        else:\n            return ResolveRelativeMode.ToAnchor\n\n    @classmethod\n    def _get_relative_mode_from_data(cls, data: Dict[str, Any]) -&gt; ResolveRelativeMode:\n        \"\"\"Gets the ResolveRelativeMode of this FileModel based on the provided data.\n\n        The ResolveRelativeMode of the FMModel is determined by the\n        'pathsRelativeToParent' property of the 'General' category.\n\n        Args:\n            data (Dict[str, Any]):\n                The unvalidated/parsed data which is fed to the pydantic base model,\n                used to determine the ResolveRelativeMode.\n\n        Returns:\n            ResolveRelativeMode: The ResolveRelativeMode of this FileModel\n        \"\"\"\n        if not (general := data.get(\"general\", None)):\n            return ResolveRelativeMode.ToParent\n        if not (relative_to_parent := general.get(\"pathsrelativetoparent\", None)):\n            return ResolveRelativeMode.ToParent\n\n        if relative_to_parent == \"0\":\n            return ResolveRelativeMode.ToAnchor\n        else:\n            return ResolveRelativeMode.ToParent\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.General","title":"<code>General</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The MDU file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class General(INIGeneral):\n    \"\"\"The MDU file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        program: Optional[str] = Field(\"Program.\", alias=\"program\")\n        version: Optional[str] = Field(\n            \"Version number of computational kernel\", alias=\"version\"\n        )\n        filetype: Optional[str] = Field(\"File type. Do not edit this\", alias=\"fileType\")\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        autostart: Optional[str] = Field(\n            \"Autostart simulation after loading MDU or not (0=no, 1=autostart, 2=autostartstop).\",\n            alias=\"autoStart\",\n        )\n        pathsrelativetoparent: Optional[str] = Field(\n            \"Whether or not (1/0) to resolve file names (e.g. inside the *.ext file) relative to their direct parent, instead of to the toplevel MDU working dir\",\n            alias=\"pathsRelativeToParent\",\n        )\n        guiversion: Optional[str] = Field(\n            \"DeltaShell FM suite version.\", alias=\"guiVersion\"\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    program: str = Field(\"D-Flow FM\", alias=\"program\")\n    version: str = Field(\"1.2.94.66079M\", alias=\"version\")\n    filetype: Literal[\"modelDef\"] = Field(\"modelDef\", alias=\"fileType\")\n    fileversion: str = Field(\"1.09\", alias=\"fileVersion\")\n    autostart: Optional[AutoStartOption] = Field(AutoStartOption.no, alias=\"autoStart\")\n    pathsrelativetoparent: bool = Field(False, alias=\"pathsRelativeToParent\")\n    guiversion: Optional[str] = Field(None, alias=\"guiVersion\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Geometry","title":"<code>Geometry</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Geometry]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.geometry</code>.</p> <p>All lowercased attributes match with the [Geometry] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Geometry(INIBasedModel):\n    \"\"\"\n    The `[Geometry]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry`.\n\n    All lowercased attributes match with the [Geometry] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        netfile: Optional[str] = Field(\"The net file &lt;*_net.nc&gt;\", alias=\"netFile\")\n        bathymetryfile: Optional[str] = Field(\n            \"Removed since March 2022. See [geometry] keyword BedLevelFile.\",\n            alias=\"bathymetryFile\",\n        )\n        drypointsfile: Optional[str] = Field(\n            \"Dry points file &lt;*.xyz&gt;, third column dummy z values, or polygon file &lt;*.pol&gt;.\",\n            alias=\"dryPointsFile\",\n        )\n        structurefile: Optional[str] = Field(\n            \"File &lt;*.ini&gt; containing list of hydraulic structures.\",\n            alias=\"structureFile\",\n        )\n        inifieldfile: Optional[str] = Field(\n            \"Initial and parameter field file &lt;*.ini&gt;.\",\n            alias=\"iniFieldFile\",\n        )\n        waterlevinifile: Optional[str] = Field(\n            \"Initial water levels sample file &lt;*.xyz&gt;.\", alias=\"waterLevIniFile\"\n        )\n        landboundaryfile: Optional[str] = Field(\n            \"Only for plotting.\", alias=\"landBoundaryFile\"\n        )\n        thindamfile: Optional[str] = Field(\n            \"&lt;*_thd.pli&gt;, Polyline(s) for tracing thin dams.\", alias=\"thinDamFile\"\n        )\n        fixedweirfile: Optional[str] = Field(\n            \"&lt;*_fxw.pliz&gt;, Polyline(s) x, y, z, z = fixed weir top levels (formerly fixed weir).\",\n            alias=\"fixedWeirFile\",\n        )\n        pillarfile: Optional[str] = Field(\n            \"&lt;*_pillar.pliz&gt;, Polyline file containing four colums with x, y, diameter and Cd coefficient for bridge pillars.\",\n            alias=\"pillarFile\",\n        )\n        usecaching: Optional[str] = Field(\n            \"Use caching for geometrical/network-related items (0: no, 1: yes) (section C.19).\",\n            alias=\"useCaching\",\n        )\n        vertplizfile: Optional[str] = Field(\n            \"&lt;*_vlay.pliz&gt;), = pliz with x, y, Z, first Z = nr of layers, second Z = laytyp.\",\n            alias=\"vertPlizFile\",\n        )\n        frictfile: Optional[str] = Field(\n            \"Location of the files with roughness data for 1D.\",\n            alias=\"frictFile\",\n        )\n        crossdeffile: Optional[str] = Field(\n            \"Cross section definitions for all cross section shapes.\",\n            alias=\"crossDefFile\",\n        )\n        crosslocfile: Optional[str] = Field(\n            \"Location definitions of the cross sections on a 1D network.\",\n            alias=\"crossLocFile\",\n        )\n        storagenodefile: Optional[str] = Field(\n            \"File containing the specification of storage nodes and/or manholes to add extra storage to 1D models.\",\n            alias=\"storageNodeFile\",\n        )\n        oned2dlinkfile: Optional[str] = Field(\n            \"File containing the custom parameterization of 1D-2D links.\",\n            alias=\"1d2dLinkFile\",\n        )\n        proflocfile: Optional[str] = Field(\n            \"&lt;*_proflocation.xyz&gt;) x, y, z, z = profile refnumber.\", alias=\"profLocFile\"\n        )\n        profdeffile: Optional[str] = Field(\n            \"&lt;*_profdefinition.def&gt;) definition for all profile nrs.\",\n            alias=\"profDefFile\",\n        )\n        profdefxyzfile: Optional[str] = Field(\n            \"&lt;*_profdefinition.def&gt;) definition for all profile nrs.\",\n            alias=\"profDefXyzFile\",\n        )\n        manholefile: Optional[str] = Field(\n            \"File containing manholes (e.g. &lt;*.dat&gt;).\", alias=\"manholeFile\"\n        )\n        partitionfile: Optional[str] = Field(\n            \"&lt;*_part.pol&gt;, polyline(s) x, y.\", alias=\"partitionFile\"\n        )\n        uniformwidth1d: Optional[str] = Field(\n            \"Uniform width for channel profiles not specified by profloc\",\n            alias=\"uniformWidth1D\",\n        )\n        dxwuimin2d: Optional[str] = Field(\n            \"Smallest fraction dx/wu , set dx &gt; Dxwuimin2D*wu\",\n            alias=\"dxWuiMin2D\",\n        )\n        waterlevini: Optional[str] = Field(\"Initial water level.\", alias=\"waterLevIni\")\n        bedlevuni: Optional[str] = Field(\n            \"Uniform bed level [m], (only if bedlevtype&gt;=3), used at missing z values in netfile.\",\n            alias=\"bedLevUni\",\n        )\n        bedslope: Optional[str] = Field(\n            \"Bed slope inclination, sets zk = bedlevuni + x*bedslope ans sets zbndz = xbndz*bedslope.\",\n            alias=\"bedSlope\",\n        )\n        bedlevtype: Optional[str] = Field(\n            \"1: at cell center (tiles xz,yz,bl,bob=max(bl)), 2: at face (tiles xu,yu,blu,bob=blu), 3: at face (using mean node values), 4: at face (using min node values), 5: at face (using max node values), 6: with bl based on node values.\",\n            alias=\"bedLevType\",\n        )\n        blmeanbelow: Optional[str] = Field(\n            \"if not -999d0, below this level [m] the cell centre bedlevel is the mean of surrouding netnodes.\",\n            alias=\"blMeanBelow\",\n        )\n        blminabove: Optional[str] = Field(\n            \"if not -999d0, above this level [m] the cell centre bedlevel is the min of surrouding netnodes.\",\n            alias=\"blMinAbove\",\n        )\n        anglat: Optional[str] = Field(\n            \"Angle of latitude S-N [deg], 0=no Coriolis.\", alias=\"angLat\"\n        )\n        anglon: Optional[str] = Field(\n            \"Angle of longitude E-W [deg], 0=Greenwich Mean Time.\", alias=\"angLon\"\n        )\n        conveyance2d: Optional[str] = Field(\n            \"-1:R=HU, 0:R=H, 1:R=A/P, 2:K=analytic-1D conv, 3:K=analytic-2D conv.\",\n            alias=\"conveyance2D\",\n        )\n        nonlin1d: Optional[str] = Field(\n            \"Non-linear 1D volumes, applicable for models with closed cross sections. 1=treat closed sections as partially open by using a Preissmann slot, 2=Nested Newton approach, 3=Partial Nested Newton approach.\",\n            alias=\"nonlin1D\",\n        )\n        nonlin2d: Optional[str] = Field(\n            \"Non-linear 2D volumes, only i.c.m. ibedlevtype = 3 and Conveyance2D&gt;=1.\",\n            alias=\"nonlin2D\",\n        )\n        sillheightmin: Optional[str] = Field(\n            \"Fixed weir only active if both ground heights are larger than this value [m].\",\n            alias=\"sillHeightMin\",\n        )\n        makeorthocenters: Optional[str] = Field(\n            \"(1: yes, 0: no) switch from circumcentres to orthocentres in geominit.\",\n            alias=\"makeOrthoCenters\",\n        )\n        dcenterinside: Optional[str] = Field(\n            \"limit cell center; 1.0:in cell &lt;-&gt; 0.0:on c/g.\", alias=\"dCenterInside\"\n        )\n        bamin: Optional[str] = Field(\n            \"Minimum grid cell area [m2], i.c.m. cutcells.\", alias=\"baMin\"\n        )\n        openboundarytolerance: Optional[str] = Field(\n            \"Search tolerance factor between boundary polyline and grid cells. [Unit: in cell size units (i.e., not meters)].\",\n            alias=\"openBoundaryTolerance\",\n        )\n        renumberflownodes: Optional[str] = Field(\n            \"Renumber the flow nodes (1: yes, 0: no).\", alias=\"renumberFlowNodes\"\n        )\n        kmx: Optional[str] = Field(\"Number of vertical layers.\", alias=\"kmx\")\n        layertype: Optional[str] = Field(\n            \"1= sigma-layers, 2 = z-layers, 3 = use VertplizFile.\", alias=\"layerType\"\n        )\n        numtopsig: Optional[str] = Field(\n            \"Number of sigma-layers on top of z-layers.\", alias=\"numTopSig\"\n        )\n        numtopsiguniform: Optional[str] = Field(\n            \"Spatially constant number of sigma layers above z-layers in a z-sigma model (1: yes, 0: no, spatially varying)\",\n            alias=\"numTopSigUniform\",\n        )\n        dztop: Optional[str] = Field(\n            \"Z-layer thickness of layers above level Dztopuniabovez\", alias=\"dzTop\"\n        )\n        floorlevtoplay: Optional[str] = Field(\n            \"Floor level of top layer\", alias=\"floorLevTopLay\"\n        )\n        dztopuniabovez: Optional[str] = Field(\n            \"Above this level layers will have uniform dzTop, below we use sigmaGrowthFactor\",\n            alias=\"dzTopUniAboveZ\",\n        )\n        keepzlayeringatbed: Optional[str] = Field(\n            \"0:possibly very thin layer at bed, 1:bedlayerthickness == zlayerthickness, 2=equal thickness first two layers\",\n            alias=\"keepZLayeringAtBed\",\n        )\n        sigmagrowthfactor: Optional[str] = Field(\n            \"layer thickness growth factor from bed up.\", alias=\"sigmaGrowthFactor\"\n        )\n        dxdoubleat1dendnodes: Optional[str] = Field(\n            \"Whether a 1D grid cell at the end of a network has to be extended with 0.5\u0394x.\",\n            alias=\"dxDoubleAt1DEndNodes\",\n        )\n        changevelocityatstructures: Optional[str] = Field(\n            \"Ignore structure dimensions for the velocity at hydraulic structures, when calculating the surrounding cell centered flow velocities.\",\n            alias=\"changeVelocityAtStructures\",\n        )\n        changestructuredimensions: Optional[str] = Field(\n            \"Change the structure dimensions in case these are inconsistent with the channel dimensions.\",\n            alias=\"changeStructureDimensions\",\n        )\n        gridenclosurefile: Optional[str] = Field(\n            \"Enclosure file &lt;*.pol&gt; to clip outer parts from the grid.\",\n            alias=\"gridEnclosureFile\",\n        )\n        allowbndatbifurcation: Optional[str] = Field(\n            \"Allow 1d boundary node when connectin branch leads to bifurcation (1: yes, 0: no).\",\n            alias=\"allowBndAtBifurcation\",\n        )\n        slotw1d: Optional[str] = Field(\"Minimum slotwidth 1D [m].\", alias=\"slotw1D\")\n        slotw2d: Optional[str] = Field(\"Minimum slotwidth 2D [m].\", alias=\"slotw2D\")\n        uniformheight1droofgutterpipes: Optional[str] = Field(\n            \"Uniform height for roof gutter pipes [m].\",\n            alias=\"uniformHeight1DRoofGutterPipes\",\n        )\n        dxmin1d: Optional[str] = Field(\"Minimum 1D link length [m].\", alias=\"dxmin1D\")\n        uniformtyp1dstreetinlets: Optional[str] = Field(\n            \"Uniform cross section type for street inlets (1: circle, 2: rectangle, -2: closed rectangle).\",\n            alias=\"uniformTyp1DStreetInlets\",\n        )\n        stretchtype: Optional[str] = Field(\n            \"Stretching type for non-uniform layers, 1=user defined, 2=exponential, otherwise=uniform.\",\n            alias=\"stretchType\",\n        )\n        zlaybot: Optional[str] = Field(\n            \"if specified, first z-layer starts from zlaybot [ ], if not, it starts from the lowest bed point.\",\n            alias=\"zlayBot\",\n        )\n        zlaytop: Optional[str] = Field(\n            \"if specified, highest z-layer ends at zlaytop [ ], if not, it ends at the initial water level.\",\n            alias=\"zlayTop\",\n        )\n        uniformheight1d: Optional[str] = Field(\n            \"Uniform height for 1D profiles and 1d2d internal links [m].\",\n            alias=\"uniformHeight1D\",\n        )\n        roofsfile: Optional[str] = Field(\n            \"Polyline file &lt;*_roof.pliz&gt;, containing roofgutter heights x, y, z level.\",\n            alias=\"roofsFile\",\n        )\n        gulliesfile: Optional[str] = Field(\n            \"Polyline file &lt;*_gul.pliz&gt;, containing lowest bed level along talweg x, y, z level.\",\n            alias=\"gulliesFile\",\n        )\n        uniformwidth1dstreetinlets: Optional[str] = Field(\n            \"Uniform width for street inlets [m].\", alias=\"uniformWidth1DStreetInlets\"\n        )\n        uniformheight1dstreetinlets: Optional[str] = Field(\n            \"Uniform height for street inlets [m]\", alias=\"uniformHeight1DStreetInlets\"\n        )\n        uniformtyp1droofgutterpipes: Optional[str] = Field(\n            \"Uniform cross section type for type roof gutter pipes (1: circle, 2: rectangle, -2: closed rectangle).\",\n            alias=\"uniformTyp1DRoofGutterPipes\",\n        )\n        uniformwidth1droofgutterpipes: Optional[str] = Field(\n            \"Uniform width for roof gutter pipes [m].\",\n            alias=\"uniformWidth1DRoofGutterPipes\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Geometry\"] = \"Geometry\"\n    netfile: Optional[NetworkModel] = Field(\n        default_factory=NetworkModel, alias=\"netFile\"\n    )\n    bathymetryfile: Optional[XYZModel] = Field(None, alias=\"bathymetryFile\")\n    drypointsfile: Optional[List[Union[XYZModel, PolyFile]]] = Field(\n        None, alias=\"dryPointsFile\"\n    )  # TODO Fix, this will always try XYZ first, alias=\"]\")\n    structurefile: Optional[List[StructureModel]] = Field(\n        None, alias=\"structureFile\", delimiter=\";\"\n    )\n    inifieldfile: Optional[IniFieldModel] = Field(None, alias=\"iniFieldFile\")\n    waterlevinifile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"waterLevIniFile\"\n    )\n    landboundaryfile: Optional[List[DiskOnlyFileModel]] = Field(\n        None, alias=\"landBoundaryFile\"\n    )\n    thindamfile: Optional[List[PolyFile]] = Field(None, alias=\"thinDamFile\")\n    fixedweirfile: Optional[List[PolyFile]] = Field(None, alias=\"fixedWeirFile\")\n    pillarfile: Optional[List[PolyFile]] = Field(None, alias=\"pillarFile\")\n    usecaching: bool = Field(True, alias=\"useCaching\")\n    vertplizfile: Optional[PolyFile] = Field(None, alias=\"vertPlizFile\")\n    frictfile: Optional[List[FrictionModel]] = Field(\n        None, alias=\"frictFile\", delimiter=\";\"\n    )\n    crossdeffile: Optional[CrossDefModel] = Field(None, alias=\"crossDefFile\")\n    crosslocfile: Optional[CrossLocModel] = Field(None, alias=\"crossLocFile\")\n    storagenodefile: Optional[StorageNodeModel] = Field(None, alias=\"storageNodeFile\")\n    oned2dlinkfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"1d2dLinkFile\"\n    )\n    proflocfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"profLocFile\"\n    )\n    profdeffile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"profDefFile\"\n    )\n    profdefxyzfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"profDefXyzFile\"\n    )\n    manholefile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"manholeFile\"\n    )\n    partitionfile: Optional[PolyFile] = Field(None, alias=\"partitionFile\")\n    uniformwidth1d: float = Field(2.0, alias=\"uniformWidth1D\")\n    dxwuimin2d: float = Field(0.0, alias=\"dxWuiMin2D\")\n    waterlevini: float = Field(0.0, alias=\"waterLevIni\")\n    bedlevuni: float = Field(-5.0, alias=\"bedLevUni\")\n    bedslope: float = Field(0.0, alias=\"bedSlope\")\n    bedlevtype: int = Field(3, alias=\"bedLevType\")\n    blmeanbelow: float = Field(-999.0, alias=\"blMeanBelow\")\n    blminabove: float = Field(-999.0, alias=\"blMinAbove\")\n    anglat: float = Field(0.0, alias=\"angLat\")\n    anglon: float = Field(0.0, alias=\"angLon\")\n    conveyance2d: int = Field(-1, alias=\"conveyance2D\")\n    nonlin1d: int = Field(1, alias=\"nonlin1D\")\n    nonlin2d: int = Field(0, alias=\"nonlin2D\")\n    sillheightmin: float = Field(0.0, alias=\"sillHeightMin\")\n    makeorthocenters: bool = Field(False, alias=\"makeOrthoCenters\")\n    dcenterinside: float = Field(1.0, alias=\"dCenterInside\")\n    bamin: float = Field(1e-06, alias=\"baMin\")\n    openboundarytolerance: float = Field(3.0, alias=\"openBoundaryTolerance\")\n    renumberflownodes: bool = Field(True, alias=\"renumberFlowNodes\")\n    kmx: int = Field(0, alias=\"kmx\")\n    layertype: int = Field(1, alias=\"layerType\")\n    numtopsig: int = Field(0, alias=\"numTopSig\")\n    numtopsiguniform: bool = Field(True, alias=\"numTopSigUniform\")\n    sigmagrowthfactor: float = Field(1.0, alias=\"sigmaGrowthFactor\")\n    dztop: Optional[float] = Field(-999, alias=\"dzTop\")\n    floorlevtoplay: Optional[float] = Field(-999, alias=\"floorLevTopLay\")\n    dztopuniabovez: Optional[float] = Field(-999, alias=\"dzTopUniAboveZ\")\n    keepzlayeringatbed: int = Field(2, alias=\"keepZLayeringAtBed\")\n    dxdoubleat1dendnodes: bool = Field(True, alias=\"dxDoubleAt1DEndNodes\")\n    changevelocityatstructures: bool = Field(False, alias=\"changeVelocityAtStructures\")\n    changestructuredimensions: bool = Field(True, alias=\"changeStructureDimensions\")\n    gridenclosurefile: Optional[PolyFile] = Field(None, alias=\"gridEnclosureFile\")\n    allowbndatbifurcation: bool = Field(False, alias=\"allowBndAtBifurcation\")\n    slotw1d: float = Field(0.001, alias=\"slotw1D\")\n    slotw2d: float = Field(0.001, alias=\"slotw2D\")\n    uniformheight1droofgutterpipes: float = Field(\n        0.1, alias=\"uniformHeight1DRoofGutterPipes\"\n    )\n    dxmin1d: float = Field(0.001, alias=\"dxmin1D\")\n    uniformtyp1dstreetinlets: int = Field(-2, alias=\"uniformTyp1DStreetInlets\")\n    stretchtype: int = Field(-1, alias=\"stretchType\")\n    zlaybot: float = Field(-999.0, alias=\"zlayBot\")\n    zlaytop: float = Field(-999.0, alias=\"zlayTop\")\n    uniformheight1d: float = Field(3.0, alias=\"uniformHeight1D\")\n    roofsfile: Optional[PolyFile] = Field(None, alias=\"roofsFile\")\n    gulliesfile: Optional[PolyFile] = Field(None, alias=\"gulliesFile\")\n    uniformwidth1dstreetinlets: float = Field(0.2, alias=\"uniformWidth1DStreetInlets\")\n    uniformheight1dstreetinlets: float = Field(0.1, alias=\"uniformHeight1DStreetInlets\")\n    uniformtyp1droofgutterpipes: int = Field(-2, alias=\"uniformTyp1DRoofGutterPipes\")\n    uniformwidth1droofgutterpipes: float = Field(\n        0.1, alias=\"uniformWidth1DRoofGutterPipes\"\n    )\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"frictfile\",\n        \"structurefile\",\n        \"drypointsfile\",\n        \"landboundaryfile\",\n        \"thindamfile\",\n        \"fixedweirfile\",\n        \"pillarfile\",\n    )\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.GroundWater","title":"<code>GroundWater</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Grw]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.grw</code>.</p> <p>All lowercased attributes match with the [Grw] input as described in UM Sec.A.3.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class GroundWater(INIBasedModel):\n    \"\"\"\n    The `[Grw]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.grw`.\n\n    All lowercased attributes match with the [Grw] input as described in\n    [UM Sec.A.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        groundwater: Optional[str] = Field(\n            \"0=No (horizontal) groundwater flow, 1=With groundwater flow\",\n            alias=\"GroundWater\",\n        )\n        infiltrationmodel: Optional[str] = Field(\n            \"Infiltration method (0: No infiltration, 1: Interception layer, 2: Constant infiltration capacity, 3: model unsaturated/saturated (with grw), 4: Horton).\",\n            alias=\"Infiltrationmodel\",\n        )\n        hinterceptionlayer: Optional[str] = Field(\n            \"Intercept this amount of rain (m)\", alias=\"Hinterceptionlayer\"\n        )\n        unifinfiltrationcapacity: Optional[str] = Field(\n            \"Uniform maximum infiltration capacity [m/s].\",\n            alias=\"UnifInfiltrationCapacity\",\n        )\n        conductivity: Optional[str] = Field(\n            \"Non-dimensionless K conductivity   saturated (m/s), Q = K*A*i (m3/s)\",\n            alias=\"Conductivity\",\n        )\n        h_aquiferuni: Optional[str] = Field(\n            \"bgrw = bl - h_aquiferuni (m), if negative, bgrw = bgrwuni.\",\n            alias=\"h_aquiferuni\",\n        )\n        bgrwuni: Optional[str] = Field(\n            \"uniform level of impervious layer, only used if h_aquiferuni is negative.\",\n            alias=\"bgrwuni\",\n        )\n        h_unsatini: Optional[str] = Field(\n            \"initial level groundwater is bedlevel - h_unsatini (m), if negative, sgrw = sgrwini.\",\n            alias=\"h_unsatini\",\n        )\n        sgrwini: Optional[str] = Field(\n            \"Initial groundwater level, if h_unsatini &lt; 0.\", alias=\"sgrwini\"\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Grw\"] = \"Grw\"\n\n    groundwater: Optional[bool] = Field(False, alias=\"GroundWater\")\n    infiltrationmodel: Optional[InfiltrationMethod] = Field(\n        InfiltrationMethod.NoInfiltration, alias=\"Infiltrationmodel\"\n    )\n    hinterceptionlayer: Optional[float] = Field(0.0, alias=\"Hinterceptionlayer\")\n    unifinfiltrationcapacity: Optional[float] = Field(\n        0.0, alias=\"UnifInfiltrationCapacity\"\n    )\n    conductivity: Optional[float] = Field(0.0, alias=\"Conductivity\")\n    h_aquiferuni: Optional[float] = Field(20.0, alias=\"h_aquiferuni\")\n    bgrwuni: Optional[float] = Field(-999, alias=\"bgrwuni\")\n    h_unsatini: Optional[float] = Field(0.2, alias=\"h_unsatini\")\n    sgrwini: Optional[float] = Field(-999, alias=\"sgrwini\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Hydrology","title":"<code>Hydrology</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Hydrology]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.hydrology</code>.</p> <p>All lowercased attributes match with the [Hydrology] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Hydrology(INIBasedModel):\n    \"\"\"\n    The `[Hydrology]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.hydrology`.\n\n    All lowercased attributes match with the [Hydrology] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        interceptionmodel: Optional[str] = Field(\n            \"Interception model (0: none, 1: on, via layer thickness).\",\n            alias=\"interceptionModel\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Hydrology\"] = \"Hydrology\"\n    interceptionmodel: bool = Field(False, alias=\"interceptionModel\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.InfiltrationMethod","title":"<code>InfiltrationMethod</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the Infiltrationmodel attribute in the GroundWater class.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class InfiltrationMethod(IntEnum):\n    \"\"\"\n    Enum class containing the valid values for the Infiltrationmodel\n    attribute in the [GroundWater][hydrolib.core.dflowfm.mdu.models.GroundWater] class.\n    \"\"\"\n\n    NoInfiltration = 0\n    InterceptionLayer = 1\n    ConstantInfiltrationCapacity = 2\n    ModelUnsaturatedSaturated = 3\n    Horton = 4\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Numerics","title":"<code>Numerics</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Numerics]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.numerics</code>.</p> <p>All lowercased attributes match with the [Numerics] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Numerics(INIBasedModel):\n    \"\"\"\n    The `[Numerics]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.numerics`.\n\n    All lowercased attributes match with the [Numerics] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        cflmax: Optional[str] = Field(\"Maximum Courant nr.\", alias=\"CFLMax\")\n        epsmaxlev: Optional[str] = Field(\n            \"Stop criterium for non linear iteration\", alias=\"EpsMaxlev\"\n        )\n        epsmaxlevm: Optional[str] = Field(\n            \"Stop criterium for Nested Newton loop in non linear iteration\",\n            alias=\"EpsMaxlevM\",\n        )\n        advectype: Optional[str] = Field(\n            \"Adv type, 0=no, 33=Perot q(uio-u) fast, 3=Perot q(uio-u).\",\n            alias=\"advecType\",\n        )\n        timesteptype: Optional[str] = Field(\n            \"0=only transport, 1=transport + velocity update, 2=full implicit step_reduce, 3=step_jacobi, 4=explicit.\",\n            alias=\"timeStepType\",\n        )\n        limtyphu: Optional[str] = Field(\n            \"Limiter type for waterdepth in continuity eq., 0=no, 1=minmod,2=vanLeer,3=Koren,4=Monotone Central.\",\n            alias=\"limTypHu\",\n        )\n        limtypmom: Optional[str] = Field(\n            \"Limiter type for cell center advection velocity, 0=no, 1=minmod,2=vanLeer,4=Monotone Central.\",\n            alias=\"limTypMom\",\n        )\n        limtypsa: Optional[str] = Field(\n            \"Limiter type for salinity transport,           0=no, 1=minmod,2=vanLeer,4=Monotone Central.\",\n            alias=\"limTypSa\",\n        )\n        icgsolver: Optional[str] = Field(\n            \"Solver type, 4 = sobekGS + Saad-ILUD (default sequential), 6 = PETSc (default parallel), 7= CG+MILU (parallel).\",\n            alias=\"icgSolver\",\n        )\n        maxdegree: Optional[str] = Field(\n            \"Maximum degree in Gauss elimination.\", alias=\"maxDegree\"\n        )\n        fixedweirscheme: Optional[str] = Field(\n            \"6 = semi-subgrid scheme, 8 = Tabellenboek, 9 = Villemonte (default).\",\n            alias=\"fixedWeirScheme\",\n        )\n        fixedweircontraction: Optional[str] = Field(\n            \"flow width = flow width*fixedWeirContraction.\",\n            alias=\"fixedWeirContraction\",\n        )\n        izbndpos: Optional[str] = Field(\n            \"Position of z boundary, 0=mirroring of closest cell (as in Delft3D-FLOW), 1=on net boundary.\",\n            alias=\"izBndPos\",\n        )\n        tlfsmo: Optional[str] = Field(\n            \"Fourier smoothing time on water level boundaries [s].\", alias=\"tlfSmo\"\n        )\n        keepstbndonoutflow: Optional[str] = Field(\n            \"Keep salinity and temperature signals on boundary also at outflow, 1=yes, 0=no. Default=0: copy inside value on outflow.\",\n            alias=\"keepSTBndOnOutflow\",\n        )\n        slopedrop2d: Optional[str] = Field(\n            \"Apply droplosses only if local bottom slope &gt; Slopedrop2D, &lt;=0 =no droplosses.\",\n            alias=\"slopeDrop2D\",\n        )\n        drop1d: Optional[str] = Field(\n            \"Limit the downstream water level in the momentum equation to the downstream invert level, BOBdown (\u03b6*down = max(BOBdown, \u03b6down)).\",\n            alias=\"drop1D\",\n        )\n        chkadvd: Optional[str] = Field(\n            \"Check advection terms if depth &lt; chkadvdp.\", alias=\"chkAdvd\"\n        )\n        teta0: Optional[str] = Field(\n            \"Theta (implicitness) of time integration, 0.5 &lt; Theta &lt; 1.0.\",\n            alias=\"teta0\",\n        )\n        qhrelax: Optional[str] = Field(None, alias=\"qhRelax\")\n        cstbnd: Optional[str] = Field(\n            \"Delft3D-FLOW type velocity treatment near boundaries for small coastal models (1) or not (0).\",\n            alias=\"cstBnd\",\n        )\n        maxitverticalforestersal: Optional[str] = Field(\n            \"Forester iterations for salinity (0: no vertical filter for salinity, &gt; 0: max nr of iterations).\",\n            alias=\"maxitVerticalForesterSal\",\n        )\n        maxitverticalforestertem: Optional[str] = Field(\n            \"Forester iterations for temperature (0: no vertical filter for temperature, &gt; 0: max nr of iterations).\",\n            alias=\"maxitVerticalForesterTem\",\n        )\n        turbulencemodel: Optional[str] = Field(\n            \"0=no, 1 = constant, 2 = algebraic, 3 = k-epsilon, 4 = k-tau.\",\n            alias=\"turbulenceModel\",\n        )\n        turbulenceadvection: Optional[str] = Field(\n            \"Turbulence advection (0=no, 3 = horizontal explicit vertical implicit).\",\n            alias=\"turbulenceAdvection\",\n        )\n        anticreep: Optional[str] = Field(\n            \"Include anti-creep calculation (0: no, 1: yes).\", alias=\"antiCreep\"\n        )\n        baroczlaybed: Optional[str] = Field(\n            \"Use fix in baroclinic pressure for zlaybed (1: yes, 0: no)\",\n            alias=\"barocZLayBed\",\n        )\n        barocponbnd: Optional[str] = Field(\n            \"Use baroclinic pressure correction on open boundaries (1: yes, 0: no)\",\n            alias=\"barocPOnBnd\",\n        )\n        maxwaterleveldiff: Optional[str] = Field(\n            \"Upper bound [m] on water level changes, (&lt;= 0: no bounds). Run will abort when violated.\",\n            alias=\"maxWaterLevelDiff\",\n        )\n        maxvelocitydiff: Optional[str] = Field(\n            \"Upper bound [m/s] on velocity changes, (&lt;= 0: no bounds). Run will abort when violated.\",\n            alias=\"maxVelocityDiff\",\n        )\n        mintimestepbreak: Optional[str] = Field(\n            \"Smallest allowed timestep (in s), checked on a sliding average of several timesteps. Run will abort when violated.\",\n            alias=\"minTimestepBreak\",\n        )\n        epshu: Optional[str] = Field(\n            \"Threshold water depth for wetting and drying [m].\", alias=\"epsHu\"\n        )\n        fixedweirrelaxationcoef: Optional[str] = Field(\n            \"Fixed weir relaxation coefficient for computation of energy loss.\",\n            alias=\"fixedWeirRelaxationCoef\",\n        )\n        implicitdiffusion2d: Optional[str] = Field(\n            \"Implicit diffusion in 2D (0: no, 1:yes).\", alias=\"implicitDiffusion2D\"\n        )\n        vertadvtyptem: Optional[str] = Field(\n            \"Vertical advection type for temperature (0: none, 4: Theta implicit, 6: higher order explicit, no Forester filter).\",\n            alias=\"vertAdvTypTem\",\n        )\n        velmagnwarn: Optional[str] = Field(\n            \"Warning level unitbrackets{m/s} on velocity magnitude (&lt;= 0: no check).\",\n            alias=\"velMagnWarn\",\n        )\n        transportautotimestepdiff: Optional[str] = Field(\n            \"Auto Timestepdiff in Transport, (0 : lim diff, no lim Dt, 1: no lim diff, lim Dt, 2: no lim diff, no lim Dt, 3: implicit (only 2D)).\",\n            alias=\"transportAutoTimestepDiff\",\n        )\n        sethorizontalbobsfor1d2d: Optional[str] = Field(\n            \"Bobs are set to 2D bedlevel, to prevent incorrect storage in sewer system (0: no, 1:yes).\",\n            alias=\"setHorizontalBobsFor1D2D\",\n        )\n        diagnostictransport: Optional[str] = Field(\n            \"No update of transport quantities, also known as diagnostic transport (0: no, 1: yes).\",\n            alias=\"diagnosticTransport\",\n        )\n        vertadvtypsal: Optional[str] = Field(\n            \"Vertical advection type for salinity (0: none, 4: Theta implicit, 6: higher order explicit, no Forester filter).\",\n            alias=\"vertAdvTypSal\",\n        )\n        zerozbndinflowadvection: Optional[str] = Field(\n            \"Switch for advection at open boundary (0: Neumann, 1=zero at inflow, 2=zero at inflow and outflow).\",\n            alias=\"zeroZBndInflowAdvection\",\n        )\n        pure1d: Optional[str] = Field(\n            \"Purely 1D advection (0: original advection using velocity vector, 1: pure 1D using flow volume vol1_f, 2: pure 1D using volume vol1)\",\n            alias=\"pure1D\",\n        )\n        testdryingflooding: Optional[str] = Field(\n            \"Drying flooding algorithm (0: D-Flow FM, 1: Delft3DFLOW, 2: Similar to 0, and volume limitation in the transport solver based on Epshu).\",\n            alias=\"testDryingFlooding\",\n        )\n        logsolverconvergence: Optional[str] = Field(\n            \"Print time step, number of solver iterations and solver residual to diagnostic output (0: no, 1: yes).\",\n            alias=\"logSolverConvergence\",\n        )\n        fixedweirscheme1d2d: Optional[str] = Field(\n            \"Fixed weir scheme for 1d2d links (0: same as fixedweirscheme, 1: lateral iterative fixed weir scheme).\",\n            alias=\"fixedWeirScheme1D2D\",\n        )\n        horizontalmomentumfilter: Optional[str] = Field(\n            \"Filter for reduction of checkerboarding; 0=No, 1=yes.\",\n            alias=\"horizontalMomentumFilter\",\n        )\n        maxnonlineariterations: Optional[str] = Field(\n            \"Maximal iterations in non-linear iteration loop before a time step reduction is applied\",\n            alias=\"maxNonLinearIterations\",\n        )\n        maxvelocity: Optional[str] = Field(\n            \"Upper bound [m/s] on velocity (&lt;= 0: no bounds). Run will abort when violated.\",\n            alias=\"maxVelocity\",\n        )\n        waterlevelwarn: Optional[str] = Field(\n            \"Warning level [m AD] on water level (&lt;= 0: no check).\",\n            alias=\"waterLevelWarn\",\n        )\n        tspinupturblogprof: Optional[str] = Field(\n            \"Spin up time [s] when starting with a parabolic viscosity profile in whole model domain.\",\n            alias=\"tSpinUpTurbLogProf\",\n        )\n        fixedweirtopfrictcoef: Optional[Optional[str]] = Field(\n            \"Uniform friction coefficient of the groyne part of fixed weirs [the unit depends on frictiontype].\",\n            alias=\"fixedWeirTopFrictCoef\",\n        )\n        fixedweir1d2d_dx: Optional[str] = Field(\n            \"Extra delta x for lateral 1d2d fixed weirs.\", alias=\"fixedWeir1D2D_dx\"\n        )\n        junction1d: Optional[str] = Field(\n            \"Advection at 1D junctions: (0: original 1D advection using velocity vector, 1 = same as along 1D channels using Pure1D=1).\",\n            alias=\"junction1D\",\n        )\n        fixedweirtopwidth: Optional[str] = Field(\n            \"Uniform width of the groyne part of fixed weirs [m].\",\n            alias=\"fixedWeirTopWidth\",\n        )\n        vertadvtypmom: Optional[str] = Field(\n            \"Vertical advection type in momentum equation; 3: Upwind implicit, 6: centerbased upwind explicit.\",\n            alias=\"vertAdvTypMom\",\n        )\n        checkerboardmonitor: Optional[str] = Field(\n            \"Flag for checkerboarding output on history file (only for sigma layers yet); 0=No, 1=yes.\",\n            alias=\"checkerboardMonitor\",\n        )\n        velocitywarn: Optional[str] = Field(\n            \"Warning level [m/s] on normal velocity(&lt;= 0: no check).\",\n            alias=\"velocityWarn\",\n        )\n        adveccorrection1d2d: Optional[str] = Field(\n            \"Advection correction of 1D2D link volume (0: regular advection, 1: link volume au*dx, 2: advection on 1D2D switched off.)\",\n            alias=\"advecCorrection1D2D\",\n        )\n        fixedweirtalud: Optional[str] = Field(\n            \"Uniform talud slope of fixed weirs.\", alias=\"fixedWeirTalud\"\n        )\n        lateral_fixedweir_umin: Optional[str] = Field(\n            \"Minimal velocity threshold for weir losses in iterative lateral 1d2d weir coupling.\",\n            alias=\"lateral_fixedweir_umin\",\n        )\n        jasfer3d: Optional[str] = Field(\n            \"Corrections for spherical coordinates (0: no, 1: yes).\",\n            alias=\"jasfer3D\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Numerics\"] = \"Numerics\"\n    cflmax: float = Field(0.7, alias=\"CFLMax\")\n    epsmaxlev: float = Field(1e-8, alias=\"EpsMaxlev\")\n    epsmaxlevm: float = Field(1e-8, alias=\"EpsMaxlevM\")\n    advectype: int = Field(33, alias=\"advecType\")\n    timesteptype: int = Field(2, alias=\"timeStepType\")\n    limtyphu: int = Field(0, alias=\"limTypHu\")\n    limtypmom: int = Field(4, alias=\"limTypMom\")\n    limtypsa: int = Field(4, alias=\"limTypSa\")\n    icgsolver: int = Field(4, alias=\"icgSolver\")\n    maxdegree: int = Field(6, alias=\"maxDegree\")\n    fixedweirscheme: int = Field(9, alias=\"fixedWeirScheme\")\n    fixedweircontraction: float = Field(1.0, alias=\"fixedWeirContraction\")\n    izbndpos: int = Field(0, alias=\"izBndPos\")\n    tlfsmo: float = Field(0.0, alias=\"tlfSmo\")\n    keepstbndonoutflow: bool = Field(False, alias=\"keepSTBndOnOutflow\")\n    slopedrop2d: float = Field(0.0, alias=\"slopeDrop2D\")\n    drop1d: bool = Field(False, alias=\"drop1D\")\n    chkadvd: float = Field(0.1, alias=\"chkAdvd\")\n    teta0: float = Field(0.55, alias=\"teta0\")\n    qhrelax: float = Field(0.01, alias=\"qhRelax\")\n    cstbnd: bool = Field(False, alias=\"cstBnd\")\n    maxitverticalforestersal: int = Field(0, alias=\"maxitVerticalForesterSal\")\n    maxitverticalforestertem: int = Field(0, alias=\"maxitVerticalForesterTem\")\n    turbulencemodel: int = Field(3, alias=\"turbulenceModel\")\n    turbulenceadvection: int = Field(3, alias=\"turbulenceAdvection\")\n    anticreep: bool = Field(False, alias=\"antiCreep\")\n    baroczlaybed: bool = Field(False, alias=\"barocZLayBed\")\n    barocponbnd: bool = Field(False, alias=\"barocPOnBnd\")\n    maxwaterleveldiff: float = Field(0.0, alias=\"maxWaterLevelDiff\")\n    maxvelocitydiff: float = Field(0.0, alias=\"maxVelocityDiff\")\n    mintimestepbreak: float = Field(0.0, alias=\"minTimestepBreak\")\n    epshu: float = Field(0.0001, alias=\"epsHu\")\n    fixedweirrelaxationcoef: float = Field(0.6, alias=\"fixedWeirRelaxationCoef\")\n    implicitdiffusion2d: bool = Field(False, alias=\"implicitDiffusion2D\")\n    vertadvtyptem: int = Field(6, alias=\"vertAdvTypTem\")\n    velmagnwarn: float = Field(0.0, alias=\"velMagnWarn\")\n    transportautotimestepdiff: int = Field(0, alias=\"transportAutoTimestepDiff\")\n    sethorizontalbobsfor1d2d: bool = Field(False, alias=\"setHorizontalBobsFor1D2D\")\n    diagnostictransport: bool = Field(False, alias=\"diagnosticTransport\")\n    vertadvtypsal: int = Field(6, alias=\"vertAdvTypSal\")\n    zerozbndinflowadvection: int = Field(0, alias=\"zeroZBndInflowAdvection\")\n    pure1d: int = Field(0, alias=\"pure1D\")\n    testdryingflooding: int = Field(0, alias=\"testDryingFlooding\")\n    logsolverconvergence: bool = Field(False, alias=\"logSolverConvergence\")\n    fixedweirscheme1d2d: int = Field(0, alias=\"fixedWeirScheme1D2D\")\n    horizontalmomentumfilter: bool = Field(False, alias=\"horizontalMomentumFilter\")\n    maxnonlineariterations: int = Field(100, alias=\"maxNonLinearIterations\")\n    maxvelocity: float = Field(0.0, alias=\"maxVelocity\")\n    waterlevelwarn: float = Field(0.0, alias=\"waterLevelWarn\")\n    tspinupturblogprof: float = Field(0.0, alias=\"tSpinUpTurbLogProf\")\n    fixedweirtopfrictcoef: Optional[float] = Field(-999, alias=\"fixedWeirTopFrictCoef\")\n    fixedweir1d2d_dx: float = Field(50.0, alias=\"fixedWeir1D2D_dx\")\n    junction1d: int = Field(0, alias=\"junction1D\")\n    fixedweirtopwidth: float = Field(3.0, alias=\"fixedWeirTopWidth\")\n    vertadvtypmom: int = Field(6, alias=\"vertAdvTypMom\")\n    checkerboardmonitor: bool = Field(False, alias=\"checkerboardMonitor\")\n    velocitywarn: float = Field(0.0, alias=\"velocityWarn\")\n    adveccorrection1d2d: int = Field(0, alias=\"advecCorrection1D2D\")\n    fixedweirtalud: float = Field(4.0, alias=\"fixedWeirTalud\")\n    lateral_fixedweir_umin: float = Field(0.0, alias=\"lateral_fixedweir_umin\")\n    jasfer3d: bool = Field(False, alias=\"jasfer3D\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Output","title":"<code>Output</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Output]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.output</code>.</p> <p>All lowercased attributes match with the [Output] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Output(INIBasedModel):\n    \"\"\"\n    The `[Output]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.output`.\n\n    All lowercased attributes match with the [Output] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        wrishp_crs: Optional[str] = Field(\n            \"Writing cross sections to shape file (0=no, 1=yes).\", alias=\"wrishp_crs\"\n        )\n        wrishp_weir: Optional[str] = Field(\n            \"Writing weirs to shape file (0=no, 1=yes).\", alias=\"wrishp_weir\"\n        )\n        wrishp_gate: Optional[str] = Field(\n            \"Writing gates to shape file (0=no, 1=yes).\", alias=\"wrishp_gate\"\n        )\n        wrishp_fxw: Optional[str] = Field(\n            \"Writing fixed weirs to shape file (0=no, 1=yes).\", alias=\"wrishp_fxw\"\n        )\n        wrishp_thd: Optional[str] = Field(\n            \"Writing thin dams to shape file (0=no, 1=yes).\", alias=\"wrishp_thd\"\n        )\n        wrishp_obs: Optional[str] = Field(\n            \"Writing observation points to shape file (0=no, 1=yes).\",\n            alias=\"wrishp_obs\",\n        )\n        wrishp_emb: Optional[str] = Field(\n            \"Writing embankments file (0=no, 1=yes).\", alias=\"wrishp_emb\"\n        )\n        wrishp_dryarea: Optional[str] = Field(\n            \"Writing dry areas to shape file (0=no, 1=yes).\", alias=\"wrishp_dryArea\"\n        )\n        wrishp_enc: Optional[str] = Field(\n            \"Writing enclosures to shape file (0=no, 1=yes).\", alias=\"wrishp_enc\"\n        )\n        wrishp_src: Optional[str] = Field(\n            \"Writing sources and sinks to shape file (0=no, 1=yes).\", alias=\"wrishp_src\"\n        )\n        wrishp_pump: Optional[str] = Field(\n            \"Writing pumps to shape file (0=no, 1=yes).\", alias=\"wrishp_pump\"\n        )\n        outputdir: Optional[str] = Field(\n            \"Output directory of map-, his-, rst-, dat- and timingsfiles, default: DFM_OUTPUT_&lt;modelname&gt;. Set to . for no dir/current dir.\",\n            alias=\"outputDir\",\n        )\n        waqoutputdir: Optional[str] = Field(\n            \"Output directory of Water Quality files.\", alias=\"waqOutputDir\"\n        )\n        flowgeomfile: Optional[str] = Field(\n            \"*_flowgeom.nc Flow geometry file in netCDF format.\", alias=\"flowGeomFile\"\n        )\n        obsfile: Optional[str] = Field(\n            \"Space separated list of files, containing information about observation points.\",\n            alias=\"obsFile\",\n        )\n        crsfile: Optional[str] = Field(\n            \"Space separated list of files, containing information about observation cross sections.\",\n            alias=\"crsFile\",\n        )\n        foufile: Optional[str] = Field(\n            \"Fourier analysis input file *.fou\", alias=\"fouFile\"\n        )\n        fouupdatestep: Optional[str] = Field(\n            \"Fourier update step type: 0=every user time step, 1=every computational timestep, 2=same as history output.\",\n            alias=\"fouUpdateStep\",\n        )\n        hisfile: Optional[str] = Field(\n            \"*_his.nc History file in netCDF format.\", alias=\"hisFile\"\n        )\n        hisinterval: Optional[str] = Field(\n            \"History output, given as 'interval' 'start period' 'end period' [s].\",\n            alias=\"hisInterval\",\n        )\n        xlsinterval: Optional[str] = Field(\n            \"Interval between XLS history [s].\", alias=\"xlsInterval\"\n        )\n        mapfile: Optional[str] = Field(\n            \"*_map.nc Map file in netCDF format.\", alias=\"mapFile\"\n        )\n        mapinterval: Optional[str] = Field(\n            \"Map file output, given as 'interval' 'start period' 'end period' [s].\",\n            alias=\"mapInterval\",\n        )\n        rstinterval: Optional[str] = Field(\n            \"Restart file output, given as 'interval' 'start period' 'end period' [s].\",\n            alias=\"rstInterval\",\n        )\n        mapformat: Optional[str] = Field(\n            \"Map file format, 1: netCDF, 2: Tecplot, 3: NetCFD and Tecplot, 4: netCDF UGRID.\",\n            alias=\"mapFormat\",\n        )\n        ncformat: Optional[str] = Field(\n            \"Format for all NetCDF output files (3: classic, 4: NetCDF4+HDF5).\",\n            alias=\"ncFormat\",\n        )\n        ncnounlimited: Optional[str] = Field(\n            \"Write full-length time-dimension instead of unlimited dimension (1: yes, 0: no). (Might require NcFormat=4.)\",\n            alias=\"ncNoUnlimited\",\n        )\n        ncnoforcedflush: Optional[str] = Field(\n            \"Do not force flushing of map-like files every output timestep (1: yes, 0: no).\",\n            alias=\"ncNoForcedFlush\",\n        )\n        ncwritelatlon: Optional[str] = Field(\n            \"Write extra lat-lon coordinates for all projected coordinate variables in each NetCDF file (for CF-compliancy) (1: yes, 0: no).\",\n            alias=\"ncWriteLatLon\",\n        )\n        wrihis_balance: Optional[str] = Field(\n            \"Write mass balance totals to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_balance\",\n        )\n        wrihis_sourcesink: Optional[str] = Field(\n            \"Write sources-sinks statistics to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_sourceSink\",\n        )\n        wrihis_structure_gen: Optional[str] = Field(\n            \"Write general structure parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_gen\",\n        )\n        wrihis_structure_dam: Optional[str] = Field(\n            \"Write dam parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_dam\",\n        )\n        wrihis_structure_pump: Optional[str] = Field(\n            \"Write pump parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_pump\",\n        )\n        wrihis_structure_gate: Optional[str] = Field(\n            \"Write gate parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_gate\",\n        )\n        wrihis_structure_weir: Optional[str] = Field(\n            \"Write weir parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_weir\",\n        )\n        wrihis_structure_orifice: Optional[str] = Field(\n            \"Write orifice parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_orifice\",\n        )\n        wrihis_structure_bridge: Optional[str] = Field(\n            \"Write bridge parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_bridge\",\n        )\n        wrihis_structure_culvert: Optional[str] = Field(\n            \"Write culvert parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_culvert\",\n        )\n        wrihis_structure_longculvert: Optional[str] = Field(\n            \"Write long culvert parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_longCulvert\",\n        )\n        wrihis_structure_dambreak: Optional[str] = Field(\n            \"Write dam break parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_damBreak\",\n        )\n        wrihis_structure_uniweir: Optional[str] = Field(\n            \"Write universal weir parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_uniWeir\",\n        )\n        wrihis_structure_compound: Optional[str] = Field(\n            \"Write compound structure parameters to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_structure_compound\",\n        )\n        wrihis_turbulence: Optional[str] = Field(\n            \"Write k, eps and vicww to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_turbulence\",\n        )\n        wrihis_wind: Optional[str] = Field(\n            \"Write wind velocities to his file (1: yes, 0: no)'\", alias=\"wrihis_wind\"\n        )\n        wrihis_airdensity: Optional[str] = Field(\n            \"Write air density to his file (1: yes, 0: no)\", alias=\"wrihis_airdensity\"\n        )\n        wrihis_rain: Optional[str] = Field(\n            \"Write precipitation to his file (1: yes, 0: no)'\", alias=\"wrihis_rain\"\n        )\n        wrihis_infiltration: Optional[str] = Field(\n            \"Write infiltration to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_infiltration\",\n        )\n        wrihis_temperature: Optional[str] = Field(\n            \"Write temperature to his file (1: yes, 0: no)'\", alias=\"wrihis_temperature\"\n        )\n        wrihis_waves: Optional[str] = Field(\n            \"Write wave data to his file (1: yes, 0: no)'\", alias=\"wrihis_waves\"\n        )\n        wrihis_heat_fluxes: Optional[str] = Field(\n            \"Write heat fluxes to his file (1: yes, 0: no)'\", alias=\"wrihis_heat_fluxes\"\n        )\n        wrihis_salinity: Optional[str] = Field(\n            \"Write salinity to his file (1: yes, 0: no)'\", alias=\"wrihis_salinity\"\n        )\n        wrihis_density: Optional[str] = Field(\n            \"Write density to his file (1: yes, 0: no)'\", alias=\"wrihis_density\"\n        )\n        wrihis_waterlevel_s1: Optional[str] = Field(\n            \"Write water level to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_waterlevel_s1\",\n        )\n        wrihis_bedlevel: Optional[str] = Field(\n            \"Write bed level to his file (1: yes, 0: no)'\", alias=\"wrihis_bedlevel\"\n        )\n        wrihis_waterdepth: Optional[str] = Field(\n            \"Write water depth to his file (1: yes, 0: no)'\", alias=\"wrihis_waterdepth\"\n        )\n        wrihis_velocity_vector: Optional[str] = Field(\n            \"Write velocity vectors to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_velocity_vector\",\n        )\n        wrihis_upward_velocity_component: Optional[str] = Field(\n            \"Write upward velocity to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_upward_velocity_component\",\n        )\n        wrihis_velocity: Optional[str] = Field(\n            \"Write velocity magnitude in observation point to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_velocity\",\n        )\n        wrihis_discharge: Optional[str] = Field(\n            \"Write discharge magnitude in observation point to his file, (1: yes, 0: no).\",\n            alias=\"wrihis_discharge\",\n        )\n        wrihis_sediment: Optional[str] = Field(\n            \"Write sediment transport to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_sediment\",\n        )\n        wrihis_constituents: Optional[str] = Field(\n            \"Write tracers to his file (1: yes, 0: no)'\", alias=\"wrihis_constituents\"\n        )\n        wrihis_zcor: Optional[str] = Field(\n            \"Write vertical coordinates to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_zcor\",\n        )\n        wrihis_lateral: Optional[str] = Field(\n            \"Write lateral data to his file, (1: yes, 0: no).\", alias=\"wrihis_lateral\"\n        )\n        wrihis_taucurrent: Optional[str] = Field(\n            \"Write mean bed shear stress to his file (1: yes, 0: no)'\",\n            alias=\"wrihis_taucurrent\",\n        )\n        wrimap_waterlevel_s0: Optional[str] = Field(\n            \"Write water levels at old time level to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_waterLevel_s0\",\n        )\n        wrimap_waterlevel_s1: Optional[str] = Field(\n            \"Write water levels at new time level to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_waterLevel_s1\",\n        )\n        wrimap_evaporation: Optional[str] = Field(\n            \"Write evaporation to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_evaporation\",\n        )\n        wrimap_waterdepth: Optional[str] = Field(\n            \"Write water depths to map file (1: yes, 0: no).\",\n            alias=\"wrimap_waterdepth\",\n        )\n        wrimap_velocity_component_u0: Optional[str] = Field(\n            \"Write velocities at old time level to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_velocity_component_u0\",\n        )\n        wrimap_velocity_component_u1: Optional[str] = Field(\n            \"Write velocities at new time level to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_velocity_component_u1\",\n        )\n        wrimap_velocity_vector: Optional[str] = Field(\n            \"Write cell-center velocity vectors to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_velocity_vector\",\n        )\n        wrimap_velocity_magnitude: Optional[str] = Field(\n            \"Write cell-center velocity vector magnitude to map file (1: yes, 0: no).\",\n            alias=\"wrimap_velocity_magnitude\",\n        )\n        wrimap_upward_velocity_component: Optional[str] = Field(\n            \"Write upward velocity component to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_upward_velocity_component\",\n        )\n        wrimap_density_rho: Optional[str] = Field(\n            \"Write density to map file, (1: yes, 0: no).\", alias=\"wrimap_density_rho\"\n        )\n        wrimap_horizontal_viscosity_viu: Optional[str] = Field(\n            \"Write horizontal viscosity to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_horizontal_viscosity_viu\",\n        )\n        wrimap_horizontal_diffusivity_diu: Optional[str] = Field(\n            \"Write horizontal diffusivity to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_horizontal_diffusivity_diu\",\n        )\n        wrimap_flow_flux_q1: Optional[str] = Field(\n            \"Write fluxes to map file, (1: yes, 0: no).\", alias=\"wrimap_flow_flux_q1\"\n        )\n        wrimap_spiral_flow: Optional[str] = Field(\n            \"Write spiral flow to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_spiral_flow\",\n        )\n        wrimap_numlimdt: Optional[str] = Field(\n            \"Write numlimdt to map file, (1: yes, 0: no).\", alias=\"wrimap_numLimdt\"\n        )\n        wrimap_taucurrent: Optional[str] = Field(\n            \"Write bottom friction to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_tauCurrent\",\n        )\n        wrimap_chezy: Optional[str] = Field(\n            \"Write chezy values to map file, (1: yes, 0: no).\", alias=\"wrimap_chezy\"\n        )\n        wrimap_turbulence: Optional[str] = Field(\n            \"Write turbulence to map file, (1: yes, 0: no).\", alias=\"wrimap_turbulence\"\n        )\n        wrimap_rain: Optional[str] = Field(\n            \"Write rainfall rate to map file, (1: yes, 0: no).\", alias=\"wrimap_rain\"\n        )\n        wrimap_wind: Optional[str] = Field(\n            \"Write winds to map file, (1: yes, 0: no).\", alias=\"wrimap_wind\"\n        )\n        wrimap_windstress: Optional[str] = Field(\n            \"Write wind stress to map file (1: yes, 0: no)\", alias=\"wrimap_windstress\"\n        )\n        wrimap_airdensity: Optional[str] = Field(\n            \"Write air density rates to map file (1: yes, 0: no)\",\n            alias=\"wrimap_airdensity\",\n        )\n        wrimap_calibration: Optional[str] = Field(\n            \"Write roughness calibration factors to map file.\",\n            alias=\"wrimap_calibration\",\n        )\n        wrimap_salinity: Optional[str] = Field(\n            \"Write salinity to map file.\", alias=\"wrimap_salinity\"\n        )\n        wrimap_temperature: Optional[str] = Field(\n            \"Write temperature to map file.\", alias=\"wrimap_temperature\"\n        )\n        writek_cdwind: Optional[str] = Field(\n            \"Write wind friction coefficients to tek file (1: yes, 0: no).\",\n            alias=\"writek_CdWind\",\n        )\n        wrimap_heat_fluxes: Optional[str] = Field(\n            \"Write heat fluxes to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_heat_fluxes\",\n        )\n        wrimap_wet_waterdepth_threshold: Optional[str] = Field(\n            \"Waterdepth threshold above which a grid point counts as 'wet'. Defaults to 0.2\u00b7Epshu. It is used for Wrimap_time_water_on_ground, Wrimap_waterdepth_on_ground and Wrimap_volume_on_ground.\",\n            alias=\"wrimap_wet_waterDepth_threshold\",\n        )\n        wrimap_time_water_on_ground: Optional[str] = Field(\n            \"Write cumulative time when water is above ground level (only for 1D nodes) to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_time_water_on_ground\",\n        )\n        wrimap_freeboard: Optional[str] = Field(\n            \"Write freeboard (only for 1D nodes) to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_freeboard\",\n        )\n        wrimap_waterdepth_on_ground: Optional[str] = Field(\n            \"Write waterdepth that is above ground level to map file (only for 1D nodes) (1: yes, 0: no).\",\n            alias=\"wrimap_waterDepth_on_ground\",\n        )\n        wrimap_volume_on_ground: Optional[str] = Field(\n            \"Write volume that is above ground level to map file (only for 1D nodes) (1: yes, 0: no).\",\n            alias=\"wrimap_volume_on_ground\",\n        )\n        wrimap_total_net_inflow_1d2d: Optional[str] = Field(\n            \"Write current total 1D2D net inflow (discharge) and cumulative total 1D2D net inflow (volume) to map file (only for 1D nodes) (1:yes, 0:no).\",\n            alias=\"wrimap_total_net_inflow_1d2d\",\n        )\n        wrimap_total_net_inflow_lateral: Optional[str] = Field(\n            \"Write current total lateral net inflow (discharge) and cumulative total lateral net inflow (volume) to map file (only for 1D nodes) (1:yes, 0:no).\",\n            alias=\"wrimap_total_net_inflow_lateral\",\n        )\n        wrimap_water_level_gradient: Optional[str] = Field(\n            \"Write water level gradient to map file (only for 1D links) (1:yes, 0:no).\",\n            alias=\"wrimap_water_level_gradient\",\n        )\n        wrimap_tidal_potential: Optional[str] = Field(\n            \"Write tidal potential to map file (1: yes, 0: no)\",\n            alias=\"wrimap_tidal_potential\",\n        )\n        wrimap_sal_potential: Optional[str] = Field(\n            \"Write self attraction and loading potential to map file (1: yes, 0: no)\",\n            alias=\"wrimap_SAL_potential\",\n        )\n        wrimap_internal_tides_dissipation: Optional[str] = Field(\n            \"Write internal tides dissipation to map file (1: yes, 0: no)\",\n            alias=\"wrimap_internal_tides_dissipation\",\n        )\n        wrimap_flow_analysis: Optional[str] = Field(\n            \"Write flow analysis data to the map file (1:yes, 0:no).\",\n            alias=\"wrimap_flow_analysis\",\n        )\n        mapoutputtimevector: Optional[str] = Field(\n            \"File (.mpt) containing fixed map output times (s) w.r.t. RefDate.\",\n            alias=\"mapOutputTimeVector\",\n        )\n        fullgridoutput: Optional[str] = Field(\n            \"Full grid output mode for layer positions (0: compact, 1: full time-varying grid layer data).\",\n            alias=\"fullGridOutput\",\n        )\n        eulervelocities: Optional[str] = Field(\n            \"Write Eulerian velocities, (1: yes, 0: no).\", alias=\"eulerVelocities\"\n        )\n        classmapfile: Optional[str] = Field(\n            \"Name of class map file.\", alias=\"classMapFile\"\n        )\n        waterlevelclasses: Optional[str] = Field(\n            \"Series of values between which water level classes are computed.\",\n            alias=\"waterLevelClasses\",\n        )\n        waterdepthclasses: Optional[str] = Field(\n            \"Series of values between which water depth classes are computed.\",\n            alias=\"waterDepthClasses\",\n        )\n        classmapinterval: Optional[str] = Field(\n            \"Interval [s] between class map file outputs.\", alias=\"classMapInterval\"\n        )\n        waqinterval: Optional[str] = Field(\n            \"Interval [s] between DELWAQ file outputs.\", alias=\"waqInterval\"\n        )\n        statsinterval: Optional[str] = Field(\n            \"Interval [s] between screen step outputs in seconds simulation time, if negative in seconds wall clock time.\",\n            alias=\"statsInterval\",\n        )\n        timingsinterval: Optional[str] = Field(\n            \"Timings output interval TimingsInterval.\", alias=\"timingsInterval\"\n        )\n        richardsononoutput: Optional[str] = Field(\n            \"Write Richardson number, (1: yes, 0: no).\", alias=\"richardsonOnOutput\"\n        )\n        wrimap_every_dt: Optional[str] = Field(\n            \"Write output to map file every computational timestep, between start and stop time from MapInterval, (1: yes, 0: no).\",\n            alias=\"wrimap_every_dt\",\n        )\n        wrimap_input_roughness: Optional[str] = Field(\n            \"Write chezy input roughness on flow links to map file, (1: yes, 0: no).\",\n            alias=\"wrimap_input_roughness\",\n        )\n        wrimap_flowarea_au: Optional[str] = Field(\n            \"Write flow areas au to map file (1: yes, 0: no).\",\n            alias=\"wrimap_flowarea_au\",\n        )\n        wrihis_airdensity: Optional[str] = Field(\n            \"Write air density to his file (1: yes, 0: no).\", alias=\"wrihis_airdensity\"\n        )\n        wrimap_flow_flux_q1_main: Optional[str] = Field(\n            \"Write flow flux in main channel to map file (1: yes, 0: no).\",\n            alias=\"wrimap_flow_flux_q1_main\",\n        )\n        wrimap_windstress: Optional[str] = Field(\n            \"Write wind stress to map file (1: yes, 0: no).\", alias=\"wrimap_windstress\"\n        )\n        wrishp_genstruc: Optional[str] = Field(\n            \"Writing general structures to shape file (0=no, 1=yes).\",\n            alias=\"wrishp_genstruc\",\n        )\n        wrimap_qin: Optional[str] = Field(\n            \"Write sum of all influxes to map file (1: yes, 0: no).\", alias=\"wrimap_qin\"\n        )\n        wrimap_dtcell: Optional[str] = Field(\n            \"Write time step per cell based on CFL (1: yes, 0: no).\",\n            alias=\"wrimap_dtcell\",\n        )\n        wrimap_velocity_vectorq: Optional[str] = Field(\n            \"Write cell-center velocity vectors (discharge-based) to map file (1: yes, 0: no).\",\n            alias=\"wrimap_velocity_vectorq\",\n        )\n        wrimap_bnd: Optional[str] = Field(\n            \"Write boundary points to map file (1: yes, 0: no).\", alias=\"wrimap_bnd\"\n        )\n        wrishp_dambreak: Optional[str] = Field(\n            \"Writing dambreaks to shape file (0=no, 1=yes).\", alias=\"wrishp_dambreak\"\n        )\n        wrimap_waterdepth_hu: Optional[str] = Field(\n            \"Write water depths on u-points to map file (1: yes, 0: no).\",\n            alias=\"wrimap_waterdepth_hu\",\n        )\n        ncmapdataprecision: Optional[str] = Field(\n            \"Precision for NetCDF data in map files (double or single).\",\n            alias=\"ncMapDataPrecision\",\n        )\n        nchisdataprecision: Optional[str] = Field(\n            \"Precision for NetCDF data in his files (double or single).\",\n            alias=\"ncHisDataPrecision\",\n        )\n        wrimap_interception: Optional[str] = Field(\n            \"Write interception to map file (1: yes, 0: no).\",\n            alias=\"wrimap_interception\",\n        )\n        wrimap_airdensity: Optional[str] = Field(\n            \"Write air density to map file, (1:yes, 0:no).\", alias=\"wrimap_airdensity\"\n        )\n        wrimap_volume1: Optional[str] = Field(\n            \"Write volumes to map file (1: yes, 0: no).\", alias=\"wrimap_volume1\"\n        )\n        wrimap_ancillary_variables: Optional[str] = Field(\n            \"Write ancillary variables attributes to map file (1: yes, 0: no).\",\n            alias=\"wrimap_ancillary_variables\",\n        )\n        wrimap_chezy_on_flow_links: Optional[str] = Field(\n            \"Write chezy roughness on flow links to map file, (1: yes, 0: no)\",\n            alias=\"wrimap_chezy_on_flow_links\",\n        )\n        writepart_domain: Optional[str] = Field(\n            \"Write partition domain info. for postprocessing (0: no, 1: yes).\",\n            alias=\"writepart_domain\",\n        )\n        velocitydirectionclassesinterval: Optional[str] = Field(\n            \"Class map's step size of class values for velocity direction.\",\n            alias=\"VelocityDirectionClassesInterval\",\n        )\n        velocitymagnitudeclasses: Optional[str] = Field(\n            \"Class map's list of class values for velocity magnitudes.\",\n            alias=\"VelocityMagnitudeClasses\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Output\"] = \"Output\"\n    wrishp_crs: bool = Field(False, alias=\"wrishp_crs\")\n    wrishp_weir: bool = Field(False, alias=\"wrishp_weir\")\n    wrishp_gate: bool = Field(False, alias=\"wrishp_gate\")\n    wrishp_fxw: bool = Field(False, alias=\"wrishp_fxw\")\n    wrishp_thd: bool = Field(False, alias=\"wrishp_thd\")\n    wrishp_obs: bool = Field(False, alias=\"wrishp_obs\")\n    wrishp_emb: bool = Field(False, alias=\"wrishp_emb\")\n    wrishp_dryarea: bool = Field(False, alias=\"wrishp_dryArea\")\n    wrishp_enc: bool = Field(False, alias=\"wrishp_enc\")\n    wrishp_src: bool = Field(False, alias=\"wrishp_src\")\n    wrishp_pump: bool = Field(False, alias=\"wrishp_pump\")\n    outputdir: Optional[Path] = Field(\"\", alias=\"outputDir\")\n    waqoutputdir: Optional[Path] = Field(\"\", alias=\"waqOutputDir\")\n    flowgeomfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"flowGeomFile\"\n    )\n    obsfile: Optional[List[ObsFile]] = Field(None, alias=\"obsFile\")\n    crsfile: Optional[List[ObsCrsFile]] = Field(None, alias=\"crsFile\")\n    foufile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"fouFile\"\n    )\n    fouupdatestep: int = Field(0, alias=\"fouUpdateStep\")\n    hisfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"hisFile\"\n    )\n    hisinterval: List[float] = Field([300.0], alias=\"hisInterval\")\n    xlsinterval: List[float] = Field([0.0], alias=\"xlsInterval\")\n    mapfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"mapFile\"\n    )\n    mapinterval: List[float] = Field([1200.0], alias=\"mapInterval\")\n    rstinterval: List[float] = Field([0.0], alias=\"rstInterval\")\n    mapformat: int = Field(4, alias=\"mapFormat\")\n    ncformat: int = Field(3, alias=\"ncFormat\")\n    ncnounlimited: bool = Field(False, alias=\"ncNoUnlimited\")\n    ncnoforcedflush: bool = Field(False, alias=\"ncNoForcedFlush\")\n    ncwritelatlon: bool = Field(False, alias=\"ncWriteLatLon\")\n\n    # his file\n    wrihis_balance: bool = Field(True, alias=\"wrihis_balance\")\n    wrihis_sourcesink: bool = Field(True, alias=\"wrihis_sourceSink\")\n    wrihis_structure_gen: bool = Field(True, alias=\"wrihis_structure_gen\")\n    wrihis_structure_dam: bool = Field(True, alias=\"wrihis_structure_dam\")\n    wrihis_structure_pump: bool = Field(True, alias=\"wrihis_structure_pump\")\n    wrihis_structure_gate: bool = Field(True, alias=\"wrihis_structure_gate\")\n    wrihis_structure_weir: bool = Field(True, alias=\"wrihis_structure_weir\")\n    wrihis_structure_orifice: bool = Field(True, alias=\"wrihis_structure_orifice\")\n    wrihis_structure_bridge: bool = Field(True, alias=\"wrihis_structure_bridge\")\n    wrihis_structure_culvert: bool = Field(True, alias=\"wrihis_structure_culvert\")\n    wrihis_structure_longculvert: bool = Field(\n        True, alias=\"wrihis_structure_longCulvert\"\n    )\n    wrihis_structure_dambreak: bool = Field(True, alias=\"wrihis_structure_damBreak\")\n    wrihis_structure_uniweir: bool = Field(True, alias=\"wrihis_structure_uniWeir\")\n    wrihis_structure_compound: bool = Field(True, alias=\"wrihis_structure_compound\")\n    wrihis_turbulence: bool = Field(True, alias=\"wrihis_turbulence\")\n    wrihis_wind: bool = Field(True, alias=\"wrihis_wind\")\n    wrihis_airdensity: bool = Field(False, alias=\"wrihis_airdensity\")\n    wrihis_rain: bool = Field(True, alias=\"wrihis_rain\")\n    wrihis_infiltration: bool = Field(True, alias=\"wrihis_infiltration\")\n    wrihis_temperature: bool = Field(True, alias=\"wrihis_temperature\")\n    wrihis_waves: bool = Field(True, alias=\"wrihis_waves\")\n    wrihis_heat_fluxes: bool = Field(True, alias=\"wrihis_heat_fluxes\")\n    wrihis_salinity: bool = Field(True, alias=\"wrihis_salinity\")\n    wrihis_density: bool = Field(True, alias=\"wrihis_density\")\n    wrihis_waterlevel_s1: bool = Field(True, alias=\"wrihis_waterlevel_s1\")\n    wrihis_bedlevel: bool = Field(True, alias=\"wrihis_bedlevel\")\n    wrihis_waterdepth: bool = Field(False, alias=\"wrihis_waterdepth\")\n    wrihis_velocity_vector: bool = Field(True, alias=\"wrihis_velocity_vector\")\n    wrihis_upward_velocity_component: bool = Field(\n        False, alias=\"wrihis_upward_velocity_component\"\n    )\n    wrihis_velocity: bool = Field(False, alias=\"wrihis_velocity\")\n    wrihis_discharge: bool = Field(False, alias=\"wrihis_discharge\")\n    wrihis_sediment: bool = Field(True, alias=\"wrihis_sediment\")\n    wrihis_constituents: bool = Field(True, alias=\"wrihis_constituents\")\n    wrihis_zcor: bool = Field(True, alias=\"wrihis_zcor\")\n    wrihis_lateral: bool = Field(True, alias=\"wrihis_lateral\")\n    wrihis_taucurrent: bool = Field(True, alias=\"wrihis_taucurrent\")\n\n    # Map file\n    wrimap_waterlevel_s0: bool = Field(True, alias=\"wrimap_waterLevel_s0\")\n    wrimap_waterlevel_s1: bool = Field(True, alias=\"wrimap_waterLevel_s1\")\n    wrimap_evaporation: bool = Field(False, alias=\"wrimap_evaporation\")\n    wrimap_waterdepth: bool = Field(True, alias=\"wrimap_waterdepth\")\n    wrimap_velocity_component_u0: bool = Field(\n        True, alias=\"wrimap_velocity_component_u0\"\n    )\n    wrimap_velocity_component_u1: bool = Field(\n        True, alias=\"wrimap_velocity_component_u1\"\n    )\n    wrimap_velocity_vector: bool = Field(True, alias=\"wrimap_velocity_vector\")\n    wrimap_velocity_magnitude: bool = Field(True, alias=\"wrimap_velocity_magnitude\")\n    wrimap_upward_velocity_component: bool = Field(\n        False, alias=\"wrimap_upward_velocity_component\"\n    )\n    wrimap_density_rho: bool = Field(True, alias=\"wrimap_density_rho\")\n    wrimap_horizontal_viscosity_viu: bool = Field(\n        True, alias=\"wrimap_horizontal_viscosity_viu\"\n    )\n    wrimap_horizontal_diffusivity_diu: bool = Field(\n        True, alias=\"wrimap_horizontal_diffusivity_diu\"\n    )\n    wrimap_flow_flux_q1: bool = Field(True, alias=\"wrimap_flow_flux_q1\")\n    wrimap_spiral_flow: bool = Field(True, alias=\"wrimap_spiral_flow\")\n    wrimap_numlimdt: bool = Field(True, alias=\"wrimap_numLimdt\")\n    wrimap_taucurrent: bool = Field(True, alias=\"wrimap_tauCurrent\")\n    wrimap_chezy: bool = Field(True, alias=\"wrimap_chezy\")\n    wrimap_turbulence: bool = Field(True, alias=\"wrimap_turbulence\")\n    wrimap_rain: bool = Field(False, alias=\"wrimap_rain\")\n    wrimap_wind: bool = Field(True, alias=\"wrimap_wind\")\n    wrimap_windstress: bool = Field(False, alias=\"wrimap_windstress\")\n    wrimap_airdensity: bool = Field(False, alias=\"wrimap_airdensity\")\n    wrimap_calibration: bool = Field(True, alias=\"wrimap_calibration\")\n    wrimap_salinity: bool = Field(True, alias=\"wrimap_salinity\")\n    wrimap_temperature: bool = Field(True, alias=\"wrimap_temperature\")\n    writek_cdwind: bool = Field(False, alias=\"writek_CdWind\")\n    wrimap_heat_fluxes: bool = Field(False, alias=\"wrimap_heat_fluxes\")\n    wrimap_wet_waterdepth_threshold: float = Field(\n        2e-5, alias=\"wrimap_wet_waterDepth_threshold\"\n    )\n    wrimap_time_water_on_ground: bool = Field(\n        False, alias=\"wrimap_time_water_on_ground\"\n    )\n    wrimap_freeboard: bool = Field(False, alias=\"wrimap_freeboard\")\n    wrimap_waterdepth_on_ground: bool = Field(\n        False, alias=\"wrimap_waterDepth_on_ground\"\n    )\n    wrimap_volume_on_ground: bool = Field(False, alias=\"wrimap_volume_on_ground\")\n    wrimap_total_net_inflow_1d2d: bool = Field(\n        False, alias=\"wrimap_total_net_inflow_1d2d\"\n    )\n    wrimap_total_net_inflow_lateral: bool = Field(\n        False, alias=\"wrimap_total_net_inflow_lateral\"\n    )\n    wrimap_water_level_gradient: bool = Field(\n        False, alias=\"wrimap_water_level_gradient\"\n    )\n    wrimap_tidal_potential: bool = Field(True, alias=\"wrimap_tidal_potential\")\n    wrimap_sal_potential: bool = Field(True, alias=\"wrimap_SAL_potential\")\n    wrimap_internal_tides_dissipation: bool = Field(\n        True, alias=\"wrimap_internal_tides_dissipation\"\n    )\n    wrimap_flow_analysis: bool = Field(False, alias=\"wrimap_flow_analysis\")\n    mapoutputtimevector: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"mapOutputTimeVector\"\n    )\n    fullgridoutput: bool = Field(False, alias=\"fullGridOutput\")\n    eulervelocities: bool = Field(False, alias=\"eulerVelocities\")\n    classmapfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"classMapFile\"\n    )\n    waterlevelclasses: List[float] = Field([0.0], alias=\"waterLevelClasses\")\n    waterdepthclasses: List[float] = Field([0.0], alias=\"waterDepthClasses\")\n    classmapinterval: List[float] = Field([0.0], alias=\"classMapInterval\")\n    waqinterval: List[float] = Field([0.0], alias=\"waqInterval\")\n    statsinterval: List[float] = Field([-60.0], alias=\"statsInterval\")\n    timingsinterval: List[float] = Field([0.0], alias=\"timingsInterval\")\n    richardsononoutput: bool = Field(False, alias=\"richardsonOnOutput\")\n    wrimap_every_dt: bool = Field(False, alias=\"wrimap_every_dt\")\n    wrimap_input_roughness: bool = Field(False, alias=\"wrimap_input_roughness\")\n    wrimap_flowarea_au: bool = Field(False, alias=\"wrimap_flowarea_au\")\n    wrihis_airdensity: bool = Field(False, alias=\"wrihis_airdensity\")\n    wrimap_flow_flux_q1_main: bool = Field(False, alias=\"wrimap_flow_flux_q1_main\")\n    wrimap_windstress: bool = Field(False, alias=\"wrimap_windstress\")\n    wrishp_genstruc: bool = Field(False, alias=\"wrishp_genstruc\")\n    wrimap_qin: bool = Field(False, alias=\"wrimap_qin\")\n    wrimap_dtcell: bool = Field(False, alias=\"wrimap_dtcell\")\n    wrimap_velocity_vectorq: bool = Field(False, alias=\"wrimap_velocity_vectorq\")\n    wrimap_bnd: bool = Field(False, alias=\"wrimap_bnd\")\n    wrishp_dambreak: bool = Field(False, alias=\"wrishp_dambreak\")\n    wrimap_waterdepth_hu: bool = Field(False, alias=\"wrimap_waterdepth_hu\")\n    ncmapdataprecision: Literal[\"single\", \"double\"] = Field(\n        \"double\", alias=\"ncMapDataPrecision\"\n    )\n    nchisdataprecision: Literal[\"single\", \"double\"] = Field(\n        \"double\", alias=\"ncHisDataPrecision\"\n    )\n    wrimap_interception: bool = Field(False, alias=\"wrimap_interception\")\n    wrimap_airdensity: bool = Field(False, alias=\"wrimap_airdensity\")\n    wrimap_volume1: bool = Field(False, alias=\"wrimap_volume1\")\n    wrimap_ancillary_variables: bool = Field(False, alias=\"wrimap_ancillary_variables\")\n    wrimap_chezy_on_flow_links: bool = Field(False, alias=\"wrimap_chezy_on_flow_links\")\n    writepart_domain: bool = Field(True, alias=\"writepart_domain\")\n    velocitydirectionclassesinterval: float = Field(\n        0.0, alias=\"VelocityDirectionClassesInterval\"\n    )\n    velocitymagnitudeclasses: List[float] = Field(\n        [0.0], alias=\"VelocityMagnitudeClasses\"\n    )\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"waterlevelclasses\",\n        \"waterdepthclasses\",\n        \"crsfile\",\n        \"obsfile\",\n        \"hisinterval\",\n        \"xlsinterval\",\n        \"mapinterval\",\n        \"rstinterval\",\n        \"classmapinterval\",\n        \"waqinterval\",\n        \"statsinterval\",\n        \"timingsinterval\",\n        \"velocitymagnitudeclasses\",\n    )\n\n    def is_intermediate_link(self) -&gt; bool:\n        return True\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Particles","title":"<code>Particles</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Particles]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.particles</code>.</p> <p>All lowercased attributes match with the [Particles] input as described in UM Sec.A.3.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Particles(INIBasedModel):\n    \"\"\"\n    The `[Particles]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.particles`.\n\n    All lowercased attributes match with the [Particles] input as described in\n    [UM Sec.A.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        particlesfile: Optional[str] = Field(\n            \"Initial particle locations file (*.xyz).\", alias=\"ParticlesFile\"\n        )\n        particlesreleasefile: Optional[str] = Field(\n            \"Particles release file (*.tim, 4 column).\", alias=\"ParticlesReleaseFile\"\n        )\n        addtracer: Optional[str] = Field(\n            \"Add tracer or not (0: no, 1: yes).\", alias=\"AddTracer\"\n        )\n        starttime: Optional[str] = Field(\"Start time (if &gt; 0) [s]\", alias=\"StartTime\")\n        timestep: Optional[str] = Field(\n            \"Time step (if &gt; 0) or every computational time step [s].\", alias=\"TimeStep\"\n        )\n        threedtype: Optional[str] = Field(\n            \"3D velocity type (0: depth averaged velocities, 1: free surface/top layer velocities).\",\n            alias=\"3Dtype\",\n        )\n\n    comments: Comments = Comments()\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Particles\"] = \"Particles\"\n\n    particlesfile: Optional[XYZModel] = Field(None, alias=\"ParticlesFile\")\n    particlesreleasefile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"ParticlesReleaseFile\"\n    )\n    addtracer: Optional[bool] = Field(False, alias=\"AddTracer\")\n    starttime: Optional[float] = Field(0.0, alias=\"StartTime\")\n    timestep: Optional[float] = Field(0.0, alias=\"TimeStep\")\n    threedtype: Optional[ParticlesThreeDType] = Field(\n        ParticlesThreeDType.DepthAveraged, alias=\"3Dtype\"\n    )\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.ParticlesThreeDType","title":"<code>ParticlesThreeDType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the 3Dtype attribute in the <code>Particles</code> class.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class ParticlesThreeDType(IntEnum):\n    \"\"\"\n    Enum class containing the valid values for the 3Dtype\n    attribute in the `Particles` class.\n    \"\"\"\n\n    DepthAveraged = 0\n    FreeSurface = 1\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Physics","title":"<code>Physics</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Physics]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.physics</code>.</p> <p>All lowercased attributes match with the [Physics] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Physics(INIBasedModel):\n    \"\"\"\n    The `[Physics]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.physics`.\n\n    All lowercased attributes match with the [Physics] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        uniffrictcoef: Optional[str] = Field(\n            \"Uniform friction coefficient (0: no friction).\", alias=\"unifFrictCoef\"\n        )\n        uniffricttype: Optional[str] = Field(\n            \"Uniform friction type (0: Chezy, 1: Manning, 2: White-Colebrook, 3: idem, WAQUA style).\",\n            alias=\"unifFrictType\",\n        )\n        uniffrictcoef1d: Optional[str] = Field(\n            \"Uniform friction coefficient in 1D links (0: no friction).\",\n            alias=\"unifFrictCoef1D\",\n        )\n        uniffrictcoeflin: Optional[str] = Field(\n            \"Uniform linear friction coefficient (0: no friction).\",\n            alias=\"unifFrictCoefLin\",\n        )\n        vicouv: Optional[str] = Field(\n            \"Uniform horizontal eddy viscosity [m2/s].\", alias=\"vicouv\"\n        )\n        dicouv: Optional[str] = Field(\n            \"Uniform horizontal eddy diffusivity [m2/s].\", alias=\"dicouv\"\n        )\n        vicoww: Optional[str] = Field(\n            \"Background vertical eddy viscosity [m2/s].\", alias=\"vicoww\"\n        )\n        dicoww: Optional[str] = Field(\n            \"Background vertical eddy diffusivity [m2/s].\", alias=\"dicoww\"\n        )\n        vicwminb: Optional[str] = Field(\n            \"Minimum viscosity in production and buoyancy term [m2/s].\",\n            alias=\"vicwminb\",\n        )\n        xlozmidov: Optional[str] = Field(\n            \"Ozmidov length scale [m], default=0.0, no contribution of internal waves to vertical diffusion.\",\n            alias=\"xlozmidov\",\n        )\n        smagorinsky: Optional[str] = Field(\n            \"Add Smagorinsky horizontal turbulence: vicu = vicu + ( (Smagorinsky*dx)**2)*S.\",\n            alias=\"smagorinsky\",\n        )\n        elder: Optional[str] = Field(\n            \"Add Elder contribution: vicu = vicu + Elder*kappa*ustar*H/6); e.g. 1.0.\",\n            alias=\"elder\",\n        )\n        irov: Optional[str] = Field(\n            \"Wall friction, 0=free slip, 1 = partial slip using wall_ks.\", alias=\"irov\"\n        )\n        wall_ks: Optional[str] = Field(\n            \"Nikuradse roughness [m] for side walls, wall_z0=wall_ks/30.\",\n            alias=\"wall_ks\",\n        )\n        rhomean: Optional[str] = Field(\n            \"Average water density [kg/m3].\", alias=\"rhomean\"\n        )\n        idensform: Optional[str] = Field(\n            \"Density calulation (0: uniform, 1: Eckart, 2: Unesco, 3=Unesco83, 13=3+pressure).\",\n            alias=\"idensform\",\n        )\n        ag: Optional[str] = Field(\"Gravitational acceleration [m/s2].\", alias=\"ag\")\n        tidalforcing: Optional[str] = Field(\n            \"Tidal forcing, if jsferic=1 (0: no, 1: yes).\", alias=\"tidalForcing\"\n        )\n        itcap: Optional[str] = Field(\n            \"Upper limit on internal tides dissipation (W/m^2)\", alias=\"ITcap\"\n        )\n        doodsonstart: Optional[str] = Field(\n            \"Doodson start time for tidal forcing [s].\", alias=\"doodsonStart\"\n        )\n        doodsonstop: Optional[str] = Field(\n            \"Doodson stop time for tidal forcing [s].\", alias=\"doodsonStop\"\n        )\n        doodsoneps: Optional[str] = Field(\n            \"Doodson tolerance level for tidal forcing [s].\", alias=\"doodsonEps\"\n        )\n        villemontecd1: Optional[str] = Field(\n            \"Calibration coefficient for Villemonte. Default = 1.0.\",\n            alias=\"villemonteCD1\",\n        )\n        villemontecd2: Optional[str] = Field(\n            \"Calibration coefficient for Villemonte. Default = 10.0.\",\n            alias=\"villemonteCD2\",\n        )\n        salinity: Optional[str] = Field(\n            \"Include salinity, (0: no, 1: yes).\", alias=\"salinity\"\n        )\n        initialsalinity: Optional[str] = Field(\n            \"Initial salinity concentration [ppt].\", alias=\"initialSalinity\"\n        )\n        sal0abovezlev: Optional[str] = Field(\n            \"Salinity 0 above level [m].\", alias=\"sal0AboveZLev\"\n        )\n        deltasalinity: Optional[str] = Field(\n            \"uniform initial salinity [ppt].\", alias=\"deltaSalinity\"\n        )\n        backgroundsalinity: Optional[str] = Field(\n            \"Background salinity for eqn. of state if salinity not computed [psu].\",\n            alias=\"backgroundSalinity\",\n        )\n        temperature: Optional[str] = Field(\n            \"Include temperature (0: no, 1: only transport, 3: excess model of D3D, 5: composite (ocean) model).\",\n            alias=\"temperature\",\n        )\n        initialtemperature: Optional[str] = Field(\n            \"Initial temperature [\u25e6C].\", alias=\"initialTemperature\"\n        )\n        backgroundwatertemperature: Optional[str] = Field(\n            \"Background water temperature for eqn. of state if temperature not computed [\u25e6C].\",\n            alias=\"backgroundWaterTemperature\",\n        )\n        secchidepth: Optional[str] = Field(\n            \"Water clarity parameter [m].\", alias=\"secchiDepth\"\n        )\n        stanton: Optional[str] = Field(\n            \"Coefficient for convective heat flux ( ), if negative, then Cd wind is used.\",\n            alias=\"stanton\",\n        )\n        dalton: Optional[str] = Field(\n            \"Coefficient for evaporative heat flux ( ), if negative, then Cd wind is used.\",\n            alias=\"dalton\",\n        )\n        tempmax: Optional[str] = Field(\n            \"Limit the temperature to max value [\u00b0C]\", alias=\"tempMax\"\n        )\n        tempmin: Optional[str] = Field(\n            \"Limit the temperature to min value [\u00b0C]\", alias=\"tempMin\"\n        )\n        salimax: Optional[str] = Field(\n            \"Limit for salinity to max value [ppt]\", alias=\"saliMax\"\n        )\n        salimin: Optional[str] = Field(\n            \"Limit for salinity to min value [ppt]\", alias=\"saliMin\"\n        )\n        heat_eachstep: Optional[str] = Field(\n            \"'1=heat each timestep, 0=heat each usertimestep\", alias=\"heat_eachStep\"\n        )\n        rhoairrhowater: Optional[str] = Field(\n            \"'windstress rhoa/rhow: 0=Rhoair/Rhomean, 1=Rhoair/rhow(), 2=rhoa0()/rhow(), 3=rhoa10()/Rhow()\",\n            alias=\"rhoAirRhoWater\",\n        )\n        nudgetimeuni: Optional[str] = Field(\n            \"Uniform nudge relaxation time [s]\", alias=\"nudgeTimeUni\"\n        )\n        iniwithnudge: Optional[str] = Field(\n            \"Initialize salinity and temperature with nudge variables (0: no, 1: yes, 2: only initialize, no nudging)\",\n            alias=\"iniWithNudge\",\n        )\n        secondaryflow: Optional[str] = Field(\n            \"Secondary flow (0: no, 1: yes).\", alias=\"secondaryFlow\"\n        )\n        betaspiral: Optional[str] = Field(\n            \"Weight factor of the spiral flow intensity on flow dispersion stresses (0d0 = disabled).\",\n            alias=\"betaSpiral\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Physics\"] = \"Physics\"\n    uniffrictcoef: float = Field(0.023, alias=\"unifFrictCoef\")\n    uniffricttype: int = Field(1, alias=\"unifFrictType\")\n    uniffrictcoef1d: float = Field(0.023, alias=\"unifFrictCoef1D\")\n    uniffrictcoeflin: float = Field(0.0, alias=\"unifFrictCoefLin\")\n    vicouv: float = Field(0.1, alias=\"vicouv\")\n    dicouv: float = Field(0.1, alias=\"dicouv\")\n    vicoww: float = Field(5e-05, alias=\"vicoww\")\n    dicoww: float = Field(5e-05, alias=\"dicoww\")\n    vicwminb: float = Field(0.0, alias=\"vicwminb\")\n    xlozmidov: float = Field(0.0, alias=\"xlozmidov\")\n    smagorinsky: float = Field(0.2, alias=\"smagorinsky\")\n    elder: float = Field(0.0, alias=\"elder\")\n    irov: int = Field(0, alias=\"irov\")\n    wall_ks: float = Field(0.0, alias=\"wall_ks\")\n    rhomean: float = Field(1000, alias=\"rhomean\")\n    idensform: int = Field(2, alias=\"idensform\")\n    ag: float = Field(9.81, alias=\"ag\")\n    tidalforcing: bool = Field(False, alias=\"tidalForcing\")\n    itcap: Optional[float] = Field(0.0, alias=\"ITcap\")\n    doodsonstart: float = Field(55.565, alias=\"doodsonStart\")\n    doodsonstop: float = Field(375.575, alias=\"doodsonStop\")\n    doodsoneps: float = Field(0.0, alias=\"doodsonEps\")\n    villemontecd1: float = Field(1.0, alias=\"villemonteCD1\")\n    villemontecd2: float = Field(10.0, alias=\"villemonteCD2\")\n    salinity: bool = Field(False, alias=\"salinity\")\n    initialsalinity: float = Field(0.0, alias=\"initialSalinity\")\n    sal0abovezlev: float = Field(-999.0, alias=\"sal0AboveZLev\")\n    deltasalinity: float = Field(-999.0, alias=\"deltaSalinity\")\n    backgroundsalinity: float = Field(30.0, alias=\"backgroundSalinity\")\n    temperature: int = Field(0, alias=\"temperature\")\n    initialtemperature: float = Field(6.0, alias=\"initialTemperature\")\n    backgroundwatertemperature: float = Field(6.0, alias=\"backgroundWaterTemperature\")\n    secchidepth: float = Field(2.0, alias=\"secchiDepth\")\n    stanton: float = Field(0.0013, alias=\"stanton\")\n    dalton: float = Field(0.0013, alias=\"dalton\")\n    tempmax: float = Field(-999.0, alias=\"tempMax\")\n    tempmin: float = Field(0.0, alias=\"tempMin\")\n    salimax: float = Field(-999.0, alias=\"saliMax\")\n    salimin: float = Field(0.0, alias=\"saliMin\")\n    heat_eachstep: bool = Field(False, alias=\"heat_eachStep\")\n    rhoairrhowater: int = Field(0, alias=\"rhoAirRhoWater\")\n    nudgetimeuni: float = Field(3600.0, alias=\"nudgeTimeUni\")\n    iniwithnudge: int = Field(0, alias=\"iniWithNudge\")\n    secondaryflow: bool = Field(False, alias=\"secondaryFlow\")\n    betaspiral: float = Field(0.0, alias=\"betaSpiral\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.ProcessFluxIntegration","title":"<code>ProcessFluxIntegration</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the ProcessFluxIntegration attribute in the Processes class.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class ProcessFluxIntegration(IntEnum):\n    \"\"\"\n    Enum class containing the valid values for the ProcessFluxIntegration\n    attribute in the [Processes][hydrolib.core.dflowfm.mdu.models.Processes] class.\n    \"\"\"\n\n    WAQ = 1\n    DFlowFM = 2\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Processes","title":"<code>Processes</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Processes]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.processes</code>.</p> <p>All lowercased attributes match with the [Processes] input as described in UM Sec.A.3.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Processes(INIBasedModel):\n    \"\"\"\n    The `[Processes]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.processes`.\n\n    All lowercased attributes match with the [Processes] input as described in\n    [UM Sec.A.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        substancefile: Optional[str] = Field(\n            \"Substance file name.\", alias=\"SubstanceFile\"\n        )\n        additionalhistoryoutputfile: Optional[str] = Field(\n            \"Extra history output filename.\",\n            alias=\"AdditionalHistoryOutputFile\",\n        )\n        statisticsfile: Optional[str] = Field(\n            \"Statistics definition file.\",\n            alias=\"StatisticsFile\",\n        )\n        thetavertical: Optional[str] = Field(\n            \"Theta value for vertical transport of water quality substances [-].\",\n            alias=\"ThetaVertical\",\n        )\n        dtprocesses: Optional[str] = Field(\n            \"Waq processes time step [s]. Must be a multiple of DtUser. If DtProcesses is negative, water quality processes are calculated with every hydrodynamic time step.\",\n            alias=\"DtProcesses\",\n        )\n        processfluxintegration: Optional[str] = Field(\n            \"Process fluxes integration option (1: WAQ, 2: D-Flow FM).\",\n            alias=\"ProcessFluxIntegration\",\n        )\n        wriwaqbot3doutput: Optional[str] = Field(\n            \"Write 3D water quality bottom variables (0: no, 1: yes).\",\n            alias=\"Wriwaqbot3Doutput\",\n        )\n        volumedrythreshold: Optional[str] = Field(\n            \"Volume [m3] below which segments are marked as dry.\",\n            alias=\"VolumeDryThreshold\",\n        )\n        depthdrythreshold: Optional[str] = Field(\n            \"Water depth [m] below which segments are marked as dry.\",\n            alias=\"DepthDryThreshold\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Processes\"] = \"Processes\"\n\n    substancefile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"SubstanceFile\"\n    )\n    additionalhistoryoutputfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None),\n        alias=\"AdditionalHistoryOutputFile\",\n    )\n    statisticsfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"StatisticsFile\"\n    )\n    thetavertical: Optional[float] = Field(0.0, alias=\"ThetaVertical\")\n    dtprocesses: Optional[float] = Field(0.0, alias=\"DtProcesses\")\n    processfluxintegration: Optional[ProcessFluxIntegration] = Field(\n        ProcessFluxIntegration.WAQ, alias=\"ProcessFluxIntegration\"\n    )\n    wriwaqbot3doutput: Optional[bool] = Field(False, alias=\"Wriwaqbot3Doutput\")\n    volumedrythreshold: Optional[float] = Field(1e-3, alias=\"VolumeDryThreshold\")\n    depthdrythreshold: Optional[float] = Field(1e-3, alias=\"DepthDryThreshold\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Restart","title":"<code>Restart</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Restart]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.restart</code>.</p> <p>All lowercased attributes match with the [Restart] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Restart(INIBasedModel):\n    \"\"\"\n    The `[Restart]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.restart`.\n\n    All lowercased attributes match with the [Restart] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        restartfile: Optional[str] = Field(\n            \"Restart file, only from netCDF-file, hence: either *_rst.nc or *_map.nc.\",\n            alias=\"restartFile\",\n        )\n        restartdatetime: Optional[str] = Field(\n            \"Restart time [YYYYMMDDHHMMSS], only relevant in case of restart from *_map.nc.\",\n            alias=\"restartDateTime\",\n        )\n\n    comments: Comments = Comments()\n\n    _disk_only_file_model_should_not_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    _header: Literal[\"Restart\"] = \"Restart\"\n    restartfile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(None), alias=\"restartFile\"\n    )\n    restartdatetime: Optional[str] = Field(\"\", alias=\"restartDateTime\")\n\n    @validator(\"restartdatetime\")\n    def _validate_datetime(cls, value, field):\n        return validate_datetime_string(value, field)\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Time","title":"<code>Time</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Time]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.time</code>.</p> <p>All lowercased attributes match with the [Time] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Time(INIBasedModel):\n    \"\"\"\n    The `[Time]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.time`.\n\n    All lowercased attributes match with the [Time] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        refdate: Optional[str] = Field(\"Reference date [yyyymmdd].\", alias=\"refDate\")\n        tzone: Optional[str] = Field(\n            \"Data Sources in GMT are interrogated with time in minutes since refdat-Tzone*60 [min].\",\n            alias=\"tZone\",\n        )\n        tunit: Optional[str] = Field(\"Time units in MDU [D, H, M or S].\", alias=\"tUnit\")\n        dtuser: Optional[str] = Field(\n            \"User timestep in seconds [s] (interval for external forcing update &amp; his/map output).\",\n            alias=\"dtUser\",\n        )\n        dtnodal: Optional[str] = Field(\n            \"Time interval [s] for updating nodal factors in astronomical boundary conditions.\",\n            alias=\"dtNodal\",\n        )\n        dtmax: Optional[str] = Field(\"Max timestep in seconds [s].\", alias=\"dtMax\")\n        dtinit: Optional[str] = Field(\n            \"Initial timestep in seconds [s].\", alias=\"dtInit\"\n        )\n        autotimestep: Optional[str] = Field(\n            \"0 = no, 1 = 2D (hor. out), 3=3D (hor. out), 5 = 3D (hor. inout + ver. inout), smallest dt\",\n            alias=\"autoTimestep\",\n        )\n        autotimestepnostruct: Optional[str] = Field(\n            \"Exclude structure links (and neighbours) from time step limitation (0 = no, 1 = yes).\",\n            alias=\"autoTimestepNoStruct\",\n        )\n        autotimestepnoqout: Optional[str] = Field(\n            \"Exclude negative qin terms from time step limitation (0 = no, 1 = yes).\",\n            alias=\"autoTimestepNoQout\",\n        )\n        tstart: Optional[str] = Field(\n            \"Start time w.r.t. RefDate [TUnit].\", alias=\"tStart\"\n        )\n        tstop: Optional[str] = Field(\"Stop time w.r.t. RefDate [TUnit].\", alias=\"tStop\")\n        startdatetime: Optional[str] = Field(\n            \"Computation Startdatetime (yyyymmddhhmmss), when specified, overrides tStart\",\n            alias=\"startDateTime\",\n        )\n        stopdatetime: Optional[str] = Field(\n            \"Computation Stopdatetime  (yyyymmddhhmmss), when specified, overrides tStop\",\n            alias=\"stopDateTime\",\n        )\n        updateroughnessinterval: Optional[str] = Field(\n            \"Update interval for time dependent roughness parameters [s].\",\n            alias=\"updateRoughnessInterval\",\n        )\n        dtfacmax: Optional[str] = Field(\n            \"Max timestep increase factor in successive time steps.\", alias=\"Dtfacmax\"\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Time\"] = \"Time\"\n    refdate: int = Field(20200101, alias=\"refDate\")  # TODO Convert to datetime\n    tzone: float = Field(0.0, alias=\"tZone\")\n    tunit: str = Field(\"S\", alias=\"tUnit\")  # DHMS\n    dtuser: float = Field(300.0, alias=\"dtUser\")\n    dtnodal: float = Field(21600.0, alias=\"dtNodal\")\n    dtmax: float = Field(30.0, alias=\"dtMax\")\n    dtinit: float = Field(1.0, alias=\"dtInit\")\n    autotimestep: Optional[int] = Field(1, alias=\"autoTimestep\")\n    autotimestepnostruct: bool = Field(False, alias=\"autoTimestepNoStruct\")\n    autotimestepnoqout: bool = Field(True, alias=\"autoTimestepNoQout\")\n    tstart: float = Field(0.0, alias=\"tStart\")\n    tstop: float = Field(86400.0, alias=\"tStop\")\n    startdatetime: Optional[str] = Field(\"\", alias=\"startDateTime\")\n    stopdatetime: Optional[str] = Field(\"\", alias=\"stopDateTime\")\n    updateroughnessinterval: float = Field(86400.0, alias=\"updateRoughnessInterval\")\n    dtfacmax: float = Field(1.1, alias=\"Dtfacmax\")\n\n    @validator(\"startdatetime\", \"stopdatetime\")\n    def _validate_datetime(cls, value, field):\n        return validate_datetime_string(value, field)\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Trachytopes","title":"<code>Trachytopes</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Trachytopes]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.trachytopes</code>.</p> <p>All lowercased attributes match with the [Trachytopes] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Trachytopes(INIBasedModel):\n    \"\"\"\n    The `[Trachytopes]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.trachytopes`.\n\n    All lowercased attributes match with the [Trachytopes] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        trtrou: Optional[str] = Field(\n            \"Flag for trachytopes (Y=on, N=off).\", alias=\"trtRou\"\n        )\n        trtdef: Optional[str] = Field(\n            \"File (*.ttd) including trachytope definitions.\", alias=\"trtDef\"\n        )\n        trtl: Optional[str] = Field(\n            \"File (*.arl) including distribution of trachytope definitions.\",\n            alias=\"trtL\",\n        )\n        dttrt: Optional[str] = Field(\n            \"Interval for updating of bottom roughness due to trachytopes in seconds [s].\",\n            alias=\"dtTrt\",\n        )\n        trtmxr: Optional[str] = Field(\n            \"Maximum recursion level for composite trachytope definitions\",\n            alias=\"trtMxR\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Trachytopes\"] = \"Trachytopes\"\n    trtrou: str = Field(\"N\", alias=\"trtRou\")  # TODO bool\n    trtdef: Optional[Path] = Field(\"\", alias=\"trtDef\")\n    trtl: Optional[Path] = Field(\"\", alias=\"trtL\")\n    dttrt: float = Field(60.0, alias=\"dtTrt\")\n    trtmxr: Optional[int] = Field(8, alias=\"trtMxR\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Vegetation","title":"<code>Vegetation</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Veg]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.veg</code>.</p> <p>All lowercased attributes match with the [Veg] input as described in UM Sec.A.3.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Vegetation(INIBasedModel):\n    \"\"\"\n    The `[Veg]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.veg`.\n\n    All lowercased attributes match with the [Veg] input as described in\n    [UM Sec.A.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.3).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        vegetationmodelnr: Optional[str] = Field(\n            \"Vegetation model nr, (0: no, 1: Baptist DFM).\", alias=\"Vegetationmodelnr\"\n        )\n        clveg: Optional[str] = Field(\"Stem distance factor [-].\", alias=\"Clveg\")\n        cdveg: Optional[str] = Field(\"Stem Cd coefficient [-].\", alias=\"Cdveg\")\n        cbveg: Optional[str] = Field(\"Stem stiffness coefficient [-].\", alias=\"Cbveg\")\n        rhoveg: Optional[str] = Field(\n            \"Stem Rho, if &gt; 0, bouyant stick procedure [kg/m3].\", alias=\"Rhoveg\"\n        )\n        stemheightstd: Optional[str] = Field(\n            \"Stem height standard deviation fraction, e.g. 0.1 [-].\",\n            alias=\"Stemheightstd\",\n        )\n        densvegminbap: Optional[str] = Field(\n            \"Minimum vegetation density in Baptist formula. Only in 2D. [1/m2].\",\n            alias=\"Densvegminbap\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Veg\"] = \"Veg\"\n\n    vegetationmodelnr: Optional[VegetationModelNr] = Field(\n        VegetationModelNr.No, alias=\"Vegetationmodelnr\"\n    )\n    clveg: Optional[float] = Field(0.8, alias=\"Clveg\")\n    cdveg: Optional[float] = Field(0.7, alias=\"Cdveg\")\n    cbveg: Optional[float] = Field(0.0, alias=\"Cbveg\")\n    rhoveg: Optional[float] = Field(0.0, alias=\"Rhoveg\")\n    stemheightstd: Optional[float] = Field(0.0, alias=\"Stemheightstd\")\n    densvegminbap: Optional[float] = Field(0.0, alias=\"Densvegminbap\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.VegetationModelNr","title":"<code>VegetationModelNr</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum class containing the valid values for the VegetationModelNr attribute in the Vegetation class.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class VegetationModelNr(IntEnum):\n    \"\"\"\n    Enum class containing the valid values for the VegetationModelNr\n    attribute in the [Vegetation][hydrolib.core.dflowfm.mdu.models.Vegetation] class.\n    \"\"\"\n\n    No = 0\n    BaptistDFM = 1\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.VolumeTables","title":"<code>VolumeTables</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[VolumeTables]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.volumetables</code>.</p> <p>All lowercased attributes match with the [VolumeTables] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class VolumeTables(INIBasedModel):\n    \"\"\"\n    The `[VolumeTables]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.volumetables`.\n\n    All lowercased attributes match with the [VolumeTables] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        usevolumetables: Optional[str] = Field(\n            \"Use 1D volume tables (0: no, 1: yes).\",\n            alias=\"useVolumeTables\",\n        )\n        increment: Optional[str] = Field(\n            \"The height increment for the volume tables [m].\", alias=\"increment\"\n        )\n        usevolumetablefile: Optional[str] = Field(\n            \"Read and write the volume table from/to file (1: yes, 0= no).\",\n            alias=\"useVolumeTableFile\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"VolumeTables\"] = \"VolumeTables\"\n    usevolumetables: bool = Field(False, alias=\"useVolumeTables\")\n    increment: float = Field(0.2, alias=\"increment\")\n    usevolumetablefile: bool = Field(False, alias=\"useVolumeTableFile\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Waves","title":"<code>Waves</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Waves]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.waves</code>.</p> <p>All lowercased attributes match with the [Waves] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Waves(INIBasedModel):\n    \"\"\"\n    The `[Waves]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.waves`.\n\n    All lowercased attributes match with the [Waves] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        wavemodelnr: Optional[str] = Field(\n            \"Wave model nr. (0: none, 1: fetch/depth limited hurdlestive, 2: Young-Verhagen, 3: SWAN, 5: uniform, 6: SWAN-NetCDF\",\n            alias=\"waveModelNr\",\n        )\n        rouwav: Optional[str] = Field(\n            \"Friction model for wave induced shear stress: FR84 (default) or: MS90, HT91, GM79, DS88, BK67, CJ85, OY88, VR04.\",\n            alias=\"rouWav\",\n        )\n        gammax: Optional[str] = Field(\n            \"Maximum wave height/water depth ratio\", alias=\"gammaX\"\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Waves\"] = \"Waves\"\n    wavemodelnr: int = Field(3, alias=\"waveModelNr\")\n    rouwav: str = Field(\"FR84\", alias=\"rouWav\")\n    gammax: float = Field(0.5, alias=\"gammaX\")\n</code></pre>"},{"location":"reference/models/mdu/#hydrolib.core.dflowfm.mdu.models.Wind","title":"<code>Wind</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Wind]</code> section in an MDU file.</p> <p>This model is typically referenced under FMModel<code>.wind</code>.</p> <p>All lowercased attributes match with the [Wind] input as described in UM Sec.A.1.</p> Source code in <code>hydrolib/core/dflowfm/mdu/models.py</code> <pre><code>class Wind(INIBasedModel):\n    \"\"\"\n    The `[Wind]` section in an MDU file.\n\n    This model is typically referenced under [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.wind`.\n\n    All lowercased attributes match with the [Wind] input as described in\n    [UM Sec.A.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.A.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        icdtyp: Optional[str] = Field(\n            \"Wind drag coefficient type (1: Const, 2: Smith&amp;Banke (2 pts), 3: S&amp;B (3 pts), 4: Charnock 1955, 5: Hwang 2005, 6: Wuest 2005, 7: Hersbach 2010 (2 pts), 8: 4+viscous).\",\n            alias=\"iCdTyp\",\n        )\n        cdbreakpoints: Optional[str] = Field(\n            \"Wind drag breakpoints, e.g. 0.00063 0.00723.\", alias=\"CdBreakpoints\"\n        )\n        windspeedbreakpoints: Optional[str] = Field(\n            \"Wind speed breakpoints [m/s], e.g. 0.0 100.0.\",\n            alias=\"windSpeedBreakpoints\",\n        )\n        rhoair: Optional[str] = Field(\"Air density [kg/m3].\", alias=\"rhoAir\")\n        relativewind: Optional[str] = Field(\n            \"Wind speed [kg/m3] relative to top-layer water speed*relativewind (0d0=no relative wind, 1d0=using full top layer speed).\",\n            alias=\"relativeWind\",\n        )\n        windpartialdry: Optional[str] = Field(\n            \"Reduce windstress on water if link partially dry, only for bedlevtyp=3, 0=no, 1=yes (default).\",\n            alias=\"windPartialDry\",\n        )\n        pavbnd: Optional[str] = Field(\n            \"Average air pressure on open boundaries [N/m2], only applied if value &gt; 0.\",\n            alias=\"pavBnd\",\n        )\n        pavini: Optional[str] = Field(\n            \"Initial air pressure [N/m2], only applied if value &gt; 0.\", alias=\"pavIni\"\n        )\n        computedairdensity: Optional[str] = Field(\n            \"Compute air density yes/no (), 1/0, default 0.\", alias=\"computedAirdensity\"\n        )\n        stresstowind: Optional[str] = Field(\n            \"Switch between Wind speed (=0) and wind stress (=1) approach for wind forcing.\",\n            alias=\"stressToWind\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Wind\"] = \"Wind\"\n    icdtyp: int = Field(2, alias=\"iCdTyp\")\n    cdbreakpoints: List[float] = Field([0.00063, 0.00723], alias=\"CdBreakpoints\")\n    windspeedbreakpoints: List[float] = Field(\n        [0.0, 100.0], alias=\"windSpeedBreakpoints\"\n    )\n    rhoair: float = Field(1.2, alias=\"rhoAir\")\n    relativewind: float = Field(0.0, alias=\"relativeWind\")\n    windpartialdry: bool = Field(True, alias=\"windPartialDry\")\n    pavbnd: float = Field(0.0, alias=\"pavBnd\")\n    pavini: float = Field(0.0, alias=\"pavIni\")\n    computedairdensity: bool = Field(False, alias=\"computedAirdensity\")\n    stresstowind: bool = Field(False, alias=\"stressToWind\")\n\n    @classmethod\n    def list_delimiter(cls) -&gt; str:\n        return \" \"\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"cdbreakpoints\",\n        \"windspeedbreakpoints\",\n    )\n</code></pre>"},{"location":"reference/models/net/","title":"Net/grid file","text":"<p>The computational grid for D-Flow FM is stored in the net file. It is an unstructured grid, where 1D and 2D can be combined. The file format is NetCDF, using the CF-, UGRID- and Deltares-conventions.</p> <p>The net file is represented by the classes below.</p>"},{"location":"reference/models/net/#model","title":"Model","text":""},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Branch","title":"<code>Branch</code>","text":"Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class Branch:\n    def __init__(\n        self,\n        geometry: np.ndarray,\n        branch_offsets: np.ndarray = None,\n        mask: np.ndarray = None,\n    ) -&gt; None:\n        # Check that the array has two collumns (x and y)\n        assert geometry.shape[1] == 2\n\n        # Split in x and y\n        self.geometry = geometry\n        self._x_coordinates = geometry[:, 0]\n        self._y_coordinates = geometry[:, 1]\n\n        # Calculate distance of coordinates along line\n        segment_distances = np.hypot(\n            np.diff(self._x_coordinates), np.diff(self._y_coordinates)\n        )\n        self._distance = np.concatenate([[0], np.cumsum(segment_distances)])\n        self.length = segment_distances.sum()\n\n        # Check if mask and branch offsets (if both given) have same shape\n        if (\n            mask is not None\n            and branch_offsets is not None\n            and branch_offsets.shape != mask.shape\n        ):\n            raise ValueError(\"Mask and branch offset have different shape.\")\n\n        # Set branch offsets\n        self.branch_offsets = branch_offsets\n        # Calculate node positions\n        if branch_offsets is not None:\n            self.node_xy = self.interpolate(branch_offsets)\n\n        # Set which of the nodes are present\n        if (mask is None) and (branch_offsets is not None):\n            self.mask = np.full(branch_offsets.shape, False)\n        else:\n            self.mask = mask\n\n    def generate_nodes(\n        self,\n        mesh1d_edge_length: float,\n        structure_chainage: Optional[List[float]] = None,\n        max_dist_to_struc: Optional[float] = None,\n    ):\n        \"\"\"Generate the branch offsets and the nodes.\n\n        Args:\n            mesh1d_edge_length (float): The edge length of the 1d mesh.\n            structure_chainage (Optional[List[float]], optional): A list with the structure chainages. If not specified, calculation will not take it into account. Defaults to None.\n            max_dist_to_struc (Optional[float], optional): The maximum distance from a node to a structure. If not specified, calculation will not take it into account. Defaults to None.\n\n        Raises:\n            ValueError: Raised when any of the structure offsets, if specified, is smaller than zero.\n            ValueError: Raised when any of the structure offsets, if specified, is greater than the branch length.\n        \"\"\"\n        # Generate offsets\n        self.branch_offsets = self._generate_offsets(\n            mesh1d_edge_length, structure_chainage, max_dist_to_struc\n        )\n        # Calculate node positions\n        self.node_xy = self.interpolate(self.branch_offsets)\n        # Add mask (all False)\n        self.mask = np.full(self.branch_offsets.shape, False)\n\n    def _generate_offsets(\n        self,\n        mesh1d_edge_length: float,\n        structure_offsets: Optional[List[float]] = None,\n        max_dist_to_struc: Optional[float] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Generate the branch offsets.\n\n        Args:\n            mesh1d_edge_length (float): The edge length of the 1d mesh.\n            structure_chainage (Optional[List[float]], optional): A list with the structure chainages. If not specified, calculation will not take it into account. Defaults to None.\n            max_dist_to_struc (Optional[float], optional): The maximum distance from a node to a structure. If not specified, calculation will not take it into account. Defaults to None.\n\n        Raises:\n            ValueError: Raised when any of the structure offsets, if specified, is smaller than zero.\n            ValueError: Raised when any of the structure offsets, if specified, is greater than the branch length.\n\n        Returns:\n            np.ndarray: The generated branch offsets.\n        \"\"\"\n        # Generate initial offsets\n        anchor_pts = [0.0, self.length]\n        offsets = self._generate_1d_spacing(anchor_pts, mesh1d_edge_length)\n\n        if structure_offsets is None:\n            return offsets\n\n        # Check the limits\n        if (excess := min(structure_offsets)) &lt; 0.0 or (\n            excess := max(structure_offsets)\n        ) &gt; self.length:\n            raise ValueError(\n                f\"Distance {excess} is outside the branch range (0.0 - {self.length}).\"\n            )\n\n        # Merge limits with start and end of branch\n        limits = [-1e-3] + list(sorted(structure_offsets)) + [self.length + 1e-3]\n\n        # if requested, check if the calculation point are close enough to the structures\n        if max_dist_to_struc is not None:\n            limits = self._generate_extended_limits(max_dist_to_struc, limits)\n\n        offsets = self._add_nodes_to_segments(\n            offsets, anchor_pts, limits, mesh1d_edge_length\n        )\n\n        return offsets\n\n    def _generate_extended_limits(\n        self, max_dist_to_struc: float, limits: List[float]\n    ) -&gt; List[float]:\n        \"\"\"Generate extended limits by taking into account the maximum distance to a structure.\n\n        Args:\n            max_dist_to_struc (float): The maximum distance from a node to a structure.\n            limits (List[float]): The limits.\n\n        Returns:\n            List[float]: A list with the updated limits.\n        \"\"\"\n\n        additional = []\n\n        # Skip the first and the last, these are no structures\n        for i in range(1, len(limits) - 1):\n            # if the distance between two limits is large than twice the max distance to structure,\n            # the mesh point will be too far away. Add a limit on the minimum of half the length and\n            # two times the max distance\n            dist_to_prev_limit = limits[i] - (\n                max(additional[-1], limits[i - 1]) if any(additional) else limits[i - 1]\n            )\n            if dist_to_prev_limit &gt; 2 * max_dist_to_struc:\n                additional.append(\n                    limits[i] - min(2 * max_dist_to_struc, dist_to_prev_limit / 2)\n                )\n\n            dist_to_next_limit = limits[i + 1] - limits[i]\n            if dist_to_next_limit &gt; 2 * max_dist_to_struc:\n                additional.append(\n                    limits[i] + min(2 * max_dist_to_struc, dist_to_next_limit / 2)\n                )\n\n        # Join the limits\n        return sorted(limits + additional)\n\n    def _add_nodes_to_segments(\n        self,\n        offsets: np.ndarray,\n        anchor_pts: List[float],\n        limits: List[float],\n        mesh1d_edge_length: float,\n    ) -&gt; np.ndarray:\n        \"\"\"Add nodes to segments that are missing a mesh node.\n\n        Args:\n            offsets (np.ndarray): The branch offsets.\n            anchor_pts (List[float]): The anchor points.\n            limits (List[float]): The limits.\n            mesh1d_edge_length (float): The edge length of the 1d mesh.\n\n        Returns:\n            np.ndarray: The array with branch offsets.\n        \"\"\"\n        # Get upper and lower limits\n        upper_limits = limits[1:]\n        lower_limits = limits[:-1]\n\n        def in_range():\n            return [\n                ((offsets &gt; lower) &amp; (offsets &lt; upper)).any()\n                for lower, upper in zip(lower_limits, upper_limits)\n            ]\n\n        # Determine the segments that are missing a mesh node\n        # Anchor points are added on these segments, such that they will get a mesh node\n        nodes_in_range = in_range()\n\n        while not all(nodes_in_range):\n            # Get the index of the first segment without grid point\n            i = nodes_in_range.index(False)\n\n            # Add it to the anchor pts\n            anchor_pts.append((lower_limits[i] + upper_limits[i]) / 2.0)\n            anchor_pts = sorted(anchor_pts)\n\n            # Generate new offsets\n            offsets = self._generate_1d_spacing(anchor_pts, mesh1d_edge_length)\n\n            # Determine the segments that are missing a grid point\n            nodes_in_range = in_range()\n\n        if len(anchor_pts) &gt; 2:\n            logger.info(\n                f\"Added 1d mesh nodes on branch at: {anchor_pts}, due to the structures at {limits}.\"\n            )\n\n        return offsets\n\n    @staticmethod\n    def _generate_1d_spacing(\n        anchor_pts: List[float], mesh1d_edge_length: float\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Generates 1d distances, called by function generate offsets\n        \"\"\"\n        offsets = []\n        # Loop through anchor point pairs\n        for i in range(len(anchor_pts) - 1):\n            # Determine section length between anchor point\n            section_length = anchor_pts[i + 1] - anchor_pts[i]\n            if section_length &lt;= 0.0:\n                raise ValueError(\"Section length must be larger than 0.0\")\n            # Determine number of nodes\n            nnodes = max(2, int(round(section_length / mesh1d_edge_length) + 1)) - 1\n            # Add nodes\n            offsets.extend(\n                np.linspace(\n                    anchor_pts[i], anchor_pts[i + 1], nnodes, endpoint=False\n                ).tolist()\n            )\n        # Add last node\n        offsets.append(anchor_pts[-1])\n\n        return np.asarray(offsets)\n\n    def interpolate(self, distance: npt.ArrayLike) -&gt; np.ndarray:\n        \"\"\"Interpolate coordinates along branch by length\n\n        Args:\n            distance (npt.ArrayLike): Length\n        \"\"\"\n        intpcoords = np.stack(\n            [\n                np.interp(distance, self._distance, self._x_coordinates),\n                np.interp(distance, self._distance, self._y_coordinates),\n            ],\n            axis=1,\n        )\n\n        return intpcoords\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Branch.generate_nodes","title":"<code>generate_nodes(mesh1d_edge_length, structure_chainage=None, max_dist_to_struc=None)</code>","text":"<p>Generate the branch offsets and the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mesh1d_edge_length</code> <code>float</code> <p>The edge length of the 1d mesh.</p> required <code>structure_chainage</code> <code>Optional[List[float]]</code> <p>A list with the structure chainages. If not specified, calculation will not take it into account. Defaults to None.</p> <code>None</code> <code>max_dist_to_struc</code> <code>Optional[float]</code> <p>The maximum distance from a node to a structure. If not specified, calculation will not take it into account. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised when any of the structure offsets, if specified, is smaller than zero.</p> <code>ValueError</code> <p>Raised when any of the structure offsets, if specified, is greater than the branch length.</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def generate_nodes(\n    self,\n    mesh1d_edge_length: float,\n    structure_chainage: Optional[List[float]] = None,\n    max_dist_to_struc: Optional[float] = None,\n):\n    \"\"\"Generate the branch offsets and the nodes.\n\n    Args:\n        mesh1d_edge_length (float): The edge length of the 1d mesh.\n        structure_chainage (Optional[List[float]], optional): A list with the structure chainages. If not specified, calculation will not take it into account. Defaults to None.\n        max_dist_to_struc (Optional[float], optional): The maximum distance from a node to a structure. If not specified, calculation will not take it into account. Defaults to None.\n\n    Raises:\n        ValueError: Raised when any of the structure offsets, if specified, is smaller than zero.\n        ValueError: Raised when any of the structure offsets, if specified, is greater than the branch length.\n    \"\"\"\n    # Generate offsets\n    self.branch_offsets = self._generate_offsets(\n        mesh1d_edge_length, structure_chainage, max_dist_to_struc\n    )\n    # Calculate node positions\n    self.node_xy = self.interpolate(self.branch_offsets)\n    # Add mask (all False)\n    self.mask = np.full(self.branch_offsets.shape, False)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Branch.interpolate","title":"<code>interpolate(distance)</code>","text":"<p>Interpolate coordinates along branch by length</p> <p>Parameters:</p> Name Type Description Default <code>distance</code> <code>ArrayLike</code> <p>Length</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def interpolate(self, distance: npt.ArrayLike) -&gt; np.ndarray:\n    \"\"\"Interpolate coordinates along branch by length\n\n    Args:\n        distance (npt.ArrayLike): Length\n    \"\"\"\n    intpcoords = np.stack(\n        [\n            np.interp(distance, self._distance, self._x_coordinates),\n            np.interp(distance, self._distance, self._y_coordinates),\n        ],\n        axis=1,\n    )\n\n    return intpcoords\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Link1d2d","title":"<code>Link1d2d</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Link1d2d defines the 1D2D Links of a model network.</p> <p>Attributes:</p> Name Type Description <code>meshkernel</code> <code>Optional[MeshKernel]</code> <p>The MeshKernel used to interact with this Link1d2d</p> <code>link1d2d_id</code> <code>ndarray</code> <p>The id of this Link1d2d</p> <code>link1d2d_long_name</code> <code>ndarray</code> <p>The long name of this Link1d2d</p> <code>link1d2d_contact_type</code> <code>ndarray</code> <p>The contact type of this Link1d2d</p> <code>link1d2d</code> <code>ndarray</code> <p>The underlying data object of this Link1d2d</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class Link1d2d(BaseModel):\n    \"\"\"Link1d2d defines the 1D2D Links of a model network.\n\n    Attributes:\n        meshkernel (Optional[mk.MeshKernel]):\n            The MeshKernel used to interact with this Link1d2d\n        link1d2d_id (np.ndarray):\n            The id of this Link1d2d\n        link1d2d_long_name (np.ndarray):\n            The long name of this Link1d2d\n        link1d2d_contact_type (np.ndarray):\n            The contact type of this Link1d2d\n        link1d2d (np.ndarray):\n            The underlying data object of this Link1d2d\n    \"\"\"\n\n    meshkernel: mk.MeshKernel = Field(default_factory=mk.MeshKernel)\n\n    @property\n    def link1d2d(self) -&gt; np.ndarray[np.int32]:\n        contacts = self.meshkernel.contacts_get()\n        link1d2d_arr = np.stack(\n            [contacts.mesh1d_indices, contacts.mesh2d_indices], axis=1\n        )\n        return link1d2d_arr\n\n    @property\n    def link1d2d_contact_type(self) -&gt; np.ndarray[np.int32]:\n        contacts = self.meshkernel.contacts_get()\n        link1d2d_contact_type_arr = np.full(contacts.mesh1d_indices.size, 3)\n        return link1d2d_contact_type_arr\n\n    @property\n    def link1d2d_id(self) -&gt; np.ndarray[object]:\n        link1d2d_id_arr = np.array([f\"{n1d:d}_{f2d:d}\" for n1d, f2d in self.link1d2d])\n        return link1d2d_id_arr\n\n    @property\n    def link1d2d_long_name(self) -&gt; np.ndarray[object]:\n        link1d2d_id_arr = np.array([f\"{n1d:d}_{f2d:d}\" for n1d, f2d in self.link1d2d])\n        return link1d2d_id_arr\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Whether this Link1d2d is currently empty.\n\n        Returns:\n            bool: True if the Link1d2d is currently empty; False otherwise.\n        \"\"\"\n        return self.link1d2d.size == 0\n\n    def read_file(self, file_path: Path) -&gt; None:\n        \"\"\"Read the Link1d2d data from the specified netCDF file at file_path into this\n\n        Args:\n            file_path (Path): Path to the netCDF file.\n        \"\"\"\n\n        reader = UgridReader(file_path)\n        reader.read_link1d2d(self)\n\n    def clear(self) -&gt; None:\n        \"\"\"Remove all saved links from the links administration\"\"\"\n        self.link1d2d_id = np.empty(0, object)\n        self.link1d2d_long_name = np.empty(0, object)\n        self.link1d2d_contact_type = np.empty(0, np.int32)\n        self.link1d2d = np.empty((0, 2), np.int32)\n        # The meshkernel object needs to be resetted\n        self.meshkernel._deallocate_state()\n        self.meshkernel._allocate_state(self.meshkernel.get_projection())\n        self.meshkernel.contacts_get()\n\n    def _link_from_1d_to_2d(\n        self, node_mask: np.ndarray, polygon: mk.GeometryList = None\n    ):\n        \"\"\"Connect 1d nodes to 2d face circumcenters. A list of branchid's can be given\n        to indicate where the 1d-side of the connections should be made. A polygon can\n        be given to indicate where the 2d-side of the connections should be made.\n\n        Note that the links are added to the already existing links. To remove these, use the method \"clear\".\n\n        Args:\n            node_mask (np.ndarray): Array indicating what 1d nodes should be connected. Defaults to None.\n            polygon (mk.GeometryList): Coordinates of the area within which the 2d side of the links are connected.\n        \"\"\"\n\n        # Computes Mesh1d-Mesh2d contacts, where each single Mesh1d node is connected to one Mesh2d face circumcenter.\n        # The boundary nodes of Mesh1d (those sharing only one Mesh1d edge) are not connected to any Mesh2d face.\n        self.meshkernel.contacts_compute_single(\n            node_mask=node_mask, polygons=polygon, projection_factor=1.0\n        )\n\n        # Note that the function \"contacts_compute_multiple\" also computes the connections, but does not take into account\n        # a bounding polygon or the end points of the 1d mesh.\n\n    def _link_from_2d_to_1d_embedded(\n        self, node_mask: np.ndarray, polygons: mk.GeometryList\n    ):\n        \"\"\"\"\"\"\n        self.meshkernel.contacts_compute_with_points(\n            node_mask=node_mask, polygons=polygons\n        )\n\n    def _link_from_2d_to_1d_lateral(\n        self,\n        node_mask: np.ndarray,\n        # boundary_face_xy: np.ndarray,\n        polygon: mk.GeometryList = None,\n        search_radius: float = None,\n    ):\n        # TODO: Missing value double for search radius?\n\n        # Computes Mesh1d-Mesh2d contacts, where Mesh1d nodes are connected to the closest Mesh2d faces at the boundary\n        self.meshkernel.contacts_compute_boundary(\n            node_mask=node_mask, polygons=polygon, search_radius=search_radius\n        )\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Link1d2d.clear","title":"<code>clear()</code>","text":"<p>Remove all saved links from the links administration</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all saved links from the links administration\"\"\"\n    self.link1d2d_id = np.empty(0, object)\n    self.link1d2d_long_name = np.empty(0, object)\n    self.link1d2d_contact_type = np.empty(0, np.int32)\n    self.link1d2d = np.empty((0, 2), np.int32)\n    # The meshkernel object needs to be resetted\n    self.meshkernel._deallocate_state()\n    self.meshkernel._allocate_state(self.meshkernel.get_projection())\n    self.meshkernel.contacts_get()\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Link1d2d.is_empty","title":"<code>is_empty()</code>","text":"<p>Whether this Link1d2d is currently empty.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the Link1d2d is currently empty; False otherwise.</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Whether this Link1d2d is currently empty.\n\n    Returns:\n        bool: True if the Link1d2d is currently empty; False otherwise.\n    \"\"\"\n    return self.link1d2d.size == 0\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Link1d2d.read_file","title":"<code>read_file(file_path)</code>","text":"<p>Read the Link1d2d data from the specified netCDF file at file_path into this</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the netCDF file.</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def read_file(self, file_path: Path) -&gt; None:\n    \"\"\"Read the Link1d2d data from the specified netCDF file at file_path into this\n\n    Args:\n        file_path (Path): Path to the netCDF file.\n    \"\"\"\n\n    reader = UgridReader(file_path)\n    reader.read_link1d2d(self)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh1d","title":"<code>Mesh1d</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class Mesh1d(BaseModel):\n    \"\"\"\"\"\"\n\n    meshkernel: mk.MeshKernel = Field(default_factory=mk.MeshKernel)\n\n    branches: Dict[str, Branch] = {}\n\n    network1d_node_id: np.ndarray = Field(default_factory=lambda: np.empty(0, object))\n    network1d_node_long_name: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, object)\n    )\n    network1d_node_x: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    network1d_node_y: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    network1d_branch_id: np.ndarray = Field(default_factory=lambda: np.empty(0, object))\n    network1d_branch_long_name: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, object)\n    )\n    network1d_branch_length: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.double)\n    )\n    network1d_branch_order: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.int32)\n    )\n    network1d_edge_nodes: np.ndarray = Field(\n        default_factory=lambda: np.empty((0, 2), np.int32)\n    )\n    # TODO: sync with node_x/node_y/edge_nodes with meshkernel: https://github.com/Deltares/HYDROLIB-core/issues/576\n    network1d_geom_x: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    network1d_geom_y: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    network1d_part_node_count: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.int32)\n    )\n\n    mesh1d_node_x: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    mesh1d_node_y: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    mesh1d_node_id: np.ndarray = Field(default_factory=lambda: np.empty(0, object))\n    mesh1d_node_long_name: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, object)\n    )\n    mesh1d_node_branch_id: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.int32)\n    )\n    mesh1d_node_branch_offset: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.double)\n    )\n\n    mesh1d_edge_nodes: np.ndarray = Field(\n        default_factory=lambda: np.empty((0, 2), np.int32)\n    )\n    mesh1d_edge_x: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    mesh1d_edge_y: np.ndarray = Field(default_factory=lambda: np.empty(0, np.double))\n    mesh1d_edge_branch_id: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.int32)\n    )\n    mesh1d_edge_branch_offset: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, np.double)\n    )\n\n    def is_empty(self) -&gt; bool:\n        return self.mesh1d_node_x.size == 0\n\n    def _get_mesh1d(self) -&gt; mk.Mesh1d:\n        \"\"\"Return mesh1d from meshkernel. Note that the meshkernel.Mesh1d instance\n        does not contain all mesh attributes that are contained in this class\"\"\"\n        return self.meshkernel.mesh1d_get()\n\n    def _set_mesh1d(self) -&gt; None:\n        self.meshkernel.mesh1d_set(\n            mk.Mesh1d(\n                node_x=self.mesh1d_node_x.astype(np.float64),\n                node_y=self.mesh1d_node_y.astype(np.float64),\n                edge_nodes=self.mesh1d_edge_nodes.ravel().astype(np.int32),\n            )\n        )\n\n    def _process_network1d(self) -&gt; None:\n        \"\"\"\n        Determine x, y locations of mesh1d nodes based on the network1d\n        \"\"\"\n        # Create a list of coordinates to create the branches from\n        ngeom = list(zip(self.network1d_geom_x, self.network1d_geom_y))\n\n        self.branches.clear()\n\n        for i, (name, nnodes) in enumerate(\n            zip(self.network1d_branch_id, self.network1d_part_node_count)\n        ):\n\n            # Create network branch\n            # Get geometry of branch from network geometry\n            geometry = np.array([ngeom.pop(0) for _ in range(nnodes)])\n            # Get branch offsets\n            idx = self.mesh1d_node_branch_id == i\n            branch_offsets = self.mesh1d_node_branch_offset[idx]\n            mask = np.full(branch_offsets.shape, False)\n\n            # Determine if a start or end coordinate needs to be added for constructing a complete branch\n            # As nodes are re-used, the last and first branch_offsets are often missing. However, they are still used\n            # for determining the length along the discretized branch.\n            if branch_offsets.size == 0 or not np.isclose(branch_offsets[0], 0.0):\n                branch_offsets = np.concatenate([[0], branch_offsets])\n                mask = np.concatenate([[True], mask])\n            length = np.hypot(*np.diff(geometry, axis=0).T).sum()\n            if not np.isclose(branch_offsets[-1], length):\n                branch_offsets = np.concatenate([branch_offsets, [length]])\n                mask = np.concatenate([mask, [True]])\n\n            # Create instance of branch object and add to dictionary\n            geo_branch = Branch(geometry, branch_offsets=branch_offsets, mask=mask)\n            self.branches[name.strip()] = geo_branch\n\n        # Convert list with all coordinates (except the appended ones for the schematized branches) to arrays\n        node_x, node_y = np.vstack(\n            [branch.node_xy[~branch.mask] for branch in self.branches.values()]\n        ).T\n\n        # Add to variables\n        self.mesh1d_node_x = node_x\n        self.mesh1d_node_y = node_y\n\n        # Calculate edge coordinates\n        edge_x, edge_y = np.vstack(\n            [\n                branch.interpolate(\n                    self.mesh1d_edge_branch_offset[self.mesh1d_edge_branch_id == i]\n                )\n                for i, branch in enumerate(self.branches.values())\n            ]\n        ).T\n\n        # Add to variables\n        self.mesh1d_edge_x = edge_x\n        self.mesh1d_edge_y = edge_y\n\n    def _network1d_node_position(self, x: float, y: float) -&gt; Union[np.int32, None]:\n        \"\"\"Determine the position (index) of a x, y coordinate in the network nodes\n\n        Args:\n            x (float): x-coordinate\n            y (float): y-coordinate\n\n        Returns:\n            Union[np.int32, None]: The index of the coordinate. None if not found\n        \"\"\"\n        return self._node_position(self.network1d_node_x, self.network1d_node_y, x, y)\n\n    def _mesh1d_node_position(self, x: float, y: float) -&gt; Union[np.int32, None]:\n        \"\"\"Determine the position (index) of a x, y coordinate in the mesh nodes\n\n        Args:\n            x (float): x-coordinate\n            y (float): y-coordinate\n\n        Returns:\n            Union[np.int32, None]: The index of the coordinate. None if not found\n        \"\"\"\n        return self._node_position(self.mesh1d_node_x, self.mesh1d_node_y, x, y)\n\n    def _node_position(\n        self, arrx: np.ndarray, arry: np.ndarray, x: float, y: float\n    ) -&gt; Union[np.int32, None]:\n        \"\"\"Determine the position (index) of a x, y coordinate in a given x and y array\n\n        Args:\n            arrx (np.ndarray): x-coordinates in which the position is sought\n            arry (np.ndarray): y-coordiantes in which the position is sought\n            x (float): x-coordinate to be sought\n            y (float): y-coordinate to be sought\n\n        Raises:\n            ValueError: If multiple positions are found for the coordinate\n\n        Returns:\n            Union[np.int32, None]: The index of the coordinate. None if not found\n        \"\"\"\n        pos = np.where(np.isclose(arrx, x, rtol=0.0) &amp; np.isclose(arry, y, rtol=0.0))[0]\n        if pos.size == 0:\n            return None\n        elif pos.size == 1:\n            return np.int32(pos[0])\n        else:\n            # Find the nearest\n            distance = np.hypot(arrx[pos] - x, arry[pos] - y)\n            if np.unique(distance).size == 1:\n                raise ValueError(\"Multiple nodes were found at the same position.\")\n            else:\n                return np.int32(pos[np.argmin(distance)])\n\n    def _add_branch(\n        self,\n        branch: Branch,\n        name: str = None,\n        branch_order: int = -1,\n        long_name: str = None,\n        force_midpoint: bool = True,\n    ):\n        \"\"\"Add the branch to mesh1d\n\n        Args:\n            branch (Branch): branch to add to the mesh1d\n            name (str): id of the branch\n            branch_order (int): interpolation order of the branch\n            long_name (str): long name of the branch\n            force_midpoint(bool): argument to control if a midpoint will be forced on the branch, use False for pipes\n\n        Returns:\n            Str: name of the branch.\n        \"\"\"\n\n        # Check if branch had coordinate discretization\n        if branch.branch_offsets.size == 0:\n            raise ValueError(\n                'Branch has no mesh discretization. Use the function \"generate_nodes\" solve generate a 1d mesh on the branch.'\n            )\n\n        if name in self.network1d_branch_id:\n            raise KeyError(f'The branch name \"{name}\" is already used.')\n        if long_name in self.network1d_branch_long_name:\n            raise KeyError(f'The branch long name \"{long_name}\" is already used.')\n\n        branch_nr = len(self.network1d_branch_id)\n        if name is None:\n            name = f\"br{branch_nr:05d}\"\n        if long_name is None:\n            long_name = name\n\n        self.branches[name] = branch\n\n        # Add branch administration\n        self.network1d_branch_order = np.append(\n            self.network1d_branch_order, branch_order\n        )\n        self.network1d_branch_length = np.append(\n            self.network1d_branch_length, branch.length\n        )\n        self.network1d_branch_id = np.append(self.network1d_branch_id, name)\n        self.network1d_branch_long_name = np.append(\n            self.network1d_branch_long_name, long_name\n        )\n\n        # Add branch geometry coordinates\n        self.network1d_part_node_count = np.append(\n            self.network1d_part_node_count, len(branch.geometry)\n        )\n        self.network1d_geom_x = np.append(self.network1d_geom_x, branch._x_coordinates)\n        self.network1d_geom_y = np.append(self.network1d_geom_y, branch._y_coordinates)\n\n        # Network edge node administration\n        # -------------------------------\n\n        first_point = branch.geometry[0]\n        last_point = branch.geometry[-1]\n\n        # Get offsets from dictionary\n        offsets = branch.branch_offsets[:]\n        # The number of links on the branch\n        nlinks = len(offsets) - 1\n\n        # Check if the first and last point of the branch are already in the set\n        first_present = self._network1d_node_position(*first_point) is not None\n        if first_present:\n            # If present, remove from branch offsets\n            offsets = offsets[1:]\n            branch.mask[0] = True\n        else:\n            # If not present, add to network nodes\n            self.network1d_node_x = np.append(self.network1d_node_x, first_point[0])\n            self.network1d_node_y = np.append(self.network1d_node_y, first_point[1])\n\n            self.network1d_node_id = np.append(\n                self.network1d_node_id, \"{:.6f}_{:.6f}\".format(*first_point)\n            )\n            self.network1d_node_long_name = np.append(\n                self.network1d_node_long_name, \"x={:.6f}_y={:.6f}\".format(*first_point)\n            )\n\n        last_present = self._network1d_node_position(*last_point) is not None\n        if last_present:\n            # If present, remove from branch offsets\n            offsets = offsets[:-1]\n            branch.mask[-1] = True\n        else:\n            # If not present, add to network nodes\n            self.network1d_node_x = np.append(self.network1d_node_x, last_point[0])\n            self.network1d_node_y = np.append(self.network1d_node_y, last_point[1])\n\n            self.network1d_node_id = np.append(\n                self.network1d_node_id, \"{:.6f}_{:.6f}\".format(*last_point)\n            )\n            self.network1d_node_long_name = np.append(\n                self.network1d_node_long_name, \"x={:.6f}_y={:.6f}\".format(*last_point)\n            )\n\n        # If no points remain, add an extra halfway: each branch should have at least 1 node\n        # Adjust the branch object as well, by adding the extra point\n        if len(offsets) == 0 and force_midpoint:\n            # Add extra offset\n            extra_offset = branch.length / 2.0\n            offsets = np.array([extra_offset])\n            nlinks += 1\n            # Adjust branch object\n            branch.branch_offsets = np.insert(branch.branch_offsets, 1, extra_offset)\n            branch.node_xy = np.insert(\n                branch.node_xy, 1, branch.interpolate(offsets), axis=0\n            )\n            branch.mask = np.insert(branch.mask, 1, False)\n\n        # Get the index of the first and last node, add as edge_nodes\n        i_from = self._network1d_node_position(first_point[0], first_point[1])\n        i_to = self._network1d_node_position(last_point[0], last_point[1])\n        if i_from == i_to:\n            raise ValueError(\n                \"Start and end node are the same. Ring geometries are not accepted.\"\n            )\n\n        self.network1d_edge_nodes = np.append(\n            self.network1d_edge_nodes,\n            np.array([[i_from, i_to]], dtype=np.int32),\n            axis=0,\n        )\n\n        # Mesh1d edge node administration\n\n        # -------------------------------\n        # First determine the start index. This is equal to the number of already present points\n        start_index = len(self.mesh1d_node_branch_id)\n        # For each link, create a new edge node connection\n        # If the first node is already present, subtract 1, since the first number will be substitud with the present node\n        if first_present:\n            start_index -= 1\n        new_edge_nodes = (\n            np.stack([np.arange(nlinks), np.arange(nlinks) + 1], axis=1) + start_index\n        ).astype(np.int32)\n\n        # If the first node is present, change the first point of the first edge to the existing point\n        if first_present:\n            new_edge_nodes[0, 0] = self._mesh1d_node_position(*first_point)\n        # If the last node is present, change the last point of the last edge too\n        if last_present:\n            new_edge_nodes[-1, 1] = self._mesh1d_node_position(*last_point)\n\n        # Add to variables\n        self.mesh1d_node_x = np.append(\n            self.mesh1d_node_x, branch.node_xy[~branch.mask, 0]\n        )\n        self.mesh1d_node_y = np.append(\n            self.mesh1d_node_y, branch.node_xy[~branch.mask, 1]\n        )\n\n        # Add to edge_nodes\n        self.mesh1d_edge_nodes = np.append(\n            self.mesh1d_edge_nodes, new_edge_nodes, axis=0\n        )\n        edge_coords = np.stack([self.mesh1d_node_x, self.mesh1d_node_y], axis=1)[\n            new_edge_nodes\n        ].mean(1)\n        edge_offsets = (branch.branch_offsets[:-1] + branch.branch_offsets[1:]) / 2\n\n        self.mesh1d_edge_branch_id = np.append(\n            self.mesh1d_edge_branch_id, np.full(len(edge_coords), branch_nr)\n        )\n        self.mesh1d_edge_branch_offset = np.append(\n            self.mesh1d_edge_branch_offset, edge_offsets\n        )\n\n        self.mesh1d_edge_x = np.append(self.mesh1d_edge_x, edge_coords[:, 0])\n        self.mesh1d_edge_y = np.append(self.mesh1d_edge_y, edge_coords[:, 1])\n\n        # Update names of nodes\n        mesh_point_names = np.array(\n            [f\"{name}_{offset:.2f}\" for offset in offsets], dtype=object\n        )\n        self.mesh1d_node_id = np.append(self.mesh1d_node_id, mesh_point_names)\n        self.mesh1d_node_long_name = np.append(\n            self.mesh1d_node_long_name, mesh_point_names\n        )\n\n        # Add mesh1d nodes\n        self.mesh1d_node_branch_id = np.append(\n            self.mesh1d_node_branch_id, np.full(len(offsets), branch_nr)\n        )\n        self.mesh1d_node_branch_offset = np.append(\n            self.mesh1d_node_branch_offset, offsets\n        )\n        return name\n\n    def get_node_mask(self, branchids: List[str] = None):\n        \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\"\n\n        mask = np.full(self.mesh1d_node_id.shape, False, dtype=bool)\n        if branchids is None:\n            mask[:] = True\n            return mask\n\n        # Get number (index) of given branches\n        idx = np.where(np.isin(self.network1d_branch_id, branchids))[0]\n        if idx.size == 0:\n            raise KeyError(\"No branches corresponding to the given keys were found.\")\n\n        mask[np.isin(self.mesh1d_node_branch_id, idx)] = True\n\n        return mask\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh1d.get_node_mask","title":"<code>get_node_mask(branchids=None)</code>","text":"<p>Get node mask, give a mask with True for each node that is in the given branchid list</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def get_node_mask(self, branchids: List[str] = None):\n    \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\"\n\n    mask = np.full(self.mesh1d_node_id.shape, False, dtype=bool)\n    if branchids is None:\n        mask[:] = True\n        return mask\n\n    # Get number (index) of given branches\n    idx = np.where(np.isin(self.network1d_branch_id, branchids))[0]\n    if idx.size == 0:\n        raise KeyError(\"No branches corresponding to the given keys were found.\")\n\n    mask[np.isin(self.mesh1d_node_branch_id, idx)] = True\n\n    return mask\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d","title":"<code>Mesh2d</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Mesh2d defines a single two dimensional grid.</p> <p>Attributes:</p> Name Type Description <code>meshkernel</code> <code>MeshKernel</code> <p>The meshkernel used to manimpulate this Mesh2d.</p> <code>mesh2d_node_z</code> <code>ndarray</code> <p>The node positions on the z-axis. Defaults to np.empty(0, dtype=np.double).</p> <code>mesh2d_face_z</code> <code>ndarray</code> <p>The face positions on the z-axis. Defaults to np.empty(0, dtype=np.double).</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class Mesh2d(BaseModel):\n    \"\"\"Mesh2d defines a single two dimensional grid.\n\n    Attributes:\n        meshkernel (mk.MeshKernel):\n            The meshkernel used to manimpulate this Mesh2d.\n        mesh2d_node_z (np.ndarray):\n            The node positions on the z-axis. Defaults to np.empty(0, dtype=np.double).\n        mesh2d_face_z (np.ndarray):\n            The face positions on the z-axis. Defaults to np.empty(0, dtype=np.double).\n    \"\"\"\n\n    meshkernel: mk.MeshKernel = Field(default_factory=mk.MeshKernel)\n\n    # placeholders for bathymetry\n    mesh2d_node_z: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, dtype=np.double)\n    )\n    mesh2d_face_z: np.ndarray = Field(\n        default_factory=lambda: np.empty(0, dtype=np.double)\n    )\n\n    @property\n    def mesh2d_node_x(self) -&gt; np.ndarray[float]:\n        \"\"\"The x-coordinates of the nodes in the mesh.\n\n        Returns:\n            ndarray[float]: A 1D double array describing the x-coordinates of the nodes.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().node_x\n\n    @property\n    def mesh2d_node_y(self) -&gt; np.ndarray[float]:\n        \"\"\"The y-coordinates of the nodes in the mesh.\n\n        Returns:\n            ndarray[float]: A 1D double array describing the y-coordinates of the nodes.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().node_y\n\n    @property\n    def mesh2d_edge_x(self) -&gt; np.ndarray[float]:\n        \"\"\"The x-coordinates of the mesh edges' middle points.\n\n        Returns:\n            ndarray[float]: A 1D double array describing x-coordinates of the mesh edges' middle points.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().edge_x\n\n    @property\n    def mesh2d_edge_y(self) -&gt; np.ndarray[float]:\n        \"\"\"The y-coordinates of the mesh edges' middle points.\n\n        Returns:\n            ndarray[float]: A 1D double array describing y-coordinates of the mesh edges' middle points.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().edge_y\n\n    @property\n    def mesh2d_edge_nodes(self) -&gt; np.ndarray[int, int]:\n        \"\"\"The node indices of the mesh edges.\n\n        Returns:\n            np.ndarray[int, int]: A 2D integer array (nEdges, 2) containg the two node indices for each edge.\n        \"\"\"\n        mesh2d_output = self.meshkernel.mesh2d_get()\n        edge_nodes = mesh2d_output.edge_nodes.reshape((-1, 2))\n        return edge_nodes\n\n    @property\n    def mesh2d_face_x(self) -&gt; np.ndarray[float]:\n        \"\"\"The x-coordinates of the mesh faces' mass centers.\n\n        Returns:\n            ndarray[float]: A 1D double array describing x-coordinates of the mesh faces' mass centers.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().face_x\n\n    @property\n    def mesh2d_face_y(self) -&gt; np.ndarray[float]:\n        \"\"\"The y-coordinates of the mesh faces' mass centers.\n\n        Returns:\n            ndarray[float]: A 1D double array describing y-coordinates of the mesh faces' mass centers.\n        \"\"\"\n        return self.meshkernel.mesh2d_get().face_y\n\n    @property\n    def mesh2d_face_nodes(self) -&gt; np.ndarray[int, int]:\n        \"\"\"The node indices of the mesh faces\n\n        Returns:\n            np.ndarray[int, int]: A 2D integer array describing the nodes composing each mesh 2d face. A 2D integer array (nFaces, maxNodesPerFace) containg the node indices for each face.\n        \"\"\"\n        mesh2d_output = self.meshkernel.mesh2d_get()\n        npf = mesh2d_output.nodes_per_face\n        if self.is_empty():\n            return np.empty((0, 0), dtype=np.int32)\n        face_node_connectivity = np.full(\n            (len(mesh2d_output.face_x), max(npf)), np.iinfo(np.int32).min\n        )\n        idx = (\n            np.ones_like(face_node_connectivity) * np.arange(max(npf))[None, :]\n        ) &lt; npf[:, None]\n        face_node_connectivity[idx] = mesh2d_output.face_nodes\n        return face_node_connectivity\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Determine whether this Mesh2d is empty.\n\n        Returns:\n            (bool): Whether this Mesh2d is empty.\n        \"\"\"\n        return self.mesh2d_node_x.size == 0\n\n    def read_file(self, file_path: Path) -&gt; None:\n        \"\"\"Read the Mesh2d from the file at file_path.\n\n        Args:\n            file_path (Path): Path to the file to be read.\n        \"\"\"\n        reader = UgridReader(file_path)\n        reader.read_mesh2d(self)\n\n    def _set_mesh2d(self, node_x, node_y, edge_nodes) -&gt; None:\n        mesh2d = mk.Mesh2d(\n            node_x=node_x.astype(np.float64),\n            node_y=node_y.astype(np.float64),\n            edge_nodes=edge_nodes.ravel().astype(np.int32),\n        )\n\n        self.meshkernel.mesh2d_set(mesh2d)\n\n    def get_mesh2d(self) -&gt; mk.Mesh2d:\n        \"\"\"Get the mesh2d as represented in the MeshKernel\n\n        Returns:\n            (mk.Mesh2d): The mesh2d as represented in the MeshKernel\n        \"\"\"\n        return self.meshkernel.mesh2d_get()\n\n    def create_rectilinear(self, extent: tuple, dx: float, dy: float) -&gt; None:\n        \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds\n\n        Args:\n            extent (tuple): Bounding box of mesh (left, bottom, right, top)\n            dx (float): Horizontal distance\n            dy (float): Vertical distance\n\n        Raises:\n            NotImplementedError: MultiPolygons\n        \"\"\"\n\n        xmin, ymin, xmax, ymax = extent\n\n        rows = int((ymax - ymin) / dy)\n        columns = int((xmax - xmin) / dx)\n\n        params = mk.MakeGridParameters(\n            num_columns=columns,\n            num_rows=rows,\n            origin_x=xmin,\n            origin_y=ymin,\n            block_size_x=dx,\n            block_size_y=dy,\n        )\n\n        mesh2d_input = self.meshkernel  # mk.MeshKernel()\n        mesh2d_input.curvilinear_compute_rectangular_grid(params)\n        mesh2d_input.curvilinear_convert_to_mesh2d()  # convert to ugrid/mesh2d\n\n    def create_triangular(self, geometry_list: mk.GeometryList) -&gt; None:\n        \"\"\"Create triangular grid within GeometryList object\n\n        Args:\n            geometry_list (mk.GeometryList): GeometryList represeting a polygon within which the mesh is generated.\n        \"\"\"\n        # Call meshkernel\n        self.meshkernel.mesh2d_make_triangular_mesh_from_polygon(geometry_list)\n\n    def clip(\n        self,\n        geometrylist: mk.GeometryList,\n        deletemeshoption: mk.DeleteMeshOption = mk.DeleteMeshOption.INSIDE_NOT_INTERSECTED,\n        inside=False,\n    ) -&gt; None:\n        \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped. It is also possible to clip inside a polygon with holes.\n\n\n        Args:\n            geometrylist (GeometryList): Polygon stored as GeometryList\n            deletemeshoption (int, optional): [description]. Defaults to 1.\n        \"\"\"\n\n        # For clipping outside\n        if not inside:\n            # Check if a multipolygon was provided when clipping outside\n            if geometrylist.geometry_separator in geometrylist.x_coordinates:\n                raise NotImplementedError(\n                    \"Deleting outside more than a single exterior (MultiPolygon) is not implemented.\"\n                )\n\n            # Get exterior and interiors\n            parts = split_by(geometrylist, geometrylist.inner_outer_separator)\n\n            exteriors = [parts[0]]\n            interiors = parts[1:]\n\n            # Check if parts are closed\n            for part in exteriors + interiors:\n                if (part.x_coordinates[0], part.y_coordinates[0]) != (\n                    part.x_coordinates[-1],\n                    part.y_coordinates[-1],\n                ):\n                    raise ValueError(\n                        \"First and last coordinate of each GeometryList part should match.\"\n                    )\n\n        # Inside\n        else:\n            # Get exterior and interiors\n            parts = split_by(geometrylist, geometrylist.geometry_separator)\n            exteriors = parts[:]\n            interiors = []\n\n        # Delete everything outside the (Multi)Polygon\n        for exterior in exteriors:\n            self.meshkernel.mesh2d_delete(\n                geometry_list=exterior,\n                delete_option=deletemeshoption,\n                invert_deletion=not inside,\n            )\n\n        # Delete all holes.\n        for interior in interiors:\n            self.meshkernel.mesh2d_delete(\n                geometry_list=interior,\n                delete_option=deletemeshoption,\n                invert_deletion=inside,\n            )\n\n    def refine(\n        self,\n        polygon: mk.GeometryList,\n        level: int,\n        parameters: mk.MeshRefinementParameters = None,\n    ):\n        \"\"\"Refine the mesh within a polygon, by a number of steps (level)\n\n        Args:\n            polygon (GeometryList): Polygon in which to refine\n            level (int): Number of refinement steps\n            parameters (MeshRefinementParameters): object containing the Meshkernel refinement parameters. Default values are taken from meskernel documentation.\n        \"\"\"\n        if parameters is None:\n            parameters = mk.MeshRefinementParameters(\n                refine_intersected=True,\n                use_mass_center_when_refining=True,\n                min_edge_size=1.0,\n                refinement_type=2,\n                connect_hanging_nodes=True,\n                account_for_samples_outside_face=True,\n                max_refinement_iterations=1,\n                smoothing_iterations=5,\n                max_courant_time=120.0,\n                directional_refinement=False,\n            )\n        parameters.max_refinement_iterations = level\n        self.meshkernel.mesh2d_refine_based_on_polygon(polygon, parameters)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_edge_nodes","title":"<code>mesh2d_edge_nodes</code>  <code>property</code>","text":"<p>The node indices of the mesh edges.</p> <p>Returns:</p> Type Description <code>ndarray[int, int]</code> <p>np.ndarray[int, int]: A 2D integer array (nEdges, 2) containg the two node indices for each edge.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_edge_x","title":"<code>mesh2d_edge_x</code>  <code>property</code>","text":"<p>The x-coordinates of the mesh edges' middle points.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing x-coordinates of the mesh edges' middle points.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_edge_y","title":"<code>mesh2d_edge_y</code>  <code>property</code>","text":"<p>The y-coordinates of the mesh edges' middle points.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing y-coordinates of the mesh edges' middle points.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_face_nodes","title":"<code>mesh2d_face_nodes</code>  <code>property</code>","text":"<p>The node indices of the mesh faces</p> <p>Returns:</p> Type Description <code>ndarray[int, int]</code> <p>np.ndarray[int, int]: A 2D integer array describing the nodes composing each mesh 2d face. A 2D integer array (nFaces, maxNodesPerFace) containg the node indices for each face.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_face_x","title":"<code>mesh2d_face_x</code>  <code>property</code>","text":"<p>The x-coordinates of the mesh faces' mass centers.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing x-coordinates of the mesh faces' mass centers.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_face_y","title":"<code>mesh2d_face_y</code>  <code>property</code>","text":"<p>The y-coordinates of the mesh faces' mass centers.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing y-coordinates of the mesh faces' mass centers.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_node_x","title":"<code>mesh2d_node_x</code>  <code>property</code>","text":"<p>The x-coordinates of the nodes in the mesh.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing the x-coordinates of the nodes.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.mesh2d_node_y","title":"<code>mesh2d_node_y</code>  <code>property</code>","text":"<p>The y-coordinates of the nodes in the mesh.</p> <p>Returns:</p> Type Description <code>ndarray[float]</code> <p>ndarray[float]: A 1D double array describing the y-coordinates of the nodes.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.clip","title":"<code>clip(geometrylist, deletemeshoption=mk.DeleteMeshOption.INSIDE_NOT_INTERSECTED, inside=False)</code>","text":"<p>Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped. It is also possible to clip inside a polygon with holes.</p> <p>Parameters:</p> Name Type Description Default <code>geometrylist</code> <code>GeometryList</code> <p>Polygon stored as GeometryList</p> required <code>deletemeshoption</code> <code>int</code> <p>[description]. Defaults to 1.</p> <code>INSIDE_NOT_INTERSECTED</code> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def clip(\n    self,\n    geometrylist: mk.GeometryList,\n    deletemeshoption: mk.DeleteMeshOption = mk.DeleteMeshOption.INSIDE_NOT_INTERSECTED,\n    inside=False,\n) -&gt; None:\n    \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped. It is also possible to clip inside a polygon with holes.\n\n\n    Args:\n        geometrylist (GeometryList): Polygon stored as GeometryList\n        deletemeshoption (int, optional): [description]. Defaults to 1.\n    \"\"\"\n\n    # For clipping outside\n    if not inside:\n        # Check if a multipolygon was provided when clipping outside\n        if geometrylist.geometry_separator in geometrylist.x_coordinates:\n            raise NotImplementedError(\n                \"Deleting outside more than a single exterior (MultiPolygon) is not implemented.\"\n            )\n\n        # Get exterior and interiors\n        parts = split_by(geometrylist, geometrylist.inner_outer_separator)\n\n        exteriors = [parts[0]]\n        interiors = parts[1:]\n\n        # Check if parts are closed\n        for part in exteriors + interiors:\n            if (part.x_coordinates[0], part.y_coordinates[0]) != (\n                part.x_coordinates[-1],\n                part.y_coordinates[-1],\n            ):\n                raise ValueError(\n                    \"First and last coordinate of each GeometryList part should match.\"\n                )\n\n    # Inside\n    else:\n        # Get exterior and interiors\n        parts = split_by(geometrylist, geometrylist.geometry_separator)\n        exteriors = parts[:]\n        interiors = []\n\n    # Delete everything outside the (Multi)Polygon\n    for exterior in exteriors:\n        self.meshkernel.mesh2d_delete(\n            geometry_list=exterior,\n            delete_option=deletemeshoption,\n            invert_deletion=not inside,\n        )\n\n    # Delete all holes.\n    for interior in interiors:\n        self.meshkernel.mesh2d_delete(\n            geometry_list=interior,\n            delete_option=deletemeshoption,\n            invert_deletion=inside,\n        )\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.create_rectilinear","title":"<code>create_rectilinear(extent, dx, dy)</code>","text":"<p>Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>tuple</code> <p>Bounding box of mesh (left, bottom, right, top)</p> required <code>dx</code> <code>float</code> <p>Horizontal distance</p> required <code>dy</code> <code>float</code> <p>Vertical distance</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>MultiPolygons</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def create_rectilinear(self, extent: tuple, dx: float, dy: float) -&gt; None:\n    \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds\n\n    Args:\n        extent (tuple): Bounding box of mesh (left, bottom, right, top)\n        dx (float): Horizontal distance\n        dy (float): Vertical distance\n\n    Raises:\n        NotImplementedError: MultiPolygons\n    \"\"\"\n\n    xmin, ymin, xmax, ymax = extent\n\n    rows = int((ymax - ymin) / dy)\n    columns = int((xmax - xmin) / dx)\n\n    params = mk.MakeGridParameters(\n        num_columns=columns,\n        num_rows=rows,\n        origin_x=xmin,\n        origin_y=ymin,\n        block_size_x=dx,\n        block_size_y=dy,\n    )\n\n    mesh2d_input = self.meshkernel  # mk.MeshKernel()\n    mesh2d_input.curvilinear_compute_rectangular_grid(params)\n    mesh2d_input.curvilinear_convert_to_mesh2d()  # convert to ugrid/mesh2d\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.create_triangular","title":"<code>create_triangular(geometry_list)</code>","text":"<p>Create triangular grid within GeometryList object</p> <p>Parameters:</p> Name Type Description Default <code>geometry_list</code> <code>GeometryList</code> <p>GeometryList represeting a polygon within which the mesh is generated.</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def create_triangular(self, geometry_list: mk.GeometryList) -&gt; None:\n    \"\"\"Create triangular grid within GeometryList object\n\n    Args:\n        geometry_list (mk.GeometryList): GeometryList represeting a polygon within which the mesh is generated.\n    \"\"\"\n    # Call meshkernel\n    self.meshkernel.mesh2d_make_triangular_mesh_from_polygon(geometry_list)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.get_mesh2d","title":"<code>get_mesh2d()</code>","text":"<p>Get the mesh2d as represented in the MeshKernel</p> <p>Returns:</p> Type Description <code>Mesh2d</code> <p>The mesh2d as represented in the MeshKernel</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def get_mesh2d(self) -&gt; mk.Mesh2d:\n    \"\"\"Get the mesh2d as represented in the MeshKernel\n\n    Returns:\n        (mk.Mesh2d): The mesh2d as represented in the MeshKernel\n    \"\"\"\n    return self.meshkernel.mesh2d_get()\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.is_empty","title":"<code>is_empty()</code>","text":"<p>Determine whether this Mesh2d is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether this Mesh2d is empty.</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Determine whether this Mesh2d is empty.\n\n    Returns:\n        (bool): Whether this Mesh2d is empty.\n    \"\"\"\n    return self.mesh2d_node_x.size == 0\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.read_file","title":"<code>read_file(file_path)</code>","text":"<p>Read the Mesh2d from the file at file_path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file to be read.</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def read_file(self, file_path: Path) -&gt; None:\n    \"\"\"Read the Mesh2d from the file at file_path.\n\n    Args:\n        file_path (Path): Path to the file to be read.\n    \"\"\"\n    reader = UgridReader(file_path)\n    reader.read_mesh2d(self)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Mesh2d.refine","title":"<code>refine(polygon, level, parameters=None)</code>","text":"<p>Refine the mesh within a polygon, by a number of steps (level)</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>GeometryList</code> <p>Polygon in which to refine</p> required <code>level</code> <code>int</code> <p>Number of refinement steps</p> required <code>parameters</code> <code>MeshRefinementParameters</code> <p>object containing the Meshkernel refinement parameters. Default values are taken from meskernel documentation.</p> <code>None</code> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def refine(\n    self,\n    polygon: mk.GeometryList,\n    level: int,\n    parameters: mk.MeshRefinementParameters = None,\n):\n    \"\"\"Refine the mesh within a polygon, by a number of steps (level)\n\n    Args:\n        polygon (GeometryList): Polygon in which to refine\n        level (int): Number of refinement steps\n        parameters (MeshRefinementParameters): object containing the Meshkernel refinement parameters. Default values are taken from meskernel documentation.\n    \"\"\"\n    if parameters is None:\n        parameters = mk.MeshRefinementParameters(\n            refine_intersected=True,\n            use_mass_center_when_refining=True,\n            min_edge_size=1.0,\n            refinement_type=2,\n            connect_hanging_nodes=True,\n            account_for_samples_outside_face=True,\n            max_refinement_iterations=1,\n            smoothing_iterations=5,\n            max_courant_time=120.0,\n            directional_refinement=False,\n        )\n    parameters.max_refinement_iterations = level\n    self.meshkernel.mesh2d_refine_based_on_polygon(polygon, parameters)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network","title":"<code>Network</code>","text":"Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class Network:\n    def __init__(self, is_geographic: bool = False) -&gt; None:\n        if not is_geographic:\n            projection = mk.ProjectionType.CARTESIAN\n        else:\n            projection = mk.ProjectionType.SPHERICAL\n\n        self.meshkernel = mk.MeshKernel(projection=projection)\n        self._mesh1d = Mesh1d(meshkernel=self.meshkernel)\n        self._mesh2d = Mesh2d(meshkernel=self.meshkernel)\n        self._link1d2d = Link1d2d(meshkernel=self.meshkernel)\n\n        # Spatial index (rtree)\n        # self._idx = index.Index()\n\n    @classmethod\n    def from_file(cls, file_path: Path) -&gt; Network:\n        \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d &amp; network1d, mesh2d, link1d2d) are\n        present, and loads them one by one.\n\n        Args:\n            file_path (Path): path to netcdf file with network data\n\n        Returns:\n            Network: The instance of the class itself that is returned\n        \"\"\"\n\n        network = cls()\n        ds = nc.Dataset(file_path)  # type: ignore[import]\n\n        reader = UgridReader(file_path)\n\n        reader.read_mesh1d_network1d(network._mesh1d)\n        reader.read_mesh2d(network._mesh2d)\n        reader.read_link1d2d(network._link1d2d)\n\n        ds.close()\n\n        return network\n\n    def to_file(self, file: Path) -&gt; None:\n        \"\"\"Write network to file\n\n        Args:\n            file (Path): File where _net.nc is written to.\n        \"\"\"\n\n        writer = UgridWriter()\n        writer.write(self, file)\n\n    @property\n    def is_geographic(self) -&gt; bool:\n        \"\"\"Whether or not this network has a geographic projection.\n\n        Returns:\n            bool: True if this network is geographic; otherwise, False.\n        \"\"\"\n        projection = self.meshkernel.get_projection()\n        if projection == mk.ProjectionType.CARTESIAN:\n            return False\n        else:\n            return True\n\n    def link1d2d_from_1d_to_2d(\n        self, branchids: List[str] = None, polygon: GeometryList = None\n    ) -&gt; None:\n        self._mesh1d._set_mesh1d()\n\n        node_mask = self._mesh1d.get_node_mask(branchids)\n        if polygon is None:\n            polygon = self.meshkernel.mesh2d_get_mesh_boundaries_as_polygons()\n\n        self._link1d2d._link_from_1d_to_2d(node_mask, polygon=polygon)\n\n    def mesh2d_create_rectilinear_within_extent(\n        self, extent: tuple, dx: float, dy: float\n    ) -&gt; None:\n        self._mesh2d.create_rectilinear(extent=extent, dx=dx, dy=dy)\n\n    def mesh2d_create_triangular_within_polygon(self, polygon: mk.GeometryList) -&gt; None:\n        \"\"\"Create triangular grid within GeometryList object. Calls _mesh2d.create_triangular\n        directly, but is easier accessible for users.\n\n        Args:\n            polygon (mk.GeometryList): GeometryList representing a polygon within which the mesh is generated.\n        \"\"\"\n        self._mesh2d.create_triangular(geometry_list=polygon)\n\n    def mesh2d_clip_mesh(\n        self,\n        geometrylist: mk.GeometryList,\n        deletemeshoption: mk.DeleteMeshOption = mk.DeleteMeshOption.INSIDE_NOT_INTERSECTED,\n        inside=True,\n    ) -&gt; None:\n        self._mesh2d.clip(\n            geometrylist=geometrylist,\n            deletemeshoption=deletemeshoption,\n            inside=inside,\n        )\n\n    def mesh2d_refine_mesh(\n        self,\n        polygon: mk.GeometryList,\n        level: int = None,\n        parameters: mk.MeshRefineParameters = None,\n    ):\n        self._mesh2d.refine(polygon=polygon, level=level, parameters=parameters)\n\n    def mesh1d_add_branch(\n        self,\n        branch: Branch,\n        name: str = None,\n        branch_order: int = -1,\n        long_name: str = None,\n        force_midpoint: bool = True,\n    ) -&gt; None:\n        name = self._mesh1d._add_branch(\n            branch=branch,\n            name=name,\n            branch_order=branch_order,\n            long_name=long_name,\n            force_midpoint=force_midpoint,\n        )\n        self._mesh1d._set_mesh1d()\n        return name\n\n    def plot(self, ax=None):\n        \"\"\"Create a plot of the 1d2d links and edges within this network.\n\n        Args:\n            ax (matplotlib.pyplot.Axes, optional): The axes where to plot the edges. Defaults to None.\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        if ax is None:\n            _, ax = plt.subplots()\n        mesh2d_output = self._mesh2d.get_mesh2d()\n        mesh1d_output = self._mesh1d._get_mesh1d()\n        links_output = self._link1d2d.meshkernel.contacts_get()\n        mesh2d_output.plot_edges(ax=ax, color=\"r\")\n        mesh1d_output.plot_edges(ax=ax, color=\"g\")\n        links_output.plot_edges(\n            ax=ax, mesh1d=mesh1d_output, mesh2d=mesh2d_output, color=\"k\"\n        )\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network.is_geographic","title":"<code>is_geographic</code>  <code>property</code>","text":"<p>Whether or not this network has a geographic projection.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if this network is geographic; otherwise, False.</p>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network.from_file","title":"<code>from_file(file_path)</code>  <code>classmethod</code>","text":"<p>Read network from file. This classmethod checks what mesh components (mesh1d &amp; network1d, mesh2d, link1d2d) are present, and loads them one by one.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>path to netcdf file with network data</p> required <p>Returns:</p> Name Type Description <code>Network</code> <code>Network</code> <p>The instance of the class itself that is returned</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>@classmethod\ndef from_file(cls, file_path: Path) -&gt; Network:\n    \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d &amp; network1d, mesh2d, link1d2d) are\n    present, and loads them one by one.\n\n    Args:\n        file_path (Path): path to netcdf file with network data\n\n    Returns:\n        Network: The instance of the class itself that is returned\n    \"\"\"\n\n    network = cls()\n    ds = nc.Dataset(file_path)  # type: ignore[import]\n\n    reader = UgridReader(file_path)\n\n    reader.read_mesh1d_network1d(network._mesh1d)\n    reader.read_mesh2d(network._mesh2d)\n    reader.read_link1d2d(network._link1d2d)\n\n    ds.close()\n\n    return network\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network.mesh2d_create_triangular_within_polygon","title":"<code>mesh2d_create_triangular_within_polygon(polygon)</code>","text":"<p>Create triangular grid within GeometryList object. Calls _mesh2d.create_triangular directly, but is easier accessible for users.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>GeometryList</code> <p>GeometryList representing a polygon within which the mesh is generated.</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def mesh2d_create_triangular_within_polygon(self, polygon: mk.GeometryList) -&gt; None:\n    \"\"\"Create triangular grid within GeometryList object. Calls _mesh2d.create_triangular\n    directly, but is easier accessible for users.\n\n    Args:\n        polygon (mk.GeometryList): GeometryList representing a polygon within which the mesh is generated.\n    \"\"\"\n    self._mesh2d.create_triangular(geometry_list=polygon)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network.plot","title":"<code>plot(ax=None)</code>","text":"<p>Create a plot of the 1d2d links and edges within this network.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes where to plot the edges. Defaults to None.</p> <code>None</code> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def plot(self, ax=None):\n    \"\"\"Create a plot of the 1d2d links and edges within this network.\n\n    Args:\n        ax (matplotlib.pyplot.Axes, optional): The axes where to plot the edges. Defaults to None.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        _, ax = plt.subplots()\n    mesh2d_output = self._mesh2d.get_mesh2d()\n    mesh1d_output = self._mesh1d._get_mesh1d()\n    links_output = self._link1d2d.meshkernel.contacts_get()\n    mesh2d_output.plot_edges(ax=ax, color=\"r\")\n    mesh1d_output.plot_edges(ax=ax, color=\"g\")\n    links_output.plot_edges(\n        ax=ax, mesh1d=mesh1d_output, mesh2d=mesh2d_output, color=\"k\"\n    )\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.Network.to_file","title":"<code>to_file(file)</code>","text":"<p>Write network to file</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Path</code> <p>File where _net.nc is written to.</p> required Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def to_file(self, file: Path) -&gt; None:\n    \"\"\"Write network to file\n\n    Args:\n        file (Path): File where _net.nc is written to.\n    \"\"\"\n\n    writer = UgridWriter()\n    writer.write(self, file)\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.NetworkModel","title":"<code>NetworkModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Network model representation.</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>class NetworkModel(ParsableFileModel):\n    \"\"\"Network model representation.\"\"\"\n\n    network: Network = Field(default_factory=Network)\n\n    def _post_init_load(self) -&gt; None:\n        \"\"\"\n        Load the network file if the filepath exists relative to the\n        current FileLoadContext.\n        \"\"\"\n        super()._post_init_load()\n\n        if self.filepath is None:\n            return\n\n        with file_load_context() as context:\n            network_path = context.resolve(self.filepath)\n\n            if network_path.is_file():\n                self.network = Network.from_file(network_path)\n\n    @property\n    def _mesh1d(self):\n        return self.network._mesh1d\n\n    @property\n    def _mesh2d(self):\n        return self.network._mesh2d\n\n    @property\n    def _link1d2d(self):\n        return self.network._link1d2d\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".nc\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"network\"\n\n    def _save(self, save_settings: ModelSaveSettings):\n        with file_load_context() as context:\n            write_path = context.resolve(self.filepath)  # type: ignore[arg-type]\n\n            write_path.parent.mkdir(parents=True, exist_ok=True)\n            self.network.to_file(write_path)\n\n    def _export(self, folder: Path) -&gt; None:\n        filename = Path(self.filepath.name) if self.filepath else self._generate_name()\n        self.filepath = folder / filename\n        folder.mkdir(parents=True, exist_ok=True)\n        self.network.to_file(self.filepath)\n\n    def _parse(self, _):\n        return {}\n\n    @classmethod\n    def _get_serializer(cls):\n        # Unused, but requires abstract implementation\n        pass\n\n    @classmethod\n    def _get_parser(cls):\n        # Unused, but requires abstract implementation\n        pass\n\n    @property\n    def plot(self):\n        return self.network.plot\n</code></pre>"},{"location":"reference/models/net/#hydrolib.core.dflowfm.net.models.split_by","title":"<code>split_by(gl, by)</code>","text":"<p>Function to split mk.GeometryList by seperator.</p> <p>Parameters:</p> Name Type Description Default <code>gl</code> <code>GeometryList</code> <p>The geometry list to split.</p> required <code>by</code> <code>float</code> <p>The value by which to split the gl.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The split lists.</p> Source code in <code>hydrolib/core/dflowfm/net/models.py</code> <pre><code>def split_by(gl: mk.GeometryList, by: float) -&gt; list:\n    \"\"\"Function to split mk.GeometryList by seperator.\n\n    Args:\n        gl (mk.GeometryList): The geometry list to split.\n        by (float): The value by which to split the gl.\n\n    Returns:\n        list: The split lists.\n    \"\"\"\n    x, y = gl.x_coordinates.copy(), gl.y_coordinates.copy()\n    idx = np.where(x == by)[0]\n\n    xparts = np.split(x, idx)\n    yparts = np.split(y, idx)\n\n    lists = [\n        mk.GeometryList(xp[min(i, 1) :], yp[min(i, 1) :])\n        for i, (xp, yp) in enumerate(zip(xparts, yparts))\n    ]\n\n    return lists\n</code></pre>"},{"location":"reference/models/observationcrosssection/","title":"Observation cross section files","text":"<p>Observation cross section files come in two flavours:</p> <ul> <li>the official <code>*_crs.ini</code> format see below</li> <li>the legacy <code>*.pli</code> format  see below</li> </ul>"},{"location":"reference/models/observationcrosssection/#observation-cross-section-ini-files","title":"Observation cross section .ini files","text":"<p>The <code>obscrosssection</code> module provides the specific logic for accessing observation cross section .ini files. for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>An observation cross section .ini file is described by the classes below.</p>"},{"location":"reference/models/observationcrosssection/#model","title":"Model","text":""},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.obscrosssection.models.ObservationCrossSection","title":"<code>ObservationCrossSection</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The observation cross section that is included in the observation cross section file.</p> <p>All lowercased attributes match with the observation cross section output as described in [UM Sec.F2.4.1] (https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsubsection.F.2.4.1)</p> Source code in <code>hydrolib/core/dflowfm/obscrosssection/models.py</code> <pre><code>class ObservationCrossSection(INIBasedModel):\n    \"\"\"\n    The observation cross section that is included in the\n    observation cross section file.\n\n    All lowercased attributes match with the observation cross\n    section output as described in [UM Sec.F2.4.1]\n    (https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsubsection.F.2.4.1)\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        name: Optional[str] = \"Name of the cross section (max. 255 characters).\"\n        branchid: Optional[str] = Field(\n            \"(optional) Branch on which the cross section is located.\", alias=\"branchId\"\n        )\n        chainage: Optional[str] = \"(optional) Location on the branch (m).\"\n        numcoordinates: Optional[str] = Field(\n            \"(optional) Number of values in xCoordinates and yCoordinates. \"\n            \"This value should be greater than or equal to 2.\",\n            alias=\"numCoordinates\",\n        )\n        xcoordinates: Optional[str] = Field(\n            \"(optional) x-coordinates of the cross section line. \"\n            \"(number of values = numCoordinates)\",\n            alias=\"xCoordinates\",\n        )\n        ycoordinates: Optional[str] = Field(\n            \"(optional) y-coordinates of the cross section line. \"\n            \"(number of values = numCoordinates)\",\n            alias=\"yCoordinates\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"ObservationCrossSection\"] = \"ObservationCrossSection\"\n    name: str = Field(max_length=255, alias=\"name\")\n    branchid: Optional[str] = Field(alias=\"branchId\")\n    chainage: Optional[float] = Field(alias=\"chainage\")\n    numcoordinates: Optional[int] = Field(alias=\"numCoordinates\")\n    xcoordinates: Optional[List[float]] = Field(alias=\"xCoordinates\")\n    ycoordinates: Optional[List[float]] = Field(alias=\"yCoordinates\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"xcoordinates\", \"ycoordinates\"\n    )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the correct location specification is given.\"\"\"\n        return validate_location_specification(\n            values,\n            config=LocationValidationConfiguration(\n                validate_node=False,\n                minimum_num_coordinates=2,\n                validate_location_type=False,\n            ),\n        )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.obscrosssection.models.ObservationCrossSection.validate_that_location_specification_is_correct","title":"<code>validate_that_location_specification_is_correct(values)</code>","text":"<p>Validates that the correct location specification is given.</p> Source code in <code>hydrolib/core/dflowfm/obscrosssection/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n    \"\"\"Validates that the correct location specification is given.\"\"\"\n    return validate_location_specification(\n        values,\n        config=LocationValidationConfiguration(\n            validate_node=False,\n            minimum_num_coordinates=2,\n            validate_location_type=False,\n        ),\n    )\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.obscrosssection.models.ObservationCrossSectionGeneral","title":"<code>ObservationCrossSectionGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The observation cross section file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/obscrosssection/models.py</code> <pre><code>class ObservationCrossSectionGeneral(INIGeneral):\n    \"\"\"The observation cross section file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'obsCross'. Do not edit this.\", alias=\"fileType\"\n        )\n\n    comments: Comments = Comments()\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"obsCross\"] = Field(\"obsCross\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.obscrosssection.models.ObservationCrossSectionModel","title":"<code>ObservationCrossSectionModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall observation cross section model that contains the contents of one observation cross section file.</p> Source code in <code>hydrolib/core/dflowfm/obscrosssection/models.py</code> <pre><code>class ObservationCrossSectionModel(INIModel):\n    \"\"\"\n    The overall observation cross section model that contains the contents\n    of one observation cross section file.\n    \"\"\"\n\n    general: ObservationCrossSectionGeneral = ObservationCrossSectionGeneral()\n    observationcrosssection: List[ObservationCrossSection] = []\n</code></pre>"},{"location":"reference/models/observationcrosssection/#legacy-observation-cross-section-pli-files","title":"Legacy observation cross section .pli files","text":"<p>Legacy .pli files for observation points are supported via the generic <code>polyfile</code> module.</p> <p>A polyfile (hence also an observation cross section .pli file) is described by the classes below.</p>"},{"location":"reference/models/observationcrosssection/#model_1","title":"Model","text":"<p>models.py defines all classes and functions related to representing pol/pli(z) files.</p>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.Description","title":"<code>Description</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Description of a single PolyObject.</p> <p>The Description will be prepended to a block. Each line will start with a '*'.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>The content of this Description.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Description(BaseModel):\n    \"\"\"Description of a single PolyObject.\n\n    The Description will be prepended to a block. Each line will\n    start with a '*'.\n\n    Attributes:\n        content (str): The content of this Description.\n    \"\"\"\n\n    content: str\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.Metadata","title":"<code>Metadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata of a single PolyObject.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the PolyObject</p> <code>n_rows</code> <code>int</code> <p>The number of rows (i.e. Point instances) of the PolyObject</p> <code>n_columns</code> <code>int</code> <p>The total number of values in a Point, including x, y, and z.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Metadata(BaseModel):\n    \"\"\"Metadata of a single PolyObject.\n\n    Attributes:\n        name (str): The name of the PolyObject\n        n_rows (int): The number of rows (i.e. Point instances) of the PolyObject\n        n_columns (int): The total number of values in a Point, including x, y, and z.\n    \"\"\"\n\n    name: str\n    n_rows: int\n    n_columns: int\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Point consisting of a x and y coordinate, an optional z coordinate and data.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>The x-coordinate of this Point</p> <code>y</code> <code>float</code> <p>The y-coordinate of this Point</p> <code>z</code> <code>Optional[float]</code> <p>An optional z-coordinate of this Point.</p> <code>data</code> <code>Sequence[float]</code> <p>The additional data variables of this Point.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Point(BaseModel):\n    \"\"\"Point consisting of a x and y coordinate, an optional z coordinate and data.\n\n    Attributes:\n        x (float): The x-coordinate of this Point\n        y (float): The y-coordinate of this Point\n        z (Optional[float]): An optional z-coordinate of this Point.\n        data (Sequence[float]): The additional data variables of this Point.\n    \"\"\"\n\n    x: float\n    y: float\n    z: Optional[float]\n    data: Sequence[float]\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        x = data.get(\"x\")\n        y = data.get(\"y\")\n        z = data.get(\"z\")\n        return f\"x:{x} y:{y} z:{z}\"\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyFile","title":"<code>PolyFile</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Poly-file (.pol/.pli/.pliz) representation.</p> Notes <ul> <li>The <code>has_z_values</code> attribute is used to determine if the PolyFile contains z-values.</li> <li>The <code>has_z_values</code> is false by default and should be set to true if the PolyFile path ends with <code>.pliz</code>.</li> <li>The <code>***.pliz</code> file should have a 2*3 structure, where the third column contains the z-values, otherwise (the parser will give an error).</li> <li>If there is a label in the file, the parser will ignore the label and read the file as a normal polyline file. <pre><code>tfl_01\n    2 2\n    0.00 1.00 #zee\n    0.00 2.00 #zee\n</code></pre></li> <li>if the file is .pliz, and the dimensions are 2*5 the first three columns will be considered as x, y, z values and the last two columns will be considered as data values. <pre><code>L1\n    2 5\n    63.35 12.95 -4.20 -5.35 0\n    45.20 6.35 -3.00 -2.90 0\n</code></pre></li> </ul> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class PolyFile(ParsableFileModel):\n    \"\"\"\n    Poly-file (.pol/.pli/.pliz) representation.\n\n    Notes:\n        - The `has_z_values` attribute is used to determine if the PolyFile contains z-values.\n        - The `has_z_values` is false by default and should be set to true if the PolyFile path ends with `.pliz`.\n        - The `***.pliz` file should have a 2*3 structure, where the third column contains the z-values, otherwise\n        (the parser will give an error).\n        - If there is a label in the file, the parser will ignore the label and read the file as a normal polyline file.\n        ```\n        tfl_01\n            2 2\n            0.00 1.00 #zee\n            0.00 2.00 #zee\n        ```\n        - if the file is .pliz, and the dimensions are 2*5 the first three columns will be considered as x, y, z values\n        and the last two columns will be considered as data values.\n        ```\n        L1\n            2 5\n            63.35 12.95 -4.20 -5.35 0\n            45.20 6.35 -3.00 -2.90 0\n        ```\n    \"\"\"\n\n    has_z_values: bool = False\n    objects: Sequence[PolyObject] = Field(default_factory=list)\n\n    def _serialize(self, _: dict, save_settings: ModelSaveSettings) -&gt; None:\n        from .serializer import write_polyfile\n\n        # We skip the passed dict for a better one.\n        write_polyfile(self._resolved_filepath, self.objects, self.serializer_config)\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".pli\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"objects\"\n\n    @classmethod\n    def _get_serializer(cls) -&gt; Callable:\n        # Unused, but requires abstract implementation\n        pass\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        # Prevent circular dependency in Parser\n        from hydrolib.core.dflowfm.polyfile.parser import read_polyfile\n\n        return read_polyfile\n\n    @property\n    def x(self) -&gt; List[float]:\n        \"\"\"X-coordinates of all points in the PolyFile.\"\"\"\n        return [point.x for obj in self.objects for point in obj.points]\n\n    @property\n    def y(self) -&gt; List[float]:\n        \"\"\"Y-coordinates of all points in the PolyFile.\"\"\"\n        return [point.y for obj in self.objects for point in obj.points]\n\n    def get_z_sources_sinks(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"\n        Get the z values of the source and sink points from the polyline file.\n\n        Returns:\n            z_source, z_sinkA: Tuple[List[float]]:\n            If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.\n            Otherwise, the z_source and the z_sink will be a single value each.\n\n        Note:\n             - calling this method on a polyline file that does not have z-values will return a list of None.\n\n        Examples:\n        in case the polyline has 3 columns:\n            &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [-3.0] [-4.2]\n\n        in case the polyline has more than 3 columns:\n            &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [-3.0, -2.9] [-4.2, -5.35]\n\n        in case the polyline does not have z-values:\n            &gt;&gt;&gt; root_dir = \"tests/data/input/dflowfm_individual_files/polylines\"\n            &gt;&gt;&gt; polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\")\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [None] [None]\n        \"\"\"\n        has_data = True if self.objects[0].points[0].data else False\n\n        z_source_sink = []\n        for elem in [0, -1]:\n            point = self.objects[0].points[elem]\n            if has_data:\n                z_source_sink.append([point.z, point.data[0]])\n            else:\n                z_source_sink.append([point.z])\n\n        z_sink: list[float | None] = z_source_sink[0]\n        z_source: list[float | None] = z_source_sink[1]\n        return z_source, z_sink\n\n    @property\n    def number_of_points(self) -&gt; int:\n        \"\"\"Total number of points in the PolyFile.\"\"\"\n        return len(self.x)\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyFile.number_of_points","title":"<code>number_of_points</code>  <code>property</code>","text":"<p>Total number of points in the PolyFile.</p>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyFile.x","title":"<code>x</code>  <code>property</code>","text":"<p>X-coordinates of all points in the PolyFile.</p>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyFile.y","title":"<code>y</code>  <code>property</code>","text":"<p>Y-coordinates of all points in the PolyFile.</p>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyFile.get_z_sources_sinks","title":"<code>get_z_sources_sinks()</code>","text":"<p>Get the z values of the source and sink points from the polyline file.</p> <p>Returns:</p> Type Description <code>List[float]</code> <p>z_source, z_sinkA: Tuple[List[float]]:</p> <code>List[float]</code> <p>If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.</p> <code>Tuple[List[float], List[float]]</code> <p>Otherwise, the z_source and the z_sink will be a single value each.</p> Note <ul> <li>calling this method on a polyline file that does not have z-values will return a list of None.</li> </ul> <p>Examples:</p> <p>in case the polyline has 3 columns:     &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")     &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()     &gt;&gt;&gt; print(z_source, z_sink)     [-3.0][-4.2]</p> in case the polyline has more than 3 columns <p>polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP z_source, z_sink = polyline.get_z_sources_sinks() print(z_source, z_sink) [-3.0, -2.9][-4.2, -5.35]</p> in case the polyline does not have z-values <p>root_dir = \"tests/data/input/dflowfm_individual_files/polylines\" polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\") z_source, z_sink = polyline.get_z_sources_sinks() print(z_source, z_sink) [None][]</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>def get_z_sources_sinks(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"\n    Get the z values of the source and sink points from the polyline file.\n\n    Returns:\n        z_source, z_sinkA: Tuple[List[float]]:\n        If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.\n        Otherwise, the z_source and the z_sink will be a single value each.\n\n    Note:\n         - calling this method on a polyline file that does not have z-values will return a list of None.\n\n    Examples:\n    in case the polyline has 3 columns:\n        &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [-3.0] [-4.2]\n\n    in case the polyline has more than 3 columns:\n        &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [-3.0, -2.9] [-4.2, -5.35]\n\n    in case the polyline does not have z-values:\n        &gt;&gt;&gt; root_dir = \"tests/data/input/dflowfm_individual_files/polylines\"\n        &gt;&gt;&gt; polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\")\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [None] [None]\n    \"\"\"\n    has_data = True if self.objects[0].points[0].data else False\n\n    z_source_sink = []\n    for elem in [0, -1]:\n        point = self.objects[0].points[elem]\n        if has_data:\n            z_source_sink.append([point.z, point.data[0]])\n        else:\n            z_source_sink.append([point.z])\n\n    z_sink: list[float | None] = z_source_sink[0]\n    z_source: list[float | None] = z_source_sink[1]\n    return z_source, z_sink\n</code></pre>"},{"location":"reference/models/observationcrosssection/#hydrolib.core.dflowfm.polyfile.models.PolyObject","title":"<code>PolyObject</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>PolyObject describing a single block in a poly file.</p> <p>The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the   metadata.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>Optional[Description]</code> <p>An optional description of this PolyObject</p> <code>metadata</code> <code>Metadata</code> <p>The Metadata of this PolObject, describing the structure</p> <code>points</code> <code>List[Point]</code> <p>The points describing this PolyObject, structured according to the Metadata</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class PolyObject(BaseModel):\n    \"\"\"PolyObject describing a single block in a poly file.\n\n    The metadata should be consistent with the points:\n    - The number of points should be equal to number of rows defined in the metadata\n    - The data of each point should be equal to the number of columns defined in the\n      metadata.\n\n    Attributes:\n        description (Optional[Description]):\n            An optional description of this PolyObject\n        metadata (Metadata):\n            The Metadata of this PolObject, describing the structure\n        points (List[Point]):\n            The points describing this PolyObject, structured according to the Metadata\n    \"\"\"\n\n    description: Optional[Description]\n    metadata: Metadata\n    points: List[Point]\n</code></pre>"},{"location":"reference/models/observationpoint/","title":"Observation point files","text":"<p>Observation point files come in two flavours:</p> <ul> <li>the official <code>*_obs.ini</code> format see below</li> <li>the legacy <code>*.xyn</code> format  see below</li> </ul>"},{"location":"reference/models/observationpoint/#observation-point-ini-files","title":"Observation point .ini files","text":"<p>The <code>obs</code> module provides the specific logic for accessing observation point .ini files for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>An observation point .ini file is described by the classes below.</p>"},{"location":"reference/models/observationpoint/#model","title":"Model","text":""},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.obs.models.ObservationPoint","title":"<code>ObservationPoint</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>An observation point that is included in the observation point file.</p> <p>All lowercased attributes match with the observation point input as described in UM Sec.F.2.2.1.</p> Source code in <code>hydrolib/core/dflowfm/obs/models.py</code> <pre><code>class ObservationPoint(INIBasedModel):\n    \"\"\"\n    An observation point that is included in the observation point file.\n\n    All lowercased attributes match with the observation point input as described in\n    [UM Sec.F.2.2.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsubsection.F.2.2.1).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        name: Optional[str] = \"Name of the observation point (max. 255 characters).\"\n        locationtype: Optional[str] = (\n            \"Only when x and y are also specified. 1d: snap to closest 1D grid point, 2d: snap to closest 2D grid cell centre, all: snap to closest 1D or 2D point.\"\n        )\n        branchid: Optional[str] = Field(\n            \"Branch on which the observation point is located.\", alias=\"branchId\"\n        )\n        chainage: Optional[str] = \"Chainage on the branch (m).\"\n\n        x: Optional[str] = Field(\n            \"x-coordinate of the location of the observation point.\",\n            alias=\"x\",\n        )\n        y: Optional[str] = Field(\n            \"y-coordinate of the location of the observation point.\",\n            alias=\"y\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"ObservationPoint\"] = \"ObservationPoint\"\n\n    name: str = Field(\"id\", max_length=255, alias=\"name\")\n    locationtype: Optional[LocationType] = Field(None, alias=\"locationType\")\n\n    branchid: Optional[str] = Field(None, alias=\"branchId\")\n    chainage: Optional[float] = Field(None, alias=\"chainage\")\n\n    x: Optional[float] = Field(None, alias=\"x\")\n    y: Optional[float] = Field(None, alias=\"y\")\n\n    _type_validator = get_enum_validator(\"locationtype\", enum=LocationType)\n\n    @root_validator(allow_reuse=True)\n    def validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the correct location specification is given.\"\"\"\n        return validate_location_specification(\n            values,\n            config=LocationValidationConfiguration(\n                validate_node=False, validate_num_coordinates=False\n            ),\n            fields=LocationValidationFieldNames(x_coordinates=\"x\", y_coordinates=\"y\"),\n        )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"name\")\n</code></pre>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.obs.models.ObservationPoint.validate_that_location_specification_is_correct","title":"<code>validate_that_location_specification_is_correct(values)</code>","text":"<p>Validates that the correct location specification is given.</p> Source code in <code>hydrolib/core/dflowfm/obs/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_location_specification_is_correct(cls, values: Dict) -&gt; Dict:\n    \"\"\"Validates that the correct location specification is given.\"\"\"\n    return validate_location_specification(\n        values,\n        config=LocationValidationConfiguration(\n            validate_node=False, validate_num_coordinates=False\n        ),\n        fields=LocationValidationFieldNames(x_coordinates=\"x\", y_coordinates=\"y\"),\n    )\n</code></pre>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.obs.models.ObservationPointGeneral","title":"<code>ObservationPointGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The observation point file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/obs/models.py</code> <pre><code>class ObservationPointGeneral(INIGeneral):\n    \"\"\"The observation point file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'obsPoints'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"obsPoints\"] = Field(\"obsPoints\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.obs.models.ObservationPointModel","title":"<code>ObservationPointModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall observation point model that contains the contents of one observation point file.</p> <p>This model is typically referenced under a FMModel<code>.output.obsfile[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>ObservationPointGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>observationpoint</code> <code>List[ObservationPoint]</code> <p>List of <code>[ObservationPoint]</code> blocks for all observation points.</p> Source code in <code>hydrolib/core/dflowfm/obs/models.py</code> <pre><code>class ObservationPointModel(INIModel):\n    \"\"\"\n    The overall observation point model that contains the contents of one observation point file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.output.obsfile[..]`.\n\n    Attributes:\n        general (ObservationPointGeneral): `[General]` block with file metadata.\n        observationpoint (List[ObservationPoint]): List of `[ObservationPoint]` blocks for all observation points.\n    \"\"\"\n\n    general: ObservationPointGeneral = ObservationPointGeneral()\n    observationpoint: List[ObservationPoint] = []\n\n    _make_list = make_list_validator(\"observationpoint\")\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"obsFile\"\n</code></pre>"},{"location":"reference/models/observationpoint/#legacy-observation-point-xyn-files","title":"Legacy observation point .xyn files","text":"<p>The <code>xyn</code> module provides the specific logic for accessing legacy observation point files for a D-Flow FM model.</p> <p>An observation point .xyn file is described by the classes below.</p>"},{"location":"reference/models/observationpoint/#model_1","title":"Model","text":""},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNModel","title":"<code>XYNModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Observation station (.xyn) file.</p> Source code in <code>hydrolib/core/dflowfm/xyn/models.py</code> <pre><code>class XYNModel(ParsableFileModel):\n    \"\"\"Observation station (.xyn) file.\"\"\"\n\n    points: List[XYNPoint] = []\n    \"\"\"List[`XYNPoint`]: List of XYN points.\"\"\"\n\n    def dict(self, *args, **kwargs):\n        # speed up serializing by not converting these lowest models to dict\n        return dict(points=self.points)\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"stations_obs\"\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".xyn\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return XYNSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable[[Path], Dict]:\n        return XYNParser.parse\n</code></pre>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNModel.points","title":"<code>points = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[<code>XYNPoint</code>]: List of XYN points.</p>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNPoint","title":"<code>XYNPoint</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single XYN point, representing a named station location.</p> Source code in <code>hydrolib/core/dflowfm/xyn/models.py</code> <pre><code>class XYNPoint(BaseModel):\n    \"\"\"Single XYN point, representing a named station location.\"\"\"\n\n    x: float\n    \"\"\"float: The x or \u03bb coordinate.\"\"\"\n\n    y: float\n    \"\"\"float: The y or \u03c6 coordinate.\"\"\"\n\n    n: str\n    \"\"\"float: The name of the point.\"\"\"\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        x = data.get(\"x\")\n        y = data.get(\"y\")\n        n = data.get(\"n\")\n        return f\"x:{x} y:{y} n:{n}\"\n\n    @validator(\"n\", pre=True)\n    def _validate_name(cls, value):\n        if str_is_empty_or_none(value):\n            raise ValueError(\"Name cannot be empty.\")\n\n        if \"'\" in value or '\"' in value:\n            raise ValueError(\n                \"Name cannot contain single or double quotes except at the start and end.\"\n            )\n\n        return value\n</code></pre>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNPoint.n","title":"<code>n</code>  <code>instance-attribute</code>","text":"<p>float: The name of the point.</p>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNPoint.x","title":"<code>x</code>  <code>instance-attribute</code>","text":"<p>float: The x or \u03bb coordinate.</p>"},{"location":"reference/models/observationpoint/#hydrolib.core.dflowfm.xyn.models.XYNPoint.y","title":"<code>y</code>  <code>instance-attribute</code>","text":"<p>float: The y or \u03c6 coordinate.</p>"},{"location":"reference/models/onedfield/","title":"1D field INI files","text":"<p>The 1D field INI files contain the spatial input data for 1D network initial conditions for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>The 1D field INI file is represented by the classes below.</p>"},{"location":"reference/models/onedfield/#model","title":"Model","text":""},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldBranch","title":"<code>OneDFieldBranch</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A <code>[Branch]</code> block for use inside a 1D field file.</p> <p>Each block can define value(s) on a particular branch.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>class OneDFieldBranch(INIBasedModel):\n    \"\"\"\n    A `[Branch]` block for use inside a 1D field file.\n\n    Each block can define value(s) on a particular branch.\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        branchid: Optional[str] = Field(\"The name of the branch\", alias=\"branchId\")\n        numlocations: Optional[str] = Field(\n            \"Number of locations on branch. The default 0 value implies branch uniform values.\",\n            alias=\"numLocations\",\n        )\n        chainage: Optional[str] = Field(\n            \"Space separated list of locations on the branch (m). Locations sorted by increasing chainage. The keyword must be specified if numLocations &gt;0.\",\n            alias=\"chainage\",\n        )\n        values: Optional[str] = Field(\n            \"Space separated list of numLocations values; one for each chainage specified. One value required if numLocations =0\",\n            alias=\"values\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Branch\"] = \"Branch\"\n\n    branchid: str = Field(alias=\"branchId\")\n    numlocations: Optional[NonNegativeInt] = Field(0, alias=\"numLocations\")\n    chainage: Optional[List[float]] = Field(alias=\"chainage\")\n    values: List[float] = Field(alias=\"values\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"chainage\",\n        \"values\",\n    )\n\n    @root_validator(allow_reuse=True)\n    def check_list_length_values(cls, values):\n        \"\"\"Validates that the length of the values field is as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"values\",\n            length_name=\"numlocations\",\n            list_required_with_length=True,\n            min_length=1,\n        )\n\n    @root_validator(allow_reuse=True)\n    def check_list_length_chainage(cls, values):\n        \"\"\"Validates that the length of the chainage field is as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"chainage\",\n            length_name=\"numlocations\",\n            list_required_with_length=True,\n        )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"branchid\")\n</code></pre>"},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldBranch.check_list_length_chainage","title":"<code>check_list_length_chainage(values)</code>","text":"<p>Validates that the length of the chainage field is as expected.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_length_chainage(cls, values):\n    \"\"\"Validates that the length of the chainage field is as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"chainage\",\n        length_name=\"numlocations\",\n        list_required_with_length=True,\n    )\n</code></pre>"},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldBranch.check_list_length_values","title":"<code>check_list_length_values(values)</code>","text":"<p>Validates that the length of the values field is as expected.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_length_values(cls, values):\n    \"\"\"Validates that the length of the values field is as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"values\",\n        length_name=\"numlocations\",\n        list_required_with_length=True,\n        min_length=1,\n    )\n</code></pre>"},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldGeneral","title":"<code>OneDFieldGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The 1D field file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>class OneDFieldGeneral(INIGeneral):\n    \"\"\"The 1D field file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be '1dField'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"1dField\"] = Field(\"1dField\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldGlobal","title":"<code>OneDFieldGlobal</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>The <code>[Global]</code> block with a uniform value for use inside a 1D field file.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>class OneDFieldGlobal(INIBasedModel):\n    \"\"\"The `[Global]` block with a uniform value for use inside a 1D field file.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        quantity: Optional[str] = Field(\"The name of the quantity\", alias=\"quantity\")\n        unit: Optional[str] = Field(\"The unit of the quantity\", alias=\"unit\")\n        value: Optional[str] = Field(\n            \"The global default value for this quantity\", alias=\"value\"\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"Global\"] = \"Global\"\n\n    quantity: str = Field(alias=\"quantity\")\n    unit: str = Field(alias=\"unit\")\n    value: float = Field(alias=\"value\")\n</code></pre>"},{"location":"reference/models/onedfield/#hydrolib.core.dflowfm.onedfield.models.OneDFieldModel","title":"<code>OneDFieldModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall 1D field model that contains the contents of a 1D field file.</p> <p>This model is typically used when a FMModel<code>.geometry.inifieldfile[..].initial[..].datafiletype==DataFileType.onedfield</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>OneDFieldGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>global_</code> <code>Optional[OneDFieldGlobal]</code> <p>Optional <code>[Global]</code> block with uniform value.</p> <code>branch</code> <code>List[OneDFieldBranch]</code> <p>Definitions of <code>[Branch]</code> field values.</p> Source code in <code>hydrolib/core/dflowfm/onedfield/models.py</code> <pre><code>class OneDFieldModel(INIModel):\n    \"\"\"\n    The overall 1D field model that contains the contents of a 1D field file.\n\n    This model is typically used when a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.inifieldfile[..].initial[..].datafiletype==DataFileType.onedfield`.\n\n    Attributes:\n        general (OneDFieldGeneral): `[General]` block with file metadata.\n        global_ (Optional[OneDFieldGlobal]): Optional `[Global]` block with uniform value.\n        branch (List[OneDFieldBranch]): Definitions of `[Branch]` field values.\n    \"\"\"\n\n    general: OneDFieldGeneral = OneDFieldGeneral()\n    global_: Optional[OneDFieldGlobal] = Field(\n        alias=\"global\"\n    )  # to circumvent built-in kw\n    branch: List[OneDFieldBranch] = []\n\n    _split_to_list = make_list_validator(\n        \"branch\",\n    )\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ini\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"1dfield\"\n</code></pre>"},{"location":"reference/models/polyfile/","title":"Polyline/Polygon Files Documentation","text":""},{"location":"reference/models/polyfile/#overview","title":"Overview","text":"<p>Polyline (.pli/.pliz) and polygon (.pol) files are basic spatial input files for a D-Flow FM model to select particular locations, and are used in various other input files. The <code>hydrolib.core.dflowfm.polyfile</code> module provides functionality for reading, writing, and manipulating these files.</p> <p>Polyline files consist of one or more blocks, each containing: 1. An optional description (lines starting with <code>*</code>) 2. A name line 3. A dimensions line (number of rows and columns) 4. A series of points with coordinates and optional data</p>"},{"location":"reference/models/polyfile/#file-format","title":"File Format","text":"<p>A typical polyline file has the following structure:</p> <pre><code>* Optional description line 1\n* Optional description line 2\nname_of_polyline\n2    3    # number_of_points number_of_columns\n    10.0    20.0    0.0    # x y z\n    30.0    40.0    0.0    # x y z\n</code></pre> <p>The file can contain multiple such blocks, each defining a separate polyline object.</p>"},{"location":"reference/models/polyfile/#class-diagram","title":"Class Diagram","text":""},{"location":"reference/models/polyfile/#mermaid-class-diagram","title":"Mermaid Class Diagram","text":"<pre><code>classDiagram\n    class Description {\n        +str content\n    }\n\n    class Metadata {\n        +str name\n        +int n_rows\n        +int n_columns\n    }\n\n    class Point {\n        +float x\n        +float y\n        +Optional float z\n        +List data\n    }\n\n    class PolyObject {\n        +Optional Description description\n        +Metadata metadata\n        +List~Point~ points\n    }\n\n    class PolyFile {\n        +bool has_z_values\n        +List~PolyObject~ objects\n        +List~float~ x()\n        +List~float~ y()\n        +int number_of_points()\n        +get_z_sources_sinks()\n    }\n\n    class Parser {\n        +feed_line()\n        +finalize()\n    }\n\n    class Serializer {\n        +serialize_*()\n    }\n\n    PolyObject o-- Point : contains\n    PolyObject o-- Description : contains\n    PolyObject *-- Metadata : contains\n    PolyFile o-- PolyObject : contains\n    PolyFile ..&gt; Parser : uses\n    PolyFile ..&gt; Serializer : uses</code></pre>"},{"location":"reference/models/polyfile/#ascii-class-diagram","title":"ASCII Class Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Description  \u2502     \u2502    Metadata   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 content: str  \u2502     \u2502 name: str     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 n_rows: int   \u2502\n                      \u2502 n_columns: int\u2502\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u25b2\n                             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Point     \u2502\u25c4\u2500\u2500\u2500\u2500\u2502   PolyObject  \u2502     \u2502   PolyFile    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 x: float      \u2502     \u2502 description   \u2502\u25c4\u2500\u2500\u2500\u2500\u2502 has_z_values  \u2502\n\u2502 y: float      \u2502     \u2502 metadata      \u2502     \u2502 objects       \u2502\n\u2502 z: Optional   \u2502     \u2502 points        \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 data: List    \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n                                                    \u25bc\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502    Parser     \u2502     \u2502  Serializer   \u2502\n                      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                      \u2502 feed_line()   \u2502     \u2502 serialize_*() \u2502\n                      \u2502 finalize()    \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/models/polyfile/#core-classes","title":"Core Classes","text":""},{"location":"reference/models/polyfile/#polyfile","title":"PolyFile","text":"<p><code>PolyFile</code> is the main class representing a polyline file. It inherits from <code>ParsableFileModel</code> and provides methods for reading, writing, and accessing polyline data.</p> <p>Key methods: - <code>x</code> property: Returns all x-coordinates as a list - <code>y</code> property: Returns all y-coordinates as a list - <code>get_z_sources_sinks()</code>: Gets z-values for source and sink points - <code>number_of_points</code> property: Returns the total number of points</p>"},{"location":"reference/models/polyfile/#polyobject","title":"PolyObject","text":"<p><code>PolyObject</code> represents a single block in a polyline file, containing a description, metadata, and a list of points.</p>"},{"location":"reference/models/polyfile/#point","title":"Point","text":"<p><code>Point</code> represents a single point in a polyline, with x and y coordinates, an optional z coordinate, and additional data values.</p>"},{"location":"reference/models/polyfile/#metadata","title":"Metadata","text":"<p><code>Metadata</code> contains information about a polyline block, including the name, number of rows (points), and number of columns (values per point).</p>"},{"location":"reference/models/polyfile/#description","title":"Description","text":"<p><code>Description</code> represents comments for a polyline block, with content starting with <code>*</code> in the file.</p>"},{"location":"reference/models/polyfile/#sequence-diagram-reading-a-polyfile","title":"Sequence Diagram: Reading a Polyfile","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Client \u2502          \u2502 PolyFile \u2502          \u2502 Parser \u2502          \u2502 PolyObject \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502 PolyFile(filepath)  \u2502                    \u2502                     \u2502\n     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502                    \u2502                     \u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502                     \u2502 read_polyfile()    \u2502                     \u2502\n     \u2502                     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502                     \u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502                     \u2502                    \u2502 feed_line()         \u2502\n     \u2502                     \u2502                    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502                     \u2502                    \u2502 finalize()          \u2502\n     \u2502                     \u2502                    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502                     \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                     \u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n     \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                    \u2502                     \u2502\n     \u2502                     \u2502                    \u2502                     \u2502\n</code></pre>"},{"location":"reference/models/polyfile/#sequence-diagram-writing-a-polyfile","title":"Sequence Diagram: Writing a Polyfile","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Client \u2502          \u2502 PolyFile \u2502          \u2502 Serializer \u2502          \u2502    File    \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502 polyfile.save()     \u2502                      \u2502                       \u2502\n     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502                      \u2502                       \u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502                     \u2502 write_polyfile()     \u2502                       \u2502\n     \u2502                     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502                       \u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502                     \u2502                      \u2502 serialize_poly_object()\u2502\n     \u2502                     \u2502                      \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502                     \u2502                      \u2502 write lines           \u2502\n     \u2502                     \u2502                      \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502                     \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                       \u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n     \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                      \u2502                       \u2502\n     \u2502                     \u2502                      \u2502                       \u2502\n</code></pre>"},{"location":"reference/models/polyfile/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/models/polyfile/#reading-a-polyline-file","title":"Reading a Polyline File","text":"<pre><code>from pathlib import Path\nfrom hydrolib.core.dflowfm.polyfile.models import PolyFile\n\n# Read a polyline file\npolyfile = PolyFile(filepath=Path(\"path/to/file.pli\"))\n\n# Access the polyline objects\nfor poly_obj in polyfile.objects:\n    print(f\"Name: {poly_obj.metadata.name}\")\n    print(f\"Number of points: {len(poly_obj.points)}\")\n\n    # Access points\n    for point in poly_obj.points:\n        print(f\"  Point: ({point.x}, {point.y})\")\n        if point.z is not None:\n            print(f\"  Z-value: {point.z}\")\n        if point.data:\n            print(f\"  Data: {point.data}\")\n</code></pre>"},{"location":"reference/models/polyfile/#creating-and-writing-a-polyline-file","title":"Creating and Writing a Polyline File","text":"<pre><code>from pathlib import Path\nfrom hydrolib.core.dflowfm.polyfile.models import PolyFile, PolyObject, Metadata, Point, Description\n\n# Create a new polyline file\npolyfile = PolyFile(has_z_values=True)\n\n# Create a polyline object\npoly_obj = PolyObject(\n    description=Description(content=\"This is a test polyline\"),\n    metadata=Metadata(name=\"test_polyline\", n_rows=2, n_columns=3),\n    points=[\n        Point(x=10.0, y=20.0, z=0.0, data=[]),\n        Point(x=30.0, y=40.0, z=1.0, data=[])\n    ]\n)\n\n# Add the polyline object to the file\npolyfile.objects = [poly_obj]\n\n# Save the file\npolyfile.save(filepath=Path(\"path/to/output.pli\"))\n</code></pre>"},{"location":"reference/models/polyfile/#accessing-coordinates","title":"Accessing Coordinates","text":"<pre><code>from pathlib import Path\nfrom hydrolib.core.dflowfm.polyfile.models import PolyFile\n\n# Read a polyline file\npolyfile = PolyFile(filepath=Path(\"path/to/file.pli\"))\n\n# Get all x and y coordinates\nx_coords = polyfile.x\ny_coords = polyfile.y\n\n# Get the total number of points\ntotal_points = polyfile.number_of_points\n\n# Get z-values for source and sink points (for .pliz files)\nz_source, z_sink = polyfile.get_z_sources_sinks()\n</code></pre>"},{"location":"reference/models/polyfile/#file-extensions","title":"File Extensions","text":"<p>The module supports different file extensions: - <code>.pli</code>: Standard polyline file - <code>.pol</code>: Polygon file (same format as .pli) - <code>.pliz</code>: Polyline file with z-values</p>"},{"location":"reference/models/polyfile/#error-handling","title":"Error Handling","text":"<p>The parser includes robust error handling for various issues: - Invalid dimensions - Missing points - Invalid point data - Empty lines (generates warnings) - Incomplete blocks</p>"},{"location":"reference/models/polyfile/#api-reference","title":"API Reference","text":""},{"location":"reference/models/polyfile/#model","title":"Model","text":"<p>models.py defines all classes and functions related to representing pol/pli(z) files.</p>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.Description","title":"<code>Description</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Description of a single PolyObject.</p> <p>The Description will be prepended to a block. Each line will start with a '*'.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>The content of this Description.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Description(BaseModel):\n    \"\"\"Description of a single PolyObject.\n\n    The Description will be prepended to a block. Each line will\n    start with a '*'.\n\n    Attributes:\n        content (str): The content of this Description.\n    \"\"\"\n\n    content: str\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.Metadata","title":"<code>Metadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata of a single PolyObject.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the PolyObject</p> <code>n_rows</code> <code>int</code> <p>The number of rows (i.e. Point instances) of the PolyObject</p> <code>n_columns</code> <code>int</code> <p>The total number of values in a Point, including x, y, and z.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Metadata(BaseModel):\n    \"\"\"Metadata of a single PolyObject.\n\n    Attributes:\n        name (str): The name of the PolyObject\n        n_rows (int): The number of rows (i.e. Point instances) of the PolyObject\n        n_columns (int): The total number of values in a Point, including x, y, and z.\n    \"\"\"\n\n    name: str\n    n_rows: int\n    n_columns: int\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Point consisting of a x and y coordinate, an optional z coordinate and data.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>The x-coordinate of this Point</p> <code>y</code> <code>float</code> <p>The y-coordinate of this Point</p> <code>z</code> <code>Optional[float]</code> <p>An optional z-coordinate of this Point.</p> <code>data</code> <code>Sequence[float]</code> <p>The additional data variables of this Point.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class Point(BaseModel):\n    \"\"\"Point consisting of a x and y coordinate, an optional z coordinate and data.\n\n    Attributes:\n        x (float): The x-coordinate of this Point\n        y (float): The y-coordinate of this Point\n        z (Optional[float]): An optional z-coordinate of this Point.\n        data (Sequence[float]): The additional data variables of this Point.\n    \"\"\"\n\n    x: float\n    y: float\n    z: Optional[float]\n    data: Sequence[float]\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        x = data.get(\"x\")\n        y = data.get(\"y\")\n        z = data.get(\"z\")\n        return f\"x:{x} y:{y} z:{z}\"\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyFile","title":"<code>PolyFile</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Poly-file (.pol/.pli/.pliz) representation.</p> Notes <ul> <li>The <code>has_z_values</code> attribute is used to determine if the PolyFile contains z-values.</li> <li>The <code>has_z_values</code> is false by default and should be set to true if the PolyFile path ends with <code>.pliz</code>.</li> <li>The <code>***.pliz</code> file should have a 2*3 structure, where the third column contains the z-values, otherwise (the parser will give an error).</li> <li>If there is a label in the file, the parser will ignore the label and read the file as a normal polyline file. <pre><code>tfl_01\n    2 2\n    0.00 1.00 #zee\n    0.00 2.00 #zee\n</code></pre></li> <li>if the file is .pliz, and the dimensions are 2*5 the first three columns will be considered as x, y, z values and the last two columns will be considered as data values. <pre><code>L1\n    2 5\n    63.35 12.95 -4.20 -5.35 0\n    45.20 6.35 -3.00 -2.90 0\n</code></pre></li> </ul> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class PolyFile(ParsableFileModel):\n    \"\"\"\n    Poly-file (.pol/.pli/.pliz) representation.\n\n    Notes:\n        - The `has_z_values` attribute is used to determine if the PolyFile contains z-values.\n        - The `has_z_values` is false by default and should be set to true if the PolyFile path ends with `.pliz`.\n        - The `***.pliz` file should have a 2*3 structure, where the third column contains the z-values, otherwise\n        (the parser will give an error).\n        - If there is a label in the file, the parser will ignore the label and read the file as a normal polyline file.\n        ```\n        tfl_01\n            2 2\n            0.00 1.00 #zee\n            0.00 2.00 #zee\n        ```\n        - if the file is .pliz, and the dimensions are 2*5 the first three columns will be considered as x, y, z values\n        and the last two columns will be considered as data values.\n        ```\n        L1\n            2 5\n            63.35 12.95 -4.20 -5.35 0\n            45.20 6.35 -3.00 -2.90 0\n        ```\n    \"\"\"\n\n    has_z_values: bool = False\n    objects: Sequence[PolyObject] = Field(default_factory=list)\n\n    def _serialize(self, _: dict, save_settings: ModelSaveSettings) -&gt; None:\n        from .serializer import write_polyfile\n\n        # We skip the passed dict for a better one.\n        write_polyfile(self._resolved_filepath, self.objects, self.serializer_config)\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".pli\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"objects\"\n\n    @classmethod\n    def _get_serializer(cls) -&gt; Callable:\n        # Unused, but requires abstract implementation\n        pass\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        # Prevent circular dependency in Parser\n        from hydrolib.core.dflowfm.polyfile.parser import read_polyfile\n\n        return read_polyfile\n\n    @property\n    def x(self) -&gt; List[float]:\n        \"\"\"X-coordinates of all points in the PolyFile.\"\"\"\n        return [point.x for obj in self.objects for point in obj.points]\n\n    @property\n    def y(self) -&gt; List[float]:\n        \"\"\"Y-coordinates of all points in the PolyFile.\"\"\"\n        return [point.y for obj in self.objects for point in obj.points]\n\n    def get_z_sources_sinks(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"\n        Get the z values of the source and sink points from the polyline file.\n\n        Returns:\n            z_source, z_sinkA: Tuple[List[float]]:\n            If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.\n            Otherwise, the z_source and the z_sink will be a single value each.\n\n        Note:\n             - calling this method on a polyline file that does not have z-values will return a list of None.\n\n        Examples:\n        in case the polyline has 3 columns:\n            &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [-3.0] [-4.2]\n\n        in case the polyline has more than 3 columns:\n            &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [-3.0, -2.9] [-4.2, -5.35]\n\n        in case the polyline does not have z-values:\n            &gt;&gt;&gt; root_dir = \"tests/data/input/dflowfm_individual_files/polylines\"\n            &gt;&gt;&gt; polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\")\n            &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n            &gt;&gt;&gt; print(z_source, z_sink)\n            [None] [None]\n        \"\"\"\n        has_data = True if self.objects[0].points[0].data else False\n\n        z_source_sink = []\n        for elem in [0, -1]:\n            point = self.objects[0].points[elem]\n            if has_data:\n                z_source_sink.append([point.z, point.data[0]])\n            else:\n                z_source_sink.append([point.z])\n\n        z_sink: list[float | None] = z_source_sink[0]\n        z_source: list[float | None] = z_source_sink[1]\n        return z_source, z_sink\n\n    @property\n    def number_of_points(self) -&gt; int:\n        \"\"\"Total number of points in the PolyFile.\"\"\"\n        return len(self.x)\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyFile.number_of_points","title":"<code>number_of_points</code>  <code>property</code>","text":"<p>Total number of points in the PolyFile.</p>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyFile.x","title":"<code>x</code>  <code>property</code>","text":"<p>X-coordinates of all points in the PolyFile.</p>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyFile.y","title":"<code>y</code>  <code>property</code>","text":"<p>Y-coordinates of all points in the PolyFile.</p>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyFile.get_z_sources_sinks","title":"<code>get_z_sources_sinks()</code>","text":"<p>Get the z values of the source and sink points from the polyline file.</p> <p>Returns:</p> Type Description <code>List[float]</code> <p>z_source, z_sinkA: Tuple[List[float]]:</p> <code>List[float]</code> <p>If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.</p> <code>Tuple[List[float], List[float]]</code> <p>Otherwise, the z_source and the z_sink will be a single value each.</p> Note <ul> <li>calling this method on a polyline file that does not have z-values will return a list of None.</li> </ul> <p>Examples:</p> <p>in case the polyline has 3 columns:     &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")     &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()     &gt;&gt;&gt; print(z_source, z_sink)     [-3.0][-4.2]</p> in case the polyline has more than 3 columns <p>polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP z_source, z_sink = polyline.get_z_sources_sinks() print(z_source, z_sink) [-3.0, -2.9][-4.2, -5.35]</p> in case the polyline does not have z-values <p>root_dir = \"tests/data/input/dflowfm_individual_files/polylines\" polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\") z_source, z_sink = polyline.get_z_sources_sinks() print(z_source, z_sink) [None][]</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>def get_z_sources_sinks(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"\n    Get the z values of the source and sink points from the polyline file.\n\n    Returns:\n        z_source, z_sinkA: Tuple[List[float]]:\n        If the polyline has data (more than 3 columns), then both the z_source and z_sink will be a list of two values.\n        Otherwise, the z_source and the z_sink will be a single value each.\n\n    Note:\n         - calling this method on a polyline file that does not have z-values will return a list of None.\n\n    Examples:\n    in case the polyline has 3 columns:\n        &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor.pliz\")\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [-3.0] [-4.2]\n\n    in case the polyline has more than 3 columns:\n        &gt;&gt;&gt; polyline = PolyFile(\"tests/data/input/source-sink/leftsor-5-columns.pliz\") #Doctest: +SKIP\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [-3.0, -2.9] [-4.2, -5.35]\n\n    in case the polyline does not have z-values:\n        &gt;&gt;&gt; root_dir = \"tests/data/input/dflowfm_individual_files/polylines\"\n        &gt;&gt;&gt; polyline = PolyFile(f\"{root_dir}/boundary-polyline-no-z-no-label.pli\")\n        &gt;&gt;&gt; z_source, z_sink = polyline.get_z_sources_sinks()\n        &gt;&gt;&gt; print(z_source, z_sink)\n        [None] [None]\n    \"\"\"\n    has_data = True if self.objects[0].points[0].data else False\n\n    z_source_sink = []\n    for elem in [0, -1]:\n        point = self.objects[0].points[elem]\n        if has_data:\n            z_source_sink.append([point.z, point.data[0]])\n        else:\n            z_source_sink.append([point.z])\n\n    z_sink: list[float | None] = z_source_sink[0]\n    z_source: list[float | None] = z_source_sink[1]\n    return z_source, z_sink\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.models.PolyObject","title":"<code>PolyObject</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>PolyObject describing a single block in a poly file.</p> <p>The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the   metadata.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>Optional[Description]</code> <p>An optional description of this PolyObject</p> <code>metadata</code> <code>Metadata</code> <p>The Metadata of this PolObject, describing the structure</p> <code>points</code> <code>List[Point]</code> <p>The points describing this PolyObject, structured according to the Metadata</p> Source code in <code>hydrolib/core/dflowfm/polyfile/models.py</code> <pre><code>class PolyObject(BaseModel):\n    \"\"\"PolyObject describing a single block in a poly file.\n\n    The metadata should be consistent with the points:\n    - The number of points should be equal to number of rows defined in the metadata\n    - The data of each point should be equal to the number of columns defined in the\n      metadata.\n\n    Attributes:\n        description (Optional[Description]):\n            An optional description of this PolyObject\n        metadata (Metadata):\n            The Metadata of this PolObject, describing the structure\n        points (List[Point]):\n            The points describing this PolyObject, structured according to the Metadata\n    \"\"\"\n\n    description: Optional[Description]\n    metadata: Metadata\n    points: List[Point]\n</code></pre>"},{"location":"reference/models/polyfile/#parser","title":"Parser","text":"<p>parser.py defines all classes and functions related to parsing pol/pli(z) files.</p>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Block","title":"<code>Block</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Block is a temporary object which will be converted into a PolyObject.</p> <p>The fields are supposed to be set during the lifetime of this object. When all fields are set, finalize can be called.</p> <p>Attributes:</p> Name Type Description <code>start_line</code> <code>int</code> <p>The starting line of this current block.</p> <code>name</code> <code>Optional[str]</code> <p>The name of this block. Defaults to None.</p> <code>dimensions</code> <code>Optional[Tuple[int, int]]</code> <p>The dimensions (n_rows, n_columns) of this Block. Defaults to None.</p> <code>points</code> <code>Optional[List[Point]]</code> <p>The points of this block. Defaults to None.</p> <code>ws_warnings</code> <code>List[ParseMsg]</code> <p>The whitespace warnings associated with this block. Defaults to an empty list.</p> <code>empty_lines</code> <code>List[int]</code> <p>The line numbers of the empty lines. Defaults to an empty list.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class Block(BaseModel):\n    \"\"\"Block is a temporary object which will be converted into a PolyObject.\n\n    The fields are supposed to be set during the lifetime of this object.\n    When all fields are set, finalize can be called.\n\n    Attributes:\n        start_line (int): The starting line of this current block.\n        name (Optional[str]): The name of this block. Defaults to None.\n        dimensions (Optional[Tuple[int, int]]):\n            The dimensions (n_rows, n_columns) of this Block. Defaults to None.\n        points (Optional[List[Point]]):\n            The points of this block. Defaults to None.\n        ws_warnings (List[ParseMsg]):\n            The whitespace warnings associated with this block.\n            Defaults to an empty list.\n        empty_lines (List[int]):\n            The line numbers of the empty lines. Defaults to an empty list.\n    \"\"\"\n\n    start_line: int\n\n    description: Optional[List[str]] = None\n    name: Optional[str] = None\n    dimensions: Optional[Tuple[int, int]] = None\n    points: Optional[List[Point]] = None\n\n    ws_warnings: List[ParseMsg] = []\n    empty_lines: List[int] = []\n\n    def finalize(self) -&gt; Optional[Tuple[PolyObject, List[ParseMsg]]]:\n        \"\"\"Finalize this Block and return the constructed PolyObject and warnings.\n\n        If the metadata or the points are None, then None is returned.\n\n        Returns:\n            Optional[Tuple[PolyObject, List[ParseMsg]]]:\n                The constructed PolyObject and warnings encountered while parsing it.\n        \"\"\"\n        metadata = self._get_metadata()\n\n        if metadata is None or self.points is None:\n            return None\n\n        obj = PolyObject(\n            description=self._get_description(), metadata=metadata, points=self.points\n        )\n\n        return obj, self.ws_warnings + self._get_empty_line_warnings()\n\n    def _get_description(self) -&gt; Optional[Description]:\n        if self.description is not None:\n            return Description(content=\"\\n\".join(self.description))\n        else:\n            return None\n\n    def _get_metadata(self) -&gt; Optional[Metadata]:\n        if self.name is None or self.dimensions is None:\n            return None\n\n        (n_rows, n_columns) = self.dimensions\n        return Metadata(name=self.name, n_rows=n_rows, n_columns=n_columns)\n\n    def _get_empty_line_warnings(self):\n        warnings = []\n        if len(self.empty_lines) &gt; 0:\n            warnings = []\n            empty_line = (self.empty_lines[0], self.empty_lines[0])\n\n            for line in self.empty_lines[1:]:\n                if line == empty_line[1] + 1:\n                    empty_line = (empty_line[0], line)\n                else:\n                    warnings.append(Block._get_empty_line_msg(empty_line))\n                    empty_line = (line, line)\n            warnings.append(Block._get_empty_line_msg(empty_line))\n\n        return warnings\n\n    @staticmethod\n    def _get_empty_line_msg(line_range: Tuple[int, int]) -&gt; ParseMsg:\n        return ParseMsg(\n            line_start=line_range[0],\n            line_end=line_range[1],\n            reason=\"Empty lines are ignored.\",\n        )\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Block.finalize","title":"<code>finalize()</code>","text":"<p>Finalize this Block and return the constructed PolyObject and warnings.</p> <p>If the metadata or the points are None, then None is returned.</p> <p>Returns:</p> Type Description <code>Optional[Tuple[PolyObject, List[ParseMsg]]]</code> <p>Optional[Tuple[PolyObject, List[ParseMsg]]]: The constructed PolyObject and warnings encountered while parsing it.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def finalize(self) -&gt; Optional[Tuple[PolyObject, List[ParseMsg]]]:\n    \"\"\"Finalize this Block and return the constructed PolyObject and warnings.\n\n    If the metadata or the points are None, then None is returned.\n\n    Returns:\n        Optional[Tuple[PolyObject, List[ParseMsg]]]:\n            The constructed PolyObject and warnings encountered while parsing it.\n    \"\"\"\n    metadata = self._get_metadata()\n\n    if metadata is None or self.points is None:\n        return None\n\n    obj = PolyObject(\n        description=self._get_description(), metadata=metadata, points=self.points\n    )\n\n    return obj, self.ws_warnings + self._get_empty_line_warnings()\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ErrorBuilder","title":"<code>ErrorBuilder</code>","text":"<p>ErrorBuilder provides the functionality to the Parser to keep track of errors.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class ErrorBuilder:\n    \"\"\"ErrorBuilder provides the functionality to the Parser to keep track of errors.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Create a new ErorrorBuilder.\"\"\"\n        self._current_block: Optional[InvalidBlock] = None\n\n    def start_invalid_block(\n        self, block_start: int, invalid_line: int, reason: str\n    ) -&gt; None:\n        \"\"\"Start a new invalid block if none exists at the moment.\n\n        If we are already in an invalid block, or the previous one\n        was never finalised, we will not log the reason, and assume\n        it is one long invalid block.\n\n        Args:\n            block_start (int): The start of the invalid block.\n            invalid_line (int): The actual offending line number.\n            reason (str): The reason why this block is invalid.\n        \"\"\"\n        if self._current_block is None:\n            self._current_block = InvalidBlock(\n                start_line=block_start, invalid_line=invalid_line, reason=reason\n            )\n\n    def end_invalid_block(self, line: int) -&gt; None:\n        \"\"\"Store the end line of the current block.\n\n        If no invalid block currently exists, nothing will be done.\n\n        Args:\n            line (int): the final line of this invalid block\n        \"\"\"\n        if self._current_block is not None:\n            self._current_block.end_line = line\n\n    def finalize_previous_error(self) -&gt; Optional[ParseMsg]:\n        \"\"\"Finalize the current invalid block if it exists.\n\n        If no current invalid block exists, None will be returned, and nothing will\n        change. If a current block exists, it will be converted into a ParseMsg and\n        returned. The current invalid block will be reset.\n\n        Returns:\n            Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists.\n        \"\"\"\n        if self._current_block is not None:\n            msg = self._current_block.to_msg()\n            self._current_block = None\n\n            return msg\n        else:\n            return None\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ErrorBuilder.__init__","title":"<code>__init__()</code>","text":"<p>Create a new ErorrorBuilder.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create a new ErorrorBuilder.\"\"\"\n    self._current_block: Optional[InvalidBlock] = None\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ErrorBuilder.end_invalid_block","title":"<code>end_invalid_block(line)</code>","text":"<p>Store the end line of the current block.</p> <p>If no invalid block currently exists, nothing will be done.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>int</code> <p>the final line of this invalid block</p> required Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def end_invalid_block(self, line: int) -&gt; None:\n    \"\"\"Store the end line of the current block.\n\n    If no invalid block currently exists, nothing will be done.\n\n    Args:\n        line (int): the final line of this invalid block\n    \"\"\"\n    if self._current_block is not None:\n        self._current_block.end_line = line\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ErrorBuilder.finalize_previous_error","title":"<code>finalize_previous_error()</code>","text":"<p>Finalize the current invalid block if it exists.</p> <p>If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset.</p> <p>Returns:</p> Type Description <code>Optional[ParseMsg]</code> <p>Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def finalize_previous_error(self) -&gt; Optional[ParseMsg]:\n    \"\"\"Finalize the current invalid block if it exists.\n\n    If no current invalid block exists, None will be returned, and nothing will\n    change. If a current block exists, it will be converted into a ParseMsg and\n    returned. The current invalid block will be reset.\n\n    Returns:\n        Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists.\n    \"\"\"\n    if self._current_block is not None:\n        msg = self._current_block.to_msg()\n        self._current_block = None\n\n        return msg\n    else:\n        return None\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ErrorBuilder.start_invalid_block","title":"<code>start_invalid_block(block_start, invalid_line, reason)</code>","text":"<p>Start a new invalid block if none exists at the moment.</p> <p>If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block.</p> <p>Parameters:</p> Name Type Description Default <code>block_start</code> <code>int</code> <p>The start of the invalid block.</p> required <code>invalid_line</code> <code>int</code> <p>The actual offending line number.</p> required <code>reason</code> <code>str</code> <p>The reason why this block is invalid.</p> required Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def start_invalid_block(\n    self, block_start: int, invalid_line: int, reason: str\n) -&gt; None:\n    \"\"\"Start a new invalid block if none exists at the moment.\n\n    If we are already in an invalid block, or the previous one\n    was never finalised, we will not log the reason, and assume\n    it is one long invalid block.\n\n    Args:\n        block_start (int): The start of the invalid block.\n        invalid_line (int): The actual offending line number.\n        reason (str): The reason why this block is invalid.\n    \"\"\"\n    if self._current_block is None:\n        self._current_block = InvalidBlock(\n            start_line=block_start, invalid_line=invalid_line, reason=reason\n        )\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.InvalidBlock","title":"<code>InvalidBlock</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>InvalidBlock is a temporary object which will be converted into a ParseMsg.</p> <p>Attributes:</p> Name Type Description <code>start_line</code> <code>int</code> <p>The start line of this InvalidBlock</p> <code>end_line</code> <code>Optional[int]</code> <p>The end line of this InvalidBlock if it is set. Defaults to None.</p> <code>invalid_line</code> <code>int</code> <p>The line which is causing this block to be invalid.</p> <code>reason</code> <code>str</code> <p>A human-readable string detailing the reason of the ParseMsg.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class InvalidBlock(BaseModel):\n    \"\"\"InvalidBlock is a temporary object which will be converted into a ParseMsg.\n\n    Attributes:\n        start_line (int): The start line of this InvalidBlock\n        end_line (Optional[int]):\n            The end line of this InvalidBlock if it is set. Defaults to None.\n        invalid_line (int): The line which is causing this block to be invalid.\n        reason (str): A human-readable string detailing the reason of the ParseMsg.\n    \"\"\"\n\n    start_line: int\n    end_line: Optional[int] = None\n    invalid_line: int\n    reason: str\n\n    def to_msg(self) -&gt; ParseMsg:\n        \"\"\"Convert this InvalidBlock to the corresponding ParseMsg.\n\n        Returns:\n            ParseMsg: The ParseMsg corresponding with this InvalidBlock\n        \"\"\"\n        return ParseMsg(\n            line_start=self.start_line,\n            line_end=self.end_line,\n            reason=f\"{self.reason} at line {self.invalid_line}.\",\n        )\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.InvalidBlock.to_msg","title":"<code>to_msg()</code>","text":"<p>Convert this InvalidBlock to the corresponding ParseMsg.</p> <p>Returns:</p> Name Type Description <code>ParseMsg</code> <code>ParseMsg</code> <p>The ParseMsg corresponding with this InvalidBlock</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def to_msg(self) -&gt; ParseMsg:\n    \"\"\"Convert this InvalidBlock to the corresponding ParseMsg.\n\n    Returns:\n        ParseMsg: The ParseMsg corresponding with this InvalidBlock\n    \"\"\"\n    return ParseMsg(\n        line_start=self.start_line,\n        line_end=self.end_line,\n        reason=f\"{self.reason} at line {self.invalid_line}.\",\n    )\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ParseMsg","title":"<code>ParseMsg</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>ParseMsg defines a single message indicating a significant parse event.</p> <p>Attributes:</p> Name Type Description <code>line_start</code> <code>int</code> <p>The start line of the block to which this ParseMsg refers.</p> <code>line_end</code> <code>int</code> <p>The end line of the block to which this ParseMsg refers.</p> <code>column</code> <code>Optional[Tuple[int, int]]</code> <p>An optional begin and end column to which this ParseMsg refers.</p> <code>reason</code> <code>str</code> <p>A human-readable string detailing the reason of the ParseMsg.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class ParseMsg(BaseModel):\n    \"\"\"ParseMsg defines a single message indicating a significant parse event.\n\n    Attributes:\n        line_start (int):\n            The start line of the block to which this ParseMsg refers.\n        line_end (int):\n            The end line of the block to which this ParseMsg refers.\n        column (Optional[Tuple[int, int]]):\n            An optional begin and end column to which this ParseMsg refers.\n        reason (str):\n            A human-readable string detailing the reason of the ParseMsg.\n    \"\"\"\n\n    line_start: int\n    line_end: int\n\n    column: Optional[Tuple[int, int]]\n    reason: str\n\n    def format_parsemsg_to_string(self, file_path: Optional[Path] = None) -&gt; str:\n        \"\"\"Format string describing this ParseMsg.\n\n        Args:\n            file_path (Optional[Path], optional):\n                The file path mentioned in the message if specified. Defaults to None.\n        \"\"\"\n        if self.line_start != self.line_end:\n            block_suffix = f\"\\nInvalid block {self.line_start}:{self.line_end}\"\n        else:\n            block_suffix = f\"\\nInvalid line {self.line_start}\"\n\n        col_suffix = (\n            f\"\\nColumns {self.column[0]}:{self.column[1]}\"\n            if self.column is not None\n            else \"\"\n        )\n        file_suffix = f\"\\nFile: {file_path}\" if file_path is not None else \"\"\n\n        message = f\"{self.reason}{block_suffix}{col_suffix}{file_suffix}\"\n\n        return message\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.ParseMsg.format_parsemsg_to_string","title":"<code>format_parsemsg_to_string(file_path=None)</code>","text":"<p>Format string describing this ParseMsg.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Optional[Path]</code> <p>The file path mentioned in the message if specified. Defaults to None.</p> <code>None</code> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def format_parsemsg_to_string(self, file_path: Optional[Path] = None) -&gt; str:\n    \"\"\"Format string describing this ParseMsg.\n\n    Args:\n        file_path (Optional[Path], optional):\n            The file path mentioned in the message if specified. Defaults to None.\n    \"\"\"\n    if self.line_start != self.line_end:\n        block_suffix = f\"\\nInvalid block {self.line_start}:{self.line_end}\"\n    else:\n        block_suffix = f\"\\nInvalid line {self.line_start}\"\n\n    col_suffix = (\n        f\"\\nColumns {self.column[0]}:{self.column[1]}\"\n        if self.column is not None\n        else \"\"\n    )\n    file_suffix = f\"\\nFile: {file_path}\" if file_path is not None else \"\"\n\n    message = f\"{self.reason}{block_suffix}{col_suffix}{file_suffix}\"\n\n    return message\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Parser","title":"<code>Parser</code>","text":"<p>Parser provides the functionality to parse a polyfile line by line.</p> <p>The Parser parses blocks describing PolyObject instances by relying on a rudimentary state machine. The states are encoded with the StateType. New lines are fed through the feed_line method. After each line the internal state will be updated. When a complete block is read, it will be converted into a PolyObject and stored internally. When finalise is called, the constructed objects, as well as any warnings and errors describing invalid blocks, will be returned.</p> <p>Each state defines a feed_line method, stored in the _feed_line dict, which consumes a line and potentially transitions the state into the next. Each state further defines a finalise method, stored in the _finalise dict, which is called upon finalising the parser.</p> <p>Invalid states are encoded with INVALID_STATE. In this state the Parser attempts to find a new block, and thus looks for a new description or name.</p> <p>Unexpected whitespace before comments, names, and dimensions, as well as empty lines will generate a warning, and will be ignored by the parser.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class Parser:\n    \"\"\"Parser provides the functionality to parse a polyfile line by line.\n\n    The Parser parses blocks describing PolyObject instances by relying on\n    a rudimentary state machine. The states are encoded with the StateType.\n    New lines are fed through the feed_line method. After each line the\n    internal state will be updated. When a complete block is read, it will\n    be converted into a PolyObject and stored internally.\n    When finalise is called, the constructed objects, as well as any warnings\n    and errors describing invalid blocks, will be returned.\n\n    Each state defines a feed_line method, stored in the _feed_line dict,\n    which consumes a line and potentially transitions the state into the next.\n    Each state further defines a finalise method, stored in the _finalise dict,\n    which is called upon finalising the parser.\n\n    Invalid states are encoded with INVALID_STATE. In this state the Parser\n    attempts to find a new block, and thus looks for a new description or\n    name.\n\n    Unexpected whitespace before comments, names, and dimensions, as well as\n    empty lines will generate a warning, and will be ignored by the parser.\n    \"\"\"\n\n    def __init__(\n        self, file_path: Path, has_z_value: bool = False, verbose: bool = False\n    ) -&gt; None:\n        \"\"\"Create a new Parser.\n\n        Args:\n            file_path (Path):\n                Name of the file being parsed, only used for providing proper warnings.\n            has_z_value (bool, optional):\n                Whether to interpret the third column as z-coordinates.\n                Defaults to False.\n            verbose (bool, optional):\n                Whether to show warnings when parsing the file. Defaults to False.\n        \"\"\"\n        self._has_z_value = has_z_value\n        self._file_path = file_path\n        self._verbose = verbose\n\n        self._line = 0\n        self._new_block()\n\n        self._error_builder = ErrorBuilder()\n\n        self._poly_objects: List[PolyObject] = []\n\n        self._current_point: int = 0\n\n        self._feed_line: Dict[StateType, Callable[[str], None]] = {\n            StateType.NEW_BLOCK: self._parse_name_or_new_description,\n            StateType.PARSED_DESCRIPTION: self._parse_name_or_next_description,\n            StateType.PARSED_NAME: self._parse_dimensions,\n            StateType.PARSING_POINTS: self._parse_next_point,\n            StateType.INVALID_STATE: self._parse_name_or_new_description,\n        }\n\n        self._finalise: Dict[StateType, Callable[[], None]] = {\n            StateType.NEW_BLOCK: self._noop,\n            StateType.PARSED_DESCRIPTION: self._add_current_block_as_incomplete_error,\n            StateType.PARSED_NAME: self._add_current_block_as_incomplete_error,\n            StateType.PARSING_POINTS: self._add_current_block_as_incomplete_error,\n            StateType.INVALID_STATE: self._noop,\n        }\n\n    def feed_line(self, line: str) -&gt; None:\n        \"\"\"Parse the next line with this Parser.\n\n        Args:\n            line (str): The line to parse\n        \"\"\"\n        if not Parser._is_empty_line(line):\n            self._feed_line[self._state](line)\n        else:\n            self._handle_empty_line()\n\n        self._increment_line()\n\n    def finalize(self) -&gt; Sequence[PolyObject]:\n        \"\"\"Finalize parsing and return the constructed PolyObject.\n\n        Raises:\n            ValueError: When the plifile is invalid.\n\n        Returns:\n            PolyObject:\n                A PolyObject containing the constructed PolyObject instances.\n        \"\"\"\n        self._error_builder.end_invalid_block(self._line)\n        last_error_msg = self._error_builder.finalize_previous_error()\n        if last_error_msg is not None:\n            self._notify_as_error(last_error_msg)\n\n        self._finalise[self._state]()\n\n        return self._poly_objects\n\n    def _new_block(self, offset: int = 0) -&gt; None:\n        self._state = StateType.NEW_BLOCK\n        self._current_block = Block(start_line=(self._line + offset))\n\n    def _finish_block(self):\n        (obj, warnings) = self._current_block.finalize()  # type: ignore\n        self._poly_objects.append(obj)\n\n        for msg in warnings:\n            self._notify_as_warning(msg)\n\n        last_error = self._error_builder.finalize_previous_error()\n        if last_error is not None:\n            self._notify_as_error(last_error)\n\n    def _increment_line(self) -&gt; None:\n        self._line += 1\n\n    def _noop(self, *_, **__) -&gt; None:\n        # no operation\n        pass\n\n    def _add_current_block_as_incomplete_error(self) -&gt; None:\n        msg = ParseMsg(\n            line_start=self._current_block.start_line,\n            line_end=self._line,\n            reason=\"EoF encountered before the block is finished.\",\n        )\n        self._notify_as_error(msg)\n\n    def _parse_name_or_new_description(self, line: str) -&gt; None:\n        if Parser._is_comment(line):\n            self._handle_new_description(line)\n        elif Parser._is_name(line):\n            self._handle_parse_name(line)\n        elif self._state != StateType.INVALID_STATE:\n            self._handle_new_error(\n                \"Settings of block might be incorrect, expected a valid name or description\"\n            )\n            return\n\n        # If we come from an invalid state, and we started a correct new block\n        # we will end the previous invalid block, if it exists.\n        self._error_builder.end_invalid_block(self._line)\n\n    def _parse_name_or_next_description(self, line: str) -&gt; None:\n        if Parser._is_comment(line):\n            self._handle_next_description(line)\n        elif Parser._is_name(line):\n            self._handle_parse_name(line)\n        else:\n            self._handle_new_error(\"Expected a valid name or description\")\n\n    def _parse_dimensions(self, line: str) -&gt; None:\n        dimensions = Parser._convert_to_dimensions(line)\n\n        if dimensions is not None:\n            self._current_block.dimensions = dimensions\n            self._current_block.points = []\n            self._current_point = 0\n            self._state = StateType.PARSING_POINTS\n        else:\n            self._handle_new_error(\"Expected valid dimensions\")\n\n    def _parse_next_point(self, line: str) -&gt; None:\n        point = Parser._convert_to_point(\n            line, self._current_block.dimensions[1], self._has_z_value  # type: ignore\n        )\n\n        if point is not None:\n            self._current_block.points.append(point)  # type: ignore\n            self._current_point += 1\n\n            if self._current_block.dimensions[0] == self._current_point:  # type: ignore\n                self._finish_block()\n                self._new_block(offset=1)\n\n        else:\n            self._handle_new_error(\"Expected a valid next point\")\n            # we parse the line again, as it might be the first line of a new valid\n            # block. For example when the invalid block was missing points.\n            self._feed_line[self._state](line)\n\n    def _handle_parse_name(self, line: str) -&gt; None:\n        self._current_block.name = Parser._convert_to_name(line)\n        self._state = StateType.PARSED_NAME\n\n    def _handle_new_description(self, line: str) -&gt; None:\n        comment = Parser._convert_to_comment(line)\n        self._current_block.description = [\n            comment,\n        ]\n        self._state = StateType.PARSED_DESCRIPTION\n\n    def _handle_next_description(self, line: str) -&gt; None:\n        comment = Parser._convert_to_comment(line)\n        self._current_block.description.append(comment)  # type: ignore\n\n    def _handle_empty_line(self) -&gt; None:\n        \"\"\"Add the empty line to the current block if it is not in an invalid state.\n\n        Notes:\n            - Empty lines are ignored, but we want to keep track of them for the purpose of warnings.\n            - Empty lines are not added to the current block if it is in an invalid state.\n        \"\"\"\n        if self._state != StateType.INVALID_STATE:\n            self._current_block.empty_lines.append(self._line)\n\n    def _handle_new_error(self, reason: str) -&gt; None:\n        self._error_builder.start_invalid_block(\n            self._current_block.start_line, self._line, reason\n        )\n        self._state = StateType.INVALID_STATE\n\n    def _notify_as_warning(self, msg: ParseMsg) -&gt; None:\n        warning_message = msg.format_parsemsg_to_string(self._file_path)\n        if self._verbose:\n            warnings.warn(warning_message, stacklevel=2)\n\n    def _notify_as_error(self, msg: ParseMsg) -&gt; None:\n        error_message = msg.format_parsemsg_to_string(self._file_path)\n        raise ValueError(f\"Invalid formatted plifile, {error_message}\")\n\n    @staticmethod\n    def _is_empty_line(line: str) -&gt; bool:\n        return len(line.strip()) == 0\n\n    @staticmethod\n    def _is_name(line: str) -&gt; bool:\n        stripped = line.strip()\n        return len(stripped) &gt;= 1 and line[0] != \"*\"\n\n    @staticmethod\n    def _convert_to_name(line: str) -&gt; str:\n        return line.strip()\n\n    @staticmethod\n    def _is_comment(line: str) -&gt; bool:\n        return line.strip().startswith(\"*\")\n\n    @staticmethod\n    def _convert_to_comment(line: str) -&gt; str:\n        return line.strip()[1:]\n\n    @staticmethod\n    def _convert_to_dimensions(line: str) -&gt; Optional[Tuple[int, int]]:\n        stripped = line.strip()\n        elems = stripped.split()\n\n        if len(elems) != 2:\n            return None\n\n        try:\n            n_rows = int(elems[0])\n            n_cols = int(elems[1])\n\n            if n_rows &lt;= 0 or n_cols &lt;= 0:\n                return None\n\n            return (n_rows, n_cols)\n        except ValueError:\n            return None\n\n    @staticmethod\n    def _convert_to_point(\n        line: str, expected_n_points: int, has_z: bool\n    ) -&gt; Optional[Point]:\n        stripped = line.strip()\n        elems = stripped.split()\n\n        if len(elems) &lt; expected_n_points:\n            return None\n\n        try:\n            values = list(float(x) for x in elems[:expected_n_points])\n\n            if has_z:\n                x, y, z, *data = values\n            else:\n                x, y, *data = values\n                z = None  # type: ignore\n\n            return Point(x=x, y=y, z=z, data=data)\n\n        except ValueError:\n            return None\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Parser.__init__","title":"<code>__init__(file_path, has_z_value=False, verbose=False)</code>","text":"<p>Create a new Parser.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Name of the file being parsed, only used for providing proper warnings.</p> required <code>has_z_value</code> <code>bool</code> <p>Whether to interpret the third column as z-coordinates. Defaults to False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to show warnings when parsing the file. Defaults to False.</p> <code>False</code> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def __init__(\n    self, file_path: Path, has_z_value: bool = False, verbose: bool = False\n) -&gt; None:\n    \"\"\"Create a new Parser.\n\n    Args:\n        file_path (Path):\n            Name of the file being parsed, only used for providing proper warnings.\n        has_z_value (bool, optional):\n            Whether to interpret the third column as z-coordinates.\n            Defaults to False.\n        verbose (bool, optional):\n            Whether to show warnings when parsing the file. Defaults to False.\n    \"\"\"\n    self._has_z_value = has_z_value\n    self._file_path = file_path\n    self._verbose = verbose\n\n    self._line = 0\n    self._new_block()\n\n    self._error_builder = ErrorBuilder()\n\n    self._poly_objects: List[PolyObject] = []\n\n    self._current_point: int = 0\n\n    self._feed_line: Dict[StateType, Callable[[str], None]] = {\n        StateType.NEW_BLOCK: self._parse_name_or_new_description,\n        StateType.PARSED_DESCRIPTION: self._parse_name_or_next_description,\n        StateType.PARSED_NAME: self._parse_dimensions,\n        StateType.PARSING_POINTS: self._parse_next_point,\n        StateType.INVALID_STATE: self._parse_name_or_new_description,\n    }\n\n    self._finalise: Dict[StateType, Callable[[], None]] = {\n        StateType.NEW_BLOCK: self._noop,\n        StateType.PARSED_DESCRIPTION: self._add_current_block_as_incomplete_error,\n        StateType.PARSED_NAME: self._add_current_block_as_incomplete_error,\n        StateType.PARSING_POINTS: self._add_current_block_as_incomplete_error,\n        StateType.INVALID_STATE: self._noop,\n    }\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Parser.feed_line","title":"<code>feed_line(line)</code>","text":"<p>Parse the next line with this Parser.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The line to parse</p> required Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def feed_line(self, line: str) -&gt; None:\n    \"\"\"Parse the next line with this Parser.\n\n    Args:\n        line (str): The line to parse\n    \"\"\"\n    if not Parser._is_empty_line(line):\n        self._feed_line[self._state](line)\n    else:\n        self._handle_empty_line()\n\n    self._increment_line()\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.Parser.finalize","title":"<code>finalize()</code>","text":"<p>Finalize parsing and return the constructed PolyObject.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the plifile is invalid.</p> <p>Returns:</p> Name Type Description <code>PolyObject</code> <code>Sequence[PolyObject]</code> <p>A PolyObject containing the constructed PolyObject instances.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def finalize(self) -&gt; Sequence[PolyObject]:\n    \"\"\"Finalize parsing and return the constructed PolyObject.\n\n    Raises:\n        ValueError: When the plifile is invalid.\n\n    Returns:\n        PolyObject:\n            A PolyObject containing the constructed PolyObject instances.\n    \"\"\"\n    self._error_builder.end_invalid_block(self._line)\n    last_error_msg = self._error_builder.finalize_previous_error()\n    if last_error_msg is not None:\n        self._notify_as_error(last_error_msg)\n\n    self._finalise[self._state]()\n\n    return self._poly_objects\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.StateType","title":"<code>StateType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>The types of state of a Parser.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>class StateType(IntEnum):\n    \"\"\"The types of state of a Parser.\"\"\"\n\n    NEW_BLOCK = 0\n    PARSED_DESCRIPTION = 1\n    PARSED_NAME = 2\n    PARSING_POINTS = 3\n    INVALID_STATE = 4\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.parser.read_polyfile","title":"<code>read_polyfile(filepath, has_z_values=None, verbose=False)</code>","text":"<p>Read the specified file and return the corresponding data.</p> <p>The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format:</p> <ul> <li>Optional description record consisting of one or more lines starting with '*'.     These will be ignored.</li> <li>Name consisting of a character string</li> <li>Two integers, Nr and Nc, representing the numbers of rows and columns respectively</li> <li>Nr number of data points, consisting of Nc floats separated by whitespace</li> </ul> <p>For example: <pre><code>...\n*\n* Polyline L008\n*\nL008\n4 2\n    131595.0 549685.0\n    131750.0 549865.0\n    131595.0 550025.0\n    131415.0 550175.0\n...\n</code></pre></p> <p>Note that the points can be arbitrarily indented, and the comments are optional.</p> <p>if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False</p> <p>Empty lines and unexpected whitespace will be flagged as warnings, and ignored.</p> <p>If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to the pli(z)/pol convention structured file.</p> required <code>has_z_values</code> <code>Optional[bool]</code> <p>Whether to create points containing a z-value. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to show warnings when parsing the file. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the plifile is invalid.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>The dictionary describing the data of a PolyObject.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/parser.py</code> <pre><code>def read_polyfile(\n    filepath: Path, has_z_values: Optional[bool] = None, verbose: bool = False\n) -&gt; Dict:\n    \"\"\"Read the specified file and return the corresponding data.\n\n    The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol\n    file is defined as consisting of a number of blocks of lines adhering to the\n    following format:\n\n    - Optional description record consisting of one or more lines starting with '*'.\n        These will be ignored.\n    - Name consisting of a character string\n    - Two integers, Nr and Nc, representing the numbers of rows and columns respectively\n    - Nr number of data points, consisting of Nc floats separated by whitespace\n\n    For example:\n    ```\n    ...\n    *\n    * Polyline L008\n    *\n    L008\n    4 2\n        131595.0 549685.0\n        131750.0 549865.0\n        131595.0 550025.0\n        131415.0 550175.0\n    ...\n    ```\n\n    Note that the points can be arbitrarily indented, and the comments are optional.\n\n    if no has_z_value has been defined, it will be based on the file path\n    extensions of the filepath:\n    - .pliz will default to True\n    - .pli and .pol will default to False\n\n    Empty lines and unexpected whitespace will be flagged as warnings, and ignored.\n\n    If invalid syntax is detected within a block, an error will be created. This block\n    will be ignored for the purpose of creating PolyObject instances.\n    Once an error is encountered, any following lines will be marked as part of the\n    invalid block, until a new valid block is found. Note that this means that sequential\n    invalid blocks will be reported as a single invalid block. Such invalid blocks will\n    be reported as warnings.\n\n    Args:\n        filepath:\n            Path to the pli(z)/pol convention structured file.\n        has_z_values:\n            Whether to create points containing a z-value. Defaults to None.\n        verbose:\n            Whether to show warnings when parsing the file. Defaults to False.\n\n    Raises:\n        ValueError: When the plifile is invalid.\n\n    Returns:\n        Dict: The dictionary describing the data of a PolyObject.\n    \"\"\"\n    if has_z_values is None:\n        has_z_values = _determine_has_z_value(filepath)\n\n    parser = Parser(filepath, has_z_value=has_z_values, verbose=verbose)\n\n    with filepath.open(\"r\", encoding=\"utf8\") as f:\n        for line in f:\n            parser.feed_line(line)\n\n    objs = parser.finalize()\n\n    return {\"has_z_values\": has_z_values, \"objects\": objs}\n</code></pre>"},{"location":"reference/models/polyfile/#serializer","title":"Serializer","text":""},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.Serializer","title":"<code>Serializer</code>","text":"<p>Serializer provides several static serialize methods for the models.</p> Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>class Serializer:\n    \"\"\"Serializer provides several static serialize methods for the models.\"\"\"\n\n    @staticmethod\n    def serialize_description(description: Optional[Description]) -&gt; Iterable[str]:\n        \"\"\"Serialize the Description to a string which can be used within a polyfile.\n\n        Returns:\n            str: The serialised equivalent of this Description\n        \"\"\"\n        if description is None:\n            return []\n        if description.content == \"\":\n            return [\n                \"*\",\n            ]\n        return (f\"*{v.rstrip()}\" for v in (description.content + \"\\n\").splitlines())\n\n    @staticmethod\n    def serialize_metadata(metadata: Metadata) -&gt; Iterable[str]:\n        \"\"\"Serialize this Metadata to a string which can be used within a polyfile.\n\n        The number of rows and number of columns are separated by four spaces.\n\n        Returns:\n            str: The serialised equivalent of this Metadata\n        \"\"\"\n        return [metadata.name, f\"{metadata.n_rows}    {metadata.n_columns}\"]\n\n    @staticmethod\n    def serialize_point(point: Point, config: SerializerConfig) -&gt; str:\n        \"\"\"Serialize this Point to a string which can be used within a polyfile.\n\n        the point data is indented with 4 spaces, and the individual values are\n        separated by 4 spaces as well.\n\n        Args:\n            point (Point): The point to serialize.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: The serialised equivalent of this Point\n        \"\"\"\n        space = 4 * \" \"\n        float_format = lambda v: f\"{v:{config.float_format}}\"\n        return space + space.join(\n            float_format(v) for v in Serializer._get_point_values(point)\n        )\n\n    @staticmethod\n    def _get_point_values(point: Point) -&gt; Generator[float, None, None]:\n        yield point.x\n        yield point.y\n        if point.z:\n            yield point.z\n        for value in point.data:\n            yield value\n\n    @staticmethod\n    def serialize_poly_object(\n        obj: PolyObject, config: SerializerConfig\n    ) -&gt; Iterable[str]:\n        \"\"\"Serialize this PolyObject to a string which can be used within a polyfile.\n\n        Args:\n            obj (PolyObject): The poly object to serializer.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: The serialised equivalent of this PolyObject\n        \"\"\"\n\n        description = Serializer.serialize_description(obj.description)\n        metadata = Serializer.serialize_metadata(obj.metadata)\n        points = [Serializer.serialize_point(obj, config) for obj in obj.points]\n        return chain(description, metadata, points)\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.Serializer.serialize_description","title":"<code>serialize_description(description)</code>  <code>staticmethod</code>","text":"<p>Serialize the Description to a string which can be used within a polyfile.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>Iterable[str]</code> <p>The serialised equivalent of this Description</p> Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>@staticmethod\ndef serialize_description(description: Optional[Description]) -&gt; Iterable[str]:\n    \"\"\"Serialize the Description to a string which can be used within a polyfile.\n\n    Returns:\n        str: The serialised equivalent of this Description\n    \"\"\"\n    if description is None:\n        return []\n    if description.content == \"\":\n        return [\n            \"*\",\n        ]\n    return (f\"*{v.rstrip()}\" for v in (description.content + \"\\n\").splitlines())\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.Serializer.serialize_metadata","title":"<code>serialize_metadata(metadata)</code>  <code>staticmethod</code>","text":"<p>Serialize this Metadata to a string which can be used within a polyfile.</p> <p>The number of rows and number of columns are separated by four spaces.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>Iterable[str]</code> <p>The serialised equivalent of this Metadata</p> Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>@staticmethod\ndef serialize_metadata(metadata: Metadata) -&gt; Iterable[str]:\n    \"\"\"Serialize this Metadata to a string which can be used within a polyfile.\n\n    The number of rows and number of columns are separated by four spaces.\n\n    Returns:\n        str: The serialised equivalent of this Metadata\n    \"\"\"\n    return [metadata.name, f\"{metadata.n_rows}    {metadata.n_columns}\"]\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.Serializer.serialize_point","title":"<code>serialize_point(point, config)</code>  <code>staticmethod</code>","text":"<p>Serialize this Point to a string which can be used within a polyfile.</p> <p>the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Point</code> <p>The point to serialize.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The serialised equivalent of this Point</p> Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>@staticmethod\ndef serialize_point(point: Point, config: SerializerConfig) -&gt; str:\n    \"\"\"Serialize this Point to a string which can be used within a polyfile.\n\n    the point data is indented with 4 spaces, and the individual values are\n    separated by 4 spaces as well.\n\n    Args:\n        point (Point): The point to serialize.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: The serialised equivalent of this Point\n    \"\"\"\n    space = 4 * \" \"\n    float_format = lambda v: f\"{v:{config.float_format}}\"\n    return space + space.join(\n        float_format(v) for v in Serializer._get_point_values(point)\n    )\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.Serializer.serialize_poly_object","title":"<code>serialize_poly_object(obj, config)</code>  <code>staticmethod</code>","text":"<p>Serialize this PolyObject to a string which can be used within a polyfile.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>PolyObject</code> <p>The poly object to serializer.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>Iterable[str]</code> <p>The serialised equivalent of this PolyObject</p> Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>@staticmethod\ndef serialize_poly_object(\n    obj: PolyObject, config: SerializerConfig\n) -&gt; Iterable[str]:\n    \"\"\"Serialize this PolyObject to a string which can be used within a polyfile.\n\n    Args:\n        obj (PolyObject): The poly object to serializer.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: The serialised equivalent of this PolyObject\n    \"\"\"\n\n    description = Serializer.serialize_description(obj.description)\n    metadata = Serializer.serialize_metadata(obj.metadata)\n    points = [Serializer.serialize_point(obj, config) for obj in obj.points]\n    return chain(description, metadata, points)\n</code></pre>"},{"location":"reference/models/polyfile/#hydrolib.core.dflowfm.polyfile.serializer.write_polyfile","title":"<code>write_polyfile(path, data, config)</code>","text":"<p>Write the data to a new file at path</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to write the data to</p> required <code>data</code> <code>Sequence[PolyObject]</code> <p>The poly objects to write</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required Source code in <code>hydrolib/core/dflowfm/polyfile/serializer.py</code> <pre><code>def write_polyfile(\n    path: Path, data: Sequence[PolyObject], config: SerializerConfig\n) -&gt; None:\n    \"\"\"Write the data to a new file at path\n\n    Args:\n        path (Path): The path to write the data to\n        data (Sequence[PolyObject]): The poly objects to write\n        config (SerializerConfig): The serialization configuration.\n    \"\"\"\n    serialized_poly_objects = [\n        Serializer.serialize_poly_object(poly_object, config) for poly_object in data\n    ]\n    serialized_data = chain.from_iterable(serialized_poly_objects)\n\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with path.open(\"w\", encoding=\"utf8\") as f:\n\n        for line in serialized_data:\n            f.write(line)\n            f.write(\"\\n\")\n</code></pre>"},{"location":"reference/models/storagenode/","title":"Storage node .ini files","text":"<p>The storage node module provides the specific logic for accessing storage node files for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>A storage node .ini file is described by the classes below.</p>"},{"location":"reference/models/storagenode/#model","title":"Model","text":""},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.Interpolation","title":"<code>Interpolation</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the interpolation type as used for a storage area table in StorageNode.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class Interpolation(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the interpolation type\n    as used for a storage area table in StorageNode.\n    \"\"\"\n\n    linear = \"linear\"\n    block = \"block\"\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.NodeType","title":"<code>NodeType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the node type as used in StorageNode.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class NodeType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the node type\n    as used in StorageNode.\n    \"\"\"\n\n    inspection = \"inspection\"\n    soakawaydrain = \"soakawayDrain\"\n    compartment = \"compartment\"\n    unspecified = \"unspecified\"\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNode","title":"<code>StorageNode</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> <p>A storage node that is included in the storage node file.</p> <p>All lowercased attributes match with the storage node input as described in UM Sec.C.17.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class StorageNode(INIBasedModel):\n    \"\"\"\n    A storage node that is included in the storage node file.\n\n    All lowercased attributes match with the storage node input as described in\n    [UM Sec.C.17](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#section.C.17).\n    \"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        id: Optional[str] = Field(\"Unique id of the storage node.\", alias=\"id\")\n        name: Optional[str] = Field(\"Long name in the user interface.\", alias=\"name\")\n        manholeid: Optional[str] = Field(\n            \"(optional) Unique id of manhole that this (compartment) node is part of.\",\n            alias=\"manholeId\",\n        )\n        nodetype: Optional[str] = Field(\n            \"(optional) Type of the node. Possible values are: \"\n            + \"inspection: inspection chamber, \"\n            + \"soakawayDrain: soakaway drain (infiltration), \"\n            + \"compartment: manhole compartment, \"\n            + \"unspecified: general storage node of unspecified type\",\n            alias=\"nodeType\",\n        )\n        nodeid: Optional[str] = Field(\n            \"Connection node on which the storage node is located.\", alias=\"nodeId\"\n        )\n        usetable: Optional[str] = Field(\n            \"Switch to select a simple (false) or tabulated (true) storage area.\",\n            alias=\"useTable\",\n        )\n        bedlevel: Optional[str] = Field(\n            \"Bed level of the storage area [m AD].\", alias=\"bedLevel\"\n        )\n        area: Optional[str] = Field(\n            \"Storage area from bedLevel up to streetLevel (and beyond if useStreetStorage = false) [m2].\",\n            alias=\"area\",\n        )\n        streetlevel: Optional[str] = Field(\n            \"Street level of the storage area [m AD].\", alias=\"streetLevel\"\n        )\n        streetstoragearea: Optional[str] = Field(\n            \"Storage area from streetLevel upwards if useStreetStorage = true [m2].\",\n            alias=\"streetStorageArea\",\n        )\n        storagetype: Optional[str] = Field(\n            \"Possible values: \"\n            + \"reservoir: Above streetLevel the storage area of this node is also taken into account. \"\n            + \"closed: Above streetLevel this storage node has no storage area.\",\n            alias=\"storageType\",\n        )\n        numlevels: Optional[str] = Field(\n            \"Number of levels in storage area table.\", alias=\"numLevels\"\n        )\n        levels: Optional[str] = Field(\n            \"Levels in storage area table [m].\", alias=\"levels\"\n        )\n        storagearea: Optional[str] = Field(\n            \"Areas in storage area table [m2].\", alias=\"storageArea\"\n        )\n        interpolate: Optional[str] = Field(\n            \"Interpolation type for storage area table. Possible values: linear or block.\",\n            alias=\"interpolate\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"StorageNode\"] = \"StorageNode\"\n    id: str = Field(alias=\"id\")\n    name: str = Field(alias=\"name\")\n    manholeid: Optional[str] = Field(alias=\"manholeId\")\n\n    nodetype: Optional[NodeType] = Field(NodeType.unspecified.value, alias=\"nodeType\")\n    nodeid: str = Field(alias=\"nodeId\")\n    usetable: bool = Field(alias=\"useTable\")\n\n    # useTable is True\n    bedlevel: Optional[float] = Field(alias=\"bedLevel\")\n    area: Optional[float] = Field(alias=\"area\")\n    streetlevel: Optional[float] = Field(alias=\"streetLevel\")\n    streetstoragearea: Optional[float] = Field(alias=\"streetStorageArea\")\n    storagetype: Optional[StorageType] = Field(\n        StorageType.reservoir.value, alias=\"storageType\"\n    )\n\n    # useTable is False\n    numlevels: Optional[int] = Field(alias=\"numLevels\")\n    levels: Optional[List[float]] = Field(alias=\"levels\")\n    storagearea: Optional[List[float]] = Field(alias=\"storageArea\")\n    interpolate: Optional[Interpolation] = Field(\n        Interpolation.linear.value, alias=\"interpolate\"\n    )\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"\n        The StorageNode does not currently support raising an error on unknown keywords.\n        \"\"\"\n        return None\n\n    _interpolation_validator = get_enum_validator(\"interpolate\", enum=Interpolation)\n    _nodetype_validator = get_enum_validator(\"nodetype\", enum=NodeType)\n    _storagetype_validator = get_enum_validator(\"storagetype\", enum=StorageType)\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"levels\",\n        \"storagearea\",\n    )\n\n    @root_validator(allow_reuse=True)\n    def check_list_length_levels(cls, values):\n        \"\"\"Validates that the length of the levels field is as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"levels\",\n            \"storagearea\",\n            length_name=\"numlevels\",\n            list_required_with_length=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_required_fields_are_present_when_using_tables(\n        cls, values: Dict\n    ) -&gt; Dict:\n        \"\"\"Validates that the specified fields are present when the usetable field is also present.\"\"\"\n        return validate_required_fields(\n            values,\n            \"numlevels\",\n            \"levels\",\n            \"storagearea\",\n            conditional_field_name=\"usetable\",\n            conditional_value=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_required_fields_are_present_when_not_using_tables(\n        cls, values: Dict\n    ) -&gt; Dict:\n        \"\"\"Validates that the specified fields are present.\"\"\"\n        return validate_required_fields(\n            values,\n            \"bedlevel\",\n            \"area\",\n            \"streetlevel\",\n            conditional_field_name=\"usetable\",\n            conditional_value=False,\n        )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\") or data.get(\"name\")\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNode.check_list_length_levels","title":"<code>check_list_length_levels(values)</code>","text":"<p>Validates that the length of the levels field is as expected.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_length_levels(cls, values):\n    \"\"\"Validates that the length of the levels field is as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"levels\",\n        \"storagearea\",\n        length_name=\"numlevels\",\n        list_required_with_length=True,\n    )\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNode.validate_that_required_fields_are_present_when_not_using_tables","title":"<code>validate_that_required_fields_are_present_when_not_using_tables(values)</code>","text":"<p>Validates that the specified fields are present.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_required_fields_are_present_when_not_using_tables(\n    cls, values: Dict\n) -&gt; Dict:\n    \"\"\"Validates that the specified fields are present.\"\"\"\n    return validate_required_fields(\n        values,\n        \"bedlevel\",\n        \"area\",\n        \"streetlevel\",\n        conditional_field_name=\"usetable\",\n        conditional_value=False,\n    )\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNode.validate_that_required_fields_are_present_when_using_tables","title":"<code>validate_that_required_fields_are_present_when_using_tables(values)</code>","text":"<p>Validates that the specified fields are present when the usetable field is also present.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_required_fields_are_present_when_using_tables(\n    cls, values: Dict\n) -&gt; Dict:\n    \"\"\"Validates that the specified fields are present when the usetable field is also present.\"\"\"\n    return validate_required_fields(\n        values,\n        \"numlevels\",\n        \"levels\",\n        \"storagearea\",\n        conditional_field_name=\"usetable\",\n        conditional_value=True,\n    )\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNodeGeneral","title":"<code>StorageNodeGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p>The storage node file's <code>[General]</code> section with file meta data.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class StorageNodeGeneral(INIGeneral):\n    \"\"\"The storage node file's `[General]` section with file meta data.\"\"\"\n\n    class Comments(INIBasedModel.Comments):\n        fileversion: Optional[str] = Field(\n            \"File version. Do not edit this.\", alias=\"fileVersion\"\n        )\n        filetype: Optional[str] = Field(\n            \"File type. Should be 'storageNodes'. Do not edit this.\",\n            alias=\"fileType\",\n        )\n        usestreetstorage: Optional[str] = Field(\n            \"Indicates whether above streetLevel the streetStorageArea must be used (true) \"\n            + \"or the regular storage area continues (false). This option is only applicable \"\n            + \"for storage nodes with useTable = false.\",\n            alias=\"useStreetStorage\",\n        )\n\n    comments: Comments = Comments()\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"2.00\", alias=\"fileVersion\")\n    filetype: Literal[\"storageNodes\"] = Field(\"storageNodes\", alias=\"fileType\")\n    usestreetstorage: Optional[bool] = Field(True, alias=\"useStreetStorage\")\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageNodeModel","title":"<code>StorageNodeModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall storage node model that contains the contents of one storage node file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.storagenodefile[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>StorageNodeGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>storagenode</code> <code>List[StorageNode]</code> <p>List of <code>[StorageNode]</code> blocks for all storage nodes.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class StorageNodeModel(INIModel):\n    \"\"\"\n    The overall storage node model that contains the contents of one storage node file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.storagenodefile[..]`.\n\n    Attributes:\n        general (StorageNodeGeneral): `[General]` block with file metadata.\n        storagenode (List[StorageNode]): List of `[StorageNode]` blocks for all storage nodes.\n    \"\"\"\n\n    general: StorageNodeGeneral = StorageNodeGeneral()\n    storagenode: List[StorageNode] = []\n\n    _make_list = make_list_validator(\"storagenode\")\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"nodeFile\"\n\n    @validator(\"storagenode\", each_item=True)\n    def _validate(cls, storagenode: StorageNode, values: dict):\n        \"\"\"Validates for each storage node whether the streetStorageArea value is provided\n        when the general useStreetStorage is True and the storage node useTable is False.\n        \"\"\"\n\n        usestreetstorage = values[\"general\"].usestreetstorage\n\n        if (\n            usestreetstorage\n            and not storagenode.usetable\n            and storagenode.streetstoragearea is None\n        ):\n            raise ValueError(\n                f\"streetStorageArea should be provided when useStreetStorage is True and useTable is False for storage node with id {storagenode.id}\"\n            )\n\n        return storagenode\n</code></pre>"},{"location":"reference/models/storagenode/#hydrolib.core.dflowfm.storagenode.models.StorageType","title":"<code>StorageType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the storage type as used in StorageNode.</p> Source code in <code>hydrolib/core/dflowfm/storagenode/models.py</code> <pre><code>class StorageType(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the storage type\n    as used in StorageNode.\n    \"\"\"\n\n    reservoir = \"reservoir\"\n    closed = \"closed\"\n</code></pre>"},{"location":"reference/models/structure/","title":"Structure .ini files","text":"<p>Structure .ini files contain the definition of hydraulic structures for a D-Flow FM model.</p> <p>Generic parsing and serializing functionality comes from the generic hydrolib.core.dflowfm.ini modules.</p> <p>A structures.ini file is described by the classes below.</p>"},{"location":"reference/models/structure/#models","title":"Models","text":"<p>structure namespace for storing the contents of an FMModel's structure file.</p>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Bridge","title":"<code>Bridge</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=bridge</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the bridge input as described in UM Sec.C.12.5.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Bridge(Structure):\n    \"\"\"\n    Hydraulic structure with `type=bridge`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the bridge input as described in\n    [UM Sec.C.12.5](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.5).\n    \"\"\"\n\n    class Comments(Structure.Comments):\n        type: Optional[str] = Field(\"Structure type; must read bridge\", alias=\"type\")\n        allowedflowdir: Optional[str] = Field(\n            FlowDirection.allowedvaluestext, alias=\"allowedFlowdir\"\n        )\n\n        csdefid: Optional[str] = Field(\n            \"Id of Cross-Section Definition.\", alias=\"csDefId\"\n        )\n        shift: Optional[str] = Field(\n            \"Vertical shift of the cross section definition [m]. Defined positive upwards.\"\n        )\n        inletlosscoeff: Optional[str] = Field(\n            \"Inlet loss coefficient [-], \u03be_i.\",\n            alias=\"inletLossCoeff\",\n        )\n        outletlosscoeff: Optional[str] = Field(\n            \"Outlet loss coefficient [-], k.\",\n            alias=\"outletLossCoeff\",\n        )\n        frictiontype: Optional[str] = Field(\n            \"Friction type, possible values are: Chezy, Manning, wallLawNikuradse, WhiteColebrook, StricklerNikuradse, Strickler, deBosBijkerk.\",\n            alias=\"frictionType\",\n        )\n        friction: Optional[str] = Field(\n            \"Friction value, used in friction loss.\",\n            alias=\"friction\",\n        )\n        length: Optional[str] = Field(\"Length [m], L.\")\n\n    comments: Comments = Comments()\n\n    type: Literal[\"bridge\"] = Field(\"bridge\", alias=\"type\")\n    allowedflowdir: FlowDirection = Field(alias=\"allowedFlowdir\")\n\n    csdefid: str = Field(alias=\"csDefId\")\n    shift: float\n    inletlosscoeff: float = Field(alias=\"inletLossCoeff\")\n    outletlosscoeff: float = Field(alias=\"outletLossCoeff\")\n    frictiontype: FrictionType = Field(alias=\"frictionType\")\n    friction: float\n    length: float\n\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Compound","title":"<code>Compound</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=compound</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the compound input as described in UM Sec.C.12.11.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Compound(Structure):\n    \"\"\"\n    Hydraulic structure with `type=compound`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the compound input as described in\n    [UM Sec.C.12.11](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.11).\n    \"\"\"\n\n    type: Literal[\"compound\"] = Field(\"compound\", alias=\"type\")\n    numstructures: int = Field(alias=\"numStructures\")\n    structureids: List[str] = Field(alias=\"structureIds\", delimiter=\";\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"structureids\",\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Culvert","title":"<code>Culvert</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=culvert</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the culvert input as described in UM Sec.C.12.3.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Culvert(Structure):\n    \"\"\"\n    Hydraulic structure with `type=culvert`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the culvert input as described in\n    [UM Sec.C.12.3](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.3).\n    \"\"\"\n\n    type: Literal[\"culvert\"] = Field(\"culvert\", alias=\"type\")\n    allowedflowdir: FlowDirection = Field(alias=\"allowedFlowDir\")\n\n    leftlevel: float = Field(alias=\"leftLevel\")\n    rightlevel: float = Field(alias=\"rightLevel\")\n    csdefid: str = Field(alias=\"csDefId\")\n    length: float = Field(alias=\"length\")\n    inletlosscoeff: float = Field(alias=\"inletLossCoeff\")\n    outletlosscoeff: float = Field(alias=\"outletLossCoeff\")\n    valveonoff: bool = Field(alias=\"valveOnOff\")\n    valveopeningheight: Optional[ForcingData] = Field(alias=\"valveOpeningHeight\")\n    numlosscoeff: Optional[int] = Field(alias=\"numLossCoeff\")\n    relopening: Optional[List[float]] = Field(alias=\"relOpening\")\n    losscoeff: Optional[List[float]] = Field(alias=\"lossCoeff\")\n    bedfrictiontype: Optional[FrictionType] = Field(alias=\"bedFrictionType\")\n    bedfriction: Optional[float] = Field(alias=\"bedFriction\")\n    subtype: Optional[CulvertSubType] = Field(\n        CulvertSubType.culvert.value, alias=\"subType\"\n    )\n    bendlosscoeff: Optional[float] = Field(alias=\"bendLossCoeff\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\"relopening\", \"losscoeff\")\n    _flowdirection_validator = get_enum_validator(\"allowedflowdir\", enum=FlowDirection)\n    _subtype_validator = get_enum_validator(\"subtype\", enum=CulvertSubType)\n    _frictiontype_validator = get_enum_validator(\"bedfrictiontype\", enum=FrictionType)\n\n    @root_validator(allow_reuse=True)\n    def validate_that_valve_related_fields_are_present_for_culverts_with_valves(\n        cls, values: Dict\n    ) -&gt; Dict:\n        \"\"\"Validates that valve-related fields are present when there is a valve present.\"\"\"\n        return validate_required_fields(\n            values,\n            \"valveopeningheight\",\n            \"numlosscoeff\",\n            \"relopening\",\n            \"losscoeff\",\n            conditional_field_name=\"valveonoff\",\n            conditional_value=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_bendlosscoeff_field_is_present_for_invertedsyphons(\n        cls, values: Dict\n    ) -&gt; Dict:\n        \"\"\"Validates that the bendlosscoeff value is present when dealing with inverted syphons.\"\"\"\n        return validate_required_fields(\n            values,\n            \"bendlosscoeff\",\n            conditional_field_name=\"subtype\",\n            conditional_value=CulvertSubType.invertedSiphon,\n        )\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths(cls, values):\n        \"\"\"Validates that the length of the relopening and losscoeff fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"relopening\",\n            \"losscoeff\",\n            length_name=\"numlosscoeff\",\n            list_required_with_length=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def validate_that_bendlosscoeff_is_not_provided_for_culverts(\n        cls, values: Dict\n    ) -&gt; Dict:\n        \"\"\"Validates that the bendlosscoeff field is not provided when the subtype is a culvert.\"\"\"\n        return validate_forbidden_fields(\n            values,\n            \"bendlosscoeff\",\n            conditional_field_name=\"subtype\",\n            conditional_value=CulvertSubType.culvert,\n        )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Culvert.check_list_lengths","title":"<code>check_list_lengths(values)</code>","text":"<p>Validates that the length of the relopening and losscoeff fields are as expected.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths(cls, values):\n    \"\"\"Validates that the length of the relopening and losscoeff fields are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"relopening\",\n        \"losscoeff\",\n        length_name=\"numlosscoeff\",\n        list_required_with_length=True,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Culvert.validate_that_bendlosscoeff_field_is_present_for_invertedsyphons","title":"<code>validate_that_bendlosscoeff_field_is_present_for_invertedsyphons(values)</code>","text":"<p>Validates that the bendlosscoeff value is present when dealing with inverted syphons.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_bendlosscoeff_field_is_present_for_invertedsyphons(\n    cls, values: Dict\n) -&gt; Dict:\n    \"\"\"Validates that the bendlosscoeff value is present when dealing with inverted syphons.\"\"\"\n    return validate_required_fields(\n        values,\n        \"bendlosscoeff\",\n        conditional_field_name=\"subtype\",\n        conditional_value=CulvertSubType.invertedSiphon,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Culvert.validate_that_bendlosscoeff_is_not_provided_for_culverts","title":"<code>validate_that_bendlosscoeff_is_not_provided_for_culverts(values)</code>","text":"<p>Validates that the bendlosscoeff field is not provided when the subtype is a culvert.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_bendlosscoeff_is_not_provided_for_culverts(\n    cls, values: Dict\n) -&gt; Dict:\n    \"\"\"Validates that the bendlosscoeff field is not provided when the subtype is a culvert.\"\"\"\n    return validate_forbidden_fields(\n        values,\n        \"bendlosscoeff\",\n        conditional_field_name=\"subtype\",\n        conditional_value=CulvertSubType.culvert,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Culvert.validate_that_valve_related_fields_are_present_for_culverts_with_valves","title":"<code>validate_that_valve_related_fields_are_present_for_culverts_with_valves(values)</code>","text":"<p>Validates that valve-related fields are present when there is a valve present.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef validate_that_valve_related_fields_are_present_for_culverts_with_valves(\n    cls, values: Dict\n) -&gt; Dict:\n    \"\"\"Validates that valve-related fields are present when there is a valve present.\"\"\"\n    return validate_required_fields(\n        values,\n        \"valveopeningheight\",\n        \"numlosscoeff\",\n        \"relopening\",\n        \"losscoeff\",\n        conditional_field_name=\"valveonoff\",\n        conditional_value=True,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.CulvertSubType","title":"<code>CulvertSubType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class to store a Culvert's subType.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class CulvertSubType(StrEnum):\n    \"\"\"Enum class to store a [Culvert][hydrolib.core.dflowfm.structure.models.Culvert]'s subType.\"\"\"\n\n    culvert = \"culvert\"\n    invertedSiphon = \"invertedSiphon\"\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Dambreak","title":"<code>Dambreak</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=dambreak</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the dambreak input as described in UM Sec.C.12.10.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Dambreak(Structure):\n    \"\"\"\n    Hydraulic structure with `type=dambreak`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the dambreak input as described in\n    [UM Sec.C.12.10](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.10).\n    \"\"\"\n\n    class Comments(Structure.Comments):\n        type: Optional[str] = Field(\"Structure type; must read dambreak\", alias=\"type\")\n        startlocationx: Optional[str] = Field(\n            \"x-coordinate of breach starting point.\", alias=\"startLocationX\"\n        )\n        startlocationy: Optional[str] = Field(\n            \"y-coordinate of breach starting point.\", alias=\"startLocationY\"\n        )\n        algorithm: Optional[str] = Field(\n            \"Breach growth algorithm. Possible values are: 1 (van der Knaap (2000)), 2 (Verheij\u2013van der Knaap (2002)), 3: Predefined time series, see dambreakLevelsAndWidths\",\n            alias=\"algorithm\",\n        )\n        crestlevelini: Optional[str] = Field(\n            \"Initial breach level zcrest level [m AD].\", alias=\"crestLevelIni\"\n        )\n        breachwidthini: Optional[str] = Field(\n            \"Initial breach width B0 [m].\", alias=\"breachWidthIni\"\n        )\n        crestlevelmin: Optional[str] = Field(\n            \"Minimal breach level zmin [m AD].\", alias=\"crestLevelMin\"\n        )\n        t0: Optional[str] = Field(\"Breach start time Tstart [s].\", alias=\"t0\")\n        timetobreachtomaximumdepth: Optional[str] = Field(\n            \"tPhase 1 [s].\", alias=\"timeToBreachToMaximumDepth\"\n        )\n        f1: Optional[str] = Field(\"Factor f1 [-]\", alias=\"f1\")\n        f2: Optional[str] = Field(\"Factor f2 [-]\", alias=\"f2\")\n        ucrit: Optional[str] = Field(\n            \"Critical flow velocity uc for erosion [m/s].\", alias=\"uCrit\"\n        )\n        waterlevelupstreamlocationx: Optional[str] = Field(\n            \"(optional) x-coordinate of custom upstream water level point.\",\n            alias=\"waterLevelUpstreamLocationX\",\n        )\n        waterlevelupstreamlocationy: Optional[str] = Field(\n            \"(optional) y-coordinate of custom upstream water level point.\",\n            alias=\"waterLevelUpstreamLocationY\",\n        )\n        waterleveldownstreamlocationx: Optional[str] = Field(\n            \"(optional) x-coordinate of custom downstream water level point.\",\n            alias=\"waterLevelDownstreamLocationX\",\n        )\n        waterleveldownstreamlocationy: Optional[str] = Field(\n            \"(optional) y-coordinate of custom downstream water level point.\",\n            alias=\"waterLevelDownstreamLocationY\",\n        )\n        waterlevelupstreamnodeid: Optional[str] = Field(\n            \"(optional) Node Id of custom upstream water level point.\",\n            alias=\"waterLevelUpstreamNodeId\",\n        )\n        waterleveldownstreamnodeid: Optional[str] = Field(\n            \"(optional) Node Id of custom downstream water level point.\",\n            alias=\"waterLevelDownstreamNodeId\",\n        )\n        dambreaklevelsandwidths: Optional[str] = Field(\n            \"(only when algorithm=3) Filename of &lt;*.tim&gt; file (Section C.4) containing the breach levels and widths.\",\n            alias=\"dambreakLevelsAndWidths\",\n        )\n\n    comments: Comments = Comments()\n    type: Literal[\"dambreak\"] = Field(\"dambreak\", alias=\"type\")\n    startlocationx: float = Field(alias=\"startLocationX\")\n    startlocationy: float = Field(alias=\"startLocationY\")\n    algorithm: DambreakAlgorithm = Field(alias=\"algorithm\")\n\n    crestlevelini: float = Field(alias=\"crestLevelIni\")\n    breachwidthini: float = Field(alias=\"breachWidthIni\")\n    crestlevelmin: float = Field(alias=\"crestLevelMin\")\n    t0: float = Field(alias=\"t0\")\n    timetobreachtomaximumdepth: float = Field(alias=\"timeToBreachToMaximumDepth\")\n    f1: float = Field(alias=\"f1\")\n    f2: float = Field(alias=\"f2\")\n    ucrit: float = Field(alias=\"uCrit\")\n    waterlevelupstreamlocationx: Optional[float] = Field(\n        alias=\"waterLevelUpstreamLocationX\"\n    )\n    waterlevelupstreamlocationy: Optional[float] = Field(\n        alias=\"waterLevelUpstreamLocationY\"\n    )\n    waterleveldownstreamlocationx: Optional[float] = Field(\n        alias=\"waterLevelDownstreamLocationX\"\n    )\n    waterleveldownstreamlocationy: Optional[float] = Field(\n        alias=\"waterLevelDownstreamLocationY\"\n    )\n    waterlevelupstreamnodeid: Optional[str] = Field(alias=\"waterLevelUpstreamNodeId\")\n    waterleveldownstreamnodeid: Optional[str] = Field(\n        alias=\"waterLevelDownstreamNodeId\"\n    )\n    dambreaklevelsandwidths: Optional[Union[TimModel, ForcingModel]] = Field(\n        alias=\"dambreakLevelsAndWidths\"\n    )\n\n    @validator(\"algorithm\", pre=True)\n    @classmethod\n    def validate_algorithm(cls, value: str) -&gt; DambreakAlgorithm:\n        \"\"\"\n        Validates the algorithm parameter for the dambreak structure.\n\n        Args:\n            value (int): algorithm value read from the user's input.\n\n        Raises:\n            ValueError: When the value given is not of type int.\n            ValueError: When the value given is not in the range [1,3]\n\n        Returns:\n            int: Validated value.\n        \"\"\"\n        int_value = -1\n        try:\n            int_value = int(value)\n        except Exception:\n            raise ValueError(\"Dambreak algorithm value should be of type int.\")\n        if 0 &lt; int_value &lt;= 3:\n            return DambreakAlgorithm(int_value)\n        raise ValueError(\"Dambreak algorithm value should be 1, 2 or 3.\")\n\n    @validator(\"dambreaklevelsandwidths\")\n    @classmethod\n    def validate_dambreak_levels_and_widths(\n        cls, field_value: Optional[Union[TimModel, ForcingModel]], values: dict\n    ) -&gt; Optional[Union[TimModel, ForcingModel]]:\n        \"\"\"\n        Validates whether a dambreak can be created with the given dambreakLevelsAndWidths\n        property. This property should be given when the algorithm value is 3.\n\n        Args:\n            field_value (Optional[Union[TimModel, ForcingModel]]): Value given for dambreakLevelsAndWidths.\n            values (dict): Dictionary of values already validated (assuming algorithm is in it).\n\n        Raises:\n            ValueError: When algorithm value is not 3 and field_value has a value.\n\n        Returns:\n            Optional[Union[TimModel, ForcingModel]]: The value given for dambreakLevelsAndwidths.\n        \"\"\"\n        # Retrieve the algorithm value (if not found use 0).\n        algorithm_value = values.get(\"algorithm\", 0)\n        if field_value is not None and algorithm_value != 3:\n            # dambreakLevelsAndWidths can only be set when algorithm = 3\n            raise ValueError(\n                f\"Dambreak field dambreakLevelsAndWidths can only be set when algorithm = 3, current value: {algorithm_value}.\"\n            )\n        return field_value\n\n    @root_validator\n    @classmethod\n    def check_location_dambreak(cls, values: dict) -&gt; dict:\n        \"\"\"\n        Verifies whether the location for this structure contains valid values for\n        numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file.\n        Verifies whether de water level location specifications are valid.\n\n        Args:\n            values (dict): Dictionary of validated values to create a Dambreak.\n\n        Raises:\n            ValueError: When the values dictionary does not contain valid coordinates or polyline file or when the water level location specifications are not valid.\n\n        Returns:\n            dict: Dictionary of validated values.\n        \"\"\"\n\n        def _validate_waterlevel_location(x_key: str, y_key: str, node_key: str):\n            x_is_given = values.get(x_key.lower()) is not None\n            y_is_given = values.get(y_key.lower()) is not None\n            node_is_given = values.get(node_key.lower()) is not None\n\n            if (x_is_given and y_is_given and not node_is_given) or (\n                node_is_given and not x_is_given and not y_is_given\n            ):\n                return\n\n            raise ValueError(\n                f\"Either `{node_key}` should be specified or `{x_key}` and `{y_key}`.\"\n            )\n\n        _validate_waterlevel_location(\n            \"waterLevelUpstreamLocationX\",\n            \"waterLevelUpstreamLocationY\",\n            \"waterLevelUpstreamNodeId\",\n        )\n        _validate_waterlevel_location(\n            \"waterLevelDownstreamLocationX\",\n            \"waterLevelDownstreamLocationY\",\n            \"waterLevelDownstreamNodeId\",\n        )\n\n        return values\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Dambreak.check_location_dambreak","title":"<code>check_location_dambreak(values)</code>  <code>classmethod</code>","text":"<p>Verifies whether the location for this structure contains valid values for numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file. Verifies whether de water level location specifications are valid.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>dict</code> <p>Dictionary of validated values to create a Dambreak.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the values dictionary does not contain valid coordinates or polyline file or when the water level location specifications are not valid.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of validated values.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator\n@classmethod\ndef check_location_dambreak(cls, values: dict) -&gt; dict:\n    \"\"\"\n    Verifies whether the location for this structure contains valid values for\n    numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file.\n    Verifies whether de water level location specifications are valid.\n\n    Args:\n        values (dict): Dictionary of validated values to create a Dambreak.\n\n    Raises:\n        ValueError: When the values dictionary does not contain valid coordinates or polyline file or when the water level location specifications are not valid.\n\n    Returns:\n        dict: Dictionary of validated values.\n    \"\"\"\n\n    def _validate_waterlevel_location(x_key: str, y_key: str, node_key: str):\n        x_is_given = values.get(x_key.lower()) is not None\n        y_is_given = values.get(y_key.lower()) is not None\n        node_is_given = values.get(node_key.lower()) is not None\n\n        if (x_is_given and y_is_given and not node_is_given) or (\n            node_is_given and not x_is_given and not y_is_given\n        ):\n            return\n\n        raise ValueError(\n            f\"Either `{node_key}` should be specified or `{x_key}` and `{y_key}`.\"\n        )\n\n    _validate_waterlevel_location(\n        \"waterLevelUpstreamLocationX\",\n        \"waterLevelUpstreamLocationY\",\n        \"waterLevelUpstreamNodeId\",\n    )\n    _validate_waterlevel_location(\n        \"waterLevelDownstreamLocationX\",\n        \"waterLevelDownstreamLocationY\",\n        \"waterLevelDownstreamNodeId\",\n    )\n\n    return values\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Dambreak.validate_algorithm","title":"<code>validate_algorithm(value)</code>  <code>classmethod</code>","text":"<p>Validates the algorithm parameter for the dambreak structure.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>algorithm value read from the user's input.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the value given is not of type int.</p> <code>ValueError</code> <p>When the value given is not in the range [1,3]</p> <p>Returns:</p> Name Type Description <code>int</code> <code>DambreakAlgorithm</code> <p>Validated value.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@validator(\"algorithm\", pre=True)\n@classmethod\ndef validate_algorithm(cls, value: str) -&gt; DambreakAlgorithm:\n    \"\"\"\n    Validates the algorithm parameter for the dambreak structure.\n\n    Args:\n        value (int): algorithm value read from the user's input.\n\n    Raises:\n        ValueError: When the value given is not of type int.\n        ValueError: When the value given is not in the range [1,3]\n\n    Returns:\n        int: Validated value.\n    \"\"\"\n    int_value = -1\n    try:\n        int_value = int(value)\n    except Exception:\n        raise ValueError(\"Dambreak algorithm value should be of type int.\")\n    if 0 &lt; int_value &lt;= 3:\n        return DambreakAlgorithm(int_value)\n    raise ValueError(\"Dambreak algorithm value should be 1, 2 or 3.\")\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Dambreak.validate_dambreak_levels_and_widths","title":"<code>validate_dambreak_levels_and_widths(field_value, values)</code>  <code>classmethod</code>","text":"<p>Validates whether a dambreak can be created with the given dambreakLevelsAndWidths property. This property should be given when the algorithm value is 3.</p> <p>Parameters:</p> Name Type Description Default <code>field_value</code> <code>Optional[Union[TimModel, ForcingModel]]</code> <p>Value given for dambreakLevelsAndWidths.</p> required <code>values</code> <code>dict</code> <p>Dictionary of values already validated (assuming algorithm is in it).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When algorithm value is not 3 and field_value has a value.</p> <p>Returns:</p> Type Description <code>Optional[Union[TimModel, ForcingModel]]</code> <p>Optional[Union[TimModel, ForcingModel]]: The value given for dambreakLevelsAndwidths.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@validator(\"dambreaklevelsandwidths\")\n@classmethod\ndef validate_dambreak_levels_and_widths(\n    cls, field_value: Optional[Union[TimModel, ForcingModel]], values: dict\n) -&gt; Optional[Union[TimModel, ForcingModel]]:\n    \"\"\"\n    Validates whether a dambreak can be created with the given dambreakLevelsAndWidths\n    property. This property should be given when the algorithm value is 3.\n\n    Args:\n        field_value (Optional[Union[TimModel, ForcingModel]]): Value given for dambreakLevelsAndWidths.\n        values (dict): Dictionary of values already validated (assuming algorithm is in it).\n\n    Raises:\n        ValueError: When algorithm value is not 3 and field_value has a value.\n\n    Returns:\n        Optional[Union[TimModel, ForcingModel]]: The value given for dambreakLevelsAndwidths.\n    \"\"\"\n    # Retrieve the algorithm value (if not found use 0).\n    algorithm_value = values.get(\"algorithm\", 0)\n    if field_value is not None and algorithm_value != 3:\n        # dambreakLevelsAndWidths can only be set when algorithm = 3\n        raise ValueError(\n            f\"Dambreak field dambreakLevelsAndWidths can only be set when algorithm = 3, current value: {algorithm_value}.\"\n        )\n    return field_value\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.DambreakAlgorithm","title":"<code>DambreakAlgorithm</code>","text":"<p>               Bases: <code>int</code>, <code>Enum</code></p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class DambreakAlgorithm(int, Enum):\n    van_der_knaap = 1  # \"van der Knaap, 2000\"\n    verheij_van_der_knaap = 2  # \"Verheij-van der Knaap, 2002\"\n    timeseries = 3  # \"Predefined time series, dambreakLevelsAndWidths.\"\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"\n        Property to return the description of the enums defined above.\n        Useful for comments in output files.\n\n        Returns:\n            str: Description for the current enum.\n        \"\"\"\n        description_dict = dict(\n            van_der_knaap=\"van der Knaap, 2000\",\n            verheij_van_der_knaap=\"Verheij-van der Knaap, 2002\",\n            timeseries=\"Predefined time series, dambreakLevelsAndWidths\",\n        )\n        return description_dict[self.name]\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.DambreakAlgorithm.description","title":"<code>description</code>  <code>property</code>","text":"<p>Property to return the description of the enums defined above. Useful for comments in output files.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Description for the current enum.</p>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.FlowDirection","title":"<code>FlowDirection</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the allowedFlowDirection attribute in several subclasses of Structure.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class FlowDirection(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the allowedFlowDirection\n    attribute in several subclasses of Structure.\n    \"\"\"\n\n    none = \"none\"\n    positive = \"positive\"\n    negative = \"negative\"\n    both = \"both\"\n    allowedvaluestext = \"Possible values: both, positive, negative, none.\"\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.GateOpeningHorizontalDirection","title":"<code>GateOpeningHorizontalDirection</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Horizontal opening direction of gate door[s].</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class GateOpeningHorizontalDirection(StrEnum):\n    \"\"\"Horizontal opening direction of gate door[s].\"\"\"\n\n    symmetric = \"symmetric\"\n    from_left = \"fromLeft\"\n    from_right = \"fromRight\"\n    allowedvaluestext = \"Possible values: symmetric, fromLeft, fromRight.\"\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.GeneralStructure","title":"<code>GeneralStructure</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=generalStructure</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the orifice input as described in UM Sec.C.12.9.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class GeneralStructure(Structure):\n    \"\"\"\n    Hydraulic structure with `type=generalStructure`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the orifice input as described in\n    [UM Sec.C.12.9](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.9).\n    \"\"\"\n\n    class Comments(Structure.Comments):\n        type: Optional[str] = Field(\n            \"Structure type; must read generalStructure\", alias=\"type\"\n        )\n        allowedflowdir: Optional[str] = Field(\n            FlowDirection.allowedvaluestext, alias=\"allowedFlowDir\"\n        )\n\n        upstream1width: Optional[str] = Field(\"w_u1 [m]\", alias=\"upstream1Width\")\n        upstream1level: Optional[str] = Field(\"z_u1 [m AD]\", alias=\"upstream1Level\")\n        upstream2width: Optional[str] = Field(\"w_u2 [m]\", alias=\"upstream2Width\")\n        upstream2level: Optional[str] = Field(\"z_u2 [m D]\", alias=\"upstream2Level\")\n\n        crestwidth: Optional[str] = Field(\"w_s [m]\", alias=\"crestWidth\")\n        crestlevel: Optional[str] = Field(\"z_s [m AD]\", alias=\"crestLevel\")\n        crestlength: Optional[str] = Field(\n            \"The crest length across the general structure [m]. When the crest length &gt; 0, the extra resistance for this structure will be ls * g/(C2 * waterdepth)\",\n            alias=\"crestLength\",\n        )\n\n        downstream1width: Optional[str] = Field(\"w_d1 [m]\", alias=\"downstream1Width\")\n        downstream1level: Optional[str] = Field(\"z_d1 [m AD]\", alias=\"downstream1Level\")\n        downstream2width: Optional[str] = Field(\"w_d2 [m]\", alias=\"downstream2Width\")\n        downstream2level: Optional[str] = Field(\"z_d2 [m AD]\", alias=\"downstream2Level\")\n\n        gateloweredgelevel: Optional[str] = Field(\n            \"Position of gate door\u2019s lower edge [m AD]\", alias=\"gateLowerEdgeLevel\"\n        )\n        posfreegateflowcoeff: Optional[str] = Field(\n            \"Positive free gate flow corr.coeff. cgf [-]\", alias=\"posFreeGateFlowCoeff\"\n        )\n        posdrowngateflowcoeff: Optional[str] = Field(\n            \"Positive drowned gate flow corr.coeff. cgd [-]\",\n            alias=\"posDrownGateFlowCoeff\",\n        )\n        posfreeweirflowcoeff: Optional[str] = Field(\n            \"Positive free weir flow corr.coeff. cwf [-]\", alias=\"posFreeWeirFlowCoeff\"\n        )\n        posdrownweirflowcoeff: Optional[str] = Field(\n            \"Positive drowned weir flow corr.coeff. cwd [-]\",\n            alias=\"posDrownWeirFlowCoeff\",\n        )\n        poscontrcoeffreegate: Optional[str] = Field(\n            \"Positive gate flow contraction coefficient \u00b5gf [-]\",\n            alias=\"posContrCoefFreeGate\",\n        )\n        negfreegateflowcoeff: Optional[str] = Field(\n            \"Negative free gate flow corr.coeff. cgf [-]\", alias=\"negFreeGateFlowCoeff\"\n        )\n        negdrowngateflowcoeff: Optional[str] = Field(\n            \"Negative drowned gate flow corr.coeff. cgd [-]\",\n            alias=\"negDrownGateFlowCoeff\",\n        )\n        negfreeweirflowcoeff: Optional[str] = Field(\n            \"Negative free weir flow corr.coeff. cwf [-]\", alias=\"negFreeWeirFlowCoeff\"\n        )\n        negdrownweirflowcoeff: Optional[str] = Field(\n            \"Negative drowned weir flow corr.coeff. cwd [-]\",\n            alias=\"negDrownWeirFlowCoeff\",\n        )\n        negcontrcoeffreegate: Optional[str] = Field(\n            \"Negative gate flow contraction coefficient mu gf [-]\",\n            alias=\"negContrCoefFreeGate\",\n        )\n        extraresistance: Optional[str] = Field(\n            \"Extra resistance [-]\", alias=\"extraResistance\"\n        )\n        gateheight: Optional[str] = Field(None, alias=\"gateHeight\")\n        gateopeningwidth: Optional[str] = Field(\n            \"Opening width between gate doors [m], should be smaller than (or equal to) crestWidth\",\n            alias=\"gateOpeningWidth\",\n        )\n        gateopeninghorizontaldirection: Optional[str] = Field(\n            \"Horizontal opening direction of gate door[s]. Possible values are: symmetric, fromLeft, fromRight\",\n            alias=\"gateOpeningHorizontalDirection\",\n        )\n        usevelocityheight: Optional[str] = Field(\n            \"Flag indicates whether the velocity height is to be calculated or not\",\n            alias=\"useVelocityHeight\",\n        )\n\n    comments: Optional[Comments] = Comments()\n\n    type: Literal[\"generalStructure\"] = Field(\"generalStructure\", alias=\"type\")\n    allowedflowdir: Optional[FlowDirection] = Field(\n        FlowDirection.both.value, alias=\"allowedFlowDir\"\n    )\n\n    upstream1width: Optional[float] = Field(10.0, alias=\"upstream1Width\")\n    upstream1level: Optional[float] = Field(0.0, alias=\"upstream1Level\")\n    upstream2width: Optional[float] = Field(10.0, alias=\"upstream2Width\")\n    upstream2level: Optional[float] = Field(0.0, alias=\"upstream2Level\")\n\n    crestwidth: Optional[float] = Field(10.0, alias=\"crestWidth\")\n    crestlevel: Optional[ForcingData] = Field(0.0, alias=\"crestLevel\")\n    crestlength: Optional[float] = Field(0.0, alias=\"crestLength\")\n\n    downstream1width: Optional[float] = Field(10.0, alias=\"downstream1Width\")\n    downstream1level: Optional[float] = Field(0.0, alias=\"downstream1Level\")\n    downstream2width: Optional[float] = Field(10.0, alias=\"downstream2Width\")\n    downstream2level: Optional[float] = Field(0.0, alias=\"downstream2Level\")\n\n    gateloweredgelevel: Optional[ForcingData] = Field(11.0, alias=\"gateLowerEdgeLevel\")\n    posfreegateflowcoeff: Optional[float] = Field(1.0, alias=\"posFreeGateFlowCoeff\")\n    posdrowngateflowcoeff: Optional[float] = Field(1.0, alias=\"posDrownGateFlowCoeff\")\n    posfreeweirflowcoeff: Optional[float] = Field(1.0, alias=\"posFreeWeirFlowCoeff\")\n    posdrownweirflowcoeff: Optional[float] = Field(1.0, alias=\"posDrownWeirFlowCoeff\")\n    poscontrcoeffreegate: Optional[float] = Field(1.0, alias=\"posContrCoefFreeGate\")\n    negfreegateflowcoeff: Optional[float] = Field(1.0, alias=\"negFreeGateFlowCoeff\")\n    negdrowngateflowcoeff: Optional[float] = Field(1.0, alias=\"negDrownGateFlowCoeff\")\n    negfreeweirflowcoeff: Optional[float] = Field(1.0, alias=\"negFreeWeirFlowCoeff\")\n    negdrownweirflowcoeff: Optional[float] = Field(1.0, alias=\"negDrownWeirFlowCoeff\")\n    negcontrcoeffreegate: Optional[float] = Field(1.0, alias=\"negContrCoefFreeGate\")\n    extraresistance: Optional[float] = Field(0.0, alias=\"extraResistance\")\n    gateheight: Optional[float] = Field(1e10, alias=\"gateHeight\")\n    gateopeningwidth: Optional[ForcingData] = Field(0.0, alias=\"gateOpeningWidth\")\n    gateopeninghorizontaldirection: Optional[GateOpeningHorizontalDirection] = Field(\n        GateOpeningHorizontalDirection.symmetric.value,\n        alias=\"gateOpeningHorizontalDirection\",\n    )\n    usevelocityheight: Optional[bool] = Field(True, alias=\"useVelocityHeight\")\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.LongCulvert","title":"<code>LongCulvert</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=longCulvert</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the long culvert input as described in UM Sec.C.13.4.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class LongCulvert(Structure):\n    \"\"\"\n    Hydraulic structure with `type=longCulvert`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the long culvert input as described in\n    [UM Sec.C.13.4](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.13.4).\n    \"\"\"\n\n    type: Literal[\"longCulvert\"] = Field(\"longCulvert\", alias=\"type\")\n    allowedflowdir: Optional[FlowDirection] = Field(alias=\"allowedFlowDir\")\n    zcoordinates: Optional[List[float]] = Field(None, alias=\"zCoordinates\")\n\n    width: float = Field(alias=\"width\")\n    height: float = Field(alias=\"height\")\n    frictiontype: FrictionType = Field(alias=\"frictionType\")\n    frictionvalue: float = Field(alias=\"frictionValue\")\n    valverelativeopening: float = Field(alias=\"valveRelativeOpening\")\n    csdefid: Optional[str] = Field(alias=\"csDefId\")\n\n    _frictiontype_validator = get_enum_validator(\"frictiontype\", enum=FrictionType)\n    _flowdirection_validator = get_enum_validator(\"allowedflowdir\", enum=FlowDirection)\n\n    _split_to_list = get_split_string_on_delimiter_validator(\"zcoordinates\")\n\n    @validator(\"zcoordinates\", always=True)\n    @classmethod\n    def _validate_zcoordinates(cls, v, values):\n        if v is None:\n            return v\n\n        if len(v) != values[\"numcoordinates\"]:\n            raise ValueError(\n                f\"Expected {values['numcoordinates']} z-coordinates, but got {len(v)}.\"\n            )\n\n        return v\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Orientation","title":"<code>Orientation</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum class containing the valid values for the orientation attribute in several subclasses of Structure.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Orientation(StrEnum):\n    \"\"\"\n    Enum class containing the valid values for the orientation\n    attribute in several subclasses of Structure.\n    \"\"\"\n\n    positive = \"positive\"\n    negative = \"negative\"\n    allowedvaluestext = \"Possible values: positive, negative.\"\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Orifice","title":"<code>Orifice</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=orifice</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the orifice input as described in UM Sec.C.12.7.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Orifice(Structure):\n    \"\"\"\n    Hydraulic structure with `type=orifice`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the orifice input as described in\n    [UM Sec.C.12.7](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.7).\n    \"\"\"\n\n    type: Literal[\"orifice\"] = Field(\"orifice\", alias=\"type\")\n    allowedflowdir: Optional[FlowDirection] = Field(\n        FlowDirection.both.value, alias=\"allowedFlowDir\"\n    )\n\n    crestlevel: ForcingData = Field(alias=\"crestLevel\")\n    crestwidth: Optional[float] = Field(None, alias=\"crestWidth\")\n    gateloweredgelevel: ForcingData = Field(alias=\"gateLowerEdgeLevel\")\n    corrcoeff: float = Field(1.0, alias=\"corrCoeff\")\n    usevelocityheight: bool = Field(True, alias=\"useVelocityHeight\")\n\n    # TODO Use a validator here to check the optionals related to the bool field\n    uselimitflowpos: Optional[bool] = Field(False, alias=\"useLimitFlowPos\")\n    limitflowpos: Optional[float] = Field(alias=\"limitFlowPos\")\n\n    uselimitflowneg: Optional[bool] = Field(False, alias=\"useLimitFlowNeg\")\n    limitflowneg: Optional[float] = Field(alias=\"limitFlowNeg\")\n\n    _flowdirection_validator = get_enum_validator(\"allowedflowdir\", enum=FlowDirection)\n\n    @validator(\"limitflowpos\", always=True)\n    @classmethod\n    def _validate_limitflowpos(cls, v, values):\n        return cls._validate_limitflow(v, values, \"limitFlowPos\", \"useLimitFlowPos\")\n\n    @validator(\"limitflowneg\", always=True)\n    @classmethod\n    def _validate_limitflowneg(cls, v, values):\n        return cls._validate_limitflow(v, values, \"limitFlowNeg\", \"useLimitFlowNeg\")\n\n    @classmethod\n    def _validate_limitflow(cls, v, values, limitflow: str, uselimitflow: str):\n        if v is None and values[uselimitflow.lower()] == True:\n            raise ValueError(\n                f\"{limitflow} should be defined when {uselimitflow} is true\"\n            )\n\n        return v\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Pump","title":"<code>Pump</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=pump</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the pump input as described in UM Sec.C.12.6.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Pump(Structure):\n    \"\"\"\n    Hydraulic structure with `type=pump`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the pump input as described in\n    [UM Sec.C.12.6](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.6).\n    \"\"\"\n\n    type: Literal[\"pump\"] = Field(\"pump\", alias=\"type\")\n\n    orientation: Optional[Orientation] = Field(alias=\"orientation\")\n    controlside: Optional[str] = Field(alias=\"controlSide\")  # TODO Enum\n    numstages: Optional[int] = Field(alias=\"numStages\")\n    capacity: ForcingData = Field(alias=\"capacity\")\n\n    startlevelsuctionside: Optional[List[float]] = Field(alias=\"startLevelSuctionSide\")\n    stoplevelsuctionside: Optional[List[float]] = Field(alias=\"stopLevelSuctionSide\")\n    startleveldeliveryside: Optional[List[float]] = Field(\n        alias=\"startLevelDeliverySide\"\n    )\n    stopleveldeliveryside: Optional[List[float]] = Field(alias=\"stopLevelDeliverySide\")\n    numreductionlevels: Optional[int] = Field(alias=\"numReductionLevels\")\n    head: Optional[List[float]] = Field(alias=\"head\")\n    reductionfactor: Optional[List[float]] = Field(alias=\"reductionFactor\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"startlevelsuctionside\",\n        \"stoplevelsuctionside\",\n        \"startleveldeliveryside\",\n        \"stopleveldeliveryside\",\n        \"head\",\n        \"reductionfactor\",\n    )\n\n    _orientation_validator = get_enum_validator(\"orientation\", enum=Orientation)\n\n    @root_validator(allow_reuse=True)\n    def validate_that_controlside_is_provided_when_numstages_is_provided(\n        cls, values: Dict\n    ) -&gt; Dict:\n        return validate_required_fields(\n            values,\n            \"controlside\",\n            conditional_field_name=\"numstages\",\n            conditional_value=0,\n            comparison_func=gt,\n        )\n\n    @classmethod\n    def _check_list_lengths_suctionside(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the length of the startlevelsuctionside and stoplevelsuctionside fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"startlevelsuctionside\",\n            \"stoplevelsuctionside\",\n            length_name=\"numstages\",\n            list_required_with_length=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def conditionally_check_list_lengths_suctionside(cls, values: Dict) -&gt; Dict:\n        \"\"\"\n        Validates the length of the suction side fields, but only if there is a controlside value\n        present in the values and the controlside is not equal to the deliverySide.\n        \"\"\"\n        return validate_conditionally(\n            cls,\n            values,\n            Pump._check_list_lengths_suctionside,\n            \"controlside\",\n            \"deliverySide\",\n            ne,\n        )\n\n    @classmethod\n    def _check_list_lengths_deliveryside(cls, values: Dict) -&gt; Dict:\n        \"\"\"Validates that the length of the startleveldeliveryside and stopleveldeliveryside fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"startleveldeliveryside\",\n            \"stopleveldeliveryside\",\n            length_name=\"numstages\",\n            list_required_with_length=True,\n        )\n\n    @root_validator(allow_reuse=True)\n    def conditionally_check_list_lengths_deliveryside(cls, values: Dict) -&gt; Dict:\n        \"\"\"\n        Validates the length of the delivery side fields, but only if there is a controlside value\n        present in the values and the controlside is not equal to the suctionSide.\n        \"\"\"\n        return validate_conditionally(\n            cls,\n            values,\n            Pump._check_list_lengths_deliveryside,\n            \"controlside\",\n            \"suctionSide\",\n            ne,\n        )\n\n    @root_validator(allow_reuse=True)\n    def check_list_lengths_head_and_reductionfactor(cls, values):\n        \"\"\"Validates that the lengths of the head and reductionfactor fields are as expected.\"\"\"\n        return validate_correct_length(\n            values,\n            \"head\",\n            \"reductionfactor\",\n            length_name=\"numreductionlevels\",\n            list_required_with_length=True,\n        )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Pump.check_list_lengths_head_and_reductionfactor","title":"<code>check_list_lengths_head_and_reductionfactor(values)</code>","text":"<p>Validates that the lengths of the head and reductionfactor fields are as expected.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef check_list_lengths_head_and_reductionfactor(cls, values):\n    \"\"\"Validates that the lengths of the head and reductionfactor fields are as expected.\"\"\"\n    return validate_correct_length(\n        values,\n        \"head\",\n        \"reductionfactor\",\n        length_name=\"numreductionlevels\",\n        list_required_with_length=True,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Pump.conditionally_check_list_lengths_deliveryside","title":"<code>conditionally_check_list_lengths_deliveryside(values)</code>","text":"<p>Validates the length of the delivery side fields, but only if there is a controlside value present in the values and the controlside is not equal to the suctionSide.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef conditionally_check_list_lengths_deliveryside(cls, values: Dict) -&gt; Dict:\n    \"\"\"\n    Validates the length of the delivery side fields, but only if there is a controlside value\n    present in the values and the controlside is not equal to the suctionSide.\n    \"\"\"\n    return validate_conditionally(\n        cls,\n        values,\n        Pump._check_list_lengths_deliveryside,\n        \"controlside\",\n        \"suctionSide\",\n        ne,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Pump.conditionally_check_list_lengths_suctionside","title":"<code>conditionally_check_list_lengths_suctionside(values)</code>","text":"<p>Validates the length of the suction side fields, but only if there is a controlside value present in the values and the controlside is not equal to the deliverySide.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator(allow_reuse=True)\ndef conditionally_check_list_lengths_suctionside(cls, values: Dict) -&gt; Dict:\n    \"\"\"\n    Validates the length of the suction side fields, but only if there is a controlside value\n    present in the values and the controlside is not equal to the deliverySide.\n    \"\"\"\n    return validate_conditionally(\n        cls,\n        values,\n        Pump._check_list_lengths_suctionside,\n        \"controlside\",\n        \"deliverySide\",\n        ne,\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Structure","title":"<code>Structure</code>","text":"<p>               Bases: <code>INIBasedModel</code></p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Structure(INIBasedModel):\n    # TODO: would we want to load this from something externally and generate these automatically\n    class Comments(INIBasedModel.Comments):\n        id: Optional[str] = \"Unique structure id (max. 256 characters).\"\n        name: Optional[str] = \"Given name in the user interface.\"\n        polylinefile: Optional[str] = Field(\n            \"*.pli; Polyline geometry definition for 2D structure.\",\n            alias=\"polylinefile\",\n        )\n        branchid: Optional[str] = Field(\n            \"Branch on which the structure is located.\", alias=\"branchId\"\n        )\n        chainage: Optional[str] = \"Chainage on the branch (m).\"\n\n        numcoordinates: Optional[str] = Field(\n            \"Number of values in xCoordinates and yCoordinates\", alias=\"numCoordinates\"\n        )\n        xcoordinates: Optional[str] = Field(\n            \"x-coordinates of the location of the structure. (number of values = numCoordinates)\",\n            alias=\"xCoordinates\",\n        )\n        ycoordinates: Optional[str] = Field(\n            \"y-coordinates of the location of the structure. (number of values = numCoordinates)\",\n            alias=\"yCoordinates\",\n        )\n\n    comments: Comments = Comments()\n\n    _header: Literal[\"Structure\"] = \"Structure\"\n\n    id: str = Field(\"id\", max_length=256, alias=\"id\")\n    name: str = Field(\"id\", alias=\"name\")\n    type: str = Field(alias=\"type\")\n\n    polylinefile: Optional[DiskOnlyFileModel] = Field(None, alias=\"polylinefile\")\n\n    branchid: Optional[str] = Field(None, alias=\"branchId\")\n    chainage: Optional[float] = Field(None, alias=\"chainage\")\n\n    numcoordinates: Optional[int] = Field(None, alias=\"numCoordinates\")\n    xcoordinates: Optional[List[float]] = Field(None, alias=\"xCoordinates\")\n    ycoordinates: Optional[List[float]] = Field(None, alias=\"yCoordinates\")\n\n    _loc_coord_fields = {\"numcoordinates\", \"xcoordinates\", \"ycoordinates\"}\n    _loc_branch_fields = {\"branchid\", \"chainage\"}\n    _loc_all_fields = _loc_coord_fields | _loc_branch_fields\n\n    @classmethod\n    def _get_unknown_keyword_error_manager(cls) -&gt; Optional[UnknownKeywordErrorManager]:\n        \"\"\"\n        The Structure does not currently support raising an error on unknown keywords.\n        \"\"\"\n        return None\n\n    _split_to_list = get_split_string_on_delimiter_validator(\n        \"xcoordinates\", \"ycoordinates\"\n    )\n\n    @validator(\"type\", pre=True)\n    def _validate_type(cls, value):\n        return get_from_subclass_defaults(Structure, \"type\", value)\n\n    @root_validator\n    @classmethod\n    def check_location(cls, values: dict) -&gt; dict:\n        \"\"\"\n        Validates the location of the structure based on the given parameters.\n        For instance, if a branchid is given, then it is expected also the chainage,\n        otherwise numcoordinates xcoordinates and ycoordinates shall be expected.\n\n        Args:\n            values (dict): Dictionary of values validated for the new structure.\n\n        Raises:\n            ValueError: When branchid or chainage values are not valid (empty strings).\n            ValueError: When the number of xcoordinates and ycoordinates do not match numcoordinates.\n\n        Returns:\n            dict: Dictionary of values validated for the new structure.\n        \"\"\"\n        filtered_values = {k: v for k, v in values.items() if v is not None}\n        structype = filtered_values.get(\"type\", \"\").lower()\n\n        if structype == \"compound\" or issubclass(cls, (Compound)):\n            # Compound structure does not require a location specification.\n            return values\n\n        # Backwards compatibility for old-style polylinefile input field (instead of num/x/yCoordinates):\n        polyline_compatible_structures = dict(\n            pump=\"Pump\",\n            dambreak=\"Dambreak\",\n            gate=\"Gate\",\n            weir=\"Weir\",\n            generalstructure=\"GeneralStructure\",\n        )\n        polylinefile_in_model = (\n            structype in polyline_compatible_structures.keys()\n            and filtered_values.get(\"polylinefile\") is not None\n        )\n\n        # No branchId+chainage for some structures:\n        only_coordinates_structures = dict(\n            longculvert=\"LongCulvert\", dambreak=\"Dambreak\"\n        )\n        coordinates_in_model = Structure.validate_coordinates_in_model(filtered_values)\n\n        # Error: do not allow both x/y and polyline file:\n        assert not (\n            polylinefile_in_model and coordinates_in_model\n        ), f\"`Specify location either by `num/x/yCoordinates` or `polylinefile`, but not both.\"\n\n        # Error: require x/y or polyline file:\n        if (\n            structype in polyline_compatible_structures.keys()\n            and structype in only_coordinates_structures.keys()\n        ):\n            assert (\n                coordinates_in_model or polylinefile_in_model\n            ), f\"Specify location either by setting `num/x/yCoordinates` or `polylinefile` fields for a {polyline_compatible_structures[structype]} structure.\"\n\n        # Error: Some structures require coordinates_in_model, but not branchId and chainage.\n        if (\n            not polylinefile_in_model\n            and structype in only_coordinates_structures.keys()\n        ):\n            assert (\n                coordinates_in_model\n            ), f\"Specify location by setting `num/x/yCoordinates` for a {only_coordinates_structures[structype]} structure.\"\n\n        # Error: final check: at least one of x/y, branchId+chainage or polyline file must be given\n        branch_and_chainage_in_model = Structure.validate_branch_and_chainage_in_model(\n            filtered_values\n        )\n        assert (\n            branch_and_chainage_in_model\n            or coordinates_in_model\n            or polylinefile_in_model\n        ), \"Specify location either by setting `branchId` and `chainage` or `num/x/yCoordinates` or `polylinefile` fields.\"\n\n        return values\n\n    @staticmethod\n    def validate_branch_and_chainage_in_model(values: dict) -&gt; bool:\n        \"\"\"\n        Static method to validate whether the given branchid and chainage values\n        match the expectation of a new structure.\n\n        Args:\n            values (dict): Dictionary of values to be used to generate a structure.\n\n        Raises:\n            ValueError: When the value for branchid or chainage are not valid.\n\n        Returns:\n            bool: Result of valid branchid / chainage in dictionary.\n        \"\"\"\n        branchid = values.get(\"branchid\", None)\n        if branchid is None:\n            return False\n\n        chainage = values.get(\"chainage\", None)\n        if str_is_empty_or_none(branchid) or chainage is None:\n            raise ValueError(\n                \"A valid value for branchId and chainage is required when branchId key is specified.\"\n            )\n        return True\n\n    @staticmethod\n    def validate_coordinates_in_model(values: dict) -&gt; bool:\n        \"\"\"\n        Static method to validate whether the given values match the expectations\n        of a structure to define its coordinates.\n\n        Args:\n            values (dict): Dictionary of values to be used to generate a structure.\n\n        Raises:\n            ValueError: When the given coordinates is less than 2.\n            ValueError: When the given coordinates do not match in expected size.\n\n        Returns:\n            bool: Result of valid coordinates in dictionary.\n        \"\"\"\n        searched_keys = [\"numcoordinates\", \"xcoordinates\", \"ycoordinates\"]\n        if any(values.get(k, None) is None for k in searched_keys):\n            return False\n\n        n_coords = values[\"numcoordinates\"]\n        if n_coords &lt; 2:\n            raise ValueError(\n                f\"Expected at least 2 coordinates, but only {n_coords} declared.\"\n            )\n\n        def get_coord_len(coord: str) -&gt; int:\n            if values[coord] is None:\n                return 0\n            return len(values[coord])\n\n        len_x_coords = get_coord_len(\"xcoordinates\")\n        len_y_coords = get_coord_len(\"ycoordinates\")\n        if n_coords == len_x_coords == len_y_coords:\n            return True\n        raise ValueError(\n            f\"Expected {n_coords} coordinates, given {len_x_coords} for xCoordinates and {len_y_coords} for yCoordinates.\"\n        )\n\n    @classmethod\n    def validate(cls, v):\n        \"\"\"Try to initialize subclass based on the `type` field.\n        This field is compared to each `type` field of the derived models of `Structure`.\n        The derived model with an equal structure type will be initialized.\n\n        Raises:\n            ValueError: When the given type is not a known structure type.\n        \"\"\"\n\n        # should be replaced by discriminated unions once merged\n        # https://github.com/samuelcolvin/pydantic/pull/2336\n        if isinstance(v, dict):\n            for c in cls.__subclasses__():\n                if (\n                    c.__fields__.get(\"type\").default.lower()\n                    == v.get(\"type\", \"\").lower()\n                ):\n                    v = c(**v)\n                    break\n            else:\n                raise ValueError(\n                    f\"Type of {cls.__name__} with id={v.get('id', '')} and type={v.get('type', '')} is not recognized.\"\n                )\n        return super().validate(v)\n\n    def _exclude_fields(self) -&gt; Set:\n        # exclude the non-applicable, or unset props like coordinates or branches\n        if self.type == \"compound\":\n            exclude_set = self._loc_all_fields\n        elif self.branchid is not None:\n            exclude_set = self._loc_coord_fields\n        else:\n            exclude_set = self._loc_branch_fields\n        exclude_set = super()._exclude_fields().union(exclude_set)\n        return exclude_set\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\") or data.get(\"name\")\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Structure.check_location","title":"<code>check_location(values)</code>  <code>classmethod</code>","text":"<p>Validates the location of the structure based on the given parameters. For instance, if a branchid is given, then it is expected also the chainage, otherwise numcoordinates xcoordinates and ycoordinates shall be expected.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>dict</code> <p>Dictionary of values validated for the new structure.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When branchid or chainage values are not valid (empty strings).</p> <code>ValueError</code> <p>When the number of xcoordinates and ycoordinates do not match numcoordinates.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of values validated for the new structure.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@root_validator\n@classmethod\ndef check_location(cls, values: dict) -&gt; dict:\n    \"\"\"\n    Validates the location of the structure based on the given parameters.\n    For instance, if a branchid is given, then it is expected also the chainage,\n    otherwise numcoordinates xcoordinates and ycoordinates shall be expected.\n\n    Args:\n        values (dict): Dictionary of values validated for the new structure.\n\n    Raises:\n        ValueError: When branchid or chainage values are not valid (empty strings).\n        ValueError: When the number of xcoordinates and ycoordinates do not match numcoordinates.\n\n    Returns:\n        dict: Dictionary of values validated for the new structure.\n    \"\"\"\n    filtered_values = {k: v for k, v in values.items() if v is not None}\n    structype = filtered_values.get(\"type\", \"\").lower()\n\n    if structype == \"compound\" or issubclass(cls, (Compound)):\n        # Compound structure does not require a location specification.\n        return values\n\n    # Backwards compatibility for old-style polylinefile input field (instead of num/x/yCoordinates):\n    polyline_compatible_structures = dict(\n        pump=\"Pump\",\n        dambreak=\"Dambreak\",\n        gate=\"Gate\",\n        weir=\"Weir\",\n        generalstructure=\"GeneralStructure\",\n    )\n    polylinefile_in_model = (\n        structype in polyline_compatible_structures.keys()\n        and filtered_values.get(\"polylinefile\") is not None\n    )\n\n    # No branchId+chainage for some structures:\n    only_coordinates_structures = dict(\n        longculvert=\"LongCulvert\", dambreak=\"Dambreak\"\n    )\n    coordinates_in_model = Structure.validate_coordinates_in_model(filtered_values)\n\n    # Error: do not allow both x/y and polyline file:\n    assert not (\n        polylinefile_in_model and coordinates_in_model\n    ), f\"`Specify location either by `num/x/yCoordinates` or `polylinefile`, but not both.\"\n\n    # Error: require x/y or polyline file:\n    if (\n        structype in polyline_compatible_structures.keys()\n        and structype in only_coordinates_structures.keys()\n    ):\n        assert (\n            coordinates_in_model or polylinefile_in_model\n        ), f\"Specify location either by setting `num/x/yCoordinates` or `polylinefile` fields for a {polyline_compatible_structures[structype]} structure.\"\n\n    # Error: Some structures require coordinates_in_model, but not branchId and chainage.\n    if (\n        not polylinefile_in_model\n        and structype in only_coordinates_structures.keys()\n    ):\n        assert (\n            coordinates_in_model\n        ), f\"Specify location by setting `num/x/yCoordinates` for a {only_coordinates_structures[structype]} structure.\"\n\n    # Error: final check: at least one of x/y, branchId+chainage or polyline file must be given\n    branch_and_chainage_in_model = Structure.validate_branch_and_chainage_in_model(\n        filtered_values\n    )\n    assert (\n        branch_and_chainage_in_model\n        or coordinates_in_model\n        or polylinefile_in_model\n    ), \"Specify location either by setting `branchId` and `chainage` or `num/x/yCoordinates` or `polylinefile` fields.\"\n\n    return values\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Structure.validate","title":"<code>validate(v)</code>  <code>classmethod</code>","text":"<p>Try to initialize subclass based on the <code>type</code> field. This field is compared to each <code>type</code> field of the derived models of <code>Structure</code>. The derived model with an equal structure type will be initialized.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the given type is not a known structure type.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@classmethod\ndef validate(cls, v):\n    \"\"\"Try to initialize subclass based on the `type` field.\n    This field is compared to each `type` field of the derived models of `Structure`.\n    The derived model with an equal structure type will be initialized.\n\n    Raises:\n        ValueError: When the given type is not a known structure type.\n    \"\"\"\n\n    # should be replaced by discriminated unions once merged\n    # https://github.com/samuelcolvin/pydantic/pull/2336\n    if isinstance(v, dict):\n        for c in cls.__subclasses__():\n            if (\n                c.__fields__.get(\"type\").default.lower()\n                == v.get(\"type\", \"\").lower()\n            ):\n                v = c(**v)\n                break\n        else:\n            raise ValueError(\n                f\"Type of {cls.__name__} with id={v.get('id', '')} and type={v.get('type', '')} is not recognized.\"\n            )\n    return super().validate(v)\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Structure.validate_branch_and_chainage_in_model","title":"<code>validate_branch_and_chainage_in_model(values)</code>  <code>staticmethod</code>","text":"<p>Static method to validate whether the given branchid and chainage values match the expectation of a new structure.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>dict</code> <p>Dictionary of values to be used to generate a structure.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the value for branchid or chainage are not valid.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Result of valid branchid / chainage in dictionary.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@staticmethod\ndef validate_branch_and_chainage_in_model(values: dict) -&gt; bool:\n    \"\"\"\n    Static method to validate whether the given branchid and chainage values\n    match the expectation of a new structure.\n\n    Args:\n        values (dict): Dictionary of values to be used to generate a structure.\n\n    Raises:\n        ValueError: When the value for branchid or chainage are not valid.\n\n    Returns:\n        bool: Result of valid branchid / chainage in dictionary.\n    \"\"\"\n    branchid = values.get(\"branchid\", None)\n    if branchid is None:\n        return False\n\n    chainage = values.get(\"chainage\", None)\n    if str_is_empty_or_none(branchid) or chainage is None:\n        raise ValueError(\n            \"A valid value for branchId and chainage is required when branchId key is specified.\"\n        )\n    return True\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Structure.validate_coordinates_in_model","title":"<code>validate_coordinates_in_model(values)</code>  <code>staticmethod</code>","text":"<p>Static method to validate whether the given values match the expectations of a structure to define its coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>dict</code> <p>Dictionary of values to be used to generate a structure.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the given coordinates is less than 2.</p> <code>ValueError</code> <p>When the given coordinates do not match in expected size.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Result of valid coordinates in dictionary.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>@staticmethod\ndef validate_coordinates_in_model(values: dict) -&gt; bool:\n    \"\"\"\n    Static method to validate whether the given values match the expectations\n    of a structure to define its coordinates.\n\n    Args:\n        values (dict): Dictionary of values to be used to generate a structure.\n\n    Raises:\n        ValueError: When the given coordinates is less than 2.\n        ValueError: When the given coordinates do not match in expected size.\n\n    Returns:\n        bool: Result of valid coordinates in dictionary.\n    \"\"\"\n    searched_keys = [\"numcoordinates\", \"xcoordinates\", \"ycoordinates\"]\n    if any(values.get(k, None) is None for k in searched_keys):\n        return False\n\n    n_coords = values[\"numcoordinates\"]\n    if n_coords &lt; 2:\n        raise ValueError(\n            f\"Expected at least 2 coordinates, but only {n_coords} declared.\"\n        )\n\n    def get_coord_len(coord: str) -&gt; int:\n        if values[coord] is None:\n            return 0\n        return len(values[coord])\n\n    len_x_coords = get_coord_len(\"xcoordinates\")\n    len_y_coords = get_coord_len(\"ycoordinates\")\n    if n_coords == len_x_coords == len_y_coords:\n        return True\n    raise ValueError(\n        f\"Expected {n_coords} coordinates, given {len_x_coords} for xCoordinates and {len_y_coords} for yCoordinates.\"\n    )\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.StructureGeneral","title":"<code>StructureGeneral</code>","text":"<p>               Bases: <code>INIGeneral</code></p> <p><code>[General]</code> section with structure file metadata.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class StructureGeneral(INIGeneral):\n    \"\"\"`[General]` section with structure file metadata.\"\"\"\n\n    _header: Literal[\"General\"] = \"General\"\n    fileversion: str = Field(\"3.00\", alias=\"fileVersion\")\n    filetype: Literal[\"structure\"] = Field(\"structure\", alias=\"fileType\")\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.StructureModel","title":"<code>StructureModel</code>","text":"<p>               Bases: <code>INIModel</code></p> <p>The overall structure model that contains the contents of one structure file.</p> <p>This model is typically referenced under a FMModel<code>.geometry.structurefile[..]</code>.</p> <p>Attributes:</p> Name Type Description <code>general</code> <code>StructureGeneral</code> <p><code>[General]</code> block with file metadata.</p> <code>branch</code> <code>List[Structure]</code> <p>List of <code>[Structure]</code> blocks for all hydraulic structures.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class StructureModel(INIModel):\n    \"\"\"\n    The overall structure model that contains the contents of one structure file.\n\n    This model is typically referenced under a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[..]`.\n\n    Attributes:\n        general (StructureGeneral): `[General]` block with file metadata.\n        branch (List[Structure]): List of `[Structure]` blocks for all hydraulic structures.\n    \"\"\"\n\n    general: StructureGeneral = StructureGeneral()\n    structure: List[Structure] = []\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".ini\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"structures\"\n\n    _split_to_list = make_list_validator(\"structure\")\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.UniversalWeir","title":"<code>UniversalWeir</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=universalWeir</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the universal weir input as described in UM Sec.C.12.2.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class UniversalWeir(Structure):\n    \"\"\"\n    Hydraulic structure with `type=universalWeir`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the universal weir input as described in\n    [UM Sec.C.12.2](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.2).\n    \"\"\"\n\n    class Comments(Structure.Comments):\n        type: Optional[str] = Field(\n            \"Structure type; must read universalWeir\", alias=\"type\"\n        )\n        allowedflowdir: Optional[str] = Field(\n            FlowDirection.allowedvaluestext, alias=\"allowedFlowdir\"\n        )\n\n        numlevels: Optional[str] = Field(\"Number of yz-Values.\", alias=\"numLevels\")\n        yvalues: Optional[str] = Field(\n            \"y-values of the cross section (m). (number of values = numLevels)\",\n            alias=\"yValues\",\n        )\n        zvalues: Optional[str] = Field(\n            \"z-values of the cross section (m). (number of values = numLevels)\",\n            alias=\"zValues\",\n        )\n        crestlevel: Optional[str] = Field(\n            \"Crest level of weir (m AD).\", alias=\"crestLevel\"\n        )\n        dischargecoeff: Optional[str] = Field(\n            \"Discharge coefficient c_e (-).\", alias=\"dischargeCoeff\"\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"universalWeir\"] = Field(\"universalWeir\", alias=\"type\")\n    allowedflowdir: FlowDirection = Field(alias=\"allowedFlowDir\")\n\n    numlevels: int = Field(alias=\"numLevels\")\n    yvalues: List[float] = Field(alias=\"yValues\")\n    zvalues: List[float] = Field(alias=\"zValues\")\n    crestlevel: float = Field(alias=\"crestLevel\")\n    dischargecoeff: float = Field(alias=\"dischargeCoeff\")\n\n    _split_to_list = get_split_string_on_delimiter_validator(\"yvalues\", \"zvalues\")\n    _flowdirection_validator = get_enum_validator(\"allowedflowdir\", enum=FlowDirection)\n</code></pre>"},{"location":"reference/models/structure/#hydrolib.core.dflowfm.structure.models.Weir","title":"<code>Weir</code>","text":"<p>               Bases: <code>Structure</code></p> <p>Hydraulic structure with <code>type=weir</code>, to be included in a structure file. Typically inside the structure list of a FMModel<code>.geometry.structurefile[0].structure[..]</code></p> <p>All lowercased attributes match with the weir input as described in UM Sec.C.12.1.</p> Source code in <code>hydrolib/core/dflowfm/structure/models.py</code> <pre><code>class Weir(Structure):\n    \"\"\"\n    Hydraulic structure with `type=weir`, to be included in a structure file.\n    Typically inside the structure list of a [FMModel][hydrolib.core.dflowfm.mdu.models.FMModel]`.geometry.structurefile[0].structure[..]`\n\n    All lowercased attributes match with the weir input as described in\n    [UM Sec.C.12.1](https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#subsection.C.12.1).\n    \"\"\"\n\n    class Comments(Structure.Comments):\n        type: Optional[str] = Field(\"Structure type; must read weir\", alias=\"type\")\n        allowedflowdir: Optional[str] = Field(\n            FlowDirection.allowedvaluestext, alias=\"allowedFlowdir\"\n        )\n\n        crestlevel: Optional[str] = Field(\n            \"Crest level of weir (m AD).\", alias=\"crestLevel\"\n        )\n        crestwidth: Optional[str] = Field(\"Width of the weir (m).\", alias=\"crestWidth\")\n        corrcoeff: Optional[str] = Field(\n            \"Correction coefficient (-).\", alias=\"corrCoeff\"\n        )\n        usevelocityheight: Optional[str] = Field(\n            \"Flag indicating whether the velocity height is to be calculated or not.\",\n            alias=\"useVelocityHeight\",\n        )\n\n    comments: Comments = Comments()\n\n    type: Literal[\"weir\"] = Field(\"weir\", alias=\"type\")\n    allowedflowdir: Optional[FlowDirection] = Field(\n        FlowDirection.both.value, alias=\"allowedFlowDir\"\n    )\n\n    crestlevel: ForcingData = Field(alias=\"crestLevel\")\n    crestwidth: Optional[float] = Field(None, alias=\"crestWidth\")\n    corrcoeff: float = Field(1.0, alias=\"corrCoeff\")\n    usevelocityheight: bool = Field(True, alias=\"useVelocityHeight\")\n\n    _flowdirection_validator = get_enum_validator(\"allowedflowdir\", enum=FlowDirection)\n</code></pre>"},{"location":"reference/models/tim/","title":"Timeseries .tim files","text":"<p>.tim files contain time series data of a D-Flow FM model. The support of .tim files for boundary time series will be discontinued. Instead, these will be replaced by the *.bc file.</p> <p>They are represented by the classes below.</p>"},{"location":"reference/models/tim/#model","title":"Model","text":""},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel","title":"<code>TimModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Class representing a tim (*.tim) file.</p> <p>Attributes:</p> Name Type Description <code>serializer_config</code> <code>TimSerializerConfig</code> <p>Configuration for serialization of the .tim file.</p> <code>comments</code> <code>List[str]</code> <p>Header comments from the .tim file.</p> <code>timeseries</code> <code>List[TimRecord]</code> <p>A list of TimRecord objects, each containing a time value and associated data.</p> <code>quantities_names</code> <code>Optional[List[str]]</code> <p>List of names for the quantities in the timeseries.</p> <p>Methods:</p> Name Description <code>_ext</code> <p>Returns the file extension for .tim files.</p> <code>_filename</code> <p>Returns the default filename for .tim files.</p> <code>_get_serializer</code> <p>Returns the serializer callable for .tim files.</p> <code>_get_parser</code> <p>Returns the parser callable for .tim files.</p> <code>_validate_timeseries_values</code> <p>List[TimRecord]) -&gt; List[TimRecord]: Validates the timeseries data.</p> <code>as_dataframe</code> <p>List[Any] = None) -&gt; DataFrame: Returns the timeseries as a pandas DataFrame.</p> <code>_validate_quantities_names</code> <p>Validates that quantities_names match the values or each record.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to the .tim file.</p> <code>None</code> <code>data</code> <code>Dict</code> <p>Parsed data containing comments and timeseries.</p> required <code>serializer_config</code> <code>TimSerializerConfig</code> <p>Configuration for serializing the .tim file.</p> required <p>Returns:</p> Type Description <p>List[TimRecord]: Validated list of TimRecord objects.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the timeseries has inconsistent column counts or duplicate time values.</p> <p>Examples:</p> <p>Create a TimModel object from a .tim file:</p> <pre><code>```python\n&gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel, TimRecord\n&gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\")\n&gt;&gt;&gt; print(tim_model.timeseries)\n[TimRecord(time=10.0, data=[1.232, 2.343, 3.454]), TimRecord(time=20.0, data=[4.565, 5.676, 6.787]), TimRecord(time=30.0, data=[1.5, 2.6, 3.7])]\n\n```\n</code></pre> <p>Provide names for the quantities in the timeseries:     <pre><code>&gt;&gt;&gt; quantities_names = [\"discharge\", \"waterlevel\", \"salinity\", \"temperature\", \"initialtracer\"]\n&gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/source-sink/tim-5-columns.tim\", quantities_names=quantities_names)\n&gt;&gt;&gt; print(tim_model.quantities_names)\n['discharge', 'waterlevel', 'salinity', 'temperature', 'initialtracer']\n&gt;&gt;&gt; print(tim_model.as_dataframe())\n       discharge  waterlevel  salinity  temperature  initialtracer\n0.0          1.0         2.0       3.0          4.0            5.0\n100.0        1.0         2.0       3.0          4.0            5.0\n200.0        1.0         2.0       3.0          4.0            5.0\n300.0        1.0         2.0       3.0          4.0            5.0\n400.0        1.0         2.0       3.0          4.0            5.0\n</code></pre></p> <p>Create a <code>TimModel</code> object from a dictionary:     <pre><code>&gt;&gt;&gt; data = {\n...     \"comments\": [\"# Example comment\"],\n...     \"timeseries\": [TimRecord(time=0.0, data=[1.0, 2.0])]\n... }\n&gt;&gt;&gt; tim_model = TimModel(**data)\n&gt;&gt;&gt; print(tim_model.timeseries)\n[TimRecord(time=0.0, data=[1.0, 2.0])]\n</code></pre></p> <p>Create <code>TimModel</code> from <code>TimRecord</code> objects:     <pre><code>&gt;&gt;&gt; new_tim = TimModel()\n&gt;&gt;&gt; new_tim.comments = [\"# Example comment\"]\n&gt;&gt;&gt; new_tim.timeseries = [TimRecord(time=0.0, data=[1.0, 2.0])]\n</code></pre></p> <p>Serialize the <code>TimModel</code> to a .tim file:     <pre><code>&gt;&gt;&gt; new_tim.save(filepath=Path(\"output.tim\")) # doctest: +SKIP\n</code></pre></p> See Also <p>TimParser: Used for parsing .tim files. TimSerializer: Used for serializing .tim files. TimRecord: Represents individual time and data entries in the timeseries.</p> Notes <p>This class ensures the integrity of the timeseries by validating data consistency and detecting duplicate time entries.</p> References <ul> <li><code>TIM file format &lt;https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#C4&gt;</code>_</li> </ul> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>class TimModel(ParsableFileModel):\n    \"\"\"Class representing a tim (*.tim) file.\n\n    Attributes:\n        serializer_config (TimSerializerConfig):\n            Configuration for serialization of the .tim file.\n        comments (List[str]):\n            Header comments from the .tim file.\n        timeseries (List[TimRecord]):\n            A list of TimRecord objects, each containing a time value and associated data.\n        quantities_names (Optional[List[str]]):\n            List of names for the quantities in the timeseries.\n\n\n    Methods:\n        _ext() -&gt; str:\n            Returns the file extension for .tim files.\n        _filename() -&gt; str:\n            Returns the default filename for .tim files.\n        _get_serializer() -&gt; Callable:\n            Returns the serializer callable for .tim files.\n        _get_parser() -&gt; Callable:\n            Returns the parser callable for .tim files.\n        _validate_timeseries_values(cls, v: List[TimRecord]) -&gt; List[TimRecord]:\n            Validates the timeseries data.\n        as_dataframe(columns: List[Any] = None) -&gt; DataFrame:\n            Returns the timeseries as a pandas DataFrame.\n        _validate_quantities_names(cls, v, values) -&gt; List[str]:\n            Validates that quantities_names match the values or each record.\n\n    Args:\n        filepath (Path):\n            Path to the .tim file.\n        data (Dict):\n            Parsed data containing comments and timeseries.\n        serializer_config (TimSerializerConfig):\n            Configuration for serializing the .tim file.\n\n    Returns:\n        List[TimRecord]:\n            Validated list of TimRecord objects.\n\n    Raises:\n        ValueError:\n            If the timeseries has inconsistent column counts or duplicate time values.\n\n    Examples:\n        Create a TimModel object from a .tim file:\n\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel, TimRecord\n            &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\")\n            &gt;&gt;&gt; print(tim_model.timeseries)\n            [TimRecord(time=10.0, data=[1.232, 2.343, 3.454]), TimRecord(time=20.0, data=[4.565, 5.676, 6.787]), TimRecord(time=30.0, data=[1.5, 2.6, 3.7])]\n\n            ```\n\n        Provide names for the quantities in the timeseries:\n            ```python\n            &gt;&gt;&gt; quantities_names = [\"discharge\", \"waterlevel\", \"salinity\", \"temperature\", \"initialtracer\"]\n            &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/source-sink/tim-5-columns.tim\", quantities_names=quantities_names)\n            &gt;&gt;&gt; print(tim_model.quantities_names)\n            ['discharge', 'waterlevel', 'salinity', 'temperature', 'initialtracer']\n            &gt;&gt;&gt; print(tim_model.as_dataframe())\n                   discharge  waterlevel  salinity  temperature  initialtracer\n            0.0          1.0         2.0       3.0          4.0            5.0\n            100.0        1.0         2.0       3.0          4.0            5.0\n            200.0        1.0         2.0       3.0          4.0            5.0\n            300.0        1.0         2.0       3.0          4.0            5.0\n            400.0        1.0         2.0       3.0          4.0            5.0\n\n            ```\n\n        Create a `TimModel` object from a dictionary:\n            ```python\n            &gt;&gt;&gt; data = {\n            ...     \"comments\": [\"# Example comment\"],\n            ...     \"timeseries\": [TimRecord(time=0.0, data=[1.0, 2.0])]\n            ... }\n            &gt;&gt;&gt; tim_model = TimModel(**data)\n            &gt;&gt;&gt; print(tim_model.timeseries)\n            [TimRecord(time=0.0, data=[1.0, 2.0])]\n\n            ```\n\n        Create `TimModel` from `TimRecord` objects:\n            ```python\n            &gt;&gt;&gt; new_tim = TimModel()\n            &gt;&gt;&gt; new_tim.comments = [\"# Example comment\"]\n            &gt;&gt;&gt; new_tim.timeseries = [TimRecord(time=0.0, data=[1.0, 2.0])]\n\n            ```\n\n        Serialize the `TimModel` to a .tim file:\n            ```python\n            &gt;&gt;&gt; new_tim.save(filepath=Path(\"output.tim\")) # doctest: +SKIP\n\n            ```\n\n    See Also:\n        TimParser: Used for parsing .tim files.\n        TimSerializer: Used for serializing .tim files.\n        TimRecord: Represents individual time and data entries in the timeseries.\n\n    Notes:\n        This class ensures the integrity of the timeseries by validating data consistency and detecting duplicate time entries.\n\n    References:\n        - `TIM file format &lt;https://content.oss.deltares.nl/delft3dfm1d2d/D-Flow_FM_User_Manual_1D2D.pdf#C4&gt;`_\n    \"\"\"\n\n    serializer_config = TimSerializerConfig()\n    \"\"\"TimSerializerConfig: The serialization configuration for the tim file.\"\"\"\n\n    comments: List[str] = Field(default_factory=list)\n    \"\"\"List[str]: A list with the header comment of the tim file.\"\"\"\n\n    timeseries: List[TimRecord] = Field(default_factory=list)\n    \"\"\"List[TimRecord]: A list containing the timeseries.\"\"\"\n\n    quantities_names: Optional[List[str]] = Field(default=None)\n\n    def __init__(\n        self,\n        filepath: Optional[Union[str, Path]] = None,\n        quantities_names: Optional[List[str]] = None,\n        **parsable_file_kwargs,\n    ):\n        \"\"\"\n        Custom initializer to handle extra parameters specific to TimModel.\n\n        Args:\n            quantities_names (Optional[List[str]]): Names for the quantities in the timeseries.\n            *args, **kwargs: Other arguments for the superclass.\n        \"\"\"\n        super().__init__(filepath=filepath, **parsable_file_kwargs)\n        self.quantities_names = quantities_names\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".tim\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"timeseries\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, TimSerializerConfig, ModelSaveSettings], None]:\n        return TimSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable[[Path], Dict]:\n        return TimParser.parse\n\n    @validator(\"timeseries\", pre=True, check_fields=True, allow_reuse=True)\n    def replace_fortran_scientific_notation_for_floats(cls, value, field):\n        for record in value:\n            if isinstance(record, dict):\n                record[\"time\"] = FortranUtils.replace_fortran_scientific_notation(\n                    record[\"time\"]\n                )\n                record[\"data\"] = FortranUtils.replace_fortran_scientific_notation(\n                    record[\"data\"]\n                )\n            elif isinstance(record, TimRecord):\n                record.time = FortranUtils.replace_fortran_scientific_notation(\n                    record.time\n                )\n                record.data = FortranUtils.replace_fortran_scientific_notation(\n                    record.data\n                )\n\n        return value\n\n    @validator(\"timeseries\")\n    @classmethod\n    def _validate_timeseries_values(cls, v: List[TimRecord]) -&gt; List[TimRecord]:\n        \"\"\"Validate if the number of columns per timeseries matches and if the timeseries have no duplicate times.\n\n        Args:\n            v (List[TimRecord]): Timeseries to validate.\n\n        Raises:\n            ValueError: When the number of columns for timeseries is zero.\n            ValueError: When the number of columns differs per timeseries.\n            ValueError: When the timeseries has a duplicate time.\n\n        Returns:\n            List[TimRecord]: Validated timeseries.\n        \"\"\"\n        if len(v) == 0:\n            return v\n\n        cls._raise_error_if_amount_of_columns_differ(v)\n        cls._raise_error_if_duplicate_time(v)\n\n        return v\n\n    @staticmethod\n    def _raise_error_if_amount_of_columns_differ(timeseries: List[TimRecord]) -&gt; None:\n        n_columns = len(timeseries[0].data)\n\n        if n_columns == 0:\n            raise ValueError(\"Time series cannot be empty.\")\n\n        for timrecord in timeseries:\n            if len(timrecord.data) != n_columns:\n                raise ValueError(\n                    f\"Time {timrecord.time}: Expected {n_columns} columns, but was {len(timrecord.data)}\"\n                )\n\n    @staticmethod\n    def _raise_error_if_duplicate_time(timeseries: List[TimRecord]) -&gt; None:\n        seen_times = set()\n        for timrecord in timeseries:\n            if timrecord.time in seen_times:\n                raise ValueError(\n                    f\"Timeseries cannot contain duplicate times. Time: {timrecord.time} is duplicate.\"\n                )\n            seen_times.add(timrecord.time)\n\n    @validator(\"quantities_names\")\n    def _validate_quantities_names(cls, v, values):\n        \"\"\"Validate if the number of quantities_names matches the number of columns in the timeseries.\n\n        The validator compared the amount of quantities_names with the number of columns in the first record of\n        the timeseries.\n        \"\"\"\n        if v is not None:\n            first_records_data = values[\"timeseries\"][0].data\n            if len(v) != len(first_records_data):\n                raise ValueError(\n                    f\"The number of quantities_names ({len(v)}) must match the number of columns in the Tim file ({len(first_records_data)}).\"\n                )\n        return v\n\n    def add_column(self, new_values: List[float], column_name: str = None) -&gt; None:\n        \"\"\"\n        Add new values to each TimRecord in the timeseries, representing a new location.\n\n        Args:\n            new_values (List[float]): A list of new values to add, one for each TimRecord.\n            column_name (str, optional): The name of the new column. Defaults to None.\n                if None, the column is named as \"quantity-{len(quantities_names) + 1}\".\n\n        Raises:\n            ValueError: If the number of new values does not match the number of TimRecords.\n\n        Examples:\n            ```python\n            &gt;&gt;&gt; tim_model = TimModel(\n            ...     timeseries=[\n            ...         TimRecord(time=0.0, data=[1.0, 2.0]),\n            ...         TimRecord(time=1.0, data=[3.0, 4.0]),\n            ...     ]\n            ... )\n            &gt;&gt;&gt; tim_model.add_column([5.0, 6.0])\n            &gt;&gt;&gt; print(tim_model.timeseries)\n            [TimRecord(time=0.0, data=[1.0, 2.0, 5.0]), TimRecord(time=1.0, data=[3.0, 4.0, 6.0])]\n\n            ```\n        \"\"\"\n        if len(new_values) != len(self.timeseries):\n            raise ValueError(\n                f\"Expected {len(self.timeseries)} values, but got {len(new_values)}.\"\n            )\n\n        for record, value in zip(self.timeseries, new_values):\n            record.data.append(value)\n\n        if self.quantities_names:\n            if column_name is None:\n                column_name = f\"quantity-{len(self.quantities_names) + 1}\"\n            self.quantities_names.append(column_name)\n\n    def as_dataframe(self, columns: List[Any] = None) -&gt; DataFrame:\n        \"\"\"Return the timeseries as a pandas DataFrame.\n\n        Args:\n            columns (List[Any, str], optional, Defaults to None):\n                The column names for the DataFrame.\n\n        Returns:\n            DataFrame: The timeseries as a pandas DataFrame.\n\n        Notes:\n            - If the columns are not provided, the quantities_names will be used as column names.\n            - If the quantities_names are not provided, the columns will be named as 0, 1, 2, etc.\n\n        Examples:\n            Create a `TimModel` object from a .tim file:\n                &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel\n                &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\")\n                &gt;&gt;&gt; df = tim_model.as_dataframe()\n                &gt;&gt;&gt; print(df)\n                          0      1      2\n                10.0  1.232  2.343  3.454\n                20.0  4.565  5.676  6.787\n                30.0  1.500  2.600  3.700\n\n            If the `TimModel` object was created with quantities names:\n                &gt;&gt;&gt; quantities_names = [\"Column1\", \"Column2\", \"Column3\"]\n                &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\", quantities_names=quantities_names)\n                &gt;&gt;&gt; df = tim_model.as_dataframe()\n                &gt;&gt;&gt; print(df)\n                      Column1  Column2  Column3\n                10.0    1.232    2.343    3.454\n                20.0    4.565    5.676    6.787\n                30.0    1.500    2.600    3.700\n\n            To add column names to the DataFrame after you have created the `TimModel` object:\n                &gt;&gt;&gt; df = tim_model.as_dataframe(columns=[\"Column1\", \"Column2\", \"Column3\"])\n                &gt;&gt;&gt; print(df)\n                      Column1  Column2  Column3\n                10.0    1.232    2.343    3.454\n                20.0    4.565    5.676    6.787\n                30.0    1.500    2.600    3.700\n        \"\"\"\n        time_series = [record.data for record in self.timeseries]\n        index = [record.time for record in self.timeseries]\n        if not columns:\n            columns = self.quantities_names\n        return DataFrame(time_series, index=index, columns=columns)\n\n    def as_dict(self) -&gt; Dict[str, List[float]]:\n        \"\"\"Extract time series data from a TIM model.\n\n        Extract the time series data (each column) from the TimModel object\n\n        Returns:\n            Dict[str, List[float]]: A dictionary containing the time series data form each column.\n            the keys of the dictionary will be index starting from 1 to the number of columns in the tim file\n            (excluding the first column(time)).\n\n        Examples:\n            ```python\n            &gt;&gt;&gt; tim_file = Path(\"tests/data/input/source-sink/leftsor.tim\")\n            &gt;&gt;&gt; time_file = TimParser.parse(tim_file)\n            &gt;&gt;&gt; tim_model = TimModel(**time_file)\n            &gt;&gt;&gt; time_series = tim_model.as_dict()\n            &gt;&gt;&gt; print(time_series) # doctest: +SKIP\n            {\n                1: [1.0, 1.0, 3.0, 5.0, 8.0],\n                2: [2.0, 2.0, 5.0, 8.0, 10.0],\n                3: [3.0, 5.0, 12.0, 9.0, 23.0],\n                4: [4.0, 4.0, 4.0, 4.0, 4.0]\n            }\n            ```\n        \"\"\"\n        data = self.as_dataframe().to_dict(orient=\"list\")\n        return data\n\n    def get_units(self):\n        \"\"\"Return the units for each quantity in the timeseries.\n\n        Returns:\n            List[str]: A list of units for each quantity in the timeseries.\n\n        Examples:\n            Create a `TimModel` object from a .tim file:\n                ```python\n                &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel\n                &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/source-sink/tim-5-columns.tim\")\n                &gt;&gt;&gt; tim_model.quantities_names = [\"discharge\", \"waterlevel\", \"temperature\", \"salinity\", \"initialtracer\"]\n                &gt;&gt;&gt; print(tim_model.get_units())\n                ['m3/s', 'm', 'degC', '1e-3', '-']\n\n                ```\n        \"\"\"\n        if self.quantities_names is None:\n            return None\n        return TimModel._get_quantity_unit(self.quantities_names)\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.comments","title":"<code>comments = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[str]: A list with the header comment of the tim file.</p>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.serializer_config","title":"<code>serializer_config = TimSerializerConfig()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>TimSerializerConfig: The serialization configuration for the tim file.</p>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.timeseries","title":"<code>timeseries = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[TimRecord]: A list containing the timeseries.</p>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.__init__","title":"<code>__init__(filepath=None, quantities_names=None, **parsable_file_kwargs)</code>","text":"<p>Custom initializer to handle extra parameters specific to TimModel.</p> <p>Parameters:</p> Name Type Description Default <code>quantities_names</code> <code>Optional[List[str]]</code> <p>Names for the quantities in the timeseries.</p> <code>None</code> <code>*args,</code> <code>**kwargs</code> <p>Other arguments for the superclass.</p> required Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>def __init__(\n    self,\n    filepath: Optional[Union[str, Path]] = None,\n    quantities_names: Optional[List[str]] = None,\n    **parsable_file_kwargs,\n):\n    \"\"\"\n    Custom initializer to handle extra parameters specific to TimModel.\n\n    Args:\n        quantities_names (Optional[List[str]]): Names for the quantities in the timeseries.\n        *args, **kwargs: Other arguments for the superclass.\n    \"\"\"\n    super().__init__(filepath=filepath, **parsable_file_kwargs)\n    self.quantities_names = quantities_names\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.add_column","title":"<code>add_column(new_values, column_name=None)</code>","text":"<p>Add new values to each TimRecord in the timeseries, representing a new location.</p> <p>Parameters:</p> Name Type Description Default <code>new_values</code> <code>List[float]</code> <p>A list of new values to add, one for each TimRecord.</p> required <code>column_name</code> <code>str</code> <p>The name of the new column. Defaults to None. if None, the column is named as \"quantity-{len(quantities_names) + 1}\".</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of new values does not match the number of TimRecords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tim_model = TimModel(\n...     timeseries=[\n...         TimRecord(time=0.0, data=[1.0, 2.0]),\n...         TimRecord(time=1.0, data=[3.0, 4.0]),\n...     ]\n... )\n&gt;&gt;&gt; tim_model.add_column([5.0, 6.0])\n&gt;&gt;&gt; print(tim_model.timeseries)\n[TimRecord(time=0.0, data=[1.0, 2.0, 5.0]), TimRecord(time=1.0, data=[3.0, 4.0, 6.0])]\n</code></pre> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>def add_column(self, new_values: List[float], column_name: str = None) -&gt; None:\n    \"\"\"\n    Add new values to each TimRecord in the timeseries, representing a new location.\n\n    Args:\n        new_values (List[float]): A list of new values to add, one for each TimRecord.\n        column_name (str, optional): The name of the new column. Defaults to None.\n            if None, the column is named as \"quantity-{len(quantities_names) + 1}\".\n\n    Raises:\n        ValueError: If the number of new values does not match the number of TimRecords.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; tim_model = TimModel(\n        ...     timeseries=[\n        ...         TimRecord(time=0.0, data=[1.0, 2.0]),\n        ...         TimRecord(time=1.0, data=[3.0, 4.0]),\n        ...     ]\n        ... )\n        &gt;&gt;&gt; tim_model.add_column([5.0, 6.0])\n        &gt;&gt;&gt; print(tim_model.timeseries)\n        [TimRecord(time=0.0, data=[1.0, 2.0, 5.0]), TimRecord(time=1.0, data=[3.0, 4.0, 6.0])]\n\n        ```\n    \"\"\"\n    if len(new_values) != len(self.timeseries):\n        raise ValueError(\n            f\"Expected {len(self.timeseries)} values, but got {len(new_values)}.\"\n        )\n\n    for record, value in zip(self.timeseries, new_values):\n        record.data.append(value)\n\n    if self.quantities_names:\n        if column_name is None:\n            column_name = f\"quantity-{len(self.quantities_names) + 1}\"\n        self.quantities_names.append(column_name)\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.as_dataframe","title":"<code>as_dataframe(columns=None)</code>","text":"<p>Return the timeseries as a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>List[Any, str], optional, Defaults to None</code> <p>The column names for the DataFrame.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>DataFrame</code> <p>The timeseries as a pandas DataFrame.</p> Notes <ul> <li>If the columns are not provided, the quantities_names will be used as column names.</li> <li>If the quantities_names are not provided, the columns will be named as 0, 1, 2, etc.</li> </ul> <p>Examples:</p> <p>Create a <code>TimModel</code> object from a .tim file:     &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel     &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\")     &gt;&gt;&gt; df = tim_model.as_dataframe()     &gt;&gt;&gt; print(df)               0      1      2     10.0  1.232  2.343  3.454     20.0  4.565  5.676  6.787     30.0  1.500  2.600  3.700</p> <p>If the <code>TimModel</code> object was created with quantities names:     &gt;&gt;&gt; quantities_names = [\"Column1\", \"Column2\", \"Column3\"]     &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\", quantities_names=quantities_names)     &gt;&gt;&gt; df = tim_model.as_dataframe()     &gt;&gt;&gt; print(df)           Column1  Column2  Column3     10.0    1.232    2.343    3.454     20.0    4.565    5.676    6.787     30.0    1.500    2.600    3.700</p> <p>To add column names to the DataFrame after you have created the <code>TimModel</code> object:     &gt;&gt;&gt; df = tim_model.as_dataframe(columns=[\"Column1\", \"Column2\", \"Column3\"])     &gt;&gt;&gt; print(df)           Column1  Column2  Column3     10.0    1.232    2.343    3.454     20.0    4.565    5.676    6.787     30.0    1.500    2.600    3.700</p> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>def as_dataframe(self, columns: List[Any] = None) -&gt; DataFrame:\n    \"\"\"Return the timeseries as a pandas DataFrame.\n\n    Args:\n        columns (List[Any, str], optional, Defaults to None):\n            The column names for the DataFrame.\n\n    Returns:\n        DataFrame: The timeseries as a pandas DataFrame.\n\n    Notes:\n        - If the columns are not provided, the quantities_names will be used as column names.\n        - If the quantities_names are not provided, the columns will be named as 0, 1, 2, etc.\n\n    Examples:\n        Create a `TimModel` object from a .tim file:\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel\n            &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\")\n            &gt;&gt;&gt; df = tim_model.as_dataframe()\n            &gt;&gt;&gt; print(df)\n                      0      1      2\n            10.0  1.232  2.343  3.454\n            20.0  4.565  5.676  6.787\n            30.0  1.500  2.600  3.700\n\n        If the `TimModel` object was created with quantities names:\n            &gt;&gt;&gt; quantities_names = [\"Column1\", \"Column2\", \"Column3\"]\n            &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/tim/triple_data_for_timeseries.tim\", quantities_names=quantities_names)\n            &gt;&gt;&gt; df = tim_model.as_dataframe()\n            &gt;&gt;&gt; print(df)\n                  Column1  Column2  Column3\n            10.0    1.232    2.343    3.454\n            20.0    4.565    5.676    6.787\n            30.0    1.500    2.600    3.700\n\n        To add column names to the DataFrame after you have created the `TimModel` object:\n            &gt;&gt;&gt; df = tim_model.as_dataframe(columns=[\"Column1\", \"Column2\", \"Column3\"])\n            &gt;&gt;&gt; print(df)\n                  Column1  Column2  Column3\n            10.0    1.232    2.343    3.454\n            20.0    4.565    5.676    6.787\n            30.0    1.500    2.600    3.700\n    \"\"\"\n    time_series = [record.data for record in self.timeseries]\n    index = [record.time for record in self.timeseries]\n    if not columns:\n        columns = self.quantities_names\n    return DataFrame(time_series, index=index, columns=columns)\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.as_dict","title":"<code>as_dict()</code>","text":"<p>Extract time series data from a TIM model.</p> <p>Extract the time series data (each column) from the TimModel object</p> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>Dict[str, List[float]]: A dictionary containing the time series data form each column.</p> <code>Dict[str, List[float]]</code> <p>the keys of the dictionary will be index starting from 1 to the number of columns in the tim file</p> <code>Dict[str, List[float]]</code> <p>(excluding the first column(time)).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tim_file = Path(\"tests/data/input/source-sink/leftsor.tim\")\n&gt;&gt;&gt; time_file = TimParser.parse(tim_file)\n&gt;&gt;&gt; tim_model = TimModel(**time_file)\n&gt;&gt;&gt; time_series = tim_model.as_dict()\n&gt;&gt;&gt; print(time_series) # doctest: +SKIP\n{\n    1: [1.0, 1.0, 3.0, 5.0, 8.0],\n    2: [2.0, 2.0, 5.0, 8.0, 10.0],\n    3: [3.0, 5.0, 12.0, 9.0, 23.0],\n    4: [4.0, 4.0, 4.0, 4.0, 4.0]\n}\n</code></pre> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>def as_dict(self) -&gt; Dict[str, List[float]]:\n    \"\"\"Extract time series data from a TIM model.\n\n    Extract the time series data (each column) from the TimModel object\n\n    Returns:\n        Dict[str, List[float]]: A dictionary containing the time series data form each column.\n        the keys of the dictionary will be index starting from 1 to the number of columns in the tim file\n        (excluding the first column(time)).\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; tim_file = Path(\"tests/data/input/source-sink/leftsor.tim\")\n        &gt;&gt;&gt; time_file = TimParser.parse(tim_file)\n        &gt;&gt;&gt; tim_model = TimModel(**time_file)\n        &gt;&gt;&gt; time_series = tim_model.as_dict()\n        &gt;&gt;&gt; print(time_series) # doctest: +SKIP\n        {\n            1: [1.0, 1.0, 3.0, 5.0, 8.0],\n            2: [2.0, 2.0, 5.0, 8.0, 10.0],\n            3: [3.0, 5.0, 12.0, 9.0, 23.0],\n            4: [4.0, 4.0, 4.0, 4.0, 4.0]\n        }\n        ```\n    \"\"\"\n    data = self.as_dataframe().to_dict(orient=\"list\")\n    return data\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimModel.get_units","title":"<code>get_units()</code>","text":"<p>Return the units for each quantity in the timeseries.</p> <p>Returns:</p> Type Description <p>List[str]: A list of units for each quantity in the timeseries.</p> <p>Examples:</p> <p>Create a <code>TimModel</code> object from a .tim file:     <pre><code>&gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel\n&gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/source-sink/tim-5-columns.tim\")\n&gt;&gt;&gt; tim_model.quantities_names = [\"discharge\", \"waterlevel\", \"temperature\", \"salinity\", \"initialtracer\"]\n&gt;&gt;&gt; print(tim_model.get_units())\n['m3/s', 'm', 'degC', '1e-3', '-']\n</code></pre></p> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>def get_units(self):\n    \"\"\"Return the units for each quantity in the timeseries.\n\n    Returns:\n        List[str]: A list of units for each quantity in the timeseries.\n\n    Examples:\n        Create a `TimModel` object from a .tim file:\n            ```python\n            &gt;&gt;&gt; from hydrolib.core.dflowfm.tim.models import TimModel\n            &gt;&gt;&gt; tim_model = TimModel(filepath=\"tests/data/input/source-sink/tim-5-columns.tim\")\n            &gt;&gt;&gt; tim_model.quantities_names = [\"discharge\", \"waterlevel\", \"temperature\", \"salinity\", \"initialtracer\"]\n            &gt;&gt;&gt; print(tim_model.get_units())\n            ['m3/s', 'm', 'degC', '1e-3', '-']\n\n            ```\n    \"\"\"\n    if self.quantities_names is None:\n        return None\n    return TimModel._get_quantity_unit(self.quantities_names)\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimRecord","title":"<code>TimRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single tim record, representing a time and a list of data.</p> Source code in <code>hydrolib/core/dflowfm/tim/models.py</code> <pre><code>class TimRecord(BaseModel):\n    \"\"\"Single tim record, representing a time and a list of data.\"\"\"\n\n    time: float\n    \"\"\"float: Time of the time record.\"\"\"\n\n    data: List[float] = Field(default_factory=list)\n    \"\"\"List[float]: Record of the time record.\"\"\"\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimRecord.data","title":"<code>data = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List[float]: Record of the time record.</p>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.models.TimRecord.time","title":"<code>time</code>  <code>instance-attribute</code>","text":"<p>float: Time of the time record.</p>"},{"location":"reference/models/tim/#parser","title":"Parser","text":""},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.parser.TimParser","title":"<code>TimParser</code>","text":"<p>               Bases: <code>BaseParser</code></p> <p>A parser for .tim files. Full line comments at the start of the file are supported. Comment lines start with either a <code>*</code> or a <code>#</code>. No other comments are supported.</p> Source code in <code>hydrolib/core/dflowfm/tim/parser.py</code> <pre><code>class TimParser(BaseParser):\n    \"\"\"\n    A parser for .tim files.\n    Full line comments at the start of the file are supported. Comment lines start with either a `*` or a `#`.\n    No other comments are supported.\n    \"\"\"\n\n    @staticmethod\n    def parse(filepath: Path) -&gt; Dict[str, List[Any]]:\n        \"\"\"Parse a .tim file into a dictionary with comments and time series data.\n\n        Args:\n            filepath (Path): Path to the .tim file to be parsed.\n\n        Returns:\n            Dict[str, List[Any]]: A dictionary with keys \"comments\" and \"timeseries\".\n            - \"comments\" represents comments found at the start of the file.\n            - \"timeseries\" is a list of dictionaries with the key as \"time\" and values as \"data\".\n                - \"time\" is a time as a string.\n                - \"data\" is data as a list of strings.\n\n        Raises:\n            ValueError: If the file contains a comment that is not at the start of the file.\n            ValueError: If the data of the timeseries is empty.\n        \"\"\"\n        with filepath.open(encoding=\"utf8\") as file:\n            lines = file.readlines()\n            comments, start_timeseries_index = TimParser._read_header_comments(lines)\n            timeseries = TimParser._read_time_series_data(lines, start_timeseries_index)\n\n        return {\"comments\": comments, \"timeseries\": timeseries}\n\n    @staticmethod\n    def _read_time_series_data(\n        lines: List[str], start_timeseries_index: int\n    ) -&gt; List[TimData]:\n        timeseries: List[TimData] = []\n        for line_index in range(start_timeseries_index, len(lines)):\n            line = lines[line_index].strip()\n\n            if len(line) == 0:\n                continue\n\n            TimParser._raise_error_if_contains_comment(line, line_index + 1)\n\n            time, *values = line.split()\n\n            TimParser._raise_error_if_values_empty(values, line_index)\n\n            timrecord = {\"time\": time, \"data\": values}\n            timeseries.append(timrecord)\n\n        return timeseries\n\n    @staticmethod\n    def _raise_error_if_values_empty(values: List[str], line_index: int) -&gt; None:\n        if len(values) == 0:\n            raise ValueError(f\"Line {line_index}: Time series cannot be empty.\")\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.parser.TimParser.parse","title":"<code>parse(filepath)</code>  <code>staticmethod</code>","text":"<p>Parse a .tim file into a dictionary with comments and time series data.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to the .tim file to be parsed.</p> required <p>Returns:</p> Type Description <code>Dict[str, List[Any]]</code> <p>Dict[str, List[Any]]: A dictionary with keys \"comments\" and \"timeseries\".</p> <code>Dict[str, List[Any]]</code> <ul> <li>\"comments\" represents comments found at the start of the file.</li> </ul> <code>Dict[str, List[Any]]</code> <ul> <li>\"timeseries\" is a list of dictionaries with the key as \"time\" and values as \"data\".</li> <li>\"time\" is a time as a string.</li> <li>\"data\" is data as a list of strings.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file contains a comment that is not at the start of the file.</p> <code>ValueError</code> <p>If the data of the timeseries is empty.</p> Source code in <code>hydrolib/core/dflowfm/tim/parser.py</code> <pre><code>@staticmethod\ndef parse(filepath: Path) -&gt; Dict[str, List[Any]]:\n    \"\"\"Parse a .tim file into a dictionary with comments and time series data.\n\n    Args:\n        filepath (Path): Path to the .tim file to be parsed.\n\n    Returns:\n        Dict[str, List[Any]]: A dictionary with keys \"comments\" and \"timeseries\".\n        - \"comments\" represents comments found at the start of the file.\n        - \"timeseries\" is a list of dictionaries with the key as \"time\" and values as \"data\".\n            - \"time\" is a time as a string.\n            - \"data\" is data as a list of strings.\n\n    Raises:\n        ValueError: If the file contains a comment that is not at the start of the file.\n        ValueError: If the data of the timeseries is empty.\n    \"\"\"\n    with filepath.open(encoding=\"utf8\") as file:\n        lines = file.readlines()\n        comments, start_timeseries_index = TimParser._read_header_comments(lines)\n        timeseries = TimParser._read_time_series_data(lines, start_timeseries_index)\n\n    return {\"comments\": comments, \"timeseries\": timeseries}\n</code></pre>"},{"location":"reference/models/tim/#serializer","title":"Serializer","text":""},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.serializer.TimSerializer","title":"<code>TimSerializer</code>","text":"Source code in <code>hydrolib/core/dflowfm/tim/serializer.py</code> <pre><code>class TimSerializer:\n    @staticmethod\n    def serialize(\n        path: Path,\n        data: Dict[str, List[Any]],\n        config: TimSerializerConfig,\n        save_settings: ModelSaveSettings,\n    ) -&gt; None:\n        \"\"\"\n        Serialize timeseries data to a file in .tim format.\n\n        Args:\n            path (Path): The path to the destination .tim file.\n            data (Dict[str, List[Any]]): A dictionary with keys \"comments\" and \"timeseries\".\n            - \"comments\" represents comments found at the start of the file.\n            - \"timeseries\" is a list of dictionaries with the key as \"time\" and values as \"data\".\n                - \"time\" is a time as a string.\n                - \"data\" is data as a list of strings.\n\n            config (TimSerializerConfig): The serialization configuration settings.\n            save_settings (ModelSaveSettings): The save settings to be used.\n        \"\"\"\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        commentlines = TimSerializer._serialize_comment_lines(data)\n        timeserieslines = TimSerializer._serialize_timeseries_lines(data, config)\n\n        file_content = TimSerializer._serialize_file_content(\n            timeserieslines, commentlines\n        )\n        with path.open(\"w\", encoding=\"utf8\") as file:\n            file.write(file_content)\n\n    @staticmethod\n    def _serialize_comment_lines(data: Dict[str, List[Any]]) -&gt; List[str]:\n        commentlines = []\n        for comment in data[\"comments\"]:\n            commentlines.append(f\"#{comment}\")\n        return commentlines\n\n    @staticmethod\n    def _serialize_timeseries_lines(\n        data: Dict[str, List[Any]], config: TimSerializerConfig\n    ) -&gt; List[str]:\n        format_float = lambda v: f\"{v:{config.float_format}}\"\n        timeseriesblock = TimSerializer._serialize_to_timeseries_block(\n            data, format_float\n        )\n        timeserieslines = TimSerializer._serialize_timeseries_to_lines(\n            timeseriesblock, config\n        )\n        return timeserieslines\n\n    @staticmethod\n    def _serialize_to_timeseries_block(\n        data: Dict[str, List[Any]], format_float: Callable[[float], str]\n    ) -&gt; TimeSeriesBlock:\n        timeseries_block: TimeSeriesBlock = []\n        for timeseries in data[\"timeseries\"]:\n            time = timeseries[\"time\"]\n            row_elements = timeseries[\"data\"]\n            timeseries_row = [format_float(time)] + [\n                format_float(value) for value in row_elements\n            ]\n            timeseries_block.append(timeseries_row)\n        return timeseries_block\n\n    @staticmethod\n    def _serialize_timeseries_to_lines(\n        timeseries_block: TimeSeriesBlock, config: TimSerializerConfig\n    ) -&gt; List[str]:\n        # Make sure the columns are aligned and have the proper spacing\n        column_space = \" \" * config.column_spacing\n        column_lengths = TimSerializer._get_column_lengths(timeseries_block)\n\n        timeserieslines = []\n        for timeseries_row in timeseries_block:\n            row_elements: List[str] = []\n            for index, value in enumerate(timeseries_row):\n                whitespace_offset = TimSerializer._get_offset_whitespace(\n                    value, column_lengths[index]\n                )\n                row_elements.append(value + whitespace_offset)\n\n            line = column_space.join(row_elements)\n            timeserieslines.append(line)\n        return timeserieslines\n\n    @staticmethod\n    def _get_offset_whitespace(value: Optional[str], max_length: int) -&gt; str:\n        value_length = len(value) if value is not None else 0\n        return \" \" * max(max_length - value_length, 0)\n\n    @staticmethod\n    def _serialize_file_content(timeserieslines: List[str], commentlines: List[str]):\n        lines = []\n        lines.extend(commentlines)\n        lines.extend(timeserieslines)\n        file_content = \"\\n\".join(lines)\n        return file_content\n\n    @staticmethod\n    def _get_column_lengths(timeseries_block: TimeSeriesBlock) -&gt; List[int]:\n        if len(timeseries_block) == 0:\n            return []\n\n        n_columns = len(timeseries_block[0])\n        column_lengths = [0] * n_columns\n\n        for timeseries_row in timeseries_block:\n            for index, row_element in enumerate(timeseries_row):\n                if len(row_element) &gt; column_lengths[index]:\n                    column_lengths[index] = len(row_element)\n\n        return column_lengths\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.serializer.TimSerializer.serialize","title":"<code>serialize(path, data, config, save_settings)</code>  <code>staticmethod</code>","text":"<p>Serialize timeseries data to a file in .tim format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to the destination .tim file.</p> required <code>data</code> <code>Dict[str, List[Any]]</code> <p>A dictionary with keys \"comments\" and \"timeseries\".</p> required <code>config</code> <code>TimSerializerConfig</code> <p>The serialization configuration settings.</p> required <code>save_settings</code> <code>ModelSaveSettings</code> <p>The save settings to be used.</p> required Source code in <code>hydrolib/core/dflowfm/tim/serializer.py</code> <pre><code>@staticmethod\ndef serialize(\n    path: Path,\n    data: Dict[str, List[Any]],\n    config: TimSerializerConfig,\n    save_settings: ModelSaveSettings,\n) -&gt; None:\n    \"\"\"\n    Serialize timeseries data to a file in .tim format.\n\n    Args:\n        path (Path): The path to the destination .tim file.\n        data (Dict[str, List[Any]]): A dictionary with keys \"comments\" and \"timeseries\".\n        - \"comments\" represents comments found at the start of the file.\n        - \"timeseries\" is a list of dictionaries with the key as \"time\" and values as \"data\".\n            - \"time\" is a time as a string.\n            - \"data\" is data as a list of strings.\n\n        config (TimSerializerConfig): The serialization configuration settings.\n        save_settings (ModelSaveSettings): The save settings to be used.\n    \"\"\"\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    commentlines = TimSerializer._serialize_comment_lines(data)\n    timeserieslines = TimSerializer._serialize_timeseries_lines(data, config)\n\n    file_content = TimSerializer._serialize_file_content(\n        timeserieslines, commentlines\n    )\n    with path.open(\"w\", encoding=\"utf8\") as file:\n        file.write(file_content)\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.serializer.TimSerializerConfig","title":"<code>TimSerializerConfig</code>","text":"<p>               Bases: <code>SerializerConfig</code></p> <p>Configuration settings for the TimSerializer.</p> Source code in <code>hydrolib/core/dflowfm/tim/serializer.py</code> <pre><code>class TimSerializerConfig(SerializerConfig):\n    \"\"\"Configuration settings for the TimSerializer.\"\"\"\n\n    column_spacing: int = 1\n    \"\"\"(int): The number of spaces to include between columns in the serialized .tim file.\"\"\"\n</code></pre>"},{"location":"reference/models/tim/#hydrolib.core.dflowfm.tim.serializer.TimSerializerConfig.column_spacing","title":"<code>column_spacing = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>(int): The number of spaces to include between columns in the serialized .tim file.</p>"},{"location":"reference/models/xyz/","title":"Sample files","text":"<p>Sample .xyz files contain spatial input point data for a D-Flow FM model, and are used in various other input files.</p> <p>A sample data file is described by the classes below.</p>"},{"location":"reference/models/xyz/#model","title":"Model","text":""},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.models.XYZModel","title":"<code>XYZModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Sample or forcing file.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>List[XYZPoint]</code> <p>List of <code>XYZPoint</code></p> Source code in <code>hydrolib/core/dflowfm/xyz/models.py</code> <pre><code>class XYZModel(ParsableFileModel):\n    \"\"\"Sample or forcing file.\n\n    Attributes:\n        points: List of [`XYZPoint`][hydrolib.core.dflowfm.xyz.models.XYZPoint]\n    \"\"\"\n\n    points: List[XYZPoint] = []\n\n    def dict(self, *args, **kwargs):\n        # speed up serializing by not converting these lowest models to dict\n        return dict(points=self.points)\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".xyz\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"sample\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return XYZSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable[[Path], Dict]:\n        return XYZParser.parse\n</code></pre>"},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.models.XYZPoint","title":"<code>XYZPoint</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single sample or forcing point.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>x or \u03bb coordinate</p> <code>y</code> <code>float</code> <p>y or \u03c6 coordinate</p> <code>z</code> <code>float</code> <p>sample value or group number (forcing)</p> <code>comment</code> <code>Optional[str]</code> <p>keyword for grouping (forcing)</p> Source code in <code>hydrolib/core/dflowfm/xyz/models.py</code> <pre><code>class XYZPoint(BaseModel):\n    \"\"\"Single sample or forcing point.\n\n    Attributes:\n        x: x or \u03bb coordinate\n        y: y or \u03c6 coordinate\n        z: sample value or group number (forcing)\n        comment: keyword for grouping (forcing)\n    \"\"\"\n\n    x: float\n    y: float\n    z: float\n    comment: Optional[str] = Field(\n        None, alias=\"group\", description=\"comment or group name\"\n    )\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        x = data.get(\"x\")\n        y = data.get(\"y\")\n        z = data.get(\"z\")\n        return f\"x:{x} y:{y} z:{z}\"\n</code></pre>"},{"location":"reference/models/xyz/#parser","title":"Parser","text":""},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.parser.XYZParser","title":"<code>XYZParser</code>","text":"<p>A parser for .xyz files which are like this:</p> <p>number number    number number number number # comment</p> <p>Note that the whitespace can vary and the comment left out.</p> Source code in <code>hydrolib/core/dflowfm/xyz/parser.py</code> <pre><code>class XYZParser:\n    \"\"\"\n    A parser for .xyz files which are like this:\n\n    number number    number\n    number number number # comment\n\n    Note that the whitespace can vary and the comment\n    left out.\n    \"\"\"\n\n    @staticmethod\n    def parse(filepath: Path) -&gt; Dict:\n        \"\"\"Parse an .xyz file into a Dict with the list of points read.\n\n        Args:\n            filepath (Path): .xyz file to be read.\n\n        Returns:\n            Dict: dictionary with \"points\" value set to a list of points\n                each of which is a dict itself, with keys 'x', 'y', 'z'\n                and 'c' for an optional comment.\n\n        Raises:\n            ValueError: if a line in the file contains no values that\n                could be parsed.\n        \"\"\"\n\n        data: Dict = dict(points=[])\n\n        with filepath.open(encoding=\"utf8\") as f:\n            for linenr, line in enumerate(f.readlines()):\n\n                line = line.strip()\n                if line.startswith(\"*\") or len(line) == 0:\n                    continue\n\n                try:\n                    x, y, z, *c = re.split(xyzpattern, line, maxsplit=3)\n                except ValueError:\n                    raise ValueError(\n                        f\"Error parsing XYZ file '{filepath}', line {linenr+1}.\"\n                    )\n\n                c = c[0] if len(c) &gt; 0 else \"\"\n                c = c.strip(\"#\").strip()\n                if len(c) == 0:\n                    c = None\n\n                data[\"points\"].append(dict(x=x, y=y, z=z, comment=c))\n\n        return data\n</code></pre>"},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.parser.XYZParser.parse","title":"<code>parse(filepath)</code>  <code>staticmethod</code>","text":"<p>Parse an .xyz file into a Dict with the list of points read.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>.xyz file to be read.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>dictionary with \"points\" value set to a list of points each of which is a dict itself, with keys 'x', 'y', 'z' and 'c' for an optional comment.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if a line in the file contains no values that could be parsed.</p> Source code in <code>hydrolib/core/dflowfm/xyz/parser.py</code> <pre><code>@staticmethod\ndef parse(filepath: Path) -&gt; Dict:\n    \"\"\"Parse an .xyz file into a Dict with the list of points read.\n\n    Args:\n        filepath (Path): .xyz file to be read.\n\n    Returns:\n        Dict: dictionary with \"points\" value set to a list of points\n            each of which is a dict itself, with keys 'x', 'y', 'z'\n            and 'c' for an optional comment.\n\n    Raises:\n        ValueError: if a line in the file contains no values that\n            could be parsed.\n    \"\"\"\n\n    data: Dict = dict(points=[])\n\n    with filepath.open(encoding=\"utf8\") as f:\n        for linenr, line in enumerate(f.readlines()):\n\n            line = line.strip()\n            if line.startswith(\"*\") or len(line) == 0:\n                continue\n\n            try:\n                x, y, z, *c = re.split(xyzpattern, line, maxsplit=3)\n            except ValueError:\n                raise ValueError(\n                    f\"Error parsing XYZ file '{filepath}', line {linenr+1}.\"\n                )\n\n            c = c[0] if len(c) &gt; 0 else \"\"\n            c = c.strip(\"#\").strip()\n            if len(c) == 0:\n                c = None\n\n            data[\"points\"].append(dict(x=x, y=y, z=z, comment=c))\n\n    return data\n</code></pre>"},{"location":"reference/models/xyz/#serializer","title":"Serializer","text":""},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.serializer.XYZSerializer","title":"<code>XYZSerializer</code>","text":"Source code in <code>hydrolib/core/dflowfm/xyz/serializer.py</code> <pre><code>class XYZSerializer:\n    @staticmethod\n    def serialize(\n        path: Path,\n        data: Dict,\n        config: SerializerConfig,\n        save_settings: ModelSaveSettings,\n    ) -&gt; None:\n        \"\"\"\n        Serializes the XYZ data to the file at the specified path.\n\n        Attributes:\n            path (Path): The path to the destination file.\n            data (Dict): The data to be serialized.\n            config (SerializerConfig): The serialization configuration.\n            save_settings (ModelSaveSettings): The model save settings.\n        \"\"\"\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        space = 1 * \" \"\n        format_float = lambda x: f\"{x:{config.float_format}}\"\n\n        with path.open(\"w\", encoding=\"utf8\") as f:\n            for point in data[\"points\"]:\n                geometry: str = space.join(\n                    [format_float(p) for p in XYZSerializer._get_point_values(point)]\n                )\n                if point.comment:\n                    f.write(f\"{geometry} # {point.comment}\\n\")\n                else:\n                    f.write(f\"{geometry}\\n\")\n\n    @staticmethod\n    def _get_point_values(point) -&gt; Generator[float, None, None]:\n        yield point.x\n        yield point.y\n        yield point.z\n</code></pre>"},{"location":"reference/models/xyz/#hydrolib.core.dflowfm.xyz.serializer.XYZSerializer.serialize","title":"<code>serialize(path, data, config, save_settings)</code>  <code>staticmethod</code>","text":"<p>Serializes the XYZ data to the file at the specified path.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>The path to the destination file.</p> <code>data</code> <code>Dict</code> <p>The data to be serialized.</p> <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> <code>save_settings</code> <code>ModelSaveSettings</code> <p>The model save settings.</p> Source code in <code>hydrolib/core/dflowfm/xyz/serializer.py</code> <pre><code>@staticmethod\ndef serialize(\n    path: Path,\n    data: Dict,\n    config: SerializerConfig,\n    save_settings: ModelSaveSettings,\n) -&gt; None:\n    \"\"\"\n    Serializes the XYZ data to the file at the specified path.\n\n    Attributes:\n        path (Path): The path to the destination file.\n        data (Dict): The data to be serialized.\n        config (SerializerConfig): The serialization configuration.\n        save_settings (ModelSaveSettings): The model save settings.\n    \"\"\"\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    space = 1 * \" \"\n    format_float = lambda x: f\"{x:{config.float_format}}\"\n\n    with path.open(\"w\", encoding=\"utf8\") as f:\n        for point in data[\"points\"]:\n            geometry: str = space.join(\n                [format_float(p) for p in XYZSerializer._get_point_values(point)]\n            )\n            if point.comment:\n                f.write(f\"{geometry} # {point.comment}\\n\")\n            else:\n                f.write(f\"{geometry}\\n\")\n</code></pre>"},{"location":"reference/rr/meteo/","title":"The Rainfall Runoff meteo layer","text":"<p>The meteo layer currently contains only support for the BUI file. The \"bui\" file contains the precipitation input data for Rainfall Runoff. It is represented by the classes below.</p>"},{"location":"reference/rr/meteo/#model","title":"Model","text":""},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.models.BuiModel","title":"<code>BuiModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Model that represents the file structure of a .bui file.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>class BuiModel(ParsableFileModel):\n    \"\"\"\n    Model that represents the file structure of a .bui file.\n    \"\"\"\n\n    default_dataset: int = 1  # Default value (always)\n    number_of_stations: int\n    name_of_stations: List[str]\n    number_of_events: int\n    seconds_per_timestep: int\n    precipitation_events: List[BuiPrecipitationEvent]\n\n    @classmethod\n    def _filename(cls):\n        return \"bui_file\"\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".bui\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return write_bui_file\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return BuiParser.parse\n\n    def get_station_events(self, station: str) -&gt; Dict[datetime, List[float]]:\n        \"\"\"\n        Returns all the events (start time and precipitations) related to a given station.\n\n        Args:\n            station (str): Name of the station to retrieve.\n\n        Raises:\n            ValueError: If the station name does not exist in the BuiModel.\n\n        Returns:\n            Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.\n        \"\"\"\n        if station not in self.name_of_stations:\n            raise ValueError(\"Station {} not found BuiModel.\".format(station))\n        station_idx = self.name_of_stations.index(station)\n        station_events = {}\n        for event in self.precipitation_events:\n            start_time, precipitations = event.get_station_precipitations(station_idx)\n            station_events[start_time] = precipitations\n        return station_events\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.models.BuiModel.get_station_events","title":"<code>get_station_events(station)</code>","text":"<p>Returns all the events (start time and precipitations) related to a given station.</p> <p>Parameters:</p> Name Type Description Default <code>station</code> <code>str</code> <p>Name of the station to retrieve.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the station name does not exist in the BuiModel.</p> <p>Returns:</p> Type Description <code>Dict[datetime, List[float]]</code> <p>Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>def get_station_events(self, station: str) -&gt; Dict[datetime, List[float]]:\n    \"\"\"\n    Returns all the events (start time and precipitations) related to a given station.\n\n    Args:\n        station (str): Name of the station to retrieve.\n\n    Raises:\n        ValueError: If the station name does not exist in the BuiModel.\n\n    Returns:\n        Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.\n    \"\"\"\n    if station not in self.name_of_stations:\n        raise ValueError(\"Station {} not found BuiModel.\".format(station))\n    station_idx = self.name_of_stations.index(station)\n    station_events = {}\n    for event in self.precipitation_events:\n        start_time, precipitations = event.get_station_precipitations(station_idx)\n        station_events[start_time] = precipitations\n    return station_events\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.models.BuiPrecipitationEvent","title":"<code>BuiPrecipitationEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>class BuiPrecipitationEvent(BaseModel):\n    start_time: datetime\n    timeseries_length: timedelta\n    precipitation_per_timestep: List[List[float]]\n\n    def get_station_precipitations(\n        self, station_idx: int\n    ) -&gt; Tuple[datetime, List[float]]:\n        \"\"\"\n        Returns all the precipitations related to the given station index (column).\n\n        Args:\n            station_idx (int): Index of the column which values need to be retrieved.\n\n        Raises:\n            ValueError: If the station index does not exist.\n\n        Returns:\n            Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.\n        \"\"\"\n        number_of_stations = len(self.precipitation_per_timestep[0])\n        if station_idx &gt;= number_of_stations:\n            raise ValueError(\n                \"Station index not found, number of stations: {}\".format(\n                    number_of_stations\n                )\n            )\n        return (\n            self.start_time,\n            [\n                ts_precipitations[station_idx]\n                for ts_precipitations in self.precipitation_per_timestep\n            ],\n        )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.models.BuiPrecipitationEvent.get_station_precipitations","title":"<code>get_station_precipitations(station_idx)</code>","text":"<p>Returns all the precipitations related to the given station index (column).</p> <p>Parameters:</p> Name Type Description Default <code>station_idx</code> <code>int</code> <p>Index of the column which values need to be retrieved.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the station index does not exist.</p> <p>Returns:</p> Type Description <code>Tuple[datetime, List[float]]</code> <p>Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>def get_station_precipitations(\n    self, station_idx: int\n) -&gt; Tuple[datetime, List[float]]:\n    \"\"\"\n    Returns all the precipitations related to the given station index (column).\n\n    Args:\n        station_idx (int): Index of the column which values need to be retrieved.\n\n    Raises:\n        ValueError: If the station index does not exist.\n\n    Returns:\n        Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.\n    \"\"\"\n    number_of_stations = len(self.precipitation_per_timestep[0])\n    if station_idx &gt;= number_of_stations:\n        raise ValueError(\n            \"Station index not found, number of stations: {}\".format(\n                number_of_stations\n            )\n        )\n    return (\n        self.start_time,\n        [\n            ts_precipitations[station_idx]\n            for ts_precipitations in self.precipitation_per_timestep\n        ],\n    )\n</code></pre>"},{"location":"reference/rr/meteo/#parser","title":"Parser","text":""},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiEventListParser","title":"<code>BuiEventListParser</code>","text":"<p>A parser for .bui events which are like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 4.2 4.2 2021 12 21 0 0 0 1 0 4 20 2.4 2.4 2.4</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>class BuiEventListParser:\n    \"\"\"\n    A parser for .bui events which are like this:\n    StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS)\n    PrecipitationPerTimestep\n    StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS)\n    PrecipitationPerTimestep\n    Example given:\n    2021 12 20 0 0 0 1 0 4 20\n    4.2\n    4.2\n    4.2\n    2021 12 21 0 0 0 1 0 4 20\n    2.4\n    2.4\n    2.4\n    \"\"\"\n\n    @staticmethod\n    def parse(raw_text: str, n_events: int, timestep: int) -&gt; List[Dict]:\n        \"\"\"\n        Parses a given raw text containing 0 to many text blocks representing a precipitation event.\n\n        Args:\n            raw_text (str): Text blocks representing precipitation events.\n            n_events (int): Number of events contained in the text block.\n            timestep (int): Number of seconds conforming a timestep.\n\n        Returns:\n            List[Dict]: List containing all the events represented as dictionaries.\n        \"\"\"\n\n        def get_event_timestep_length(raw_line: str) -&gt; int:\n            timereference = BuiEventParser.parse_event_time_reference(raw_line)\n            ts_length: timedelta = timereference[\"timeseries_length\"]\n            return ts_length.total_seconds()\n\n        def get_multiple_events(raw_lines: List[str]) -&gt; Iterator[BuiEventParser]:\n            n_line = 0\n            while n_line &lt; len(raw_lines):\n                ts_seconds = get_event_timestep_length(raw_lines[n_line])\n                event_lines = int(ts_seconds / timestep) + 1\n                yield BuiEventParser.parse(\"\\n\".join(raw_lines[n_line:][:event_lines]))\n                n_line += event_lines\n\n        event_list = []\n        if n_events == 1:\n            event_list.append(BuiEventParser.parse(raw_text))\n        elif n_events &gt; 1:\n            raw_lines = raw_text.splitlines(keepends=False)\n            event_list = list(get_multiple_events(raw_lines))\n\n        return event_list\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiEventListParser.parse","title":"<code>parse(raw_text, n_events, timestep)</code>  <code>staticmethod</code>","text":"<p>Parses a given raw text containing 0 to many text blocks representing a precipitation event.</p> <p>Parameters:</p> Name Type Description Default <code>raw_text</code> <code>str</code> <p>Text blocks representing precipitation events.</p> required <code>n_events</code> <code>int</code> <p>Number of events contained in the text block.</p> required <code>timestep</code> <code>int</code> <p>Number of seconds conforming a timestep.</p> required <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List containing all the events represented as dictionaries.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>@staticmethod\ndef parse(raw_text: str, n_events: int, timestep: int) -&gt; List[Dict]:\n    \"\"\"\n    Parses a given raw text containing 0 to many text blocks representing a precipitation event.\n\n    Args:\n        raw_text (str): Text blocks representing precipitation events.\n        n_events (int): Number of events contained in the text block.\n        timestep (int): Number of seconds conforming a timestep.\n\n    Returns:\n        List[Dict]: List containing all the events represented as dictionaries.\n    \"\"\"\n\n    def get_event_timestep_length(raw_line: str) -&gt; int:\n        timereference = BuiEventParser.parse_event_time_reference(raw_line)\n        ts_length: timedelta = timereference[\"timeseries_length\"]\n        return ts_length.total_seconds()\n\n    def get_multiple_events(raw_lines: List[str]) -&gt; Iterator[BuiEventParser]:\n        n_line = 0\n        while n_line &lt; len(raw_lines):\n            ts_seconds = get_event_timestep_length(raw_lines[n_line])\n            event_lines = int(ts_seconds / timestep) + 1\n            yield BuiEventParser.parse(\"\\n\".join(raw_lines[n_line:][:event_lines]))\n            n_line += event_lines\n\n    event_list = []\n    if n_events == 1:\n        event_list.append(BuiEventParser.parse(raw_text))\n    elif n_events &gt; 1:\n        raw_lines = raw_text.splitlines(keepends=False)\n        event_list = list(get_multiple_events(raw_lines))\n\n    return event_list\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiEventParser","title":"<code>BuiEventParser</code>","text":"<p>A parser for the precipitation event section within a .bui file. It resembles something like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 2.4 4.2 2.4 4.2 2.4 (it should match the timeseries length based on the seconds per timstep.) Each column of the last three lines represents a station.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>class BuiEventParser:\n    \"\"\"\n    A parser for the precipitation event section within a .bui file.\n    It resembles something like this:\n    StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS)\n    PrecipitationPerTimestep\n    Example given:\n    2021 12 20 0 0 0 1 0 4 20\n    4.2 2.4\n    4.2 2.4\n    4.2 2.4\n    (it should match the timeseries length based on the seconds per timstep.)\n    Each column of the last three lines represents a station.\n    \"\"\"\n\n    @staticmethod\n    def parse(raw_text: str) -&gt; Dict:\n        \"\"\"\n        Given text representing a single BuiPrecipitationEvent parses it into a dictionary.\n\n        Args:\n            raw_text (str): Text containing a single precipitation event.\n\n        Returns:\n            Dict: Mapped contents of the text.\n        \"\"\"\n\n        def get_precipitations_per_ts(line: str) -&gt; List[str]:\n            return [prec for prec in line.split()]\n\n        event_lines = raw_text.splitlines(keepends=False)\n        time_reference = BuiEventParser.parse_event_time_reference(event_lines[0])\n        return dict(\n            start_time=time_reference[\"start_time\"],\n            timeseries_length=time_reference[\"timeseries_length\"],\n            precipitation_per_timestep=list(\n                map(get_precipitations_per_ts, event_lines[1:])\n            ),\n        )\n\n    @staticmethod\n    def parse_event_time_reference(raw_text: str) -&gt; Dict:\n        \"\"\"\n        Parses a single event time reference line containing both the start time\n        and the timeseries length into a dictionary.\n\n        Args:\n            raw_text (str): Line representing both start time and timeseries length.\n\n        Returns:\n            Dict: Resulting dictionary with keys start_time and timeseries_length.\n        \"\"\"\n\n        def get_start_time(line: str) -&gt; datetime:\n            return datetime.strptime(line, \"%Y %m %d %H %M %S\")\n\n        def get_timeseries_length(line: str) -&gt; timedelta:\n            time_fields = line.split()\n            return timedelta(\n                days=int(time_fields[0]),\n                hours=int(time_fields[1]),\n                minutes=int(time_fields[2]),\n                seconds=int(time_fields[3]),\n            )\n\n        timeref = raw_text.split()\n        return dict(\n            start_time=get_start_time(\" \".join(timeref[:6])),\n            timeseries_length=get_timeseries_length(\" \".join(timeref[6:])),\n        )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiEventParser.parse","title":"<code>parse(raw_text)</code>  <code>staticmethod</code>","text":"<p>Given text representing a single BuiPrecipitationEvent parses it into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>raw_text</code> <code>str</code> <p>Text containing a single precipitation event.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Mapped contents of the text.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>@staticmethod\ndef parse(raw_text: str) -&gt; Dict:\n    \"\"\"\n    Given text representing a single BuiPrecipitationEvent parses it into a dictionary.\n\n    Args:\n        raw_text (str): Text containing a single precipitation event.\n\n    Returns:\n        Dict: Mapped contents of the text.\n    \"\"\"\n\n    def get_precipitations_per_ts(line: str) -&gt; List[str]:\n        return [prec for prec in line.split()]\n\n    event_lines = raw_text.splitlines(keepends=False)\n    time_reference = BuiEventParser.parse_event_time_reference(event_lines[0])\n    return dict(\n        start_time=time_reference[\"start_time\"],\n        timeseries_length=time_reference[\"timeseries_length\"],\n        precipitation_per_timestep=list(\n            map(get_precipitations_per_ts, event_lines[1:])\n        ),\n    )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiEventParser.parse_event_time_reference","title":"<code>parse_event_time_reference(raw_text)</code>  <code>staticmethod</code>","text":"<p>Parses a single event time reference line containing both the start time and the timeseries length into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>raw_text</code> <code>str</code> <p>Line representing both start time and timeseries length.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Resulting dictionary with keys start_time and timeseries_length.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>@staticmethod\ndef parse_event_time_reference(raw_text: str) -&gt; Dict:\n    \"\"\"\n    Parses a single event time reference line containing both the start time\n    and the timeseries length into a dictionary.\n\n    Args:\n        raw_text (str): Line representing both start time and timeseries length.\n\n    Returns:\n        Dict: Resulting dictionary with keys start_time and timeseries_length.\n    \"\"\"\n\n    def get_start_time(line: str) -&gt; datetime:\n        return datetime.strptime(line, \"%Y %m %d %H %M %S\")\n\n    def get_timeseries_length(line: str) -&gt; timedelta:\n        time_fields = line.split()\n        return timedelta(\n            days=int(time_fields[0]),\n            hours=int(time_fields[1]),\n            minutes=int(time_fields[2]),\n            seconds=int(time_fields[3]),\n        )\n\n    timeref = raw_text.split()\n    return dict(\n        start_time=get_start_time(\" \".join(timeref[:6])),\n        timeseries_length=get_timeseries_length(\" \".join(timeref[6:])),\n    )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiParser","title":"<code>BuiParser</code>","text":"<p>A parser for .bui files which are like this: * comments Dataset type to use (always 1). * comments Number of stations. * comments Name of stations * comments Number of events Number of seconds per timestep. * comments First datetime reference. Precipitation per timestep per station.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>class BuiParser:\n    \"\"\"\n    A parser for .bui files which are like this:\n    * comments\n    Dataset type to use (always 1).\n    * comments\n    Number of stations.\n    * comments\n    Name of stations\n    * comments\n    Number of events Number of seconds per timestep.\n    * comments\n    First datetime reference.\n    Precipitation per timestep per station.\n    \"\"\"\n\n    @staticmethod\n    def parse(filepath: Path) -&gt; Dict:\n        \"\"\"\n        Parses a given file, in case valid, into a dictionary which can later be mapped\n        to the BuiModel.\n\n        Args:\n            filepath (Path): Path to file containing the data to parse.\n\n        Returns:\n            Dict: Parsed values.\n        \"\"\"\n\n        def get_station_ids(lines: List[str]) -&gt; List[str]:\n            return [s_id.strip(\"'\\\"\") for s_id in lines]\n\n        def parse_events_and_timestep(line: str) -&gt; Tuple[int, int]:\n            n_events_timestep = line.split()\n            return (int(n_events_timestep[0]), int(n_events_timestep[1]))\n\n        bui_lines = [\n            line\n            for line in filepath.read_text(encoding=\"utf8\").splitlines()\n            if not line.startswith(\"*\")\n        ]\n        number_of_stations = int(bui_lines[1])\n        last_station_line = 1 + number_of_stations\n\n        n_events, timestep = parse_events_and_timestep(bui_lines[last_station_line + 1])\n\n        return dict(\n            default_dataset=bui_lines[0],\n            number_of_stations=bui_lines[1],\n            name_of_stations=get_station_ids(bui_lines[2 : last_station_line + 1]),\n            number_of_events=n_events,\n            seconds_per_timestep=timestep,\n            precipitation_events=BuiEventListParser.parse(\n                \"\\n\".join(bui_lines[last_station_line + 2 :]), n_events, timestep\n            ),\n        )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.parser.BuiParser.parse","title":"<code>parse(filepath)</code>  <code>staticmethod</code>","text":"<p>Parses a given file, in case valid, into a dictionary which can later be mapped to the BuiModel.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to file containing the data to parse.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Parsed values.</p> Source code in <code>hydrolib/core/rr/meteo/parser.py</code> <pre><code>@staticmethod\ndef parse(filepath: Path) -&gt; Dict:\n    \"\"\"\n    Parses a given file, in case valid, into a dictionary which can later be mapped\n    to the BuiModel.\n\n    Args:\n        filepath (Path): Path to file containing the data to parse.\n\n    Returns:\n        Dict: Parsed values.\n    \"\"\"\n\n    def get_station_ids(lines: List[str]) -&gt; List[str]:\n        return [s_id.strip(\"'\\\"\") for s_id in lines]\n\n    def parse_events_and_timestep(line: str) -&gt; Tuple[int, int]:\n        n_events_timestep = line.split()\n        return (int(n_events_timestep[0]), int(n_events_timestep[1]))\n\n    bui_lines = [\n        line\n        for line in filepath.read_text(encoding=\"utf8\").splitlines()\n        if not line.startswith(\"*\")\n    ]\n    number_of_stations = int(bui_lines[1])\n    last_station_line = 1 + number_of_stations\n\n    n_events, timestep = parse_events_and_timestep(bui_lines[last_station_line + 1])\n\n    return dict(\n        default_dataset=bui_lines[0],\n        number_of_stations=bui_lines[1],\n        name_of_stations=get_station_ids(bui_lines[2 : last_station_line + 1]),\n        number_of_events=n_events,\n        seconds_per_timestep=timestep,\n        precipitation_events=BuiEventListParser.parse(\n            \"\\n\".join(bui_lines[last_station_line + 2 :]), n_events, timestep\n        ),\n    )\n</code></pre>"},{"location":"reference/rr/meteo/#serializer","title":"Serializer","text":""},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer","title":"<code>BuiEventSerializer</code>","text":"<p>Serializer class to transform a bui event into a text block.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>class BuiEventSerializer:\n    \"\"\"\n    Serializer class to transform a bui event into a text block.\n    \"\"\"\n\n    bui_event_template = inspect.cleandoc(\n        \"\"\"\n        * Event {event_idx} duration days:{d_days} hours:{d_hours} minutes:{d_minutes} seconds:{d_seconds}\n        * Start date and time of the event: yyyy mm dd hh mm ss\n        * Duration of the event           : dd hh mm ss\n        * Rainfall value per time step [mm/time step]\n        {start_time} {timeseries_length}\n        {precipitation_per_timestep}\n    \"\"\"\n    )\n\n    @staticmethod\n    def serialize(event_data: Dict, config: SerializerConfig) -&gt; str:\n        \"\"\"\n        Serializes a dictionary representing an event into a text block.\n\n        Args:\n            event_data (Dict): Dictionary representing precipitation event.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: Formatted string.\n        \"\"\"\n        event_data[\"start_time\"] = BuiEventSerializer.serialize_start_time(\n            event_data[\"start_time\"]\n        )\n        ts_duration = event_data[\"timeseries_length\"]\n        event_data = {\n            **event_data,\n            **BuiEventSerializer.get_timedelta_fields(ts_duration),\n        }\n        event_data[\"timeseries_length\"] = (\n            BuiEventSerializer.serialize_timeseries_length(\n                event_data[\"timeseries_length\"]\n            )\n        )\n        event_data[\"precipitation_per_timestep\"] = (\n            BuiEventSerializer.serialize_precipitation_per_timestep(\n                event_data[\"precipitation_per_timestep\"], config\n            )\n        )\n        if \"event_idx\" not in event_data.keys():\n            event_data[\"event_idx\"] = 1\n        return BuiEventSerializer.bui_event_template.format(**event_data)\n\n    @staticmethod\n    def get_timedelta_fields(duration: timedelta) -&gt; Dict:\n        \"\"\"\n        Gets a dictionary containing the time delta in days, hours, minutes and seconds.\n        This means that the seconds field does not contain the accumulative value of days\n        hours and minutes.\n\n        Args:\n            duration (timedelta): Timedelta to convert.\n\n        Returns:\n            Dict: Dictionary containing all fields.\n        \"\"\"\n        total_hours = int(duration.seconds / (60 * 60))\n        total_minutes = int((duration.seconds / 60) - (total_hours * 60))\n        total_seconds = int(\n            duration.seconds - ((total_hours * 60 + total_minutes) * 60)\n        )\n        return dict(\n            d_seconds=total_seconds,\n            d_minutes=total_minutes,\n            d_hours=total_hours,\n            d_days=duration.days,\n        )\n\n    @staticmethod\n    def serialize_start_time(data_to_serialize: datetime) -&gt; str:\n        \"\"\"\n        Serializes a datetime into the expected .bui format.\n\n        Args:\n            data_to_serialize (datetime): Datetime representing reference time.\n\n        Returns:\n            str: Converted datetime into string.\n        \"\"\"\n        # Not using the following format because we only want one digit instead of\n        # double (day 1 -&gt; 1, instead of 01).\n        # data_to_serialize.strftime(\"%Y %m %d %H %M %S\")\n        dt = data_to_serialize\n        return f\"{dt.year} {dt.month} {dt.day} {dt.hour} {dt.minute} {dt.second}\"\n\n    @staticmethod\n    def serialize_timeseries_length(data_to_serialize: timedelta) -&gt; str:\n        \"\"\"\n        Serializes a given timedelta into the .bui format.\n\n        Args:\n            data_to_serialize (timedelta): Reference timespan to serialize.\n\n        Returns:\n            str: Converted timedelta in string.\n        \"\"\"\n        fields_dict = BuiEventSerializer.get_timedelta_fields(data_to_serialize)\n        total_hours = fields_dict[\"d_hours\"]\n        total_minutes = fields_dict[\"d_minutes\"]\n        total_seconds = fields_dict[\"d_seconds\"]\n        return f\"{data_to_serialize.days} {total_hours} {total_minutes} {total_seconds}\"\n\n    @staticmethod\n    def serialize_precipitation_per_timestep(\n        data_to_serialize: List[List[float]], config: SerializerConfig\n    ) -&gt; str:\n        \"\"\"\n        Serialized the data containing all the precipitations per timestep (and station)\n        into a single string ready to be mapped.\n\n        Args:\n            data_to_serialize (List[List[str]]): Data to be mapped.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: Serialized string in .bui format.\n        \"\"\"\n        float_format = lambda v: f\"{v:{config.float_format}}\"\n        serialized_data = str.join(\n            \"\\n\",\n            [\n                str.join(\" \", map(float_format, listed_data))\n                for listed_data in data_to_serialize\n            ],\n        )\n        return serialized_data\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer.get_timedelta_fields","title":"<code>get_timedelta_fields(duration)</code>  <code>staticmethod</code>","text":"<p>Gets a dictionary containing the time delta in days, hours, minutes and seconds. This means that the seconds field does not contain the accumulative value of days hours and minutes.</p> <p>Parameters:</p> Name Type Description Default <code>duration</code> <code>timedelta</code> <p>Timedelta to convert.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Dictionary containing all fields.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef get_timedelta_fields(duration: timedelta) -&gt; Dict:\n    \"\"\"\n    Gets a dictionary containing the time delta in days, hours, minutes and seconds.\n    This means that the seconds field does not contain the accumulative value of days\n    hours and minutes.\n\n    Args:\n        duration (timedelta): Timedelta to convert.\n\n    Returns:\n        Dict: Dictionary containing all fields.\n    \"\"\"\n    total_hours = int(duration.seconds / (60 * 60))\n    total_minutes = int((duration.seconds / 60) - (total_hours * 60))\n    total_seconds = int(\n        duration.seconds - ((total_hours * 60 + total_minutes) * 60)\n    )\n    return dict(\n        d_seconds=total_seconds,\n        d_minutes=total_minutes,\n        d_hours=total_hours,\n        d_days=duration.days,\n    )\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer.serialize","title":"<code>serialize(event_data, config)</code>  <code>staticmethod</code>","text":"<p>Serializes a dictionary representing an event into a text block.</p> <p>Parameters:</p> Name Type Description Default <code>event_data</code> <code>Dict</code> <p>Dictionary representing precipitation event.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted string.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize(event_data: Dict, config: SerializerConfig) -&gt; str:\n    \"\"\"\n    Serializes a dictionary representing an event into a text block.\n\n    Args:\n        event_data (Dict): Dictionary representing precipitation event.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: Formatted string.\n    \"\"\"\n    event_data[\"start_time\"] = BuiEventSerializer.serialize_start_time(\n        event_data[\"start_time\"]\n    )\n    ts_duration = event_data[\"timeseries_length\"]\n    event_data = {\n        **event_data,\n        **BuiEventSerializer.get_timedelta_fields(ts_duration),\n    }\n    event_data[\"timeseries_length\"] = (\n        BuiEventSerializer.serialize_timeseries_length(\n            event_data[\"timeseries_length\"]\n        )\n    )\n    event_data[\"precipitation_per_timestep\"] = (\n        BuiEventSerializer.serialize_precipitation_per_timestep(\n            event_data[\"precipitation_per_timestep\"], config\n        )\n    )\n    if \"event_idx\" not in event_data.keys():\n        event_data[\"event_idx\"] = 1\n    return BuiEventSerializer.bui_event_template.format(**event_data)\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer.serialize_precipitation_per_timestep","title":"<code>serialize_precipitation_per_timestep(data_to_serialize, config)</code>  <code>staticmethod</code>","text":"<p>Serialized the data containing all the precipitations per timestep (and station) into a single string ready to be mapped.</p> <p>Parameters:</p> Name Type Description Default <code>data_to_serialize</code> <code>List[List[str]]</code> <p>Data to be mapped.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Serialized string in .bui format.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize_precipitation_per_timestep(\n    data_to_serialize: List[List[float]], config: SerializerConfig\n) -&gt; str:\n    \"\"\"\n    Serialized the data containing all the precipitations per timestep (and station)\n    into a single string ready to be mapped.\n\n    Args:\n        data_to_serialize (List[List[str]]): Data to be mapped.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: Serialized string in .bui format.\n    \"\"\"\n    float_format = lambda v: f\"{v:{config.float_format}}\"\n    serialized_data = str.join(\n        \"\\n\",\n        [\n            str.join(\" \", map(float_format, listed_data))\n            for listed_data in data_to_serialize\n        ],\n    )\n    return serialized_data\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer.serialize_start_time","title":"<code>serialize_start_time(data_to_serialize)</code>  <code>staticmethod</code>","text":"<p>Serializes a datetime into the expected .bui format.</p> <p>Parameters:</p> Name Type Description Default <code>data_to_serialize</code> <code>datetime</code> <p>Datetime representing reference time.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Converted datetime into string.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize_start_time(data_to_serialize: datetime) -&gt; str:\n    \"\"\"\n    Serializes a datetime into the expected .bui format.\n\n    Args:\n        data_to_serialize (datetime): Datetime representing reference time.\n\n    Returns:\n        str: Converted datetime into string.\n    \"\"\"\n    # Not using the following format because we only want one digit instead of\n    # double (day 1 -&gt; 1, instead of 01).\n    # data_to_serialize.strftime(\"%Y %m %d %H %M %S\")\n    dt = data_to_serialize\n    return f\"{dt.year} {dt.month} {dt.day} {dt.hour} {dt.minute} {dt.second}\"\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiEventSerializer.serialize_timeseries_length","title":"<code>serialize_timeseries_length(data_to_serialize)</code>  <code>staticmethod</code>","text":"<p>Serializes a given timedelta into the .bui format.</p> <p>Parameters:</p> Name Type Description Default <code>data_to_serialize</code> <code>timedelta</code> <p>Reference timespan to serialize.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Converted timedelta in string.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize_timeseries_length(data_to_serialize: timedelta) -&gt; str:\n    \"\"\"\n    Serializes a given timedelta into the .bui format.\n\n    Args:\n        data_to_serialize (timedelta): Reference timespan to serialize.\n\n    Returns:\n        str: Converted timedelta in string.\n    \"\"\"\n    fields_dict = BuiEventSerializer.get_timedelta_fields(data_to_serialize)\n    total_hours = fields_dict[\"d_hours\"]\n    total_minutes = fields_dict[\"d_minutes\"]\n    total_seconds = fields_dict[\"d_seconds\"]\n    return f\"{data_to_serialize.days} {total_hours} {total_minutes} {total_seconds}\"\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiSerializer","title":"<code>BuiSerializer</code>","text":"<p>Serializer class to transform an object into a .bui file text format.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>class BuiSerializer:\n    \"\"\"\n    Serializer class to transform an object into a .bui file text format.\n    \"\"\"\n\n    bui_template = inspect.cleandoc(\n        \"\"\"\n        *Name of this file: {filepath}\n        *Date and time of construction: {datetime_now}\n        *Comments are following an * (asterisk) and written above variables\n        {default_dataset}\n        *Number of stations\n        {number_of_stations}\n        *Station Name\n        {name_of_stations}\n        *Number_of_events seconds_per_timestamp\n        {number_of_events} {seconds_per_timestep}\n        {precipitation_events}\n        \"\"\"\n    )\n\n    @staticmethod\n    def serialize(bui_data: Dict, config: SerializerConfig) -&gt; str:\n        \"\"\"\n        Formats the bui_template with the content of the given data.\n        NOTE: It requires that caller injects file_path into bui_data prior to this call.\n        Otherwise it will crash.\n\n        Args:\n            bui_data (Dict): Data to serialize.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: The serialized data.\n        \"\"\"\n        bui_data[\"datetime_now\"] = datetime.now().strftime(\"%d-%m-%y %H:%M:%S\")\n        bui_data[\"name_of_stations\"] = BuiSerializer.serialize_stations_ids(\n            bui_data[\"name_of_stations\"]\n        )\n        bui_data[\"precipitation_events\"] = BuiSerializer.serialize_event_list(\n            bui_data[\"precipitation_events\"], config\n        )\n        return BuiSerializer.bui_template.format(**bui_data)\n\n    @staticmethod\n    def serialize_event_list(\n        data_to_serialize: List[Dict], config: SerializerConfig\n    ) -&gt; str:\n        \"\"\"\n        Serializes a event list dictionary into a single text block.\n\n        Args:\n            data_to_serialize (Dict): Dictionary containing list of events.\n            config (SerializerConfig): The serialization configuration.\n\n        Returns:\n            str: Text block representing all precipitation events.\n        \"\"\"\n        serialized_list = []\n        for n_event, event in enumerate(data_to_serialize):\n            event[\"event_idx\"] = n_event + 1\n            serialized_list.append(BuiEventSerializer.serialize(event, config))\n        return \"\\n\".join(serialized_list)\n\n    @staticmethod\n    def serialize_stations_ids(data_to_serialize: List[str]) -&gt; str:\n        \"\"\"\n        Serializes the stations ids into a single string as expected in a .bui file.\n\n        Args:\n            data_to_serialize (List[str]): List of station ids.\n\n        Returns:\n            str: Serialized string.\n        \"\"\"\n        return \"\\n\".join(f\"'{station_id}'\" for station_id in data_to_serialize)\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiSerializer.serialize","title":"<code>serialize(bui_data, config)</code>  <code>staticmethod</code>","text":"<p>Formats the bui_template with the content of the given data. NOTE: It requires that caller injects file_path into bui_data prior to this call. Otherwise it will crash.</p> <p>Parameters:</p> Name Type Description Default <code>bui_data</code> <code>Dict</code> <p>Data to serialize.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The serialized data.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize(bui_data: Dict, config: SerializerConfig) -&gt; str:\n    \"\"\"\n    Formats the bui_template with the content of the given data.\n    NOTE: It requires that caller injects file_path into bui_data prior to this call.\n    Otherwise it will crash.\n\n    Args:\n        bui_data (Dict): Data to serialize.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: The serialized data.\n    \"\"\"\n    bui_data[\"datetime_now\"] = datetime.now().strftime(\"%d-%m-%y %H:%M:%S\")\n    bui_data[\"name_of_stations\"] = BuiSerializer.serialize_stations_ids(\n        bui_data[\"name_of_stations\"]\n    )\n    bui_data[\"precipitation_events\"] = BuiSerializer.serialize_event_list(\n        bui_data[\"precipitation_events\"], config\n    )\n    return BuiSerializer.bui_template.format(**bui_data)\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiSerializer.serialize_event_list","title":"<code>serialize_event_list(data_to_serialize, config)</code>  <code>staticmethod</code>","text":"<p>Serializes a event list dictionary into a single text block.</p> <p>Parameters:</p> Name Type Description Default <code>data_to_serialize</code> <code>Dict</code> <p>Dictionary containing list of events.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Text block representing all precipitation events.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize_event_list(\n    data_to_serialize: List[Dict], config: SerializerConfig\n) -&gt; str:\n    \"\"\"\n    Serializes a event list dictionary into a single text block.\n\n    Args:\n        data_to_serialize (Dict): Dictionary containing list of events.\n        config (SerializerConfig): The serialization configuration.\n\n    Returns:\n        str: Text block representing all precipitation events.\n    \"\"\"\n    serialized_list = []\n    for n_event, event in enumerate(data_to_serialize):\n        event[\"event_idx\"] = n_event + 1\n        serialized_list.append(BuiEventSerializer.serialize(event, config))\n    return \"\\n\".join(serialized_list)\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.BuiSerializer.serialize_stations_ids","title":"<code>serialize_stations_ids(data_to_serialize)</code>  <code>staticmethod</code>","text":"<p>Serializes the stations ids into a single string as expected in a .bui file.</p> <p>Parameters:</p> Name Type Description Default <code>data_to_serialize</code> <code>List[str]</code> <p>List of station ids.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Serialized string.</p> Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>@staticmethod\ndef serialize_stations_ids(data_to_serialize: List[str]) -&gt; str:\n    \"\"\"\n    Serializes the stations ids into a single string as expected in a .bui file.\n\n    Args:\n        data_to_serialize (List[str]): List of station ids.\n\n    Returns:\n        str: Serialized string.\n    \"\"\"\n    return \"\\n\".join(f\"'{station_id}'\" for station_id in data_to_serialize)\n</code></pre>"},{"location":"reference/rr/meteo/#hydrolib.core.rr.meteo.serializer.write_bui_file","title":"<code>write_bui_file(path, data, config, save_settings)</code>","text":"<p>Writes a .bui file in the given path based on the data given in a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path where to output the text.</p> required <code>data</code> <code>Dict</code> <p>Data to serialize into the file.</p> required <code>config</code> <code>SerializerConfig</code> <p>The serialization configuration.</p> required <code>save_settings</code> <code>ModelSaveSettings</code> <p>The model save settings.</p> required Source code in <code>hydrolib/core/rr/meteo/serializer.py</code> <pre><code>def write_bui_file(\n    path: Path, data: Dict, config: SerializerConfig, save_settings: ModelSaveSettings\n) -&gt; None:\n    \"\"\"\n    Writes a .bui file in the given path based on the data given in a dictionary.\n\n    Args:\n        path (Path): Path where to output the text.\n        data (Dict): Data to serialize into the file.\n        config (SerializerConfig): The serialization configuration.\n        save_settings (ModelSaveSettings): The model save settings.\n    \"\"\"\n    data[\"filepath\"] = path  # This is redundant as already exists in the data.\n    serialized_bui_data = BuiSerializer.serialize(data, config)\n\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(serialized_bui_data, encoding=\"utf8\")\n</code></pre>"},{"location":"reference/rr/rr/","title":"RainfallRunoff file models","text":"<p>The rr module provides the various file models for files that are input to the  Rainfall Runoff kernel. Support is still basic, but growing. The input 'layers' listed below correspond with the input description in the SOBEK UM.</p>"},{"location":"reference/rr/rr/#main-input-sobek_3bfnm","title":"Main input (sobek_3b.fnm)","text":"<p>models.py defines the RainfallRunoffModel and supporting structures.</p>"},{"location":"reference/rr/rr/#hydrolib.core.rr.models.ImmutableDiskOnlyFileModel","title":"<code>ImmutableDiskOnlyFileModel</code>","text":"<p>               Bases: <code>DiskOnlyFileModel</code></p> <p>ImmutableDiskOnlyFileModel modifies the DiskOnlyFileModel to provide faux immutablitity.</p> <p>This behaviour is required for the mappix properties, which should always have the same name and path and should not be modified by users.</p> Source code in <code>hydrolib/core/rr/models.py</code> <pre><code>class ImmutableDiskOnlyFileModel(DiskOnlyFileModel, allow_mutation=False):\n    \"\"\"\n    ImmutableDiskOnlyFileModel modifies the DiskOnlyFileModel to provide faux\n    immutablitity.\n\n    This behaviour is required for the mappix properties, which should always\n    have the same name and path and should not be modified by users.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.models.RainfallRunoffModel","title":"<code>RainfallRunoffModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>The RainfallRunoffModel contains all paths and sub-models related to the Rainfall Runoff model.</p> Source code in <code>hydrolib/core/rr/models.py</code> <pre><code>class RainfallRunoffModel(ParsableFileModel):\n    \"\"\"The RainfallRunoffModel contains all paths and sub-models related to the\n    Rainfall Runoff model.\n    \"\"\"\n\n    _disk_only_file_model_cannot_be_none = (\n        validator_set_default_disk_only_file_model_when_none()\n    )\n\n    # Note that order is defined by the .fnm file type and is used for parsing the data.\n    control_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"delft_3b.ini\"))\n    )\n    node_data: Optional[NodeFile] = Field(None)\n    link_data: Optional[LinkFile] = Field(None)\n    open_water_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3brunoff.tp\"))\n    )\n    paved_area_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"paved.3b\"))\n    )\n    paved_area_storage: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"paved.sto\"))\n    )\n    paved_area_dwa: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"paved.dwa\"))\n    )\n    paved_area_sewer_pump_capacity: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"paved.tbl\"))\n    )\n    boundaries: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"pluvius.dwa\"))\n    )\n    pluvius: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"pluvius.3b\"))\n    )\n    pluvius_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"pluvius.alg\"))\n    )\n    kasklasse: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"kasklass\"))\n    )\n    bui_file: Optional[BuiModel] = Field(None)\n    verdampings_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"default.evp\"))\n    )\n    unpaved_area_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.3b\"))\n    )\n    unpaved_area_storage: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.sto\"))\n    )\n    green_house_area_initialisation: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"kasinit\"))\n    )\n    green_house_area_usage_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"kasgebr\"))\n    )\n    crop_factors: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"cropfact\"))\n    )\n    table_bergingscoef: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"bergcoef\"))\n    )\n    unpaved_alpha_factor_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.alf\"))\n    )\n    run_log_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sobek_3b.log\"))\n    )\n    schema_overview: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_gener.out\"))\n    )\n    output_results_paved_area: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"paved.out\"))\n    )\n    output_results_unpaved_area: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.out\"))\n    )\n    output_results_green_houses: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"grnhous.out\"))\n    )\n    output_results_open_water: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"openwate.out\"))\n    )\n    output_results_structures: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"struct3b.out\"))\n    )\n    output_results_boundaries: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"bound3b.out\"))\n    )\n    output_results_pluvius: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"pluvius.out\"))\n    )\n    infiltration_definitions_unpaved: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.inf\"))\n    )\n    run_debug_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sobek_3b.dbg\"))\n    )\n    unpaved_seepage: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.sep\"))\n    )\n    unpaved_initial_values_tables: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unpaved.tbl\"))\n    )\n    green_house_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"greenhse.3b\"))\n    )\n    green_house_roof_storage: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"greenhse.rf\"))\n    )\n    pluvius_sewage_entry: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"runoff.out\"))\n    )\n    input_variable_gauges_on_edge_nodes: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sbk_rtc.his\"))\n    )\n    input_salt_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"salt.3b\"))\n    )\n    input_crop_factors_open_water: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"crop_ow.prn\"))\n    )\n    restart_file_input: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"RSRR_IN\"))\n    )\n    restart_file_output: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"RSRR_OUT\"))\n    )\n    binary_file_input: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_input.bin\"))\n    )\n    sacramento_input: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sacrmnto.3b\"))\n    )\n    output_flow_rates_edge_nodes: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"aanvoer.abr\"))\n    )\n    output_salt_concentration_edge: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"saltbnd.out\"))\n    )\n    output_salt_exportation: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"salt.out\"))\n    )\n    greenhouse_silo_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"greenhse.sil\"))\n    )\n    open_water_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"openwate.3b\"))\n    )\n    open_water_seepage_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"openwate.sep\"))\n    )\n    open_water_tables_target_levels: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"openwate.tbl\"))\n    )\n    structure_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"struct3b.dat\"))\n    )\n    structure_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"struct3b.def\"))\n    )\n    controller_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"contr3b.def\"))\n    )\n    structure_tables: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"struct3b.tbl\"))\n    )\n    boundary_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"bound3b.3b\"))\n    )\n    boundary_tables: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"bound3b.tbl\"))\n    )\n    sobek_location_rtc: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sbk_loc.rtc\"))\n    )\n    wwtp_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"wwtp.3b\"))\n    )\n    wwtp_tables: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"wwtp.tbl\"))\n    )\n    industry_general: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"industry.3b\"))\n    )\n\n    # Mappix paths should not change and always hold the defined values.\n    _validate_mappix_paved_area_sewage_storage = _validator_mappix_value(\n        \"mappix_paved_area_sewage_storage\", _mappix_paved_area_sewage_storage_name\n    )\n    mappix_paved_area_sewage_storage: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_paved_area_sewage_storage_name)),\n        allow_mutation=False,\n    )\n\n    _validate_mappix_paved_area_flow_rates = _validator_mappix_value(\n        \"mappix_paved_area_flow_rates\", _mappix_paved_area_flow_rates_name\n    )\n    mappix_paved_area_flow_rates: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_paved_area_flow_rates_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_unpaved_area_flow_rates = _validator_mappix_value(\n        \"mappix_unpaved_area_flow_rates\", _mappix_unpaved_area_flow_rates_name\n    )\n    mappix_unpaved_area_flow_rates: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_unpaved_area_flow_rates_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_ground_water_levels = _validator_mappix_value(\n        \"mappix_ground_water_levels\", _mappix_ground_water_levels_name\n    )\n    mappix_ground_water_levels: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_ground_water_levels_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_green_house_bassins_storage = _validator_mappix_value(\n        \"mappix_green_house_bassins_storage\", _mappix_green_house_bassins_storage_name\n    )\n    mappix_green_house_bassins_storage: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_green_house_bassins_storage_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_green_house_bassins_results = _validator_mappix_value(\n        \"mappix_green_house_bassins_results\", _mappix_green_house_bassins_results_name\n    )\n    mappix_green_house_bassins_results: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_green_house_bassins_results_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_open_water_details = _validator_mappix_value(\n        \"mappix_open_water_details\", _mappix_open_water_details_name\n    )\n    mappix_open_water_details: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_open_water_details_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_exceedance_time_reference_levels = _validator_mappix_value(\n        \"mappix_exceedance_time_reference_levels\",\n        _mappix_exceedance_time_reference_levels_name,\n    )\n    mappix_exceedance_time_reference_levels: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_exceedance_time_reference_levels_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_flow_rates_over_structures = _validator_mappix_value(\n        \"mappix_flow_rates_over_structures\", _mappix_flow_rates_over_structures_name\n    )\n    mappix_flow_rates_over_structures: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_flow_rates_over_structures_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_flow_rates_to_edge = _validator_mappix_value(\n        \"mappix_flow_rates_to_edge\", _mappix_flow_rates_to_edge_name\n    )\n    mappix_flow_rates_to_edge: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_flow_rates_to_edge_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_pluvius_max_sewage_storage = _validator_mappix_value(\n        \"mappix_pluvius_max_sewage_storage\", _mappix_pluvius_max_sewage_storage_name\n    )\n    mappix_pluvius_max_sewage_storage: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_pluvius_max_sewage_storage_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_pluvius_max_flow_rates = _validator_mappix_value(\n        \"mappix_pluvius_max_flow_rates\", _mappix_pluvius_max_flow_rates_name\n    )\n    mappix_pluvius_max_flow_rates: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_pluvius_max_flow_rates_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_balance = _validator_mappix_value(\n        \"mappix_balance\", _mappix_balance_name\n    )\n    mappix_balance: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_balance_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_cumulative_balance = _validator_mappix_value(\n        \"mappix_cumulative_balance\", _mappix_cumulative_balance_name\n    )\n    mappix_cumulative_balance: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_cumulative_balance_name)),\n        allow_mutation=False,\n    )\n    _validate_mappix_salt_concentrations = _validator_mappix_value(\n        \"mappix_salt_concentrations\", _mappix_salt_concentrations_name\n    )\n    mappix_salt_concentrations: ImmutableDiskOnlyFileModel = Field(\n        ImmutableDiskOnlyFileModel(Path(_mappix_salt_concentrations_name)),\n        allow_mutation=False,\n    )\n\n    industry_tables: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"industry.tbl\"))\n    )\n    maalstop: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rtc_3b.his\"))\n    )\n    time_series_temperature: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"default.tmp\"))\n    )\n    time_series_runoff: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rnff.#\"))\n    )\n    discharges_totals_at_edge_nodes: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"bndfltot.his\"))\n    )\n    language_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sobek_3b.lng\"))\n    )\n    ow_volume: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"ow_vol.his\"))\n    )\n    ow_levels: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"ow_level.his\"))\n    )\n    balance_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_bal.out\"))\n    )\n    his_3B_area_length: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3bareas.his\"))\n    )\n    his_3B_structure_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3bstrdim.his\"))\n    )\n    his_rr_runoff: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rrrunoff.his\"))\n    )\n    his_sacramento: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sacrmnto.his\"))\n    )\n    his_rwzi: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"wwtpdt.his\"))\n    )\n    his_industry: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"industdt.his\"))\n    )\n    ctrl_ini: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"ctrl.ini\"))\n    )\n    root_capsim_input_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"root_sim.inp\"))\n    )\n    unsa_capsim_input_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"unsa_sim.inp\"))\n    )\n    capsim_message_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"capsim.msg\"))\n    )\n    capsim_debug_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"capsim.dbg\"))\n    )\n    restart_1_hour: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"restart1.out\"))\n    )\n    restart_12_hours: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"restart12.out\"))\n    )\n    rr_ready: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"RR-ready\"))\n    )\n    nwrw_areas: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"NwrwArea.His\"))\n    )\n    link_flows: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3blinks.his\"))\n    )\n    modflow_rr: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"modflow_rr.His\"))\n    )\n    rr_modflow: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rr_modflow.His\"))\n    )\n    rr_wlm_balance: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rr_wlmbal.His\"))\n    )\n    sacramento_ascii_output: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sacrmnto.out\"))\n    )\n    nwrw_input_dwa_table: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"pluvius.tbl\"))\n    )\n    rr_balance: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"rrbalans.his\"))\n    )\n    green_house_classes: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"KasKlasData.dat\"))\n    )\n    green_house_init: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"KasInitData.dat\"))\n    )\n    green_house_usage: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"KasGebrData.dat\"))\n    )\n    crop_factor: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"CropData.dat\"))\n    )\n    crop_ow: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"CropOWData.dat\"))\n    )\n    soil_data: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"SoilData.dat\"))\n    )\n    dio_config_ini_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"dioconfig.ini\"))\n    )\n    bui_file_for_continuous_calculation_series: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"NWRWCONT.#\"))\n    )\n    nwrw_output: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"NwrwSys.His\"))\n    )\n    rr_routing_link_definitions: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_rout.3b\"))\n    )\n    cell_input_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_cel.3b\"))\n    )\n    cell_output_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"3b_cel.his\"))\n    )\n    rr_simulate_log_file: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"sobek3b_progress.txt\"))\n    )\n    rtc_coupling_wq_salt: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"wqrtc.his\"))\n    )\n    rr_boundary_conditions_sobek3: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(Path(\"BoundaryConditions.bc\"))\n    )\n\n    rr_ascii_restart_openda: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(filepath=None)\n    )\n    lgsi_cachefile: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(filepath=None)\n    )\n    meteo_input_file_rainfall: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(filepath=None)\n    )\n    meteo_input_file_evaporation: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(filepath=None)\n    )\n    meteo_input_file_temperature: DiskOnlyFileModel = Field(\n        default_factory=lambda: DiskOnlyFileModel(filepath=None)\n    )\n\n    @classmethod\n    def property_keys(cls) -&gt; Iterable[str]:\n        # Skip first two elements corresponding with file_path and serializer_config introduced by the FileModel.\n        return list(cls.schema()[\"properties\"].keys())[2:]\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".fnm\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"rr\"\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable[[FilePath], Dict]:\n        return lambda path: read(cls.property_keys(), path)\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return write\n</code></pre>"},{"location":"reference/rr/rr/#general-layer","title":"General layer","text":""},{"location":"reference/rr/rr/#rainfall-file","title":"rainfall file","text":""},{"location":"reference/rr/rr/#hydrolib.core.rr.meteo.models.BuiModel","title":"<code>BuiModel</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Model that represents the file structure of a .bui file.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>class BuiModel(ParsableFileModel):\n    \"\"\"\n    Model that represents the file structure of a .bui file.\n    \"\"\"\n\n    default_dataset: int = 1  # Default value (always)\n    number_of_stations: int\n    name_of_stations: List[str]\n    number_of_events: int\n    seconds_per_timestep: int\n    precipitation_events: List[BuiPrecipitationEvent]\n\n    @classmethod\n    def _filename(cls):\n        return \"bui_file\"\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".bui\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return write_bui_file\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return BuiParser.parse\n\n    def get_station_events(self, station: str) -&gt; Dict[datetime, List[float]]:\n        \"\"\"\n        Returns all the events (start time and precipitations) related to a given station.\n\n        Args:\n            station (str): Name of the station to retrieve.\n\n        Raises:\n            ValueError: If the station name does not exist in the BuiModel.\n\n        Returns:\n            Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.\n        \"\"\"\n        if station not in self.name_of_stations:\n            raise ValueError(\"Station {} not found BuiModel.\".format(station))\n        station_idx = self.name_of_stations.index(station)\n        station_events = {}\n        for event in self.precipitation_events:\n            start_time, precipitations = event.get_station_precipitations(station_idx)\n            station_events[start_time] = precipitations\n        return station_events\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.meteo.models.BuiModel.get_station_events","title":"<code>get_station_events(station)</code>","text":"<p>Returns all the events (start time and precipitations) related to a given station.</p> <p>Parameters:</p> Name Type Description Default <code>station</code> <code>str</code> <p>Name of the station to retrieve.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the station name does not exist in the BuiModel.</p> <p>Returns:</p> Type Description <code>Dict[datetime, List[float]]</code> <p>Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>def get_station_events(self, station: str) -&gt; Dict[datetime, List[float]]:\n    \"\"\"\n    Returns all the events (start time and precipitations) related to a given station.\n\n    Args:\n        station (str): Name of the station to retrieve.\n\n    Raises:\n        ValueError: If the station name does not exist in the BuiModel.\n\n    Returns:\n        Dict[datetime, List[float]]: Dictionary with the start time and its precipitations.\n    \"\"\"\n    if station not in self.name_of_stations:\n        raise ValueError(\"Station {} not found BuiModel.\".format(station))\n    station_idx = self.name_of_stations.index(station)\n    station_events = {}\n    for event in self.precipitation_events:\n        start_time, precipitations = event.get_station_precipitations(station_idx)\n        station_events[start_time] = precipitations\n    return station_events\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.meteo.models.BuiPrecipitationEvent","title":"<code>BuiPrecipitationEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>class BuiPrecipitationEvent(BaseModel):\n    start_time: datetime\n    timeseries_length: timedelta\n    precipitation_per_timestep: List[List[float]]\n\n    def get_station_precipitations(\n        self, station_idx: int\n    ) -&gt; Tuple[datetime, List[float]]:\n        \"\"\"\n        Returns all the precipitations related to the given station index (column).\n\n        Args:\n            station_idx (int): Index of the column which values need to be retrieved.\n\n        Raises:\n            ValueError: If the station index does not exist.\n\n        Returns:\n            Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.\n        \"\"\"\n        number_of_stations = len(self.precipitation_per_timestep[0])\n        if station_idx &gt;= number_of_stations:\n            raise ValueError(\n                \"Station index not found, number of stations: {}\".format(\n                    number_of_stations\n                )\n            )\n        return (\n            self.start_time,\n            [\n                ts_precipitations[station_idx]\n                for ts_precipitations in self.precipitation_per_timestep\n            ],\n        )\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.meteo.models.BuiPrecipitationEvent.get_station_precipitations","title":"<code>get_station_precipitations(station_idx)</code>","text":"<p>Returns all the precipitations related to the given station index (column).</p> <p>Parameters:</p> Name Type Description Default <code>station_idx</code> <code>int</code> <p>Index of the column which values need to be retrieved.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the station index does not exist.</p> <p>Returns:</p> Type Description <code>Tuple[datetime, List[float]]</code> <p>Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.</p> Source code in <code>hydrolib/core/rr/meteo/models.py</code> <pre><code>def get_station_precipitations(\n    self, station_idx: int\n) -&gt; Tuple[datetime, List[float]]:\n    \"\"\"\n    Returns all the precipitations related to the given station index (column).\n\n    Args:\n        station_idx (int): Index of the column which values need to be retrieved.\n\n    Raises:\n        ValueError: If the station index does not exist.\n\n    Returns:\n        Tuple[datetime, List[float]]: Tuple with the start time and its precipitations.\n    \"\"\"\n    number_of_stations = len(self.precipitation_per_timestep[0])\n    if station_idx &gt;= number_of_stations:\n        raise ValueError(\n            \"Station index not found, number of stations: {}\".format(\n                number_of_stations\n            )\n        )\n    return (\n        self.start_time,\n        [\n            ts_precipitations[station_idx]\n            for ts_precipitations in self.precipitation_per_timestep\n        ],\n    )\n</code></pre>"},{"location":"reference/rr/rr/#topology-layer-topography-in-sobek-um","title":"Topology layer (\"Topography\" in SOBEK UM)","text":""},{"location":"reference/rr/rr/#hydrolib.core.rr.topology.models.nodetypes_netter_to_rr","title":"<code>nodetypes_netter_to_rr = {43: 1, 44: 2, 45: 3, 46: 4, -5: 5, 34: 6, 35: 6, 47: 6, 48: 8, 49: 9, 50: 10, 51: 11, 52: 12, 56: 14, 55: 15, 54: 16, -21: 21, 69: 23}</code>  <code>module-attribute</code>","text":"<p>Dictionary with <code>nt</code> mapped against the expected <code>mt</code>.</p> <p>Some model types <code>mt</code> do not have a related netter type; in that case the dict key is a dummy value of -."},{"location":"reference/rr/rr/#hydrolib.core.rr.topology.models.Link","title":"<code>Link</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a link from the topology link file.</p> Source code in <code>hydrolib/core/rr/topology/models.py</code> <pre><code>class Link(BaseModel):\n    \"\"\"Represents a link from the topology link file.\"\"\"\n\n    id: str = Field(alias=\"id\")\n    name: Optional[str] = Field(alias=\"nm\")\n    branchid: int = Field(alias=\"ri\")\n    modellinktype: int = Field(alias=\"mt\")\n    branchtype: int = Field(alias=\"bt\")\n    objectid: str = Field(alias=\"ObID\")\n    beginnode: str = Field(alias=\"bn\")\n    endnode: str = Field(alias=\"en\")\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\") or data.get(\"nm\")\n\n    def dict(self, *args, **kwargs):\n        kwargs[\"by_alias\"] = True\n        return super().dict(*args, **kwargs)\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.topology.models.LinkFile","title":"<code>LinkFile</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Represents the file with the RR link topology data.</p> Source code in <code>hydrolib/core/rr/topology/models.py</code> <pre><code>class LinkFile(ParsableFileModel):\n    \"\"\"Represents the file with the RR link topology data.\"\"\"\n\n    _parser = NetworkTopologyFileParser(enclosing_tag=\"brch\")\n    link: List[Link] = Field([], alias=\"brch\")\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".tp\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"3b_link\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return LinkFileSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return cls._parser.parse\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.topology.models.Node","title":"<code>Node</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a node from the topology node file.</p> Source code in <code>hydrolib/core/rr/topology/models.py</code> <pre><code>class Node(BaseModel):\n    \"\"\"Represents a node from the topology node file.\"\"\"\n\n    id: str = Field(alias=\"id\")\n    name: Optional[str] = Field(alias=\"nm\")\n    branchid: int = Field(alias=\"ri\")\n    modelnodetype: int = Field(alias=\"mt\")\n    netternodetype: int = Field(alias=\"nt\")\n    objectid: str = Field(alias=\"ObID\")\n    xposition: float = Field(alias=\"px\")\n    yposition: float = Field(alias=\"py\")\n\n    def _get_identifier(self, data: dict) -&gt; Optional[str]:\n        return data.get(\"id\") or data.get(\"nm\")\n\n    def dict(self, *args, **kwargs):\n        kwargs[\"by_alias\"] = True\n        return super().dict(*args, **kwargs)\n\n    @root_validator()\n    @classmethod\n    def _validate_node_type(cls, values):\n\n        cls._raise_if_invalid_type(\n            values,\n            \"modelnodetype\",\n            set(nodetypes_netter_to_rr.values()),\n            \"model node type (mt)\",\n        )\n\n        modelnodetype = values.get(\"modelnodetype\")\n\n        # modelnodetype=6 (\"boundary node\") is a special case that allows various netter nodetypes,\n        # so therefore it always validates well.\n        if modelnodetype == 6:\n            return values\n\n        cls._raise_if_invalid_type(\n            values,\n            \"netternodetype\",\n            set(nodetypes_netter_to_rr.keys()),\n            \"netter node type (nt)\",\n        )\n\n        netternodetype = values.get(\"netternodetype\")\n        modelnodetype_expected = nodetypes_netter_to_rr[netternodetype]\n\n        if modelnodetype != modelnodetype_expected:\n            raise ValueError(\n                f\"{modelnodetype} is not a supported model node type (mt) when netter node type (nt) is {netternodetype}. Supported value: {modelnodetype_expected}.\"\n            )\n\n        return values\n\n    @classmethod\n    def _raise_if_invalid_type(\n        cls, values, field_name: str, supported_values: set, description: str\n    ):\n        \"\"\"Validates the node type for the provided `field_name`.\n        The specified node type should contain a supported value,\n        otherwise a `ValueError` is raised.\n\n\n        Args:\n            values ([type]): Dictionary with values that are used to create this `Node`.\n            field_name (str): Field name of the node type to validate.\n            supported_values (set): Set of all the supported values for this node type.\n            description (str): Description of this node type that will be readable for the user.\n\n        Raises:\n            ValueError: Thrown when `supported_values` does node contain the node type.\n        \"\"\"\n        field_value = values.get(field_name)\n\n        if field_value not in supported_values:\n            str_supported_values = \", \".join([str(t) for t in supported_values])\n            raise ValueError(\n                f\"{field_value} is not a supported {description}. Supported values: {str_supported_values}.\"\n            )\n</code></pre>"},{"location":"reference/rr/rr/#hydrolib.core.rr.topology.models.NodeFile","title":"<code>NodeFile</code>","text":"<p>               Bases: <code>ParsableFileModel</code></p> <p>Represents the file with the RR node topology data.</p> Source code in <code>hydrolib/core/rr/topology/models.py</code> <pre><code>class NodeFile(ParsableFileModel):\n    \"\"\"Represents the file with the RR node topology data.\"\"\"\n\n    _parser = NetworkTopologyFileParser(enclosing_tag=\"node\")\n    node: List[Node] = Field([], alias=\"node\")\n\n    @classmethod\n    def _ext(cls) -&gt; str:\n        return \".tp\"\n\n    @classmethod\n    def _filename(cls) -&gt; str:\n        return \"3b_nod\"\n\n    @classmethod\n    def _get_serializer(\n        cls,\n    ) -&gt; Callable[[Path, Dict, SerializerConfig, ModelSaveSettings], None]:\n        return NodeFileSerializer.serialize\n\n    @classmethod\n    def _get_parser(cls) -&gt; Callable:\n        return cls._parser.parse\n</code></pre>"},{"location":"reference/rr/rr/#other-input-layers-foreseen-in-future-releases","title":"(Other input layers foreseen in future releases)","text":""},{"location":"topics/dhydro_support/","title":"List of D-HYDRO functionalities and support in HYDROLIB-core","text":"<p>Below is a list of D-HYDRO functionalities, grouped by kernel, and the current status of support inside hydrolib-core.</p>"},{"location":"topics/dhydro_support/#symbology","title":"Symbology","text":"<ul> <li> : All toplevel file contents can be read/written.</li> <li> : Partial support, see notes.</li> <li> : No support yet, but may come in future.</li> <li> : No support foreseen. Out of scope.</li> </ul> <p>* indicates a scheduled release that is not out yet.</p>"},{"location":"topics/dhydro_support/#dimr","title":"DIMR","text":"Functionality Read Write Supported since API ref Notes DIMR <code>dimr_config.xml</code> 0.2.0 DIMR Critical bugfix for #127. FM component 0.1.1 FMComponent RR component 0.1.1 RRComponent RTC component parallel MPI models 0.1.1 Component coupler elements 0.1.1 Coupler"},{"location":"topics/dhydro_support/#fm","title":"FM","text":"Functionality Read Write Supported since API ref Notes FM MDU file 0.1.1 FMModel Network file <code>_net.nc</code> 0.1.1 Mesh2d Structure file 0.1.1 StructureModel * Weir 0.1.1 Weir * Universal weir 0.1.1 UniversalWeir * Culvert 0.1.1 Culvert * Long culvert * Bridge 0.1.5 Bridge * Pump 0.1.1 Pump * Orifice 0.1.1 Orifice * Gate * General structure 0.2.0 GeneralStructure * Dambreak 0.1.5 Dambreak * Compound structure 0.1.1 Compound External forcings file External forcings file (old) 0.5.0 ExtOldModel External forcings file (new) 0.1.1 ExtModel * Boundary 0.1.1 Boundary * Lateral 0.1.1 Lateral * Meteo 0.5.0 Meteo .bc file 0.1.1 ForcingModel * timeSeries 0.1.1 TimeSeries * harmonic (-Correction) 0.1.1 Harmonic * astronomic (-Correction) 0.1.1 Astronomic * t3D 0.3.1 T3D * QHTable 0.1.1 QHTable * constant 0.1.1 Constant * vector quantities 0.3.1 VectorQuantityUnitPairs .tim file 0.5.0 TimModel Cross section files Moved to io.crosssections in 0.2.0 Cross section definition file 0.1.1 CrossDefModel * Circle 0.1.5 CircleCrsDef * Rectangle 0.1.5 RectangleCrsDef * Tabulated river 0.1.5 ZWRiverCrsDef * ZW (tabulated) 0.1.5 ZWCrsDef * XYZ 0.1.5 XYZCrsDef * YZ 0.1.5 YZCrsDef Cross section location file 0.1.1 CrossLocModel 1D roughness file 0.2.0 FrictionModel Storage node file 0.2.0 StorageNodeModel Spatial data files Initial and parameter field file 0.2.0 IniFieldModel 1D field INI files 0.2.0 OneDFieldModel Sample file 0.1.1 XYZModel Output Observation station file (.xyn) 0.5.0 XYNModel Observation station file (.ini) 0.3.0 ObservationPointModel Observation crosssection file (.pli) 0.5.0 PolyFile Observation crosssection file (.ini) 0.3.1 ObservationCrossSectionModel History file <code>_his.nc</code> Map file (old) Map file (UGRID) <code>_map.nc</code> Fourier input file Fourier output file <code>_fou.nc</code> via map file reader Class map file via map file reader"},{"location":"topics/dhydro_support/#rr","title":"RR","text":"Functionality Read Write Supported since API ref Notes RR Main sobek_3b.fnm 0.1.5 RainfallRunoffModel Used to be in hydrolib.core.io.fnm.models before 0.3.0 Rainfall .bui file 0.1.5 BuiModel Used to be in hydrolib.core.io.bui.models before 0.3.0 Topology layer Node file 3b_node.tp 0.2.0 NodeFile Link file 3b_link.tp 0.2.0 LinkFile <p>(Table source available on: https://github.com/Deltares/HYDROLIB-core/blob/main/docs/topics/dhydro_support_hydrolib-core.xlsx)</p>"},{"location":"topics/loadsave/","title":"Loading and Saving within HYDROLIB-core","text":"<p>This article describes the architectural choices of saving and loading, if you are looking for how to save, please refer to the tutorials.</p> <p>The motivation of HYDROLIB-core is to provide a python library to interact with the D-HYDRO suite files. These files generally form a sort of tree structure, with a single root model (generally a DIMR or an FM model), and different layers of child models  which are referenced in their parent models. These child models can either be  referenced relative to their parent models or with absolute file paths. This leads to potentially complex model structures, which need to be read and written correctly  by HYDROLIB-core without any changes to either the contents or the structure.</p> <p>This article discusses the architectural choices made when designing the read and write  capabalities, as well as the considerations that should be taken when implementing your own models. As such we will discuss the following topics:</p> <ul> <li>Motivation: HYDROLIB-core should not adjust files when reading and writing</li> <li>Structure of Models</li> <li>Loading Models: Resolving the tree structure with the <code>FileLoadContext</code></li> <li>Saving Models: Traversing the model tree with the <code>ModelTreeTraverser</code></li> <li>Extensions: Caveats to ensure your model plays nice with HYDROLIB-core</li> </ul>"},{"location":"topics/loadsave/#motivation-hydrolib-core-should-not-adjust-files-when-reading-and-writing","title":"Motivation: HYDROLIB-core should not adjust files when reading and writing","text":"<p>When implementing the model read and write behaviour of HYDROLIB-core, the main  design choice is to ensure models are read and written as is. Properties should not be adjusted nor dropped when reading or writing (unless there is a very  clear reason to do so). This behaviour should extend to the way the tree structure  of the models is handled. Therefor, file paths, stored in the <code>filepath</code> property, which are not explicitly set to be absolute are kept relative and resolved while reading or writing. </p> <p>This has the drawback that the file location of a child model is not explicitly defined without the root model it is part of. Within the current implementation, child models have no reference to their parent. This simplifies the bookkeeping when building models in memory, however it also means that it is not possible  to resolve the absolute path of a child model without also providing the root model it is part of. This behaviour is further documented in the following sections. In order to alleviate this shortcoming, each file model internally keeps track of its  resolved save location, which can be explicitly synchronized with the file path of the root model, if this is required.</p>"},{"location":"topics/loadsave/#loading-models-resolving-the-tree-structure-with-the-fileloadcontext","title":"Loading Models: Resolving the tree structure with the <code>FileLoadContext</code>","text":"<p>In order to load a model from disk, we need to call the appropriate constructor with a file path to an existing model file. The constructor will then ensure the model, and  its child models are read. Multiple references to the same sub-model will reference the same sub-model after reading.</p>"},{"location":"topics/loadsave/#current-behaviour-root-models-are-read-through-the-constructor-while-caching-sub-models","title":"Current Behaviour: Root models are read through the constructor while caching sub-models","text":"<p>Currently, a model is loaded by calling the constructor with the filepath of the input file. HYDROLIB-core will then load the model as well as any children. Every child will only be read once, multiple references to the same child in the input files will result in references to the same child model in memory. When reading the model and its  children, the file structure will be kept intact. Any models with absolute paths will still reference the same absolute paths, while models with relative paths will also  have the same relative paths as within the original file. </p>"},{"location":"topics/loadsave/#architectural-choices-the-tree-structure-is-resolved-with-the-fileloadcontext","title":"Architectural Choices: The tree structure is resolved with the <code>FileLoadContext</code>","text":"<p>In order to properly resolve the model tree, we need to be able to keep track of the current parent of a model, as well as a way to store and retrieve read models. Both of these tasks are handled by the <code>FileLoadContext</code>. The context can be used to resolve relative paths by keeping track of the current parent folder of a model. It also  provides a cache for read models, which ensures files are not read more than once. </p> <p>A single <code>FileLoadContext</code> is created at the start of the constructor of the root model as a context variable. Subsequent child models can then reference this  <code>FileLoadContext</code>, by retrieving this same <code>FileLoadContext</code>. A convenience context manager is provided through the <code>file_load_context()</code> method in the  <code>basemodel.py</code>.</p> <p>The constructor of the filepath performs the following tasks:</p> <ol> <li>Request the context.</li> <li>Register itself within the model cache with its file path.</li> <li>Store the absolute file path anchor (i.e. the absolute path to its parent)</li> <li>Resolve its absolute path, to read from.</li> <li>Update the current parent directory.</li> <li>Read all the model data including sub-models.</li> <li>Remove itself as a parent directory.</li> </ol> <p>Because the constructor recursively reads child models, and the data is only read after the current parent directory has been updated, the child models will correctly resolve their resolve their relative paths. </p> <p>The <code>FileModel</code> further overrides its <code>__new__</code>. During the <code>__new__</code> call, it will  verify if the current (resolved) filepath which is being read, has already been  defined in the file model cache. If it is, then this instance will be returned,  instead of creating a new instance through the <code>__init__</code>. This ensures no duplicates are created.</p>"},{"location":"topics/loadsave/#saving-models-traversing-the-model-tree-with-the-modeltreetraverser","title":"Saving Models: Traversing the model tree with the <code>ModelTreeTraverser</code>","text":"<p>Currently, the save function on the <code>FileModel</code> offers the following options:</p> <ul> <li><code>filepath</code>:  Allows the user to set a new file path. If none is defined, the current file path will be used.</li> <li><code>recurse</code>: A flag indicating whether only this model needs to be saved, or also it child models.</li> </ul> <p>As such it is possible to store both individual models, as well as model trees. </p> <p>When saving a model, it will be stored at the <code>save_location</code>. If <code>recurse</code> is true, then the child model will be evaluated with regards to the root model. This may lead to some  inconsistencies, especially with the deprecated <code>pathsRelativeToParent</code> set to false in  the FlowFM model. As such care needs to be taken by the user.</p> <p>The <code>save_location</code> of relative child models will NOT be automatically updated when the parent <code>filepath</code> is updated. If such an update is required the user is expected to call  <code>synchronize_filepaths</code> on the parent model.</p>"},{"location":"topics/loadsave/#modeltreetraverser","title":"<code>ModelTreeTraverser</code>","text":"<p>For writing the models to file, as well as other operations, we need to be able to traverse the model tree. In order to do so, the <code>ModelTreeTraverser</code> is provided. It can be configured with the following 4 functions:</p> <ul> <li>should_traverse: Evaluates whether to traverse to the provided BaseModel.</li> <li>should_execute: Determines whether the traverse functions are executed for the given model.</li> <li>pre_traverse_func: Function called with the current model before traversal into the children, i.e. top-down behaviour.</li> <li>post_traverse_func: Function called with the current model after traversal into the children, i.e. bottom-up behaviour.</li> </ul> <p>All functions receive an accumulator, which flows through the program and is finally returned to the caller. This can be used to store state in between calls to traverse or to build an output value while traversing the model tree.</p>"},{"location":"topics/loadsave/#saving-a-complete-model-tree","title":"Saving a complete model tree","text":"<p>In order to store a model as well as its children, we need to perform the following  tasks.</p> <ol> <li>Ensure the file paths of both the model and all of its children are set.</li> <li>Save the the models and its children recursively.</li> </ol> <p>We need to ensure all file paths are set before we store the models, in order to  resolve the actual file paths during the save operation. As such these two operations are done in separate steps. </p> <p>Both of these tasks make use of the <code>ModelTreeTraverser</code>. It will traverse through any immediate file link model, and execute the pre and post functions for any file link.  In case of task 1, it will generate the file paths if none is set. The save traversal uses the pre and post traverse functions to maintain the parent path used to resolve the relative file paths of any models. The post function is further used to actually write the model to file through a dedicated <code>_save</code> function.</p>"},{"location":"topics/loadsave/#saving-a-sub-tree-relative-to-some-model-tree","title":"Saving a sub-tree relative to some model tree","text":"<p>Saving a sub tree is in principle the same as calling <code>save</code> on the root model, but only a child model. One thing that should be taken into account is, the save is called relative to the current value in <code>save_location</code>. As such if changes were made to the <code>filepath</code> of a parent model, <code>synchronize_filepaths</code> should be called on the root model.</p>"},{"location":"topics/loadsave/#saving-individual-models-without-their-children","title":"Saving individual models without their children","text":"<p>An individual model can be saved with the <code>save</code> and <code>recurse</code> set to <code>False</code> (i.e.  the default behaviour). When this is done, only the model on which <code>save</code> was called will be written to disk at the current <code>save_location</code>.</p>"},{"location":"topics/loadsave/#exporting-save-as","title":"Exporting / Save as","text":"<p>Exporting is currently not implemented, but will be as part of issue #170.</p>"},{"location":"topics/loadsave/#inheritance-hierachy-of-filemodels-serializablefilemodels-and-diskonlyfilemodels","title":"Inheritance hierachy of FileModels: SerializableFileModels and DiskOnlyFileModels","text":"<p>The <code>FileModel</code> is the abstract base class for any file model. It provides the logic  to manage the file paths as well as the common logic to load and save models. In order to do so, it requires child classes to implement a <code>_save</code> and a <code>_load</code> method. Two child classes have been defined which extend the <code>FileModel</code>:</p> <ul> <li><code>ParsableFileModel</code>: Abstract class which defines a <code>FileModel</code> with a      serializer and parser. This is the base model used by most in-memory models.</li> <li><code>DiskOnlyFileModel</code>: A generic file model which does not read data into memory     but does copy the underlying file when a parent <code>FileModel</code> is saved recursively.</li> </ul>"},{"location":"topics/loadsave/#parsablefilemodel","title":"<code>ParsableFileModel</code>","text":"<p>The <code>ParsableFileModel</code> defines an abstract base class for in-memory models, it does so by requiring child classes to define a parser, to read input files, and a serializer, to write the data again. This forms the basis for most of the in-memory file models.</p>"},{"location":"topics/loadsave/#diskonlyfilemodel","title":"<code>DiskOnlyFileModel</code>","text":"<p>The <code>DiskOnlyFileModel</code> provides a file model implementation for files which do not have a  representation in <code>HYDROLIB.Core</code> (yet). The <code>DiskOnlyFileModel</code> ensures the underlying  file, specified with the <code>filepath</code> of the <code>FileModel</code>, is copied when a parent model is saved recursively. It does so by maintaining an internal source file path, which is initialized at construction of the <code>DiskOnlyFileModel</code>. When a <code>DiskOnlyFileModel</code> is saved, the underlying file is copied from this internal source file path to the new target path. If the file at the source file model does not exist, or the target path is invalid, no file is copied. Lastly, regardless of whether a file was copied, the internal source file path is updated.</p>"},{"location":"topics/loadsave/#extensions-caveats-to-ensure-your-model-plays-nice-with-hydrolib-core","title":"Extensions: Caveats to ensure your model plays nice with HYDROLIB-core","text":"<p>In the most common case, all of the file reading and writing is handled in the <code>FileModel</code> as such, just inheriting from the <code>FileModel</code> and providing the required parser and  setting the <code>_parser</code> and <code>_serializer</code> will be enough to ensure your model works as expected. There might be however some exceptions to your model that require additional configuration. The file model provides several hooks for this:</p> <p>For loading: </p> <ul> <li><code>_post_init_load</code>: function called after a model is initialised but before the current <code>FileLoadContext</code> is changed. This allows the user to put any actions here which require a <code>FileLoadContext</code>. Examples of this can be found in the <code>DIMR</code> and <code>NetworkModel</code> classes.</li> <li>Overwrite <code>__init__</code>: We can overwrite the <code>__init__</code> of a child the <code>FileModel</code> however some care needs to be taken in this case. In particular the <code>__super__</code> needs to be called in order to ensure the model is loaded appropriately. Furthermore, if the <code>FileLoadContext</code> is required within the <code>__init__</code>, the <code>file_load_context</code> should be called before <code>__super__</code>:</li> </ul> <pre><code>def __init__(self, ...):\n    with file_load_context() as context:\n        __super__().__init__()\n        ...\n        # your code using the context\n        ...\n</code></pre> <p>For saving:</p> <ul> <li><code>_save</code>: provides the save functionality called by the recursive saving of models. Overwriting this will allow you complete control over how the model is saved. An example of this can be found in the <code>NetworkFile</code>.</li> <li><code>_serialize</code>: provides the method to serialize your model. This can be overwritten in case a more specialised serialization is required, for example as done in <code>IniBasedModel</code> children.</li> <li><code>self._resolved_filepath</code>: will provide you with a resolved absolute version of the <code>filepath</code>. This only works in the context of <code>_save</code> and <code>_serialize</code>, as it relies on the context being started in the <code>save</code> method.</li> </ul>"},{"location":"topics/principles/","title":"First principles","text":"<p>hydrolib-core is structured around the input and output files (I/O) of the DHYDRO suite.</p>"},{"location":"topics/principles/#inheritancefile-handling","title":"Inheritance/file handling","text":"<p>Model setups often consist of different files, many implicitly linked to each other. HYDROLIB makes these links explicit, by recursively loading all child configuration files.</p> <p>For example, when parsing a DIMR file, one could happen upon a reference to an MDU file, which contain references to other files, such as cross sections, etc.</p> <pre><code>&gt;&gt;&gt; dimr = DIMR(filepath=Path(test_data_dir / \"dimr_config.xml\"))\n</code></pre> <p>You can see this tree structure if you call <code>show_tree</code>.</p> <pre><code>&gt;&gt;&gt; dimr.show_tree()\n  DIMR represented by dimr_config.xml.\n    RRComponent\n    FMComponent\n     \u221f FMModel represented by FlowFM.mdu.\n       \u221f Geometry\n         \u221f StructureModel represented by structures.ini.\n         \u221f CrossDefModel represented by crsdef.ini.\n         \u221f CrossLocModel represented by crsloc.ini.\n         \u221f FrictionModel represented by roughness-Main.ini.\n         \u221f FrictionModel represented by roughness-Sewer1.ini.\n         \u221f FrictionModel represented by roughness-Sewer2.ini.\n       \u221f ExternalForcing\n         \u221f ExtModel represented by FlowFM_bnd.ext.\n           \u221f Boundary\n             \u221f ForcingModel represented by FlowFM_boundaryconditions1d.bc.\n           \u221f Boundary\n             \u221f ForcingModel represented by FlowFM_boundaryconditions1d.bc.\n           \u221f Boundary\n             \u221f ForcingModel represented by FlowFM_boundaryconditions1d.bc.\n</code></pre>"},{"location":"topics/principles/#program-flow-while-recursively-creating-filemodels","title":"Program flow while recursively creating FileModels","text":""},{"location":"topics/principles/#in-short","title":"In short:","text":"<ul> <li>The file resolver and the model cache are stored in context variable <code>context_file_loading</code>, such that referenced files can be found.</li> <li>During loading, the parsed data from files are cached in the <code>FileLoadContext</code> to ensure multiple references to the same model will not result in duplicate parsing and instances.</li> <li>Pydantic first calls the <code>FileModel.validate</code> and then the initializer (<code>FileModel.__new__</code> and <code>FileModel.__init__</code>).</li> </ul>"},{"location":"topics/principles/#in-detail","title":"In detail:","text":"<p>User initializes a new root FileModel from file:</p> <ol> <li><code>FileModel.__new__(cls, filepath: str/Path)</code><ul> <li>Returns the result of the default <code>__new__</code> function</li> </ul> </li> <li><code>FileModel.__init__(self, filepath: str/Path)</code><ul> <li><code>self</code> holds the FileModel instance that was returned in step 1.  </li> <li><code>filepath</code> is holds the file path to the root file.</li> <li>Registers this model in the <code>FileLoadContext</code> with the file path.</li> <li>Resolves the absolute path to this model.</li> <li>Adds the folder of this model to the file resolver, such that the children can be resolved as well.</li> <li>Loads the data (<code>dict</code>) from the file.</li> <li>Initialize <code>self</code> with the data.</li> <li>Pydantic tries to convert the data to objects, a.o. sub FileModels:</li> </ul> </li> <li><code>FileModel.validate(value: str)</code><ul> <li><code>value</code> holds a relative or absolute file path to the referenced file.</li> <li>If <code>value</code> is not an absolute file path, resolves the absolute path by using the <code>FileLoadContext</code> stored in the <code>context_file_loading</code>, previously set in step 2.</li> <li>Calls <code>super().validate(value)</code> with the file path stored in <code>value</code>.</li> <li>Pydantic create a new FileModel with the data:</li> </ul> </li> <li><code>FileModel.__new__(cls, filepath: str)</code><ul> <li><code>filepath</code> holds the file path.</li> <li>If <code>FileModel._file_models_cache</code> already contains a FileModel instance with this <code>filepath</code>, returns the cached instance,<ul> <li>Otherwise, returns the result of the default <code>__new__</code> function.</li> </ul> </li> </ul> </li> <li>Repeat steps 2-4</li> </ol>"},{"location":"topics/principles/#parsing-and-serializing-inibasedmodels","title":"Parsing and serializing <code>INIBasedModels</code>","text":"<p>Parsing an INI file should be case-insensitive. To achieve this, the parsable field names of each <code>INIBasedModel</code> should be equal to the expected key in the file in lower case. </p> <p>Some property values are explicitly made case-insensitive for parsing as well. This applies to enum values and values that represent a specific type of <code>INIBasedModel</code>, such as the type property of a structure. To support this, custom validators are placed to compare the given value with the available known values. Structures are initialized based on the value in the <code>type</code> field. The value of this field of each subclass of a <code>Structure</code> is compared to the input and the subclass with the corresponding type is initialized. </p> <p>The serialization of an <code>INIBasedModel</code> to an INI file should respect certain casing rules (overriding the casing used by the user): - Property keys need to be \"lowerCamelCase\" - Section headers need to be \"UpperCamelCase\"</p> <p>To achieve this, each serializable field in a <code>INIBasedModel</code> has an alias. This alias will be written as property key to file. Each <code>INIBasedModel</code> that represents an INI section, has a field <code>_header</code>. The default value of this field will be written to file. Enum values and the values that represent a specific type of <code>INIBasedModel</code> will be serialized to file by how they are defined.</p>"},{"location":"topics/pydantic/","title":"Pydantic","text":""},{"location":"topics/pydantic/#pydantic-override","title":"Pydantic override","text":"<p>We love using Pydantic , but we need have multiple overrides in place to enable specific functionality. This document tries to document these instances, as they are in essence exceptions to an otherwise well understood and documented architecture.</p>"},{"location":"topics/pydantic/#basemodel-__init__-override","title":"BaseModel <code>__init__</code> override","text":"<p>We override de <code>__init__</code> method to catch all validation errors and reissue them with an better error message.</p>"},{"location":"topics/pydantic/#filemodel-override","title":"FileModel override","text":"<p>We override both <code>__new__</code> and <code>__init__</code> of the <code>FileModel</code> to cache models from disk. The <code>FileModel</code> utilises the <code>FileLoadContext</code> to resolve relative paths and to retrieve models previously read as part of the loading of a root model. </p> <p>Specifically we also use it to load a filepath from disk.</p> <p>This mostly happens in <code>validate</code>, a Pydantic override, to make sure that if we initialize with a single unnamed argument (Pydantic only accepts keyword arguments) we try to parse it as a filepath.</p>"},{"location":"topics/pydantic/#forcingbase-structure-and-crosssectiondefinition-validate-override","title":"ForcingBase, Structure and CrossSectionDefinition <code>validate</code> override","text":"<p>Validate is overriden to try to initialize the correct subclass of ForcingBase and CrossSectionDefinition, as discriminated unions do not work yet in Pydantic. I.e. if you specify Union{A, B} and A and B have clearly defined Literals it still can't choose whether to create A or B. The PR to fix this hasn't been merged yet.</p> <p> The code is duplicated in three places.</p>"},{"location":"topics/pydantic/#inibasedmodel-validate-override","title":"INIBasedModel <code>validate</code> override","text":"<p>In INIBasedModel we override validate to make sure we can flatten any <code>Section</code> input coming from the parser.</p> <p> Couldn't this be done in the parser?</p>"},{"location":"topics/pydantic/#structure-root-validator-explicitely-checks-subclass","title":"Structure Root validator explicitely checks subclass","text":"<p>Because the validation behaviour is different for <code>Compound</code>, <code>Dambreak</code> etc. We might want to split these things once a new Pydantic release has been made that allows a root_validator to be overriden.</p>"},{"location":"tutorials/dataframe_handling/","title":"Dataframe handling","text":"<p>We can use <code>DataFrame</code>s from pandas together with hydrolib-core.</p> <p>Note that this functionality can only work on files that are in essence tables and are represented by a <code>List</code> of objects in hydrolib-core.</p> <p>Examples of such <code>ParsableFileModel</code>s with their <code>List</code> fields are: - ForcingModel.forcing - CrossDefModel.definition - CrossLocModel.crosssection - ExtModel.boundary - ExtModel.lateral</p> <p>Say we load in a .bc file and want the resulting forcing in a dataframe.</p> <pre><code>from hydrolib.core.dflowfm.bc.models import ForcingModel\n\nfilepath = (\n    \"tests/data/input/e02/f101_1D-boundaries/c01_steady-state-flow/BoundaryConditions.bc\"\n)\nm = ForcingModel(filepath)\nm.forcing\n\n[Constant(comments=None, datablock=[[2.5]], name='T1_Dwn_Bnd', function='constant', quantityunitpair=[QuantityUnitPair(quantity='waterlevelbnd', unit='m')], offset=0.0, factor=1.0),\n Constant(comments=None, datablock=[[100.0]], name='T1_Up_Bnd', function='constant', quantityunitpair=[QuantityUnitPair(quantity='dischargebnd', unit='m\u00b3/s')], offset=0.0, factor=1.0),\n Constant(comments=None, datablock=[[2.5]], name='T2_Dwn_Bnd', function='constant', quantityunitpair=[QuantityUnitPair(quantity='waterlevelbnd', unit='m')], offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[0.0, 0.0], [1800.0, 100.0], [4320.0, 100.0]], name='T2_Up_Bnd', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='dischargebnd', unit='m\u00b3/s')], timeinterpolation='linear', offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[0.0, 0.0], [1800.0, 2.5], [4320.0, 2.5]], name='T3_Dwn_Bnd', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='waterlevelbnd', unit='m')], timeinterpolation='linear', offset=0.0, factor=1.0),\n Constant(comments=None, datablock=[[100.0]], name='T3_Up_Bnd', function='constant', quantityunitpair=[QuantityUnitPair(quantity='dischargebnd', unit='m\u00b3/s')], offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[0.0, 0.0], [1800.0, 100.0], [4320.0, 100.0]], name='T4_Up_Bnd', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='dischargebnd', unit='m\u00b3/s')], timeinterpolation='linear', offset=0.0, factor=1.0),\n QHTable(comments=None, datablock=[[50.0, 1.25], [100.0, 2.5], [150.0, 3.75]], name='T4_Dwn_Bnd', function='qhtable', quantityunitpair=[QuantityUnitPair(quantity='qhbnd discharge', unit='m\u00b3/s'), QuantityUnitPair(quantity='qhbnd waterlevel', unit='m')]),\n TimeSeries(comments=None, datablock=[[-2629440.0, 0.0]], name='model_wide', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='wind_speed', unit='m/s')], timeinterpolation='linear', offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[-2629440.0, 0.0]], name='model_wide', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='wind_from_direction', unit='degree')], timeinterpolation='linear', offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[-2629440.0, 0.0]], name='model_wide', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='air_temperature', unit='degrees C')], timeinterpolation='linear', offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[-2629440.0, 0.0]], name='model_wide', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='humidity', unit='percentage')], timeinterpolation='linear', offset=0.0, factor=1.0),\n TimeSeries(comments=None, datablock=[[-2629440.0, 0.0]], name='model_wide', function='timeseries', quantityunitpair=[QuantityUnitPair(quantity='time', unit='minutes since 2015-01-01 00:00:00'), QuantityUnitPair(quantity='cloudiness', unit='percentage')], timeinterpolation='linear', offset=0.0, factor=1.0)]\n</code></pre> <p>We now have a list of forcings that we can convert into a DataFrame. <pre><code>import pandas as pd\ndf = pd.DataFrame([f.__dict__ for f in m.forcing])\n\n   comments                                       datablock        name    function  ... offset factor  _header  timeinterpolation\n0      None                                         [[2.5]]  T1_Dwn_Bnd    constant  ...    0.0    1.0  forcing             linear\n1      None                                       [[100.0]]   T1_Up_Bnd    constant  ...    0.0    1.0  forcing             linear\n2      None                                         [[2.5]]  T2_Dwn_Bnd    constant  ...    0.0    1.0  forcing             linear\n3      None  [[0.0, 0.0], [1800.0, 100.0], [4320.0, 100.0]]   T2_Up_Bnd  timeseries  ...    0.0    1.0  forcing             linear\n4      None      [[0.0, 0.0], [1800.0, 2.5], [4320.0, 2.5]]  T3_Dwn_Bnd  timeseries  ...    0.0    1.0  forcing             linear\n5      None                                       [[100.0]]   T3_Up_Bnd    constant  ...    0.0    1.0  forcing             linear\n6      None  [[0.0, 0.0], [1800.0, 100.0], [4320.0, 100.0]]   T4_Up_Bnd  timeseries  ...    0.0    1.0  forcing             linear\n7      None     [[50.0, 1.25], [100.0, 2.5], [150.0, 3.75]]  T4_Dwn_Bnd     qhtable  ...    NaN    NaN  forcing                NaN\n8      None                             [[-2629440.0, 0.0]]  model_wide  timeseries  ...    0.0    1.0  forcing             linear\n9      None                             [[-2629440.0, 0.0]]  model_wide  timeseries  ...    0.0    1.0  forcing             linear\n10     None                             [[-2629440.0, 0.0]]  model_wide  timeseries  ...    0.0    1.0  forcing             linear\n11     None                             [[-2629440.0, 0.0]]  model_wide  timeseries  ...    0.0    1.0  forcing             linear\n12     None                             [[-2629440.0, 0.0]]  model_wide  timeseries  ...    0.0    1.0  forcing             linear\n\n[13 rows x 10 columns]\n</code></pre> Note that because there are several types of forcings, with different fields, some values have become NaN.</p> <p>We can also convert this DataFrame back to a <code>ForcingModel</code>. <pre><code>fm = ForcingModel(forcing=df.to_dict('records'))\nfm.forcing == m.forcing\n\nTrue\n</code></pre></p>"},{"location":"tutorials/loading_and_saving_a_model/","title":"Loading and saving a model","text":"<p>In this article we will look at loading and saving a model. First we will load a model, and store it in a new location. Then make adjustments to one of the sub models, and  store the model in place. Lastly, we will look at some caveats of saving and loading models.</p> <p>If you do not have a DIMR model, you can use the example model in the test data.</p>"},{"location":"tutorials/loading_and_saving_a_model/#load-the-model","title":"Load the model","text":"<p>We can load a model by constructing a new DIMR model by calling the <code>DIMR</code> with the file path to this model:</p> <pre><code># assuming the DIMR model is stored in your current working directory.\nmodel_path = Path(\"./dimr_config.xml\")\ndimr_model = DIMR(filepath=model_path)\n</code></pre> <p>It is also possible to not recursively load models: <pre><code>dimr_model = DIMR(filepath=model_path, recurse=False)\n</code></pre></p> <p>This will only load a DIMR model without its underlying child file models, such as the Flow FM model.</p>"},{"location":"tutorials/loading_and_saving_a_model/#save-the-model-in-a-new-location","title":"Save the model in a new location","text":"<p>If we want to store the full model in a different location we can use the <code>save</code> function:</p> <pre><code># Adjust this new_path to a path convenient for you.\nnew_path = Path(\"some/other/path/dimr_config.xml\")  \ndimr_model.save(filepath=new_path, recurse=True)\n</code></pre> <p>By setting <code>recurse</code> to <code>True</code> we will ensure all files (which are supported by HYDROLIB-core)  are written to the new location, relative to the file path of the root model.  Providing the <code>filepath</code> argument has the same result as first setting the filepath, and then calling save:</p> <pre><code>new_path = Path(\"some/other/path/dimr_config.xml\")  \ndimr_model.filepath = new_path\ndimr_model.save(recurse=True)\n</code></pre> <p>As such, when calling <code>filepath</code> after <code>save</code> it should be the same as <code>new_path</code>. Once save has been called all files (supported by HYDROLIB-core) should be located in the parent folder.</p>"},{"location":"tutorials/loading_and_saving_a_model/#adjust-the-model-in-a-update-it-on-disk","title":"Adjust the model in a update it on disk","text":"<p>Now that we have written our model in a different location, we can make some adjustments to it. We can retrieve the FM sub model as follows:</p> <pre><code>fm_component = dimr_model.component[1]  # Index 0 corresponds with the RRComponent.\nfm_model = fm_component.model\n</code></pre> <p>We can adjust the model, by for example changing some of the properties. For example let's change the  <code>MapInterval</code> from 60 to 30:</p> <pre><code>fm_model.output.mapinterval = 30.0\n</code></pre> <p>With that change made we can go ahead and save just this specific sub model, in order to update the values on disk:</p> <pre><code>fm_model.save()\n</code></pre> <p>By default, if no <code>filepath</code> is selected, it will be stored in the current <code>save_location</code>. This should  correspond with the place where it was last stored on disk. Furthermore, by default <code>recurse</code> is set to  <code>False</code>, as such we will only rewrite the <code>.mdu</code> file.</p> <p>If we now inspect the <code>.mdu</code> file, we should see that the <code>MapInterval</code> in the <code>output</code> header has been set to 30:</p> <pre><code>...\n[output]\n...\nMapInterval       = 30.0\n...\n</code></pre>"},{"location":"tutorials/loading_and_saving_a_model/#loading-models-on-case-sensitive-systems","title":"Loading models on case-sensitive systems","text":"<p>Model files may contain references to other model files of which the casing does not match with the file on disk. On Windows, loading a model with differently cased references will work just fine, since Windows is case-insensitive. However on Linux, the referenced file cannot be found and will raise an error.  To aid users in migrating their models, HYDROLIB-core offers a feature to resolve the casing of referenced files and supports three operating systems: Windows, Linux and MacOS.</p> <p>Consider an MDU model file that references a network file: <code>Network/flowfm_net.nc</code>. The file on disk is actually called <code>network/FlowFM_net.nc</code>.</p> <p>To load the model and simultaneously repair the file references in the in-memory model:</p> <pre><code>from hydrolib.core.dflowfm.mdu.models import FMModel\nmodel = FMModel(\"FlowFM.mdu\", resolve_casing=True)\n\n# assert that file reference has been updated from Network/flowfm_net.nc to network/FlowFM_net.nc\nassert model.geometry.netfile.filepath == Path(\"network/FlowFM_net.nc\")\n</code></pre> <p>The <code>resolve_casing</code> argument is by default <code>False</code>. Using the <code>resolve_casing</code> functionality might heavily influence the performance of model loading depending on the model size, the file tree structure and the operating system.</p>"},{"location":"tutorials/loading_and_saving_a_model/#saving-and-loading-models-between-different-operating-systems","title":"Saving and loading models between different operating systems","text":"<p>In certain cases, it may be necessary to switch effortlessly between operating systems (OS) using the same model. This allows the model to be loaded seamlessly on both Unix and Windows systems. However, it is important to note that the file paths look different for both OSs. Absolute file paths on Unix have a leading slash, while on Windows systems they start with a drive letter. Additionally, Unix systems don't allow backward slashes, whereas Windows supports both forward and backward slashes in file paths. These unique differences may cause issues when attempting to interpret files references within the model on another OS.</p> <p>Fortunately, HYDROLIB-core features a functionality that allows the conversion of file paths from one OS path style to another. This resolves the issue and ensures that the model functions seamlessly on both Unix and Windows systems.</p>"},{"location":"tutorials/loading_and_saving_a_model/#examples","title":"Examples","text":"<p>Loading a model with Unix file paths on Windows: <pre><code>model = FMModel(filepath=Path(\"p:/model/FlowFM.mdu\"), path_style=\"unix\")\n</code></pre></p> <p>Loading a model with Windows file paths on Linux/MacOS: <pre><code>model = FMModel(filepath=Path(\"/p/model/FlowFM.mdu\"), path_style=\"windows\")\n</code></pre></p> <p>In the two examples mentioned above, the <code>path_style</code> option specifies the path style that is used in the model files to be loaded. This information allows HYDROLIB-core to accurately convert the file paths to match the path style of the running operating system and interpret them correctly.</p> <p>Saving a model with Unix file paths on Windows: <pre><code>model.save(filepath=Path(\"p:/model/FlowFM.mdu\"), recurse=True, path_style=\"unix\")\n</code></pre></p> <p>Saving a model with Windows file paths on Linux/MacOS: <pre><code>model.save(filepath=Path(\"/p/model/FlowFM.mdu\"), recurse=True, path_style=\"windows\")\n</code></pre></p> <p>In the two examples mentioned above, the <code>path_style</code> option specifies the preferred path style of the saved model files. However, if this option is not specified when initializing or saving the model, it will default to the path style of the current operating system.</p> <p>The <code>path_style</code> option supports these three values: * <code>None</code> (will default to either <code>\"windows\"</code> or <code>\"unix\"</code> depending on the running OS) * <code>\"windows\"</code> * <code>\"unix\"</code></p> <p>Other values are not supported and an error will be raised.</p>"},{"location":"tutorials/loading_and_saving_a_model/#caveats-when-saving-models","title":"Caveats when saving models","text":"<p>There are some caveats to take into account when saving models.</p>"},{"location":"tutorials/loading_and_saving_a_model/#filepath-changes-do-not-automatically-propagate","title":"Filepath changes do not automatically propagate","text":"<p>When changing the <code>filepath</code> property of a parent model, the changes in <code>save_location</code> will not automatically propagate. As such, when saving a child model with a relative path, if the parent model's <code>filepath</code> has been changed, the child model will still be saved at its original save location. In order to update the save location, <code>synchronize_filepaths</code> should be called on the root model.</p>"},{"location":"tutorials/loading_and_saving_a_model/#synchronizing-filepaths-is-relative-to-the-model-it-is-called-upon","title":"Synchronizing filepaths is relative to the model it is called upon","text":"<p><code>synchronize_filepaths</code> will only update the file paths of child models. As such it will not propagate changes mode in a parent model:</p> <pre><code>dimr_model.filepath = Path(\"some/other/path/dimr_config.xml\")\nfm_model.synchronize_filepaths()  # This has no effect.\n</code></pre> <p>Because the <code>save_location</code> of the <code>fm_model</code> has not been changed, none of the child models will change either.</p> <p>Furthermore, extra care needs to be taken when dealing with FM models with the <code>pathsRelativeToParent</code> set to  <code>False</code>. This option will make all relative paths of child models relative to the <code>.mdu</code>. If <code>synchronize_filepaths</code> is called on a child model of the fm model, it will instead make all <code>save_locations</code> relative to this child model, which is incorrect.</p> <p>It is recommended to not use <code>pathsRelativeToParent</code> set to <code>False</code>.</p>"},{"location":"tutorials/plotting_a_network/","title":"Plotting a network","text":"<p>We can visualise a Network with the following code:</p> <pre><code>from hydrolib.core.dflowfm.net.models import Network\n\nimport matplotlib\nfrom matplotlib.collections import LineCollection\nimport numpy as np\n\ndef plot(\n    network: Network,\n    ax: matplotlib.axes._subplots.AxesSubplot,\n    mesh1d_kwargs: dict = None,\n    mesh2d_kwargs: dict = None,\n    links1d2d_kwargs: dict = None,\n) -&gt; None:\n\n    if mesh1d_kwargs is None:\n        mesh1d_kwargs = {\"color\": \"C3\", \"lw\": 1.0}\n    if mesh2d_kwargs is None:\n        mesh2d_kwargs = {\"color\": \"C0\", \"lw\": 0.5}\n    if links1d2d_kwargs is None:\n        links1d2d_kwargs = {\"color\": \"k\", \"lw\": 1.0}\n\n    # Mesh 1d\n    if not network._mesh1d.is_empty():\n        nodes1d = np.stack(\n            [network._mesh1d.mesh1d_node_x, network._mesh1d.mesh1d_node_y], axis=1\n        )\n        edge_nodes = network._mesh1d.mesh1d_edge_nodes\n        lc_mesh1d = LineCollection(nodes1d[edge_nodes], **mesh1d_kwargs)\n        ax.add_collection(lc_mesh1d)\n\n    # Mesh 2d\n    if not network._mesh2d.is_empty():\n        nodes2d = np.stack(\n            [network._mesh2d.mesh2d_node_x, network._mesh2d.mesh2d_node_y], axis=1\n        )\n        edge_nodes = network._mesh2d.mesh2d_edge_nodes\n        lc_mesh2d = LineCollection(nodes2d[edge_nodes], **mesh2d_kwargs)\n        ax.add_collection(lc_mesh2d)\n\n    # Links\n    if not network._link1d2d.is_empty():\n        faces2d = np.stack(\n            [network._mesh2d.mesh2d_face_x, network._mesh2d.mesh2d_face_y], axis=1\n        )\n        link_coords = np.stack(\n            [\n                nodes1d[network._link1d2d.link1d2d[:, 0]],\n                faces2d[network._link1d2d.link1d2d[:, 1]],\n            ],\n            axis=1,\n        )\n        lc_link1d2d = LineCollection(link_coords, **links1d2d_kwargs)\n        ax.add_collection(lc_link1d2d)\n</code></pre>"},{"location":"tutorials/tutorials/","title":"Introduction to tutorials","text":"<p>The tutorials below can help you becoming familiar with the basics as well as the more advanced use of HYDROLIB-core:</p> <ul> <li>Tutorial: Build a basic model - iPython notebook</li> <li>Tutorial: Loading and saving a model </li> <li>Tutorial: Dataframe handling</li> <li>Tutorial: Plotting a network</li> </ul> <p>To run these examples on your local machine you need a copy of the repository and an installation of HYDROLIB-core including some additional packages. The installation of HYDROLIB-core is explained in Installation. The tutorials are then located in <code>docs/tutorials/</code>.</p>"},{"location":"tutorials/dsd_2023/instructions/","title":"HYDROLIB-core guide for the Delft Software Days 2023","text":""},{"location":"tutorials/dsd_2023/instructions/#contents","title":"Contents","text":"<ul> <li>HYDROLIB-core guide for the Delft Software Days 2023</li> <li>Contents</li> <li>Introduction</li> <li>User guide<ul> <li>Requirements</li> <li>Installation</li> <li>Run the demo notebook</li> </ul> </li> <li>Cheat sheet<ul> <li>Kernel files vs HYDROLIB-core FileModels</li> <li>Commonly used functions of a FileModel</li> </ul> </li> </ul>"},{"location":"tutorials/dsd_2023/instructions/#introduction","title":"Introduction","text":"<p>This document contains instructions about the installation and usage of HYDROLIB-core during the Delft Software Days 2023.</p> <p>HYDROLIB-core is a Python package that offers functionality to process D-HYDRO input files. It offers Python-wrapped classes that represent these files and their content.  HYDROLIB-core serves as the basis for various pre- and postprocessing tools for a modelling workflow of hydrodynamic simulations in D-HYDRO.</p>"},{"location":"tutorials/dsd_2023/instructions/#user-guide","title":"User guide","text":""},{"location":"tutorials/dsd_2023/instructions/#requirements","title":"Requirements","text":"<p>Before getting started with HYDROLIB-core, make sure you have the following software and tools installed:</p> <ul> <li>Anaconda: https://www.anaconda.com/download Anaconda is an open-source distribution for Python and contains the package manager \"conda\".  (!) Make sure to add Anaconda to your PATH environment variable during installation.</li> </ul>"},{"location":"tutorials/dsd_2023/instructions/#installation","title":"Installation","text":"<p>Once you've installed the required software, you can create a Python 3.11 environment with HYDROLIB-core 0.5.2, the latest release.  Note that the environment that we are creating now contains not only HYDROLIB-core, but also the other packages that are needed today during the breakout sessions.</p> <p>Follow these steps:</p> <ol> <li>Open your command line interface</li> <li>Enter the following commands:</li> </ol> <pre><code>conda create --name dsd_env python=3.11 git -c conda-forge -y\nconda activate dsd_env\npip install hydromt_delft3dfm[examples] dfm_tools pyogrio openpyxl\nconda deactivate\n</code></pre> <p>After executing these commands, an Anaconda environment with the latest HYDROLIB-core is created. After deactivation, you can reactivate this environment at any time by using the following command: <pre><code>conda activate dsd_env\n</code></pre></p> <p>If you'd like to remove the environment entirely, call the following command:</p> <pre><code>conda remove -n dsd_env --all\n</code></pre> <p>This will remove all the packages in the environment and the environment folder itself.</p>"},{"location":"tutorials/dsd_2023/instructions/#run-the-demo-notebook","title":"Run the demo notebook","text":"<p>We'd like to be able to run the provided demo notebook. We can set it up with the following steps:</p> <ol> <li>Open a command line in the HYDROLIB-core folder</li> <li>Activate the conda environment: <pre><code>conda activate dsd_env\n</code></pre></li> <li>And start Jupyter Notebook: <pre><code>jupyter notebook\n</code></pre></li> <li>Open the demo.ipynb inside the demo folder</li> </ol>"},{"location":"tutorials/dsd_2023/instructions/#cheat-sheet","title":"Cheat sheet","text":"<p>In HYDROLIB-core, there is a class called FileModel, which is used to represent an individual kernel file. This class has multiple derived implementations, with each one corresponding to a specific kernel file. Every FileModel, except for the root model, is referenced within another FileModel, following the same hierarchy as the kernel files themselves.</p> <p>The table below contains the models relevant for today's exercises. </p>"},{"location":"tutorials/dsd_2023/instructions/#kernel-files-vs-hydrolib-core-filemodels","title":"Kernel files vs HYDROLIB-core FileModels","text":"Kernel file FileModel File reference Model definition file (*.mdu) FMModel - Network file (*_net.nc) NetworkModel Model definition file &gt; geometry &gt; netFile Cross-section location file (crosloc.ini) CrossLocModel Model definition file &gt; geometry &gt; crossLocFile Cross-section definition file (crosdef.ini) CrossDefModel Model definition file &gt; geometry &gt; crossDefFile Roughness file (roughness-*.ini) FrictionModel Model definition file &gt; geometry &gt; frictFile New external forcing file (*_bnd.ext) ExtModel Model definition file &gt; external forcing &gt; extForceFileNew Boundary conditions file (*.bc) ForcingModel New external forcing file &gt; boundary &gt; forcingFile 1D initial conditions field file (*.ini) OneDFieldModel Initial field file &gt; initial &gt; dataFile Initial field file (*.ini) IniFieldModel Model definition file &gt; geometry &gt; iniFieldFile Structures file (structures.ini) StructureModel Model definition file &gt; geometry &gt; structureFile"},{"location":"tutorials/dsd_2023/instructions/#commonly-used-functions-of-a-filemodel","title":"Commonly used functions of a FileModel","text":"<p>Each FileModel offers a set of commonly used functions. </p> <p>init() --- Initialize a new file model instance</p> <p>Parameters (all optional): * <code>filepath (Path)</code>: The file path from which the file model should be loaded. Default to None. * <code>resolve_casing (bool)</code>: Whether or not to resolve the file name references so that they match the case with what is on disk. Defaults to False. * <code>recurse (bool)</code>: Whether or not to recursively load the model. Defaults to True. * <code>path_style (str)</code>: Which path style is used in the loaded files. Options: 'unix', 'windows'. Defaults to the path style that matches the current operating system. </p> <p>save() --- Export the file model data to a file</p> <p>Parameters (all optional): * <code>filepath (Path)</code>: The file path at which this model is saved. If None is specified it defaults to the filepath currently stored in the filemodel. Defaults to None. * <code>recurse (bool)</code>: Whether or not to recursively save all children of this file model, or only save this model. Defaults to False. * <code>path_style (str)</code>: With which file path style to save the model. File references will be written with the specified path style. Options: 'unix', 'windows'. Defaults to the path style used by the current operating system.</p> <p>show_tree() --- Print the file model tree</p>"},{"location":"tutorials/extforce-convert/external_forcing_conversion/","title":"Macro Syntax Error","text":"<p>File: <code>tutorials/extforce-convert/external_forcing_conversion.md</code></p> <p>Line 65 in Markdown file: Missing end of comment tag <pre><code>### `--version` {#version}\n</code></pre></p>"}]}