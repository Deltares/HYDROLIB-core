{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 HYDROLIB-core is the core library of Python wrappers around the D-HYDRO model files (input and output) and model engines (kernel libraries).","title":"Introduction"},{"location":"#introduction","text":"HYDROLIB-core is the core library of Python wrappers around the D-HYDRO model files (input and output) and model engines (kernel libraries).","title":"Introduction"},{"location":"changelog/","text":"0.1.3 (2021-08-05) \u00b6 Fix \u00b6 netcdf serialization path. 0.1.2 (2021-08-05) \u00b6 Fix \u00b6 test_version : Fix updated version 0.1.1 (2021-08-05) \u00b6 Fix \u00b6 NetworkModel : Fix default init of Network within NetworkModel","title":"Changelog"},{"location":"changelog/#013-2021-08-05","text":"","title":"0.1.3 (2021-08-05)"},{"location":"changelog/#fix","text":"netcdf serialization path.","title":"Fix"},{"location":"changelog/#012-2021-08-05","text":"","title":"0.1.2 (2021-08-05)"},{"location":"changelog/#fix_1","text":"test_version : Fix updated version","title":"Fix"},{"location":"changelog/#011-2021-08-05","text":"","title":"0.1.1 (2021-08-05)"},{"location":"changelog/#fix_2","text":"NetworkModel : Fix default init of Network within NetworkModel","title":"Fix"},{"location":"guides/contributing/","text":"Contributing \u00b6 Tooling \u00b6 Black \u00b6 We use black as an autoformatter. It is also run during CI and will fail if it's not formatted beforehand. Isort \u00b6 We use isort as an autoformatter. Commitizen \u00b6 We use commitizen to automatically bump the version number. If you use conventional commit messages , the changelog.md is generated automatically. Development \u00b6 Branches \u00b6 For each issue or feature, a separate branch should be created from the main. To keep the branches organized a feature branch should be created with the feature/ prefix. When starting development on a branch, a pull request should be created for reviews and continous integration. During continuous integration, the checks will be run with python 3.8 and 3.9 on Windows, Ubuntu and MacOS. The checks consist of running the tests, checking the code formatting and running SonarCloud. We advise to use a draft pull request, to prevent the branch to be merged back before developement is finished. When the branch is ready for review, you can update the status of the pull request to \"ready for review\". Reviews \u00b6 When an issue is ready for review, it should be moved to the \"Ready for review\" column on the GitHub board for visibility. Merging \u00b6 Merging a branch can only happen when a pull request is accepted through review. When a pull request is accepted the changes should be merged back with the \"squash and merge\" option. Coding guidelines \u00b6 If there is code that needs to be tested, there should be tests written for it. If there are any additions or changes to the public API, the documentation should be updated. Files should be added to the appropriate folder to keep modules and objects within the correct scope.","title":"Contributing"},{"location":"guides/contributing/#contributing","text":"","title":"Contributing"},{"location":"guides/contributing/#tooling","text":"","title":"Tooling"},{"location":"guides/contributing/#black","text":"We use black as an autoformatter. It is also run during CI and will fail if it's not formatted beforehand.","title":"Black"},{"location":"guides/contributing/#isort","text":"We use isort as an autoformatter.","title":"Isort"},{"location":"guides/contributing/#commitizen","text":"We use commitizen to automatically bump the version number. If you use conventional commit messages , the changelog.md is generated automatically.","title":"Commitizen"},{"location":"guides/contributing/#development","text":"","title":"Development"},{"location":"guides/contributing/#branches","text":"For each issue or feature, a separate branch should be created from the main. To keep the branches organized a feature branch should be created with the feature/ prefix. When starting development on a branch, a pull request should be created for reviews and continous integration. During continuous integration, the checks will be run with python 3.8 and 3.9 on Windows, Ubuntu and MacOS. The checks consist of running the tests, checking the code formatting and running SonarCloud. We advise to use a draft pull request, to prevent the branch to be merged back before developement is finished. When the branch is ready for review, you can update the status of the pull request to \"ready for review\".","title":"Branches"},{"location":"guides/contributing/#reviews","text":"When an issue is ready for review, it should be moved to the \"Ready for review\" column on the GitHub board for visibility.","title":"Reviews"},{"location":"guides/contributing/#merging","text":"Merging a branch can only happen when a pull request is accepted through review. When a pull request is accepted the changes should be merged back with the \"squash and merge\" option.","title":"Merging"},{"location":"guides/contributing/#coding-guidelines","text":"If there is code that needs to be tested, there should be tests written for it. If there are any additions or changes to the public API, the documentation should be updated. Files should be added to the appropriate folder to keep modules and objects within the correct scope.","title":"Coding guidelines"},{"location":"guides/devcontainers/","text":"Devcontainers: Developing HYDROLIB in an isolated environment \u00b6 A common struggle while working on any software project, is to ensure all of your dependencies are available and you can actually build the software, run the tests etc. While any developer is free to choose their own toolchain, environment etc, HYDROLIB-Core includes the necessary files to run the project within a so called devcontainer within Visual Studio Code. With the help of Docker, we can spin up an independent development environment, ensuring that HYDROLIB-Core works out of the box and you are insulated from any specific local configurations on your machines. This should allow you to start working on HYDROLIB-Core quickly. The following sub sections will walk you through the necessary dependencies, and how to use it, and modify it, to fit your own needs. This will be done in the following order: Requirements: Docker and Visual Studio Code Remote - Containers extension Dockerfile configures python, poetry and other dependencies devcontainer.json specifies how visual studio code should be configured External references Requirements: Docker and Visual Studio Code Remote - Containers extension \u00b6 In order to run HYDROLIB in a dev container we need the following dependencies Docker Visual Studio Code Visual Studio Code Remote - Containers extension Docker will ensure we can spin up an isolated container. A full tutorial on how to use Docker is outside the scope of this tutorial, however the Getting Started guide of Docker should provide you with the steps to install Docker on your machine. Visual Studio Code is the editor we will use. The website should provide you with the necessary steps to install it. Lastly, we need to install the Visual Studio Code Remote - Containers extension . The install button on the marketplace should walk you through the steps to install it. Run HYDROLIB in a devcontainer by executing \"Reopen in container\" command \u00b6 With all of the dependencies set up, we should be able to run HYDROLIB within our devcontainer. When opening the HYDROLIB-Core repository in Visual Studio Code, we should either get a pop-up asking us to reopen the project within a remote container, or we can select the \"Open a Remote Window\" button, the green button in the bottom left corner of your visual studio code window, after which we can select \"Reopen in container\". Both will then spin up a new container in which we can work. Note that if it is the first time starting our repository, or if we have made changes to the Docker Images we might need to build the container, which could take a few moments. Once opened in a separate container, we can start a terminal to verify everything is working correctly. When we start a new terminal, we should see the terminal of our container, e.g. something a long the lines of ( .venv ) root@7573572275f1:/workspaces/HYDROLIB-core# It should now be possible to run the HYDROLIB-Core tests within our container. You might get prompted to configure either the python interpreter, or the python test framework. Once this is done all tests should pass as they would normally. Dockerfile configures python, poetry and other dependencies \u00b6 The Dockerfile which specifies our specific devcontainer can be found here in the repository . Currently, it extends the python 3.9 slim buster image provided by the Python foundation. It then does the following: Installs Poetry 1.1.7 and configure the necessary paths Copies the poetry.lock and pyproject.toml and installs the project Installs git within the container This should provide us with a ready to go environment to run HYDROLIB-Core with. devcontainer.json specifies how visual studio code should be configured \u00b6 We can further customise our environment by editing the devcontainer.json located here in the repository . In particular, you can add any Visual Studio Code extensions you require for your work to the extensions field. Currently it is populated with several common Python extensions which we use to develop HYDROLIB. For a full overview how to customise this file, you can find the documentation here External references: \u00b6 Developing inside a Container - VS Code docs Develop with containers - VS Code docs (guide specific for python) Document docker poetry best practices - Poetry issue","title":"Devcontainers: Developing HYDROLIB in an isolated environment"},{"location":"guides/devcontainers/#devcontainers-developing-hydrolib-in-an-isolated-environment","text":"A common struggle while working on any software project, is to ensure all of your dependencies are available and you can actually build the software, run the tests etc. While any developer is free to choose their own toolchain, environment etc, HYDROLIB-Core includes the necessary files to run the project within a so called devcontainer within Visual Studio Code. With the help of Docker, we can spin up an independent development environment, ensuring that HYDROLIB-Core works out of the box and you are insulated from any specific local configurations on your machines. This should allow you to start working on HYDROLIB-Core quickly. The following sub sections will walk you through the necessary dependencies, and how to use it, and modify it, to fit your own needs. This will be done in the following order: Requirements: Docker and Visual Studio Code Remote - Containers extension Dockerfile configures python, poetry and other dependencies devcontainer.json specifies how visual studio code should be configured External references","title":"Devcontainers: Developing HYDROLIB in an isolated environment"},{"location":"guides/devcontainers/#requirements-docker-and-visual-studio-code-remote-containers-extension","text":"In order to run HYDROLIB in a dev container we need the following dependencies Docker Visual Studio Code Visual Studio Code Remote - Containers extension Docker will ensure we can spin up an isolated container. A full tutorial on how to use Docker is outside the scope of this tutorial, however the Getting Started guide of Docker should provide you with the steps to install Docker on your machine. Visual Studio Code is the editor we will use. The website should provide you with the necessary steps to install it. Lastly, we need to install the Visual Studio Code Remote - Containers extension . The install button on the marketplace should walk you through the steps to install it.","title":"Requirements: Docker and Visual Studio Code Remote - Containers extension"},{"location":"guides/devcontainers/#run-hydrolib-in-a-devcontainer-by-executing-reopen-in-container-command","text":"With all of the dependencies set up, we should be able to run HYDROLIB within our devcontainer. When opening the HYDROLIB-Core repository in Visual Studio Code, we should either get a pop-up asking us to reopen the project within a remote container, or we can select the \"Open a Remote Window\" button, the green button in the bottom left corner of your visual studio code window, after which we can select \"Reopen in container\". Both will then spin up a new container in which we can work. Note that if it is the first time starting our repository, or if we have made changes to the Docker Images we might need to build the container, which could take a few moments. Once opened in a separate container, we can start a terminal to verify everything is working correctly. When we start a new terminal, we should see the terminal of our container, e.g. something a long the lines of ( .venv ) root@7573572275f1:/workspaces/HYDROLIB-core# It should now be possible to run the HYDROLIB-Core tests within our container. You might get prompted to configure either the python interpreter, or the python test framework. Once this is done all tests should pass as they would normally.","title":"Run HYDROLIB in a devcontainer by executing \"Reopen in container\" command"},{"location":"guides/devcontainers/#dockerfile-configures-python-poetry-and-other-dependencies","text":"The Dockerfile which specifies our specific devcontainer can be found here in the repository . Currently, it extends the python 3.9 slim buster image provided by the Python foundation. It then does the following: Installs Poetry 1.1.7 and configure the necessary paths Copies the poetry.lock and pyproject.toml and installs the project Installs git within the container This should provide us with a ready to go environment to run HYDROLIB-Core with.","title":"Dockerfile configures python, poetry and other dependencies"},{"location":"guides/devcontainers/#devcontainerjson-specifies-how-visual-studio-code-should-be-configured","text":"We can further customise our environment by editing the devcontainer.json located here in the repository . In particular, you can add any Visual Studio Code extensions you require for your work to the extensions field. Currently it is populated with several common Python extensions which we use to develop HYDROLIB. For a full overview how to customise this file, you can find the documentation here","title":"devcontainer.json specifies how visual studio code should be configured"},{"location":"guides/devcontainers/#external-references","text":"Developing inside a Container - VS Code docs Develop with containers - VS Code docs (guide specific for python) Document docker poetry best practices - Poetry issue","title":"External references:"},{"location":"guides/documentation/","text":"Documentation \u00b6 We use MKdocs for documentation. For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Documentation"},{"location":"guides/documentation/#documentation","text":"We use MKdocs for documentation. For full documentation visit mkdocs.org .","title":"Documentation"},{"location":"guides/documentation/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"guides/documentation/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"guides/setup/","text":"Installation \u00b6 You should be able to install hydrolib-core with: pip install hydrolib-core or if you prefer (especially on Windows) conda install hydrolib-core -c conda-forge Note If you use conda , it's advisable to install hydrolib-core within a new environment with only conda-forge as channel.","title":"Installation"},{"location":"guides/setup/#installation","text":"You should be able to install hydrolib-core with: pip install hydrolib-core or if you prefer (especially on Windows) conda install hydrolib-core -c conda-forge Note If you use conda , it's advisable to install hydrolib-core within a new environment with only conda-forge as channel.","title":"Installation"},{"location":"reference/api/","text":"BaseModel and FileModel \u00b6 Here we define our Pydantic BaseModel with custom settings, as well as a FileModel that inherits from a BaseModel but also represents a file on disk. BaseModel ( BaseModel ) pydantic-model \u00b6 is_file_link ( self ) -> bool \u00b6 Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : \"\"\"Generic attribute for models backed by a file.\"\"\" return False is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/basemodel.py def is_intermediate_link ( self ) -> bool : \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\" return self . is_file_link () show_tree ( self , indent = 0 ) \u00b6 Recursive print function for showing a tree of a model. Source code in hydrolib/core/basemodel.py def show_tree ( self , indent = 0 ): \"\"\"Recursive print function for showing a tree of a model.\"\"\" angle = \"\u221f\" if indent > 0 else \"\" # Only print if we're backed by a file if self . is_file_link (): print ( \" \" * indent * 2 , angle , self ) # Otherwise we recurse through the fields of a model for _ , value in self : # Handle lists of items if not isinstance ( value , list ): value = [ value ] for v in value : if hasattr ( v , \"is_intermediate_link\" ) and v . is_intermediate_link (): # If the field is only an intermediate, print the name only if not v . is_file_link (): print ( \" \" * ( indent * 2 + 2 ), angle , v . __class__ . __name__ ) v . show_tree ( indent + 1 ) FileModel ( BaseModel , ABC ) pydantic-model \u00b6 Base class to represent models with a file representation. It therefore always has a filepath and if it is given on initilization, it will parse that file. This class extends the validate option of Pydantic, so when when a Path is given to a field with type FileModel , it doesn't error, but actually initializes the FileModel . __init__ ( self , filepath : Optional [ pathlib . Path ] = None , * args , ** kwargs ) special \u00b6 Initialize a model. The model is empty (with defaults) if no filepath is given, otherwise the file at filepath will be parsed. Source code in hydrolib/core/basemodel.py def __init__ ( self , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Initialize a model. The model is empty (with defaults) if no `filepath` is given, otherwise the file at `filepath` will be parsed.\"\"\" # Parse the file if path is given context_dir_reset_token = None if filepath : filepath = Path ( filepath ) # so we also accept strings # If a context is set, use it if ( folder := context_dir . get ( None )) and not filepath . is_absolute (): logger . info ( f \"Used context to get { folder } for { filepath } \" ) filepath = folder / filepath # Otherwise we're the root filepath # and should set the context else : logger . info ( f \"Set context to { filepath . parent } \" ) context_dir_reset_token = context_dir . set ( filepath . parent ) data = self . _load ( filepath ) data [ \"filepath\" ] = filepath kwargs . update ( data ) super () . __init__ ( * args , ** kwargs ) _reset_context_dir ( context_dir_reset_token ) __str__ ( self ) -> str special \u00b6 Return str(self). Source code in hydrolib/core/basemodel.py def __str__ ( self ) -> str : return str ( self . filepath if self . filepath else \"\" ) is_file_link ( self ) -> bool \u00b6 Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : return True save ( self , folder : Optional [ pathlib . Path ] = None ) -> Path \u00b6 Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given folder and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Parameters: Name Type Description Default folder Optional[pathlib.Path] path to the folder where this FileModel will be stored None Source code in hydrolib/core/basemodel.py def save ( self , folder : Optional [ Path ] = None ) -> Path : \"\"\"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given `folder` and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Args: folder: path to the folder where this FileModel will be stored \"\"\" if not self . filepath and not folder : raise ValueError ( \"Either set the `filepath` on the model or pass a `folder` when saving.\" ) if not folder : folder = self . filepath . absolute () . parent self . _apply_recurse ( \"_save\" , folder ) return self . filepath . absolute ()","title":"Api"},{"location":"reference/api/#basemodel-and-filemodel","text":"Here we define our Pydantic BaseModel with custom settings, as well as a FileModel that inherits from a BaseModel but also represents a file on disk.","title":"BaseModel and FileModel"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel","text":"","title":"BaseModel"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.is_file_link","text":"Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : \"\"\"Generic attribute for models backed by a file.\"\"\" return False","title":"is_file_link()"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/basemodel.py def is_intermediate_link ( self ) -> bool : \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\" return self . is_file_link ()","title":"is_intermediate_link()"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.show_tree","text":"Recursive print function for showing a tree of a model. Source code in hydrolib/core/basemodel.py def show_tree ( self , indent = 0 ): \"\"\"Recursive print function for showing a tree of a model.\"\"\" angle = \"\u221f\" if indent > 0 else \"\" # Only print if we're backed by a file if self . is_file_link (): print ( \" \" * indent * 2 , angle , self ) # Otherwise we recurse through the fields of a model for _ , value in self : # Handle lists of items if not isinstance ( value , list ): value = [ value ] for v in value : if hasattr ( v , \"is_intermediate_link\" ) and v . is_intermediate_link (): # If the field is only an intermediate, print the name only if not v . is_file_link (): print ( \" \" * ( indent * 2 + 2 ), angle , v . __class__ . __name__ ) v . show_tree ( indent + 1 )","title":"show_tree()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel","text":"Base class to represent models with a file representation. It therefore always has a filepath and if it is given on initilization, it will parse that file. This class extends the validate option of Pydantic, so when when a Path is given to a field with type FileModel , it doesn't error, but actually initializes the FileModel .","title":"FileModel"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.__init__","text":"Initialize a model. The model is empty (with defaults) if no filepath is given, otherwise the file at filepath will be parsed. Source code in hydrolib/core/basemodel.py def __init__ ( self , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Initialize a model. The model is empty (with defaults) if no `filepath` is given, otherwise the file at `filepath` will be parsed.\"\"\" # Parse the file if path is given context_dir_reset_token = None if filepath : filepath = Path ( filepath ) # so we also accept strings # If a context is set, use it if ( folder := context_dir . get ( None )) and not filepath . is_absolute (): logger . info ( f \"Used context to get { folder } for { filepath } \" ) filepath = folder / filepath # Otherwise we're the root filepath # and should set the context else : logger . info ( f \"Set context to { filepath . parent } \" ) context_dir_reset_token = context_dir . set ( filepath . parent ) data = self . _load ( filepath ) data [ \"filepath\" ] = filepath kwargs . update ( data ) super () . __init__ ( * args , ** kwargs ) _reset_context_dir ( context_dir_reset_token )","title":"__init__()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.__str__","text":"Return str(self). Source code in hydrolib/core/basemodel.py def __str__ ( self ) -> str : return str ( self . filepath if self . filepath else \"\" )","title":"__str__()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.is_file_link","text":"Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : return True","title":"is_file_link()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.save","text":"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given folder and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Parameters: Name Type Description Default folder Optional[pathlib.Path] path to the folder where this FileModel will be stored None Source code in hydrolib/core/basemodel.py def save ( self , folder : Optional [ Path ] = None ) -> Path : \"\"\"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given `folder` and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Args: folder: path to the folder where this FileModel will be stored \"\"\" if not self . filepath and not folder : raise ValueError ( \"Either set the `filepath` on the model or pass a `folder` when saving.\" ) if not folder : folder = self . filepath . absolute () . parent self . _apply_recurse ( \"_save\" , folder ) return self . filepath . absolute ()","title":"save()"},{"location":"reference/dimr/","text":"DIMR xml files \u00b6 Model \u00b6 Component ( BaseModel , ABC ) pydantic-model \u00b6 Specification of a BMI-compliant model component instance that will be executed by DIMR. Attributes: Name Type Description library str The library name of the compoment. name str The component name. workingDir Path The working directory. inputFile Path The name of the input file. process Optional[int] Number of subprocesses in the component. setting Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model before initialization. parameter Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model after initialization. mpiCommunicator Optional[str] The MPI communicator value. model Optional[hydrolib.core.basemodel.FileModel] The model represented by this component. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : return True ComponentOrCouplerRef ( BaseModel ) pydantic-model \u00b6 Reference to a BMI-compliant model component instance. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance. Control ( BaseModel ) pydantic-model \u00b6 Control flow specification for the DIMR-execution. Attributes: Name Type Description parallel Optional[List[hydrolib.core.io.dimr.models.Parallel]] Specification of a control flow that has to be executed in parallel. start Optional[List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef]] Reference to the component instance to be started. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False CoupledItem ( BaseModel ) pydantic-model \u00b6 Specification of an item that has to be exchanged. Attributes: Name Type Description sourceName str Name of the item at the source component. targetName str Name of the item at the target component. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False Coupler ( BaseModel ) pydantic-model \u00b6 Specification of the coupling actions to be performed between two BMI-compliant model components. Attributes: Name Type Description name str The name of the coupler. sourceComponent str The component that provides the data to has to be exchanged. targetComponent str The component that consumes the data to has to be exchanged. item List[hydrolib.core.io.dimr.models.CoupledItem] A list of items that have to be exchanged. logger Optional[hydrolib.core.io.dimr.models.Logger] Logger for logging the values that get exchanged. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False DIMR ( FileModel ) pydantic-model \u00b6 DIMR model representation. dict ( self , * args , ** kwargs ) \u00b6 Converts this object recursively to a dictionary. Returns: Type Description dict The created dictionary for this object. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): \"\"\"Converts this object recursively to a dictionary. Returns: dict: The created dictionary for this object. \"\"\" return self . _to_serializable_dict ( self ) Documentation ( BaseModel ) pydantic-model \u00b6 Information on the present DIMR configuration file. Attributes: Name Type Description fileVersion str The DIMR file version. createdBy str Creators of the DIMR file. creationDate datetime The creation date of the DIMR file. GlobalSettings ( BaseModel ) pydantic-model \u00b6 Global settings for the DIMR configuration. Attributes: Name Type Description logger_ncFormat int NetCDF format type for logging. KeyValuePair ( BaseModel ) pydantic-model \u00b6 Key value pair to specify settings and parameters. Attributes: Name Type Description key str The key. value str The value. Logger ( BaseModel ) pydantic-model \u00b6 Used to log values to the specified file in workingdir for each timestep Attributes: Name Type Description workingDir Path Directory where the log file is written. outputFile Path Name of the log file. Parallel ( BaseModel ) pydantic-model \u00b6 Specification of a parallel control flow: one main component and a group of related components and couplers. Step wise execution order according to order in parallel control flow. Attributes: Name Type Description startGroup StartGroup Group of components and couplers to be executed. start ComponentOrCouplerRef Main component to be executed step wise (provides start time, end time and time step). StartGroup ( BaseModel ) pydantic-model \u00b6 Specification of model components and couplers to be executed with a certain frequency. Attributes: Name Type Description time str Time frame specification for the present group: start time, stop time and frequency. Expressed in terms of the time frame of the main component. start List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Ordered list of components to be executed. coupler List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Oredered list of couplers to be executed. Parser \u00b6 DIMRParser \u00b6 A parser for DIMR xml files. parse ( path : Path ) -> dict staticmethod \u00b6 Parses a DIMR file to a dictionary. Parameters: Name Type Description Default path Path Path to the DIMR configuration file. required Source code in hydrolib/core/io/dimr/parser.py @staticmethod def parse ( path : Path ) -> dict : \"\"\"Parses a DIMR file to a dictionary. Args: path (Path): Path to the DIMR configuration file. \"\"\" if not path . is_file (): warn ( f \"File: ` { path } ` not found, skipped parsing.\" ) return {} parser = etree . XMLParser ( remove_comments = True , resolve_entities = False , no_network = True ) root = etree . parse ( str ( path ), parser = parser ) . getroot () return DIMRParser . _node_to_dictionary ( root , True ) Serializer \u00b6 DIMRSerializer \u00b6 A serializer for DIMR files. serialize ( path : Path , data : dict ) staticmethod \u00b6 Serializes the DIMR data to the file at the specified path. Attributes: Name Type Description path Path The path to the destination file. data Dict The data to be serialized. Source code in hydrolib/core/io/dimr/serializer.py @staticmethod def serialize ( path : Path , data : dict ): \"\"\" Serializes the DIMR data to the file at the specified path. Attributes: path (Path): The path to the destination file. data (Dict): The data to be serialized. \"\"\" path . parent . mkdir ( parents = True , exist_ok = True ) xmlns = \"http://schemas.deltares.nl/dimr\" xsi = \"http://www.w3.org/2001/XMLSchema-instance\" schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\" attrib = { e . QName ( xsi , \"schemaLocation\" ): f \" { xmlns } { schema_location } \" } namespaces = { None : xmlns , \"xsi\" : xsi } root = e . Element ( \"dimrConfig\" , attrib = attrib , nsmap = namespaces , ) DIMRSerializer . _build_tree ( root , data ) to_string = minidom . parseString ( e . tostring ( root )) xml = to_string . toprettyxml ( indent = \" \" , encoding = \"utf-8\" ) with path . open ( \"wb\" ) as f : f . write ( xml )","title":"Dimr"},{"location":"reference/dimr/#dimr-xml-files","text":"","title":"DIMR xml files"},{"location":"reference/dimr/#model","text":"","title":"Model"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Component","text":"Specification of a BMI-compliant model component instance that will be executed by DIMR. Attributes: Name Type Description library str The library name of the compoment. name str The component name. workingDir Path The working directory. inputFile Path The name of the input file. process Optional[int] Number of subprocesses in the component. setting Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model before initialization. parameter Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model after initialization. mpiCommunicator Optional[str] The MPI communicator value. model Optional[hydrolib.core.basemodel.FileModel] The model represented by this component.","title":"Component"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Component.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.ComponentOrCouplerRef","text":"Reference to a BMI-compliant model component instance. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance.","title":"ComponentOrCouplerRef"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Control","text":"Control flow specification for the DIMR-execution. Attributes: Name Type Description parallel Optional[List[hydrolib.core.io.dimr.models.Parallel]] Specification of a control flow that has to be executed in parallel. start Optional[List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef]] Reference to the component instance to be started.","title":"Control"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Control.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.CoupledItem","text":"Specification of an item that has to be exchanged. Attributes: Name Type Description sourceName str Name of the item at the source component. targetName str Name of the item at the target component.","title":"CoupledItem"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.CoupledItem.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Coupler","text":"Specification of the coupling actions to be performed between two BMI-compliant model components. Attributes: Name Type Description name str The name of the coupler. sourceComponent str The component that provides the data to has to be exchanged. targetComponent str The component that consumes the data to has to be exchanged. item List[hydrolib.core.io.dimr.models.CoupledItem] A list of items that have to be exchanged. logger Optional[hydrolib.core.io.dimr.models.Logger] Logger for logging the values that get exchanged.","title":"Coupler"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Coupler.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.DIMR","text":"DIMR model representation.","title":"DIMR"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.DIMR.dict","text":"Converts this object recursively to a dictionary. Returns: Type Description dict The created dictionary for this object. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): \"\"\"Converts this object recursively to a dictionary. Returns: dict: The created dictionary for this object. \"\"\" return self . _to_serializable_dict ( self )","title":"dict()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Documentation","text":"Information on the present DIMR configuration file. Attributes: Name Type Description fileVersion str The DIMR file version. createdBy str Creators of the DIMR file. creationDate datetime The creation date of the DIMR file.","title":"Documentation"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.GlobalSettings","text":"Global settings for the DIMR configuration. Attributes: Name Type Description logger_ncFormat int NetCDF format type for logging.","title":"GlobalSettings"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.KeyValuePair","text":"Key value pair to specify settings and parameters. Attributes: Name Type Description key str The key. value str The value.","title":"KeyValuePair"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Logger","text":"Used to log values to the specified file in workingdir for each timestep Attributes: Name Type Description workingDir Path Directory where the log file is written. outputFile Path Name of the log file.","title":"Logger"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Parallel","text":"Specification of a parallel control flow: one main component and a group of related components and couplers. Step wise execution order according to order in parallel control flow. Attributes: Name Type Description startGroup StartGroup Group of components and couplers to be executed. start ComponentOrCouplerRef Main component to be executed step wise (provides start time, end time and time step).","title":"Parallel"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.StartGroup","text":"Specification of model components and couplers to be executed with a certain frequency. Attributes: Name Type Description time str Time frame specification for the present group: start time, stop time and frequency. Expressed in terms of the time frame of the main component. start List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Ordered list of components to be executed. coupler List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Oredered list of couplers to be executed.","title":"StartGroup"},{"location":"reference/dimr/#parser","text":"","title":"Parser"},{"location":"reference/dimr/#hydrolib.core.io.dimr.parser.DIMRParser","text":"A parser for DIMR xml files.","title":"DIMRParser"},{"location":"reference/dimr/#hydrolib.core.io.dimr.parser.DIMRParser.parse","text":"Parses a DIMR file to a dictionary. Parameters: Name Type Description Default path Path Path to the DIMR configuration file. required Source code in hydrolib/core/io/dimr/parser.py @staticmethod def parse ( path : Path ) -> dict : \"\"\"Parses a DIMR file to a dictionary. Args: path (Path): Path to the DIMR configuration file. \"\"\" if not path . is_file (): warn ( f \"File: ` { path } ` not found, skipped parsing.\" ) return {} parser = etree . XMLParser ( remove_comments = True , resolve_entities = False , no_network = True ) root = etree . parse ( str ( path ), parser = parser ) . getroot () return DIMRParser . _node_to_dictionary ( root , True )","title":"parse()"},{"location":"reference/dimr/#serializer","text":"","title":"Serializer"},{"location":"reference/dimr/#hydrolib.core.io.dimr.serializer.DIMRSerializer","text":"A serializer for DIMR files.","title":"DIMRSerializer"},{"location":"reference/dimr/#hydrolib.core.io.dimr.serializer.DIMRSerializer.serialize","text":"Serializes the DIMR data to the file at the specified path. Attributes: Name Type Description path Path The path to the destination file. data Dict The data to be serialized. Source code in hydrolib/core/io/dimr/serializer.py @staticmethod def serialize ( path : Path , data : dict ): \"\"\" Serializes the DIMR data to the file at the specified path. Attributes: path (Path): The path to the destination file. data (Dict): The data to be serialized. \"\"\" path . parent . mkdir ( parents = True , exist_ok = True ) xmlns = \"http://schemas.deltares.nl/dimr\" xsi = \"http://www.w3.org/2001/XMLSchema-instance\" schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\" attrib = { e . QName ( xsi , \"schemaLocation\" ): f \" { xmlns } { schema_location } \" } namespaces = { None : xmlns , \"xsi\" : xsi } root = e . Element ( \"dimrConfig\" , attrib = attrib , nsmap = namespaces , ) DIMRSerializer . _build_tree ( root , data ) to_string = minidom . parseString ( e . tostring ( root )) xml = to_string . toprettyxml ( indent = \" \" , encoding = \"utf-8\" ) with path . open ( \"wb\" ) as f : f . write ( xml )","title":"serialize()"},{"location":"reference/forcing/","text":"ForcingBase ( DataBlockINIBasedModel ) pydantic-model \u00b6 validate ( v ) classmethod \u00b6 Try to iniatialize subclass based on function field. Source code in hydrolib/core/io/bc/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on function field.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"function\" ) . default == v . get ( \"function\" , \"\" ) . lower () ): v = c ( ** v ) break return v TimeInterpolation ( str , Enum ) \u00b6 An enumeration. VerticalInterpolation ( str , Enum ) \u00b6 An enumeration. VerticalPositionType ( str , Enum ) \u00b6 An enumeration.","title":"Forcing"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.ForcingBase","text":"","title":"ForcingBase"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.ForcingBase.validate","text":"Try to iniatialize subclass based on function field. Source code in hydrolib/core/io/bc/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on function field.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"function\" ) . default == v . get ( \"function\" , \"\" ) . lower () ): v = c ( ** v ) break return v","title":"validate()"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.TimeInterpolation","text":"An enumeration.","title":"TimeInterpolation"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.VerticalInterpolation","text":"An enumeration.","title":"VerticalInterpolation"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.VerticalPositionType","text":"An enumeration.","title":"VerticalPositionType"},{"location":"reference/glossary/","text":"Glossary \u00b6 The list below is a nonexhaustive list of terminology and concepts used in HYDROLIB(-core) and Delft3D Flexible Mesh. A \u00b6 B \u00b6 BC file \u00b6 Input file containing the actual forcing data for model forcings specified elsewhere in the model input, for example time series or astronomical components. Originates from boundary conditions as specified in the external forcings file , but nowadays also used in structure files . More details about the syntax and the various supported function types in the Delft3D FM User Manual . Boundary condition \u00b6 Flow (or constituent) boundary condition that forces a D-Flow FM model, such as waterlevel and discharge boundary conditions. Defined in the external forcings file . More details in the Delft3D FM User Manual . Branch \u00b6 The network edges in a network topology of 1D models. The computational grid points are positioned on these branches using branch id and a chainage value. Branch Id \u00b6 Identification text string for a particular branch in a 1D network. C \u00b6 Chainage \u00b6 The distance along a 1D network branch to define a specific location on that branch. Always used in combination with a branch Id . CF conventions \u00b6 Established metadata conventions for storing all kinds of data, e.g., model input and output, in NetCDF files. More details on: https://cfconventions.org/. HYDROLIB-core and Delft3D Flexible Mesh rely on CF, and extend this with UGRID conventions where unstructured grids are applicable. Computational backend \u00b6 Computational core, also called kernel. The program/library of simulation software that does the actual calculations. Often also available with a graphical user interface on top of it. Cross section files \u00b6 Input files for D-Flow FM that define the 1D network's cross sections. Two parts: cross section definition file and cross section location files . Not to be confused with observation cross section files ! Cross section definition file \u00b6 Input file for D-Flow FM that defines the various cross section shapes in a model with a 1D network. Format is INI-like. More details in the Delft3D FM User Manual . Cross section location file \u00b6 Input file for D-Flow FM that defines the location of cross section shapes in a model with a 1D network. Each location refers to a (possible shared) cross section definition . Format is INI-like. More details in the Delft3D FM User Manual . D \u00b6 Deltares conventions \u00b6 A proposal for additional NetCDF conventions that build on the existing UGRID conventions , intended to properly describe 1D network topologies as a coordinate space on which 1D computational grids are defined. Also 1D2D grid couplings are included. More details in: the Delft3D FM User Manual . D-Flow FM \u00b6 D-Flow Flexible Mesh. The computational backend that solves 1D/2D/3D hydrodynamics in the Delf3D Flexible Mesh Suite. Toplevel input is the MDU file . More details in the Delft3D FM User Manual . D-HYDRO Suite 1D2D (Beta) \u00b6 Integral software suite for hydraulic 1D2D modelling, including rainfall runoff and realtime control. More details on: https://www.deltares.nl/nl/d-hydro-suite-1d2d-beta/. DIMR \u00b6 Deltares Integrated Model Runner. Executable/library that runs integrated models by coupling multiple computational backends in a simulation timeloop. Uses a single DIMR config file as input. DIMR config file \u00b6 Input file for DIMR (typically dimr_config.xml ) for an integrated model run, describing which models are coupled and which quantities need to be exchanged. E \u00b6 Edge (mesh) \u00b6 A geometrical \"line\" in a 1D, 2D or 3D mesh. Connects two mesh nodes as its end points. Building block of the UGRID-conventions . External forcings file \u00b6 Input file for D-Flow FM describing model forcings such as boundary conditions , laterals and meteo . Format is INI-like. More details in the Delft3D FM User Manual . F \u00b6 Face (mesh) \u00b6 A geometrical \"cell\" in a 2D mesh. Formed by 3 or more mesh nodes as its vertices. Building block of the UGRID-conventions . Flow link \u00b6 An open connection/interface between two flow nodes in the staggered D-Flow FM model grid. Is the same as a \"velocity point\", and corresponds with (but is not equal to) an edge , both in 1D and in 2D. In 3D a flow link corresponds with a 3D face between two volumes . Flow node \u00b6 A single finite volume \"cell\" in the staggered D-Flow FM model grid. Is the same as a \"pressure point\", and is in fact a face in 2D/3D or a node in 1D. G \u00b6 Grid \u00b6 The computational grid on which a flow simulation is done. The grid for D-Flow FM is defined in an input net file , and also appears (slightly differently) in the output map file . Grid snapping \u00b6 The snapping of D-Flow FM model input in x,y-coordinates to discrete locations in the staggered model grid . This process makes most model input independent of the chosen model grid and grid resolution. Snapping is done either to (sets of) flow nodes or (sequence of) flow links , depending on whether pressure-point data or velocity-point data is concerned. H \u00b6 His file \u00b6 Output file of D-Flow FM containing model results as time series on a specific set of discrete locations, which are typically the hydraulic structures, observation stations and more. More details in the Delft3D FM User Manual . I \u00b6 Integrated model \u00b6 Model consisting of more than one model. Typically used when multiple computational backends are coupled, for example D-Flow FM and Rainfall Runoff or D-Flow FM and Real Time Control . Integrated models can be run using the Deltares Integrated Model Runner (DIMR) . INI-files \u00b6 Delft3D FM uses several input files that are formatted in an INI-like syntax. The abstract syntax depends on the particular file type, see: cross section files , initial field file , external forcings file , MDU file , observation files , rougness file , structure file . Initial field file \u00b6 Input file for D-Flow FM describing initial conditions and other spatially varying parameter fields. Format is INI-like. More details in the Delft3D FM User Manual . J \u00b6 K \u00b6 L \u00b6 Lateral \u00b6 Lateral discharge in D-Flow FM , which acts as a source (or sink) of volume. Defined in the external forcings file . The actual forcing data may come from timeseries in a .bc file or from RR a coupled/integrated model. More details in the Delft3D FM User Manual . M \u00b6 Map file \u00b6 Output file of D-Flow FM containing the model results on all grid points. More details in the Delft3D FM User Manual . MDU file \u00b6 Main input file of D-Flow FM . Format is INI-like. More details in the Delft3D FM User Manual . meteo \u00b6 Meteorological forcings of a model. Typically sources (or sinks) of volume via precipitation and evaporation, or forcing via wind. For D-Flow FM defined in the external forcings file . More details in the Delft3D FM User Manual . mesh \u00b6 See grid . N \u00b6 Net file \u00b6 Or grid file. Input file for D-Flow FM containing the computational model grid. Format is NetCDF, adhering to CF - and UGRID -conventions, and optionally also the Deltares-extension for 1D network topology and geometry. NetCDF \u00b6 File format used by HYDROLIB-core and Delft3D Flexible Mesh for the model input grid and for model results in output files. These files typically adhere to the CF conventions and sometimes UGRID conventions . Node (mesh) \u00b6 A geometrical \"point\" in a 1D, 2D or 3D mesh. Defined by x- and y-coordinate, in 3D also a z-coordinate. Can be connected by mesh edges , and can form the vertices of a mesh face . Building block of the UGRID-conventions . O \u00b6 Observation files \u00b6 Files that define the model locations for which output should be produced in the his file . Two types: observation point file and observation cross section file . Observation cross section file \u00b6 Input file for D-Flow FM that describes the model locations for which (cumulative) flow \"flux\" output should be produced in the his file . For example: cumulative discharge, salinity transport. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual . Observation point file \u00b6 Input file for D-Flow FM that describes the model point locations for which local output should be produced in the his file . For example: waterlevel, velocity vector/magnitude, tracer concentration as instantanous values. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual . P \u00b6 Polyline file \u00b6 File containing a sequence of polylines in model coordinates. Each polyline has header lines with a label and row+column count, and at least a list of x, y-points. More than 2 columns may be present (z, data1, ...) for particular model inputs, see for example the fixed weir file . More details in the Delft3D FM User Manual . Polygon file \u00b6 See polyline file . The point sequences are interpreted as closed polygons. Q \u00b6 R \u00b6 Rainfall runoff \u00b6 RR for short. The computational backend that solves lumped rainfall runoff, offering various runoff concepts. Toplevel input is the sobek_3b.fnm file. Part of the D-Hydrology software module. More details on: https://www.deltares.nl/en/software/module/d-hydrology. Real Time Control \u00b6 RTC for short. The computational backend for real-time control of hydraulic model components (typically hydraulic structures). Toplevel input is in various rtc*.xml files. Part of the D-Real Time Control software module. More details on: https://www.deltares.nl/en/software/module/d-real-time-control. Roughness file \u00b6 Input file for D-Flow FM describing roughness values on the 1D network. Format is INI-like. More details in the Delft3D FM User Manual . S \u00b6 Sample file \u00b6 File containing an unstructured set of sample point values. Typically used as input file for initial fields or other spatially varying fields in the initial fields file . More details in the Delft3D FM User Manual . Staggered grid \u00b6 Discretization method used in D-Flow FM where the PDE variables are not all defined on the same topological grid locations. Water level, concentrations and other volume-related variables are defined on the pressure points (also: flow nodes ), and the fluxes and other transport-related variables are defined on the velocity points (also: flow links ). Structure file \u00b6 Input file for D-Flow FM containing the hydraulic structures. Format is INI-like. More details in the Delft3D FM User Manual . T \u00b6 U \u00b6 UGRID conventions \u00b6 Metadata conventions for storing unstructured grids in NetCDF files. More details on: http://ugrid-conventions.github.io/ugrid-conventions/. V \u00b6 volume (mesh) \u00b6 A geometrical \"cell\" in a 3D mesh. Formed by 4 or more mesh nodes as its vertices (or: 4 or more mesh faces as its \"sides\"). Building block of the UGRID-conventions . W \u00b6 X \u00b6 XYZ file \u00b6 See sample file . Y \u00b6 Z \u00b6","title":"Glossary"},{"location":"reference/glossary/#glossary","text":"The list below is a nonexhaustive list of terminology and concepts used in HYDROLIB(-core) and Delft3D Flexible Mesh.","title":"Glossary"},{"location":"reference/glossary/#a","text":"","title":"A"},{"location":"reference/glossary/#b","text":"","title":"B"},{"location":"reference/glossary/#bc-file","text":"Input file containing the actual forcing data for model forcings specified elsewhere in the model input, for example time series or astronomical components. Originates from boundary conditions as specified in the external forcings file , but nowadays also used in structure files . More details about the syntax and the various supported function types in the Delft3D FM User Manual .","title":"BC file"},{"location":"reference/glossary/#boundary-condition","text":"Flow (or constituent) boundary condition that forces a D-Flow FM model, such as waterlevel and discharge boundary conditions. Defined in the external forcings file . More details in the Delft3D FM User Manual .","title":"Boundary condition"},{"location":"reference/glossary/#branch","text":"The network edges in a network topology of 1D models. The computational grid points are positioned on these branches using branch id and a chainage value.","title":"Branch"},{"location":"reference/glossary/#branch-id","text":"Identification text string for a particular branch in a 1D network.","title":"Branch Id"},{"location":"reference/glossary/#c","text":"","title":"C"},{"location":"reference/glossary/#chainage","text":"The distance along a 1D network branch to define a specific location on that branch. Always used in combination with a branch Id .","title":"Chainage"},{"location":"reference/glossary/#cf-conventions","text":"Established metadata conventions for storing all kinds of data, e.g., model input and output, in NetCDF files. More details on: https://cfconventions.org/. HYDROLIB-core and Delft3D Flexible Mesh rely on CF, and extend this with UGRID conventions where unstructured grids are applicable.","title":"CF conventions"},{"location":"reference/glossary/#computational-backend","text":"Computational core, also called kernel. The program/library of simulation software that does the actual calculations. Often also available with a graphical user interface on top of it.","title":"Computational backend"},{"location":"reference/glossary/#cross-section-files","text":"Input files for D-Flow FM that define the 1D network's cross sections. Two parts: cross section definition file and cross section location files . Not to be confused with observation cross section files !","title":"Cross section files"},{"location":"reference/glossary/#cross-section-definition-file","text":"Input file for D-Flow FM that defines the various cross section shapes in a model with a 1D network. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Cross section definition file"},{"location":"reference/glossary/#cross-section-location-file","text":"Input file for D-Flow FM that defines the location of cross section shapes in a model with a 1D network. Each location refers to a (possible shared) cross section definition . Format is INI-like. More details in the Delft3D FM User Manual .","title":"Cross section location file"},{"location":"reference/glossary/#d","text":"","title":"D"},{"location":"reference/glossary/#deltares-conventions","text":"A proposal for additional NetCDF conventions that build on the existing UGRID conventions , intended to properly describe 1D network topologies as a coordinate space on which 1D computational grids are defined. Also 1D2D grid couplings are included. More details in: the Delft3D FM User Manual .","title":"Deltares conventions"},{"location":"reference/glossary/#d-flow-fm","text":"D-Flow Flexible Mesh. The computational backend that solves 1D/2D/3D hydrodynamics in the Delf3D Flexible Mesh Suite. Toplevel input is the MDU file . More details in the Delft3D FM User Manual .","title":"D-Flow FM"},{"location":"reference/glossary/#d-hydro-suite-1d2d-beta","text":"Integral software suite for hydraulic 1D2D modelling, including rainfall runoff and realtime control. More details on: https://www.deltares.nl/nl/d-hydro-suite-1d2d-beta/.","title":"D-HYDRO Suite 1D2D (Beta)"},{"location":"reference/glossary/#dimr","text":"Deltares Integrated Model Runner. Executable/library that runs integrated models by coupling multiple computational backends in a simulation timeloop. Uses a single DIMR config file as input.","title":"DIMR"},{"location":"reference/glossary/#dimr-config-file","text":"Input file for DIMR (typically dimr_config.xml ) for an integrated model run, describing which models are coupled and which quantities need to be exchanged.","title":"DIMR config file"},{"location":"reference/glossary/#e","text":"","title":"E"},{"location":"reference/glossary/#edge-mesh","text":"A geometrical \"line\" in a 1D, 2D or 3D mesh. Connects two mesh nodes as its end points. Building block of the UGRID-conventions .","title":"Edge (mesh)"},{"location":"reference/glossary/#external-forcings-file","text":"Input file for D-Flow FM describing model forcings such as boundary conditions , laterals and meteo . Format is INI-like. More details in the Delft3D FM User Manual .","title":"External forcings file"},{"location":"reference/glossary/#f","text":"","title":"F"},{"location":"reference/glossary/#face-mesh","text":"A geometrical \"cell\" in a 2D mesh. Formed by 3 or more mesh nodes as its vertices. Building block of the UGRID-conventions .","title":"Face (mesh)"},{"location":"reference/glossary/#flow-link","text":"An open connection/interface between two flow nodes in the staggered D-Flow FM model grid. Is the same as a \"velocity point\", and corresponds with (but is not equal to) an edge , both in 1D and in 2D. In 3D a flow link corresponds with a 3D face between two volumes .","title":"Flow link"},{"location":"reference/glossary/#flow-node","text":"A single finite volume \"cell\" in the staggered D-Flow FM model grid. Is the same as a \"pressure point\", and is in fact a face in 2D/3D or a node in 1D.","title":"Flow node"},{"location":"reference/glossary/#g","text":"","title":"G"},{"location":"reference/glossary/#grid","text":"The computational grid on which a flow simulation is done. The grid for D-Flow FM is defined in an input net file , and also appears (slightly differently) in the output map file .","title":"Grid"},{"location":"reference/glossary/#grid-snapping","text":"The snapping of D-Flow FM model input in x,y-coordinates to discrete locations in the staggered model grid . This process makes most model input independent of the chosen model grid and grid resolution. Snapping is done either to (sets of) flow nodes or (sequence of) flow links , depending on whether pressure-point data or velocity-point data is concerned.","title":"Grid snapping"},{"location":"reference/glossary/#h","text":"","title":"H"},{"location":"reference/glossary/#his-file","text":"Output file of D-Flow FM containing model results as time series on a specific set of discrete locations, which are typically the hydraulic structures, observation stations and more. More details in the Delft3D FM User Manual .","title":"His file"},{"location":"reference/glossary/#i","text":"","title":"I"},{"location":"reference/glossary/#integrated-model","text":"Model consisting of more than one model. Typically used when multiple computational backends are coupled, for example D-Flow FM and Rainfall Runoff or D-Flow FM and Real Time Control . Integrated models can be run using the Deltares Integrated Model Runner (DIMR) .","title":"Integrated model"},{"location":"reference/glossary/#ini-files","text":"Delft3D FM uses several input files that are formatted in an INI-like syntax. The abstract syntax depends on the particular file type, see: cross section files , initial field file , external forcings file , MDU file , observation files , rougness file , structure file .","title":"INI-files"},{"location":"reference/glossary/#initial-field-file","text":"Input file for D-Flow FM describing initial conditions and other spatially varying parameter fields. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Initial field file"},{"location":"reference/glossary/#j","text":"","title":"J"},{"location":"reference/glossary/#k","text":"","title":"K"},{"location":"reference/glossary/#l","text":"","title":"L"},{"location":"reference/glossary/#lateral","text":"Lateral discharge in D-Flow FM , which acts as a source (or sink) of volume. Defined in the external forcings file . The actual forcing data may come from timeseries in a .bc file or from RR a coupled/integrated model. More details in the Delft3D FM User Manual .","title":"Lateral"},{"location":"reference/glossary/#m","text":"","title":"M"},{"location":"reference/glossary/#map-file","text":"Output file of D-Flow FM containing the model results on all grid points. More details in the Delft3D FM User Manual .","title":"Map file"},{"location":"reference/glossary/#mdu-file","text":"Main input file of D-Flow FM . Format is INI-like. More details in the Delft3D FM User Manual .","title":"MDU file"},{"location":"reference/glossary/#meteo","text":"Meteorological forcings of a model. Typically sources (or sinks) of volume via precipitation and evaporation, or forcing via wind. For D-Flow FM defined in the external forcings file . More details in the Delft3D FM User Manual .","title":"meteo"},{"location":"reference/glossary/#mesh","text":"See grid .","title":"mesh"},{"location":"reference/glossary/#n","text":"","title":"N"},{"location":"reference/glossary/#net-file","text":"Or grid file. Input file for D-Flow FM containing the computational model grid. Format is NetCDF, adhering to CF - and UGRID -conventions, and optionally also the Deltares-extension for 1D network topology and geometry.","title":"Net file"},{"location":"reference/glossary/#netcdf","text":"File format used by HYDROLIB-core and Delft3D Flexible Mesh for the model input grid and for model results in output files. These files typically adhere to the CF conventions and sometimes UGRID conventions .","title":"NetCDF"},{"location":"reference/glossary/#node-mesh","text":"A geometrical \"point\" in a 1D, 2D or 3D mesh. Defined by x- and y-coordinate, in 3D also a z-coordinate. Can be connected by mesh edges , and can form the vertices of a mesh face . Building block of the UGRID-conventions .","title":"Node (mesh)"},{"location":"reference/glossary/#o","text":"","title":"O"},{"location":"reference/glossary/#observation-files","text":"Files that define the model locations for which output should be produced in the his file . Two types: observation point file and observation cross section file .","title":"Observation files"},{"location":"reference/glossary/#observation-cross-section-file","text":"Input file for D-Flow FM that describes the model locations for which (cumulative) flow \"flux\" output should be produced in the his file . For example: cumulative discharge, salinity transport. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Observation cross section file"},{"location":"reference/glossary/#observation-point-file","text":"Input file for D-Flow FM that describes the model point locations for which local output should be produced in the his file . For example: waterlevel, velocity vector/magnitude, tracer concentration as instantanous values. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Observation point file"},{"location":"reference/glossary/#p","text":"","title":"P"},{"location":"reference/glossary/#polyline-file","text":"File containing a sequence of polylines in model coordinates. Each polyline has header lines with a label and row+column count, and at least a list of x, y-points. More than 2 columns may be present (z, data1, ...) for particular model inputs, see for example the fixed weir file . More details in the Delft3D FM User Manual .","title":"Polyline file"},{"location":"reference/glossary/#polygon-file","text":"See polyline file . The point sequences are interpreted as closed polygons.","title":"Polygon file"},{"location":"reference/glossary/#q","text":"","title":"Q"},{"location":"reference/glossary/#r","text":"","title":"R"},{"location":"reference/glossary/#rainfall-runoff","text":"RR for short. The computational backend that solves lumped rainfall runoff, offering various runoff concepts. Toplevel input is the sobek_3b.fnm file. Part of the D-Hydrology software module. More details on: https://www.deltares.nl/en/software/module/d-hydrology.","title":"Rainfall runoff"},{"location":"reference/glossary/#real-time-control","text":"RTC for short. The computational backend for real-time control of hydraulic model components (typically hydraulic structures). Toplevel input is in various rtc*.xml files. Part of the D-Real Time Control software module. More details on: https://www.deltares.nl/en/software/module/d-real-time-control.","title":"Real Time Control"},{"location":"reference/glossary/#roughness-file","text":"Input file for D-Flow FM describing roughness values on the 1D network. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Roughness file"},{"location":"reference/glossary/#s","text":"","title":"S"},{"location":"reference/glossary/#sample-file","text":"File containing an unstructured set of sample point values. Typically used as input file for initial fields or other spatially varying fields in the initial fields file . More details in the Delft3D FM User Manual .","title":"Sample file"},{"location":"reference/glossary/#staggered-grid","text":"Discretization method used in D-Flow FM where the PDE variables are not all defined on the same topological grid locations. Water level, concentrations and other volume-related variables are defined on the pressure points (also: flow nodes ), and the fluxes and other transport-related variables are defined on the velocity points (also: flow links ).","title":"Staggered grid"},{"location":"reference/glossary/#structure-file","text":"Input file for D-Flow FM containing the hydraulic structures. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Structure file"},{"location":"reference/glossary/#t","text":"","title":"T"},{"location":"reference/glossary/#u","text":"","title":"U"},{"location":"reference/glossary/#ugrid-conventions","text":"Metadata conventions for storing unstructured grids in NetCDF files. More details on: http://ugrid-conventions.github.io/ugrid-conventions/.","title":"UGRID conventions"},{"location":"reference/glossary/#v","text":"","title":"V"},{"location":"reference/glossary/#volume-mesh","text":"A geometrical \"cell\" in a 3D mesh. Formed by 4 or more mesh nodes as its vertices (or: 4 or more mesh faces as its \"sides\"). Building block of the UGRID-conventions .","title":"volume (mesh)"},{"location":"reference/glossary/#w","text":"","title":"W"},{"location":"reference/glossary/#x","text":"","title":"X"},{"location":"reference/glossary/#xyz-file","text":"See sample file .","title":"XYZ file"},{"location":"reference/glossary/#y","text":"","title":"Y"},{"location":"reference/glossary/#z","text":"","title":"Z"},{"location":"reference/ini/","text":"ini \u00b6 The ini module provides the generic logic for parsing Deltares ini based files, such as the mdu, structures files, as well as more complex files such as the boundary condition (bc) files. Model \u00b6 DataBlockINIBasedModel ( INIBasedModel ) pydantic-model \u00b6 DataBlockINIBasedModel defines the base model for ini models with datablocks. INIBasedModel ( BaseModel , ABC ) pydantic-model \u00b6 INIBasedModel defines the base model for ini models INIBasedModel instances can be created from Section instances obtained through parsing ini documents. It further supports adding arbitrary fields to it, which will be written to file. Lastly, no arbitrary types are allowed for the defined fields. Attributes: Name Type Description comments Optional[Comments] Optional Comments if defined by the user. Comments ( BaseModel , ABC ) pydantic-model \u00b6 Comments defines the comments of an INIBasedModel INIModel ( FileModel ) pydantic-model \u00b6 INI Model representation. Parser \u00b6 Parser \u00b6 Parser defines a generic Parser for Deltares ini files. The Parser can be configured with a ParserConfig object. __init__ ( self , config : ParserConfig ) -> None special \u00b6 Creates a new Parser configured with the provided config Parameters: Name Type Description Default config ParserConfig The configuration of this Parser required Source code in hydrolib/core/io/ini/parser.py def __init__ ( self , config : ParserConfig ) -> None : \"\"\"Creates a new Parser configured with the provided config Args: config (ParserConfig): The configuration of this Parser \"\"\" self . _config = config self . _document = Document () self . _current_section : Optional [ _IntermediateSection ] = None self . _current_header_block : Optional [ _IntermediateCommentBlock ] = None self . _state = self . _StateType . NO_SECTION_FOUND self . _line_index = 0 # TODO add invalid blocks self . _feed_line : Dict [ Parser . _StateType , List [ Tuple [ Callable [[ str ], bool ], Callable [[ str ], None ]]] ] = { Parser . _StateType . NO_SECTION_FOUND : [ ( self . _is_comment , self . _handle_header_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ], Parser . _StateType . PARSING_PROPERTIES : [ ( self . _is_comment , self . _handle_section_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_property , self . _handle_property ), ( self . _is_datarow , self . _handle_new_datarow ), ], Parser . _StateType . PARSING_DATABLOCK : [ ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_datarow , self . _handle_datarow ), ], } self . _handle_emptyline : Dict [ Parser . _StateType , Callable [[], None ]] = { self . _StateType . NO_SECTION_FOUND : self . _finish_current_header_block , self . _StateType . PARSING_PROPERTIES : self . _noop , self . _StateType . PARSING_DATABLOCK : self . _noop , } feed_line ( self , line : str ) -> None \u00b6 Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/ini/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not self . _is_empty_line ( line ): for ( is_line_type , handle_line_type ) in self . _feed_line [ self . _state ]: if is_line_type ( line ): handle_line_type ( line ) break else : # handle exception pass else : self . _handle_emptyline [ self . _state ]() self . _increment_line () finalize ( self ) -> Document \u00b6 Finalize parsing and return the constructed Document. Returns: Type Description Document A Document describing the parsed ini file. Source code in hydrolib/core/io/ini/parser.py def finalize ( self ) -> Document : \"\"\"Finalize parsing and return the constructed Document. Returns: Document: A Document describing the parsed ini file. \"\"\" # TODO handle invalid block self . _finish_current_header_block () self . _finalise_current_section () return self . _document ParserConfig ( BaseModel ) pydantic-model \u00b6 ParserConfig defines the configuration options of the Parser Note that we cannot set both allow_only_keywords and parse_datablocks to True because we cannot distinguish between datablocks and key only properties. As such this will lead to a validation error. Attributes: Name Type Description allow_only_keywords bool Whether to allow properties with only keys (no '=' or value). Defaults to True. parse_datablocks bool Whether to allow parsing of datablocks at the bottom of sections. Defaults to False. parse_comments bool Whether we allow parsing of comments defined with the comment_delimeter. Defaults to True. comment_delimiter str The character or sequence of character used to define a comment. Defaults to '#'. Serializer \u00b6 MaxLengths ( BaseModel ) pydantic-model \u00b6 MaxLengths defines the maxmimum lengths of the parts of a section Attributes: Name Type Description key int The maximum length of all the keys of the properties within a section. If no properties are present it should be 0. value int The maximum length of all the non None values of the properties within a section. If no properties are present, or all values are None, it should be 0. datablock Optional[Sequence[int]] The maximum length of the values of each column of the Datablock. If no datablock is present it defaults to None. from_section ( section : Section ) -> MaxLengths classmethod \u00b6 Generate a MaxLengths instance from the given Section Parameters: Name Type Description Default section Section The section of which the MaxLengths are calculated required Returns: Type Description MaxLengths The MaxLengths corresponding with the provided section Source code in hydrolib/core/io/ini/serializer.py @classmethod def from_section ( cls , section : Section ) -> \"MaxLengths\" : \"\"\"Generate a MaxLengths instance from the given Section Args: section (Section): The section of which the MaxLengths are calculated Returns: MaxLengths: The MaxLengths corresponding with the provided section \"\"\" properties = list ( p for p in section . content if isinstance ( p , Property )) keys = ( prop . key for prop in properties ) values = ( prop . value for prop in properties if prop . value is not None ) max_key_length = max (( len ( k ) for k in keys ), default = 0 ) max_value_length = max (( len ( v ) for v in values ), default = 0 ) max_datablock_lengths = MaxLengths . _of_datablock ( section . datablock ) return cls ( key = max_key_length , value = max_value_length , datablock = max_datablock_lengths , ) SectionSerializer \u00b6 SectionSerializer provides the serialize method to serialize a Section The entrypoint of this method is the serialize method, which will construct an actual instance and serializes the Section with it. __init__ ( self , config : SerializerConfig , max_length : MaxLengths ) special \u00b6 Create a new SectionSerializer Parameters: Name Type Description Default config SerializerConfig The config describing the serialization options required max_length MaxLengths The max lengths of the section being serialized required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig , max_length : MaxLengths ): \"\"\"Create a new SectionSerializer Args: config (SerializerConfig): The config describing the serialization options max_length (MaxLengths): The max lengths of the section being serialized \"\"\" self . _config = config self . _max_length = max_length config : SerializerConfig property readonly \u00b6 The SerializerConfig used while serializing the section. max_length : MaxLengths property readonly \u00b6 The MaxLengths of the Section being serialized by this SectionSerializer. serialize ( section : Section , config : SerializerConfig ) -> Iterable [ str ] classmethod \u00b6 Serialize the provided section with the given config Parameters: Name Type Description Default section Section The section to serialize required config SerializerConfig The config describing the serialization options required Returns: Type Description Lines The iterable lines of the serialized section Source code in hydrolib/core/io/ini/serializer.py @classmethod def serialize ( cls , section : Section , config : SerializerConfig ) -> Lines : \"\"\"Serialize the provided section with the given config Args: section (Section): The section to serialize config (SerializerConfig): The config describing the serialization options Returns: Lines: The iterable lines of the serialized section \"\"\" serializer = cls ( config , MaxLengths . from_section ( section )) return serializer . _serialize_section ( section ) Serializer \u00b6 Serializer serializes Document to its corresponding lines. __init__ ( self , config : SerializerConfig ) special \u00b6 Creates a new Serializer with the provided configuration. Parameters: Name Type Description Default config SerializerConfig The configuration of this Serializer. required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig ): \"\"\"Creates a new Serializer with the provided configuration. Args: config (SerializerConfig): The configuration of this Serializer. \"\"\" self . _config = config serialize ( self , document : Document ) -> Iterable [ str ] \u00b6 Serialize the provided document into an iterable of lines. Parameters: Name Type Description Default document Document The Document to serialize. required Returns: Type Description Lines An iterable returning each line of the serialized Document. Source code in hydrolib/core/io/ini/serializer.py def serialize ( self , document : Document ) -> Lines : \"\"\"Serialize the provided document into an iterable of lines. Args: document (Document): The Document to serialize. Returns: Lines: An iterable returning each line of the serialized Document. \"\"\" header_iterable = self . _serialize_document_header ( document . header_comment ) serialize_section = lambda s : SectionSerializer . serialize ( s , self . _config ) sections = ( serialize_section ( section ) for section in document . sections ) sections_with_spacing = Serializer . _interweave ( sections , [ \"\" ]) sections_iterable = chain . from_iterable ( sections_with_spacing ) return chain ( header_iterable , sections_iterable ) SerializerConfig ( BaseModel ) pydantic-model \u00b6 SerializerConfig defines the configuration options of the Serializer Attributes: Name Type Description section_indent int The number of spaces with which whole sections should be indented. Defaults to 0. property_indent int The number of spaces with which properties should be indented relative to the section header (i.e. the full indent equals the section_indent plus property_indent). Defaults to 4. datablock_indent int The number of spaces with which datablock rows are indented relative to the section header (i.e. the full indent equals the section_indent plus datablock_indent). Defaults to 8. datablock_spacing int The number of spaces between datablock columns. Note that there might be additional offset to ensure . is lined out. Defaults to 4. comment_delimiter str The character used to delimit comments. Defaults to '#'. total_datablock_indent : int property readonly \u00b6 The combined datablock indentation, i.e. section_indent + datablock_indent total_property_indent : int property readonly \u00b6 The combined property indentation, i.e. section_indent + property_indent write_ini ( path : Path , document : Document , config : Optional [ hydrolib . core . io . ini . serializer . SerializerConfig ] = None ) -> None \u00b6 Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Parameters: Name Type Description Default path Path The path to which the document should be written. required document Document The document to serialize to the specified path. required config Optional[SerializerConfig] An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. None Source code in hydrolib/core/io/ini/serializer.py def write_ini ( path : Path , document : Document , config : Optional [ SerializerConfig ] = None , ) -> None : \"\"\"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Args: path (Path): The path to which the document should be written. document (Document): The document to serialize to the specified path. config (Optional[SerializerConfig], optional): An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. \"\"\" if config is None : config = SerializerConfig () serializer = Serializer ( config ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serializer . serialize ( document ): f . write ( line + \" \\n \" )","title":"Ini"},{"location":"reference/ini/#ini","text":"The ini module provides the generic logic for parsing Deltares ini based files, such as the mdu, structures files, as well as more complex files such as the boundary condition (bc) files.","title":"ini"},{"location":"reference/ini/#model","text":"","title":"Model"},{"location":"reference/ini/#hydrolib.core.io.ini.models.DataBlockINIBasedModel","text":"DataBlockINIBasedModel defines the base model for ini models with datablocks.","title":"DataBlockINIBasedModel"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIBasedModel","text":"INIBasedModel defines the base model for ini models INIBasedModel instances can be created from Section instances obtained through parsing ini documents. It further supports adding arbitrary fields to it, which will be written to file. Lastly, no arbitrary types are allowed for the defined fields. Attributes: Name Type Description comments Optional[Comments] Optional Comments if defined by the user.","title":"INIBasedModel"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIBasedModel.Comments","text":"Comments defines the comments of an INIBasedModel","title":"Comments"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIModel","text":"INI Model representation.","title":"INIModel"},{"location":"reference/ini/#parser","text":"","title":"Parser"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser","text":"Parser defines a generic Parser for Deltares ini files. The Parser can be configured with a ParserConfig object.","title":"Parser"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.__init__","text":"Creates a new Parser configured with the provided config Parameters: Name Type Description Default config ParserConfig The configuration of this Parser required Source code in hydrolib/core/io/ini/parser.py def __init__ ( self , config : ParserConfig ) -> None : \"\"\"Creates a new Parser configured with the provided config Args: config (ParserConfig): The configuration of this Parser \"\"\" self . _config = config self . _document = Document () self . _current_section : Optional [ _IntermediateSection ] = None self . _current_header_block : Optional [ _IntermediateCommentBlock ] = None self . _state = self . _StateType . NO_SECTION_FOUND self . _line_index = 0 # TODO add invalid blocks self . _feed_line : Dict [ Parser . _StateType , List [ Tuple [ Callable [[ str ], bool ], Callable [[ str ], None ]]] ] = { Parser . _StateType . NO_SECTION_FOUND : [ ( self . _is_comment , self . _handle_header_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ], Parser . _StateType . PARSING_PROPERTIES : [ ( self . _is_comment , self . _handle_section_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_property , self . _handle_property ), ( self . _is_datarow , self . _handle_new_datarow ), ], Parser . _StateType . PARSING_DATABLOCK : [ ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_datarow , self . _handle_datarow ), ], } self . _handle_emptyline : Dict [ Parser . _StateType , Callable [[], None ]] = { self . _StateType . NO_SECTION_FOUND : self . _finish_current_header_block , self . _StateType . PARSING_PROPERTIES : self . _noop , self . _StateType . PARSING_DATABLOCK : self . _noop , }","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.feed_line","text":"Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/ini/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not self . _is_empty_line ( line ): for ( is_line_type , handle_line_type ) in self . _feed_line [ self . _state ]: if is_line_type ( line ): handle_line_type ( line ) break else : # handle exception pass else : self . _handle_emptyline [ self . _state ]() self . _increment_line ()","title":"feed_line()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.finalize","text":"Finalize parsing and return the constructed Document. Returns: Type Description Document A Document describing the parsed ini file. Source code in hydrolib/core/io/ini/parser.py def finalize ( self ) -> Document : \"\"\"Finalize parsing and return the constructed Document. Returns: Document: A Document describing the parsed ini file. \"\"\" # TODO handle invalid block self . _finish_current_header_block () self . _finalise_current_section () return self . _document","title":"finalize()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.ParserConfig","text":"ParserConfig defines the configuration options of the Parser Note that we cannot set both allow_only_keywords and parse_datablocks to True because we cannot distinguish between datablocks and key only properties. As such this will lead to a validation error. Attributes: Name Type Description allow_only_keywords bool Whether to allow properties with only keys (no '=' or value). Defaults to True. parse_datablocks bool Whether to allow parsing of datablocks at the bottom of sections. Defaults to False. parse_comments bool Whether we allow parsing of comments defined with the comment_delimeter. Defaults to True. comment_delimiter str The character or sequence of character used to define a comment. Defaults to '#'.","title":"ParserConfig"},{"location":"reference/ini/#serializer","text":"","title":"Serializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.MaxLengths","text":"MaxLengths defines the maxmimum lengths of the parts of a section Attributes: Name Type Description key int The maximum length of all the keys of the properties within a section. If no properties are present it should be 0. value int The maximum length of all the non None values of the properties within a section. If no properties are present, or all values are None, it should be 0. datablock Optional[Sequence[int]] The maximum length of the values of each column of the Datablock. If no datablock is present it defaults to None.","title":"MaxLengths"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.MaxLengths.from_section","text":"Generate a MaxLengths instance from the given Section Parameters: Name Type Description Default section Section The section of which the MaxLengths are calculated required Returns: Type Description MaxLengths The MaxLengths corresponding with the provided section Source code in hydrolib/core/io/ini/serializer.py @classmethod def from_section ( cls , section : Section ) -> \"MaxLengths\" : \"\"\"Generate a MaxLengths instance from the given Section Args: section (Section): The section of which the MaxLengths are calculated Returns: MaxLengths: The MaxLengths corresponding with the provided section \"\"\" properties = list ( p for p in section . content if isinstance ( p , Property )) keys = ( prop . key for prop in properties ) values = ( prop . value for prop in properties if prop . value is not None ) max_key_length = max (( len ( k ) for k in keys ), default = 0 ) max_value_length = max (( len ( v ) for v in values ), default = 0 ) max_datablock_lengths = MaxLengths . _of_datablock ( section . datablock ) return cls ( key = max_key_length , value = max_value_length , datablock = max_datablock_lengths , )","title":"from_section()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer","text":"SectionSerializer provides the serialize method to serialize a Section The entrypoint of this method is the serialize method, which will construct an actual instance and serializes the Section with it.","title":"SectionSerializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.__init__","text":"Create a new SectionSerializer Parameters: Name Type Description Default config SerializerConfig The config describing the serialization options required max_length MaxLengths The max lengths of the section being serialized required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig , max_length : MaxLengths ): \"\"\"Create a new SectionSerializer Args: config (SerializerConfig): The config describing the serialization options max_length (MaxLengths): The max lengths of the section being serialized \"\"\" self . _config = config self . _max_length = max_length","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.config","text":"The SerializerConfig used while serializing the section.","title":"config"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.max_length","text":"The MaxLengths of the Section being serialized by this SectionSerializer.","title":"max_length"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.serialize","text":"Serialize the provided section with the given config Parameters: Name Type Description Default section Section The section to serialize required config SerializerConfig The config describing the serialization options required Returns: Type Description Lines The iterable lines of the serialized section Source code in hydrolib/core/io/ini/serializer.py @classmethod def serialize ( cls , section : Section , config : SerializerConfig ) -> Lines : \"\"\"Serialize the provided section with the given config Args: section (Section): The section to serialize config (SerializerConfig): The config describing the serialization options Returns: Lines: The iterable lines of the serialized section \"\"\" serializer = cls ( config , MaxLengths . from_section ( section )) return serializer . _serialize_section ( section )","title":"serialize()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer","text":"Serializer serializes Document to its corresponding lines.","title":"Serializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer.__init__","text":"Creates a new Serializer with the provided configuration. Parameters: Name Type Description Default config SerializerConfig The configuration of this Serializer. required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig ): \"\"\"Creates a new Serializer with the provided configuration. Args: config (SerializerConfig): The configuration of this Serializer. \"\"\" self . _config = config","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer.serialize","text":"Serialize the provided document into an iterable of lines. Parameters: Name Type Description Default document Document The Document to serialize. required Returns: Type Description Lines An iterable returning each line of the serialized Document. Source code in hydrolib/core/io/ini/serializer.py def serialize ( self , document : Document ) -> Lines : \"\"\"Serialize the provided document into an iterable of lines. Args: document (Document): The Document to serialize. Returns: Lines: An iterable returning each line of the serialized Document. \"\"\" header_iterable = self . _serialize_document_header ( document . header_comment ) serialize_section = lambda s : SectionSerializer . serialize ( s , self . _config ) sections = ( serialize_section ( section ) for section in document . sections ) sections_with_spacing = Serializer . _interweave ( sections , [ \"\" ]) sections_iterable = chain . from_iterable ( sections_with_spacing ) return chain ( header_iterable , sections_iterable )","title":"serialize()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig","text":"SerializerConfig defines the configuration options of the Serializer Attributes: Name Type Description section_indent int The number of spaces with which whole sections should be indented. Defaults to 0. property_indent int The number of spaces with which properties should be indented relative to the section header (i.e. the full indent equals the section_indent plus property_indent). Defaults to 4. datablock_indent int The number of spaces with which datablock rows are indented relative to the section header (i.e. the full indent equals the section_indent plus datablock_indent). Defaults to 8. datablock_spacing int The number of spaces between datablock columns. Note that there might be additional offset to ensure . is lined out. Defaults to 4. comment_delimiter str The character used to delimit comments. Defaults to '#'.","title":"SerializerConfig"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig.total_datablock_indent","text":"The combined datablock indentation, i.e. section_indent + datablock_indent","title":"total_datablock_indent"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig.total_property_indent","text":"The combined property indentation, i.e. section_indent + property_indent","title":"total_property_indent"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.write_ini","text":"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Parameters: Name Type Description Default path Path The path to which the document should be written. required document Document The document to serialize to the specified path. required config Optional[SerializerConfig] An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. None Source code in hydrolib/core/io/ini/serializer.py def write_ini ( path : Path , document : Document , config : Optional [ SerializerConfig ] = None , ) -> None : \"\"\"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Args: path (Path): The path to which the document should be written. document (Document): The document to serialize to the specified path. config (Optional[SerializerConfig], optional): An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. \"\"\" if config is None : config = SerializerConfig () serializer = Serializer ( config ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serializer . serialize ( document ): f . write ( line + \" \\n \" )","title":"write_ini()"},{"location":"reference/mdu/","text":"Boundary ( INIBasedModel ) pydantic-model \u00b6 is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True ExternalForcing ( INIBasedModel ) pydantic-model \u00b6 is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True FMModel ( INIModel ) pydantic-model \u00b6 FM Model representation. Geometry ( INIBasedModel ) pydantic-model \u00b6 is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True Output ( INIBasedModel ) pydantic-model \u00b6 is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"Mdu"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Boundary","text":"","title":"Boundary"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Boundary.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.ExternalForcing","text":"","title":"ExternalForcing"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.ExternalForcing.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.FMModel","text":"FM Model representation.","title":"FMModel"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Geometry","text":"","title":"Geometry"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Geometry.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Output","text":"","title":"Output"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Output.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/net/","text":"Branch \u00b6 interpolate ( self , distance : Union [ float , np . ndarray ]) -> np . ndarray \u00b6 Interpolate coordinates along branch by length TODO: How to handle these kind of union datatypes? The array should also consist of floats \u00b6 Parameters: Name Type Description Default distance Union[float, np.ndarray] Length required Source code in hydrolib/core/io/net/models.py def interpolate ( self , distance : Union [ float , np . ndarray ]) -> np . ndarray : \"\"\"Interpolate coordinates along branch by length #TODO: How to handle these kind of union datatypes? The array should also consist of floats Args: distance (Union[float, np.ndarray]): Length \"\"\" intpcoords = np . stack ( [ np . interp ( distance , self . _distance , self . _x_coordinates ), np . interp ( distance , self . _distance , self . _y_coordinates ), ], axis = 1 , ) return intpcoords Link1d2d ( BaseModel ) pydantic-model \u00b6 clear ( self ) -> None \u00b6 Remove all saved links from the links administration Source code in hydrolib/core/io/net/models.py def clear ( self ) -> None : \"\"\"Remove all saved links from the links administration\"\"\" self . link1d2d_id = np . empty ( 0 , object ) self . link1d2d_long_name = np . empty ( 0 , object ) self . link1d2d_contact_type = np . empty ( 0 , np . int32 ) self . link1d2d = np . empty (( 0 , 2 ), np . int32 ) Mesh1d ( BaseModel ) pydantic-model \u00b6 get_node_mask ( self , branchids : List [ str ] = None ) \u00b6 Get node mask, give a mask with True for each node that is in the given branchid list Source code in hydrolib/core/io/net/models.py def get_node_mask ( self , branchids : List [ str ] = None ): \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\" mask = np . full ( self . mesh1d_node_id . shape , False , dtype = bool ) if branchids is None : mask [:] = True return mask # Get number (index) of given branches idx = np . where ( np . isin ( self . network1d_branch_id , branchids ))[ 0 ] if idx . size == 0 : raise KeyError ( \"No branches corresponding to the given keys were found.\" ) mask [ np . isin ( self . mesh1d_node_branch_id , idx )] = True return mask Mesh2d ( BaseModel ) pydantic-model \u00b6 clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ) \u00b6 Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Parameters: Name Type Description Default polygon GeometryList Polygon stored as GeometryList required deletemeshoption int [description]. Defaults to 1. 1 Source code in hydrolib/core/io/net/models.py def clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ): \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Args: polygon (GeometryList): Polygon stored as GeometryList deletemeshoption (int, optional): [description]. Defaults to 1. \"\"\" # Add current mesh to Mesh2d instance self . _set_mesh2d () # Delete outside polygon deletemeshoption = mk . DeleteMeshOption ( deletemeshoption ) parts = split_by ( polygon , - 998.0 ) # Check if parts are closed for part in parts : if not ( part . x_coordinates [ 0 ], part . y_coordinates [ 0 ]) == ( part . x_coordinates [ - 1 ], part . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) self . meshkernel . mesh2d_delete ( parts [ 0 ], deletemeshoption , True ) # Delete all holes for interior in parts [ 1 :]: self . meshkernel . mesh2d_delete ( interior , deletemeshoption , False ) # Process self . _process ( self . meshkernel . mesh2d_get ()) create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None \u00b6 Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Parameters: Name Type Description Default extent tuple Bounding box of mesh (left, bottom, right, top) required dx float Horizontal distance required dy float Vertical distance required TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Exceptions: Type Description NotImplementedError MultiPolygons Source code in hydrolib/core/io/net/models.py def create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None : \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Args: extent (tuple): Bounding box of mesh (left, bottom, right, top) dx (float): Horizontal distance dy (float): Vertical distance TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Raises: NotImplementedError: MultiPolygons \"\"\" xmin , ymin , xmax , ymax = extent # Generate mesh mesh2d_input = mk . Mesh2dFactory . create_rectilinear_mesh ( rows = int (( ymax - ymin ) / dy ), columns = int (( xmax - xmin ) / dx ), origin_x = xmin , origin_y = ymin , spacing_x = dx , spacing_y = dy , ) # Process self . _process ( mesh2d_input ) get_mesh2d ( self ) -> mk . Mesh2d \u00b6 Return mesh2d from meshkernel Source code in hydrolib/core/io/net/models.py def get_mesh2d ( self ) -> mk . Mesh2d : \"\"\"Return mesh2d from meshkernel\"\"\" return self . meshkernel . mesh2d_get () refine ( self , polygon : mk . GeometryList , level : int ) \u00b6 Refine the mesh within a polygon, by a number of steps (level) Parameters: Name Type Description Default polygon GeometryList Polygon in which to refine required level int Number of refinement steps required Source code in hydrolib/core/io/net/models.py def refine ( self , polygon : mk . GeometryList , level : int ): \"\"\"Refine the mesh within a polygon, by a number of steps (level) Args: polygon (GeometryList): Polygon in which to refine level (int): Number of refinement steps \"\"\" # Add current mesh to Mesh2d instance mesh2d_input = mk . Mesh2d ( node_x = self . mesh2d_node_x , node_y = self . mesh2d_node_y , edge_nodes = self . mesh2d_edge_nodes . ravel (), ) self . meshkernel . mesh2d_set ( mesh2d_input ) # Check if parts are closed if not ( polygon . x_coordinates [ 0 ], polygon . y_coordinates [ 0 ]) == ( polygon . x_coordinates [ - 1 ], polygon . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) parameters = mk . MeshRefinementParameters ( refine_intersected = True , use_mass_center_when_refining = False , min_face_size = 10.0 , # Does nothing? refinement_type = 1 , connect_hanging_nodes = True , account_for_samples_outside_face = False , max_refinement_iterations = level , ) self . meshkernel . mesh2d_refine_based_on_polygon ( polygon , parameters ) # Process self . _process ( self . meshkernel . mesh2d_get ()) Network \u00b6 from_file ( file_path : Path ) -> Network classmethod \u00b6 Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Parameters: Name Type Description Default file Path path to netcdf file with network data required Returns: Type Description Network The instance of the class itself that is returned Source code in hydrolib/core/io/net/models.py @classmethod def from_file ( cls , file_path : Path ) -> Network : \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Args: file (Path): path to netcdf file with network data Returns: Network: The instance of the class itself that is returned \"\"\" network = cls () ds = nc . Dataset ( file_path ) # type: ignore[import] reader = UgridReader ( file_path ) if reader . _explorer . mesh1d_key is not None : reader . read_mesh1d_network1d ( network . _mesh1d ) if reader . _explorer . mesh2d_key is not None : reader . read_mesh2d ( network . _mesh2d ) if reader . _explorer . link1d2d_key is not None : reader . read_link1d2d ( network . _link1d2d ) ds . close () return network to_file ( self , file : Path ) -> None \u00b6 Write network to file Parameters: Name Type Description Default file Path File where _net.nc is written to. required Source code in hydrolib/core/io/net/models.py def to_file ( self , file : Path ) -> None : \"\"\"Write network to file Args: file (Path): File where _net.nc is written to. \"\"\" writer = UgridWriter () writer . write ( self , file ) NetworkModel ( FileModel ) pydantic-model \u00b6 Network model representation. split_by ( gl : mk . GeometryList , by : float ) -> list \u00b6 Function to split mk.GeometryList by seperator. Source code in hydrolib/core/io/net/models.py def split_by ( gl : mk . GeometryList , by : float ) -> list : \"\"\"Function to split mk.GeometryList by seperator.\"\"\" x , y = gl . x_coordinates . copy (), gl . y_coordinates . copy () idx = np . where ( x == by )[ 0 ] xparts = np . split ( x , idx ) yparts = np . split ( y , idx ) lists = [ mk . GeometryList ( xp [ min ( i , 1 ) :], yp [ min ( i , 1 ) :]) for i , ( xp , yp ) in enumerate ( zip ( xparts , yparts )) ] return lists","title":"Net"},{"location":"reference/net/#hydrolib.core.io.net.models.Branch","text":"","title":"Branch"},{"location":"reference/net/#hydrolib.core.io.net.models.Branch.interpolate","text":"Interpolate coordinates along branch by length","title":"interpolate()"},{"location":"reference/net/#hydrolib.core.io.net.models.Branch.interpolate--todo-how-to-handle-these-kind-of-union-datatypes-the-array-should-also-consist-of-floats","text":"Parameters: Name Type Description Default distance Union[float, np.ndarray] Length required Source code in hydrolib/core/io/net/models.py def interpolate ( self , distance : Union [ float , np . ndarray ]) -> np . ndarray : \"\"\"Interpolate coordinates along branch by length #TODO: How to handle these kind of union datatypes? The array should also consist of floats Args: distance (Union[float, np.ndarray]): Length \"\"\" intpcoords = np . stack ( [ np . interp ( distance , self . _distance , self . _x_coordinates ), np . interp ( distance , self . _distance , self . _y_coordinates ), ], axis = 1 , ) return intpcoords","title":"TODO: How to handle these kind of union datatypes? The array should also consist of floats"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d","text":"","title":"Link1d2d"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d.clear","text":"Remove all saved links from the links administration Source code in hydrolib/core/io/net/models.py def clear ( self ) -> None : \"\"\"Remove all saved links from the links administration\"\"\" self . link1d2d_id = np . empty ( 0 , object ) self . link1d2d_long_name = np . empty ( 0 , object ) self . link1d2d_contact_type = np . empty ( 0 , np . int32 ) self . link1d2d = np . empty (( 0 , 2 ), np . int32 )","title":"clear()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh1d","text":"","title":"Mesh1d"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh1d.get_node_mask","text":"Get node mask, give a mask with True for each node that is in the given branchid list Source code in hydrolib/core/io/net/models.py def get_node_mask ( self , branchids : List [ str ] = None ): \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\" mask = np . full ( self . mesh1d_node_id . shape , False , dtype = bool ) if branchids is None : mask [:] = True return mask # Get number (index) of given branches idx = np . where ( np . isin ( self . network1d_branch_id , branchids ))[ 0 ] if idx . size == 0 : raise KeyError ( \"No branches corresponding to the given keys were found.\" ) mask [ np . isin ( self . mesh1d_node_branch_id , idx )] = True return mask","title":"get_node_mask()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d","text":"","title":"Mesh2d"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.clip","text":"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Parameters: Name Type Description Default polygon GeometryList Polygon stored as GeometryList required deletemeshoption int [description]. Defaults to 1. 1 Source code in hydrolib/core/io/net/models.py def clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ): \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Args: polygon (GeometryList): Polygon stored as GeometryList deletemeshoption (int, optional): [description]. Defaults to 1. \"\"\" # Add current mesh to Mesh2d instance self . _set_mesh2d () # Delete outside polygon deletemeshoption = mk . DeleteMeshOption ( deletemeshoption ) parts = split_by ( polygon , - 998.0 ) # Check if parts are closed for part in parts : if not ( part . x_coordinates [ 0 ], part . y_coordinates [ 0 ]) == ( part . x_coordinates [ - 1 ], part . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) self . meshkernel . mesh2d_delete ( parts [ 0 ], deletemeshoption , True ) # Delete all holes for interior in parts [ 1 :]: self . meshkernel . mesh2d_delete ( interior , deletemeshoption , False ) # Process self . _process ( self . meshkernel . mesh2d_get ())","title":"clip()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.create_rectilinear","text":"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Parameters: Name Type Description Default extent tuple Bounding box of mesh (left, bottom, right, top) required dx float Horizontal distance required dy float Vertical distance required TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Exceptions: Type Description NotImplementedError MultiPolygons Source code in hydrolib/core/io/net/models.py def create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None : \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Args: extent (tuple): Bounding box of mesh (left, bottom, right, top) dx (float): Horizontal distance dy (float): Vertical distance TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Raises: NotImplementedError: MultiPolygons \"\"\" xmin , ymin , xmax , ymax = extent # Generate mesh mesh2d_input = mk . Mesh2dFactory . create_rectilinear_mesh ( rows = int (( ymax - ymin ) / dy ), columns = int (( xmax - xmin ) / dx ), origin_x = xmin , origin_y = ymin , spacing_x = dx , spacing_y = dy , ) # Process self . _process ( mesh2d_input )","title":"create_rectilinear()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.get_mesh2d","text":"Return mesh2d from meshkernel Source code in hydrolib/core/io/net/models.py def get_mesh2d ( self ) -> mk . Mesh2d : \"\"\"Return mesh2d from meshkernel\"\"\" return self . meshkernel . mesh2d_get ()","title":"get_mesh2d()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.refine","text":"Refine the mesh within a polygon, by a number of steps (level) Parameters: Name Type Description Default polygon GeometryList Polygon in which to refine required level int Number of refinement steps required Source code in hydrolib/core/io/net/models.py def refine ( self , polygon : mk . GeometryList , level : int ): \"\"\"Refine the mesh within a polygon, by a number of steps (level) Args: polygon (GeometryList): Polygon in which to refine level (int): Number of refinement steps \"\"\" # Add current mesh to Mesh2d instance mesh2d_input = mk . Mesh2d ( node_x = self . mesh2d_node_x , node_y = self . mesh2d_node_y , edge_nodes = self . mesh2d_edge_nodes . ravel (), ) self . meshkernel . mesh2d_set ( mesh2d_input ) # Check if parts are closed if not ( polygon . x_coordinates [ 0 ], polygon . y_coordinates [ 0 ]) == ( polygon . x_coordinates [ - 1 ], polygon . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) parameters = mk . MeshRefinementParameters ( refine_intersected = True , use_mass_center_when_refining = False , min_face_size = 10.0 , # Does nothing? refinement_type = 1 , connect_hanging_nodes = True , account_for_samples_outside_face = False , max_refinement_iterations = level , ) self . meshkernel . mesh2d_refine_based_on_polygon ( polygon , parameters ) # Process self . _process ( self . meshkernel . mesh2d_get ())","title":"refine()"},{"location":"reference/net/#hydrolib.core.io.net.models.Network","text":"","title":"Network"},{"location":"reference/net/#hydrolib.core.io.net.models.Network.from_file","text":"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Parameters: Name Type Description Default file Path path to netcdf file with network data required Returns: Type Description Network The instance of the class itself that is returned Source code in hydrolib/core/io/net/models.py @classmethod def from_file ( cls , file_path : Path ) -> Network : \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Args: file (Path): path to netcdf file with network data Returns: Network: The instance of the class itself that is returned \"\"\" network = cls () ds = nc . Dataset ( file_path ) # type: ignore[import] reader = UgridReader ( file_path ) if reader . _explorer . mesh1d_key is not None : reader . read_mesh1d_network1d ( network . _mesh1d ) if reader . _explorer . mesh2d_key is not None : reader . read_mesh2d ( network . _mesh2d ) if reader . _explorer . link1d2d_key is not None : reader . read_link1d2d ( network . _link1d2d ) ds . close () return network","title":"from_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.Network.to_file","text":"Write network to file Parameters: Name Type Description Default file Path File where _net.nc is written to. required Source code in hydrolib/core/io/net/models.py def to_file ( self , file : Path ) -> None : \"\"\"Write network to file Args: file (Path): File where _net.nc is written to. \"\"\" writer = UgridWriter () writer . write ( self , file )","title":"to_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.NetworkModel","text":"Network model representation.","title":"NetworkModel"},{"location":"reference/net/#hydrolib.core.io.net.models.split_by","text":"Function to split mk.GeometryList by seperator. Source code in hydrolib/core/io/net/models.py def split_by ( gl : mk . GeometryList , by : float ) -> list : \"\"\"Function to split mk.GeometryList by seperator.\"\"\" x , y = gl . x_coordinates . copy (), gl . y_coordinates . copy () idx = np . where ( x == by )[ 0 ] xparts = np . split ( x , idx ) yparts = np . split ( y , idx ) lists = [ mk . GeometryList ( xp [ min ( i , 1 ) :], yp [ min ( i , 1 ) :]) for i , ( xp , yp ) in enumerate ( zip ( xparts , yparts )) ] return lists","title":"split_by()"},{"location":"reference/polyfile/","text":"polyfile: .pli(z) and .pol files \u00b6 Model \u00b6 models.py defines all classes and functions related to representing pol/pli(z) files. Description ( BaseModel ) pydantic-model \u00b6 Description of a single PolyObject. The Description will be prepended to a block. Each line will start with a '*'. Attributes: Name Type Description content str The content of this Description. Metadata ( BaseModel ) pydantic-model \u00b6 Metadata of a single PolyObject. Attributes: Name Type Description name str The name of the PolyObject n_rows int The number of rows (i.e. Point instances) of the PolyObject n_columns int The total number of values in a Point, including x, y, and z. Point ( BaseModel ) pydantic-model \u00b6 Point consisting of a x and y coordinate, an optional z coordinate and data. Attributes: Name Type Description x float The x-coordinate of this Point y float The y-coordinate of this Point z Optional[float] An optional z-coordinate of this Point. data Sequence[float] The additional data variables of this Point. PolyFile ( FileModel ) pydantic-model \u00b6 Poly-file (.pol/.pli/.pliz) representation. PolyObject ( BaseModel ) pydantic-model \u00b6 PolyObject describing a single block in a poly file. The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the metadata. Attributes: Name Type Description description Optional[Description] An optional description of this PolyObject metadata Metadata The Metadata of this PolObject, describing the structure points List[Point] The points describing this PolyObject, structured according to the Metadata Parser \u00b6 parser.py defines all classes and functions related to parsing pol/pli(z) files. Block ( BaseModel ) pydantic-model \u00b6 Block is a temporary object which will be converted into a PolyObject. The fields are supposed to be set during the lifetime of this object. When all fields are set, finalize can be called. Attributes: Name Type Description start_line int The starting line of this current block. name Optional[str] The name of this block. Defaults to None. dimensions Optional[Tuple[int, int]] The dimensions (n_rows, n_columns) of this Block. Defaults to None. points Optional[List[Point]] The points of this block. Defaults to None. ws_warnings List[ParseMsg] The whitespace warnings associated with this block. Defaults to an empty list. empty_lines List[int] The line numbers of the empty lines. Defaults to an empty list. finalize ( self ) -> Optional [ Tuple [ hydrolib . core . io . polyfile . models . PolyObject , List [ hydrolib . core . io . polyfile . parser . ParseMsg ]]] \u00b6 Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Type Description Optional[Tuple[PolyObject, List[ParseMsg]]] The constructed PolyObject and warnings encountered while parsing it. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Optional [ Tuple [ PolyObject , List [ ParseMsg ]]]: \"\"\"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Optional[Tuple[PolyObject, List[ParseMsg]]]: The constructed PolyObject and warnings encountered while parsing it. \"\"\" metadata = self . _get_metadata () if metadata is None or self . points is None : return None obj = PolyObject ( description = self . _get_description (), metadata = metadata , points = self . points ) return obj , self . ws_warnings + self . _get_empty_line_warnings () ErrorBuilder \u00b6 ErrorBuilder provides the functionality to the Parser to keep track of errors. __init__ ( self ) -> None special \u00b6 Create a new ErorrorBuilder Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self ) -> None : \"\"\"Create a new ErorrorBuilder\"\"\" self . _current_block : Optional [ InvalidBlock ] = None end_invalid_block ( self , line : int ) -> None \u00b6 Store the end line of the current block If no invalid block currently exists, nothing will be done. Parameters: Name Type Description Default line int the final line of this invalid block required Source code in hydrolib/core/io/polyfile/parser.py def end_invalid_block ( self , line : int ) -> None : \"\"\"Store the end line of the current block If no invalid block currently exists, nothing will be done. Args: line (int): the final line of this invalid block \"\"\" if self . _current_block is not None : self . _current_block . end_line = line finalize_previous_error ( self ) -> Optional [ hydrolib . core . io . polyfile . parser . ParseMsg ] \u00b6 Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Type Description Optional[ParseMsg] The corresponding ParseMsg if an InvalidBlock exists. Source code in hydrolib/core/io/polyfile/parser.py def finalize_previous_error ( self ) -> Optional [ ParseMsg ]: \"\"\"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists. \"\"\" if self . _current_block is not None : msg = self . _current_block . to_msg () self . _current_block = None return msg else : return None start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None \u00b6 Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Parameters: Name Type Description Default block_start int The start of the invalid block. required invalid_line int The actual offending line number. required reason str The reason why this block is invalid. required Source code in hydrolib/core/io/polyfile/parser.py def start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None : \"\"\"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Args: block_start (int): The start of the invalid block. invalid_line (int): The actual offending line number. reason (str): The reason why this block is invalid. \"\"\" if self . _current_block is None : self . _current_block = InvalidBlock ( start_line = block_start , invalid_line = invalid_line , reason = reason ) InvalidBlock ( BaseModel ) pydantic-model \u00b6 InvalidBlock is a temporary object which will be converted into a ParseMsg. Attributes: Name Type Description start_line int The start line of this InvalidBlock end_line Optional[int] The end line of this InvalidBlock if it is set. Defaults to None. invalid_line int The line which is causing this block to be invalid. reason str A human-readable string detailing the reason of the ParseMsg. to_msg ( self ) -> ParseMsg \u00b6 Convert this InvalidBlock to the corresponding ParseMsg Returns: Type Description ParseMsg The ParseMsg corresponding with this InvalidBlock Source code in hydrolib/core/io/polyfile/parser.py def to_msg ( self ) -> ParseMsg : \"\"\"Convert this InvalidBlock to the corresponding ParseMsg Returns: ParseMsg: The ParseMsg corresponding with this InvalidBlock \"\"\" return ParseMsg ( line_start = self . start_line , line_end = self . end_line , reason = f \" { self . reason } at line { self . invalid_line } .\" , ) ParseMsg ( BaseModel ) pydantic-model \u00b6 ParseMsg defines a single message indicating a significant parse event. Attributes: Name Type Description line_start int The start line of the block to which this ParseMsg refers. line_end int The end line of the block to which this ParseMsg refers. column Optional[Tuple[int, int]] An optional begin and end column to which this ParseMsg refers. reason str A human-readable string detailing the reason of the ParseMsg. notify_as_warning ( self , file_path : Optional [ pathlib . Path ] = None ) \u00b6 Call warnings.warn with a formatted string describing this ParseMsg Parameters: Name Type Description Default file_path Optional[Path] The file path mentioned in the warning if specified. Defaults to None. None Source code in hydrolib/core/io/polyfile/parser.py def notify_as_warning ( self , file_path : Optional [ Path ] = None ): \"\"\"Call warnings.warn with a formatted string describing this ParseMsg Args: file_path (Optional[Path], optional): The file path mentioned in the warning if specified. Defaults to None. \"\"\" if self . line_start != self . line_end : block_suffix = f \" \\n Invalid block { self . line_start } : { self . line_end } \" else : block_suffix = f \" \\n Invalid line { self . line_start } \" col_suffix = ( f \" \\n Columns { self . column [ 0 ] } : { self . column [ 1 ] } \" if self . column is not None else \"\" ) file_suffix = f \" \\n File: { file_path } \" if file_path is not None else \"\" warnings . warn ( f \" { self . reason }{ block_suffix }{ col_suffix }{ file_suffix } \" ) Parser \u00b6 Parser provides the functionality to parse a polyfile line by line. The Parser parses blocks describing PolyObject instances by relying on a rudimentary state machine. The states are encoded with the StateType. New lines are fed through the feed_line method. After each line the internal state will be updated. When a complete block is read, it will be converted into a PolyObject and stored internally. When finalise is called, the constructed objects, as well as any warnings and errors describing invalid blocks, will be returned. Each state defines a feed_line method, stored in the _feed_line dict, which consumes a line and potentially transitions the state into the next. Each state further defines a finalise method, stored in the _finalise dict, which is called upon finalising the parser. Invalid states are encoded with INVALID_STATE. In this state the Parser attempts to find a new block, and thus looks for a new description or name. Unexpected whitespace before comments, names, and dimensions, as well as empty lines will generate a warning, and will be ignored by the parser. __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None special \u00b6 Create a new Parser Parameters: Name Type Description Default file_path Path Name of the file being parsed, only used for providing proper warnings. required has_z_value bool Whether to interpret the third column as z-coordinates. Defaults to False. False Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None : \"\"\"Create a new Parser Args: file_path (Path): Name of the file being parsed, only used for providing proper warnings. has_z_value (bool, optional): Whether to interpret the third column as z-coordinates. Defaults to False. \"\"\" self . _has_z_value = has_z_value self . _file_path = file_path self . _line = 0 self . _new_block () self . _error_builder = ErrorBuilder () self . _poly_objects : List [ PolyObject ] = [] self . _current_point : int = 0 self . _feed_line : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _parse_name_or_new_description , StateType . PARSED_DESCRIPTION : self . _parse_name_or_next_description , StateType . PARSED_NAME : self . _parse_dimensions , StateType . PARSING_POINTS : self . _parse_next_point , StateType . INVALID_STATE : self . _parse_name_or_new_description , } self . _finalise : Dict [ StateType , Callable [[], None ]] = { StateType . NEW_BLOCK : self . _noop , StateType . PARSED_DESCRIPTION : self . _add_current_block_as_incomplete_error , StateType . PARSED_NAME : self . _add_current_block_as_incomplete_error , StateType . PARSING_POINTS : self . _add_current_block_as_incomplete_error , StateType . INVALID_STATE : self . _noop , } self . _handle_ws : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _log_ws_warning , StateType . PARSED_DESCRIPTION : self . _log_ws_warning , StateType . PARSED_NAME : self . _log_ws_warning , StateType . PARSING_POINTS : self . _noop , StateType . INVALID_STATE : self . _noop , } feed_line ( self , line : str ) -> None \u00b6 Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/polyfile/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not Parser . _is_empty_line ( line ): self . _handle_ws [ self . _state ]( line ) self . _feed_line [ self . _state ]( line ) else : self . _handle_empty_line () self . _increment_line () finalize ( self ) -> Sequence [ hydrolib . core . io . polyfile . models . PolyObject ] \u00b6 Finalize parsing and return the constructed PolyObject. Returns: Type Description PolyObject A PolyObject containing the constructed PolyObject instances. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Sequence [ PolyObject ]: \"\"\"Finalize parsing and return the constructed PolyObject. Returns: PolyObject: A PolyObject containing the constructed PolyObject instances. \"\"\" self . _error_builder . end_invalid_block ( self . _line ) last_error_msg = self . _error_builder . finalize_previous_error () if last_error_msg is not None : self . _handle_parse_msg ( last_error_msg ) self . _finalise [ self . _state ]() return self . _poly_objects StateType ( IntEnum ) \u00b6 The types of state of a Parser. read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict \u00b6 Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: Optional description record consisting of one or more lines starting with '*'. These will be ignored. Name consisting of a non-blank character string Two integers, Nr and Nc, representing the numbers of rows and columns respectively Nr number of data points, consisting of Nc floats separated by whitespace For example: ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Parameters: Name Type Description Default filepath Path Path to the pli(z)/pol convention structured file. required has_z_values bool Whether to create points containing a z-value. Defaults to None. required Returns: Type Description Dict The dictionary describing the data of a PolyObject. Source code in hydrolib/core/io/polyfile/parser.py def read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict : \"\"\"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: - Optional description record consisting of one or more lines starting with '*'. These will be ignored. - Name consisting of a non-blank character string - Two integers, Nr and Nc, representing the numbers of rows and columns respectively - Nr number of data points, consisting of Nc floats separated by whitespace For example: ``` ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... ``` Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Args: filepath: Path to the pli(z)/pol convention structured file. has_z_values: Whether to create points containing a z-value. Defaults to None. Returns: Dict: The dictionary describing the data of a PolyObject. \"\"\" if has_z_values is None : has_z_values = _determine_has_z_value ( filepath ) parser = Parser ( filepath , has_z_value = has_z_values ) with filepath . open ( \"r\" ) as f : for line in f : parser . feed_line ( line ) objs = parser . finalize () return { \"has_z_values\" : has_z_values , \"objects\" : objs } Serializer \u00b6 Serializer \u00b6 Serializer provides several static serialize methods for the models. serialize_description ( description : Optional [ hydrolib . core . io . polyfile . models . Description ]) -> Iterable [ str ] staticmethod \u00b6 Serialize the Description to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Description Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_description ( description : Optional [ Description ]) -> Iterable [ str ]: \"\"\"Serialize the Description to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Description \"\"\" if description is None : return [] if description . content == \"\" : return [ \"*\" , ] return ( f \"* { v . rstrip () } \" for v in description . content . splitlines ()) serialize_metadata ( metadata : Metadata ) -> Iterable [ str ] staticmethod \u00b6 Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: Type Description str The serialised equivalent of this Metadata Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_metadata ( metadata : Metadata ) -> Iterable [ str ]: \"\"\"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: str: The serialised equivalent of this Metadata \"\"\" return [ metadata . name , f \" { metadata . n_rows } { metadata . n_columns } \" ] serialize_point ( point : Point ) -> str staticmethod \u00b6 Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_point ( point : Point ) -> str : \"\"\"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: str: The serialised equivalent of this Point \"\"\" z_val = f \" { point . z } \" if point . z is not None else \"\" data_vals = \" \" . join ( str ( v ) for v in point . data ) return f \" { point . x } { point . y } { z_val }{ data_vals } \" . rstrip () serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ] staticmethod \u00b6 Serialize this PolyObject to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ]: \"\"\"Serialize this PolyObject to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Point \"\"\" description = Serializer . serialize_description ( obj . description ) metadata = Serializer . serialize_metadata ( obj . metadata ) points = map ( Serializer . serialize_point , obj . points ) return chain ( description , metadata , points ) write_polyfile ( path : Path , data : Dict ) -> None \u00b6 Write the data to a new file at path Parameters: Name Type Description Default path Path The path to write the data to required data PolyFile The data to write required Source code in hydrolib/core/io/polyfile/serializer.py def write_polyfile ( path : Path , data : Dict ) -> None : \"\"\"Write the data to a new file at path Args: path (Path): The path to write the data to data (PolyFile): The data to write \"\"\" serialized_data = chain . from_iterable ( map ( Serializer . serialize_poly_object , data [ \"objects\" ]) ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serialized_data : f . write ( line ) f . write ( \" \\n \" )","title":"Polyfile"},{"location":"reference/polyfile/#polyfile-pliz-and-pol-files","text":"","title":"polyfile: .pli(z) and .pol files"},{"location":"reference/polyfile/#model","text":"models.py defines all classes and functions related to representing pol/pli(z) files.","title":"Model"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Description","text":"Description of a single PolyObject. The Description will be prepended to a block. Each line will start with a '*'. Attributes: Name Type Description content str The content of this Description.","title":"Description"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Metadata","text":"Metadata of a single PolyObject. Attributes: Name Type Description name str The name of the PolyObject n_rows int The number of rows (i.e. Point instances) of the PolyObject n_columns int The total number of values in a Point, including x, y, and z.","title":"Metadata"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Point","text":"Point consisting of a x and y coordinate, an optional z coordinate and data. Attributes: Name Type Description x float The x-coordinate of this Point y float The y-coordinate of this Point z Optional[float] An optional z-coordinate of this Point. data Sequence[float] The additional data variables of this Point.","title":"Point"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.PolyFile","text":"Poly-file (.pol/.pli/.pliz) representation.","title":"PolyFile"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.PolyObject","text":"PolyObject describing a single block in a poly file. The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the metadata. Attributes: Name Type Description description Optional[Description] An optional description of this PolyObject metadata Metadata The Metadata of this PolObject, describing the structure points List[Point] The points describing this PolyObject, structured according to the Metadata","title":"PolyObject"},{"location":"reference/polyfile/#parser","text":"parser.py defines all classes and functions related to parsing pol/pli(z) files.","title":"Parser"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Block","text":"Block is a temporary object which will be converted into a PolyObject. The fields are supposed to be set during the lifetime of this object. When all fields are set, finalize can be called. Attributes: Name Type Description start_line int The starting line of this current block. name Optional[str] The name of this block. Defaults to None. dimensions Optional[Tuple[int, int]] The dimensions (n_rows, n_columns) of this Block. Defaults to None. points Optional[List[Point]] The points of this block. Defaults to None. ws_warnings List[ParseMsg] The whitespace warnings associated with this block. Defaults to an empty list. empty_lines List[int] The line numbers of the empty lines. Defaults to an empty list.","title":"Block"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Block.finalize","text":"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Type Description Optional[Tuple[PolyObject, List[ParseMsg]]] The constructed PolyObject and warnings encountered while parsing it. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Optional [ Tuple [ PolyObject , List [ ParseMsg ]]]: \"\"\"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Optional[Tuple[PolyObject, List[ParseMsg]]]: The constructed PolyObject and warnings encountered while parsing it. \"\"\" metadata = self . _get_metadata () if metadata is None or self . points is None : return None obj = PolyObject ( description = self . _get_description (), metadata = metadata , points = self . points ) return obj , self . ws_warnings + self . _get_empty_line_warnings ()","title":"finalize()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder","text":"ErrorBuilder provides the functionality to the Parser to keep track of errors.","title":"ErrorBuilder"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.__init__","text":"Create a new ErorrorBuilder Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self ) -> None : \"\"\"Create a new ErorrorBuilder\"\"\" self . _current_block : Optional [ InvalidBlock ] = None","title":"__init__()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.end_invalid_block","text":"Store the end line of the current block If no invalid block currently exists, nothing will be done. Parameters: Name Type Description Default line int the final line of this invalid block required Source code in hydrolib/core/io/polyfile/parser.py def end_invalid_block ( self , line : int ) -> None : \"\"\"Store the end line of the current block If no invalid block currently exists, nothing will be done. Args: line (int): the final line of this invalid block \"\"\" if self . _current_block is not None : self . _current_block . end_line = line","title":"end_invalid_block()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.finalize_previous_error","text":"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Type Description Optional[ParseMsg] The corresponding ParseMsg if an InvalidBlock exists. Source code in hydrolib/core/io/polyfile/parser.py def finalize_previous_error ( self ) -> Optional [ ParseMsg ]: \"\"\"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists. \"\"\" if self . _current_block is not None : msg = self . _current_block . to_msg () self . _current_block = None return msg else : return None","title":"finalize_previous_error()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.start_invalid_block","text":"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Parameters: Name Type Description Default block_start int The start of the invalid block. required invalid_line int The actual offending line number. required reason str The reason why this block is invalid. required Source code in hydrolib/core/io/polyfile/parser.py def start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None : \"\"\"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Args: block_start (int): The start of the invalid block. invalid_line (int): The actual offending line number. reason (str): The reason why this block is invalid. \"\"\" if self . _current_block is None : self . _current_block = InvalidBlock ( start_line = block_start , invalid_line = invalid_line , reason = reason )","title":"start_invalid_block()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.InvalidBlock","text":"InvalidBlock is a temporary object which will be converted into a ParseMsg. Attributes: Name Type Description start_line int The start line of this InvalidBlock end_line Optional[int] The end line of this InvalidBlock if it is set. Defaults to None. invalid_line int The line which is causing this block to be invalid. reason str A human-readable string detailing the reason of the ParseMsg.","title":"InvalidBlock"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.InvalidBlock.to_msg","text":"Convert this InvalidBlock to the corresponding ParseMsg Returns: Type Description ParseMsg The ParseMsg corresponding with this InvalidBlock Source code in hydrolib/core/io/polyfile/parser.py def to_msg ( self ) -> ParseMsg : \"\"\"Convert this InvalidBlock to the corresponding ParseMsg Returns: ParseMsg: The ParseMsg corresponding with this InvalidBlock \"\"\" return ParseMsg ( line_start = self . start_line , line_end = self . end_line , reason = f \" { self . reason } at line { self . invalid_line } .\" , )","title":"to_msg()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ParseMsg","text":"ParseMsg defines a single message indicating a significant parse event. Attributes: Name Type Description line_start int The start line of the block to which this ParseMsg refers. line_end int The end line of the block to which this ParseMsg refers. column Optional[Tuple[int, int]] An optional begin and end column to which this ParseMsg refers. reason str A human-readable string detailing the reason of the ParseMsg.","title":"ParseMsg"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ParseMsg.notify_as_warning","text":"Call warnings.warn with a formatted string describing this ParseMsg Parameters: Name Type Description Default file_path Optional[Path] The file path mentioned in the warning if specified. Defaults to None. None Source code in hydrolib/core/io/polyfile/parser.py def notify_as_warning ( self , file_path : Optional [ Path ] = None ): \"\"\"Call warnings.warn with a formatted string describing this ParseMsg Args: file_path (Optional[Path], optional): The file path mentioned in the warning if specified. Defaults to None. \"\"\" if self . line_start != self . line_end : block_suffix = f \" \\n Invalid block { self . line_start } : { self . line_end } \" else : block_suffix = f \" \\n Invalid line { self . line_start } \" col_suffix = ( f \" \\n Columns { self . column [ 0 ] } : { self . column [ 1 ] } \" if self . column is not None else \"\" ) file_suffix = f \" \\n File: { file_path } \" if file_path is not None else \"\" warnings . warn ( f \" { self . reason }{ block_suffix }{ col_suffix }{ file_suffix } \" )","title":"notify_as_warning()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser","text":"Parser provides the functionality to parse a polyfile line by line. The Parser parses blocks describing PolyObject instances by relying on a rudimentary state machine. The states are encoded with the StateType. New lines are fed through the feed_line method. After each line the internal state will be updated. When a complete block is read, it will be converted into a PolyObject and stored internally. When finalise is called, the constructed objects, as well as any warnings and errors describing invalid blocks, will be returned. Each state defines a feed_line method, stored in the _feed_line dict, which consumes a line and potentially transitions the state into the next. Each state further defines a finalise method, stored in the _finalise dict, which is called upon finalising the parser. Invalid states are encoded with INVALID_STATE. In this state the Parser attempts to find a new block, and thus looks for a new description or name. Unexpected whitespace before comments, names, and dimensions, as well as empty lines will generate a warning, and will be ignored by the parser.","title":"Parser"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.__init__","text":"Create a new Parser Parameters: Name Type Description Default file_path Path Name of the file being parsed, only used for providing proper warnings. required has_z_value bool Whether to interpret the third column as z-coordinates. Defaults to False. False Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None : \"\"\"Create a new Parser Args: file_path (Path): Name of the file being parsed, only used for providing proper warnings. has_z_value (bool, optional): Whether to interpret the third column as z-coordinates. Defaults to False. \"\"\" self . _has_z_value = has_z_value self . _file_path = file_path self . _line = 0 self . _new_block () self . _error_builder = ErrorBuilder () self . _poly_objects : List [ PolyObject ] = [] self . _current_point : int = 0 self . _feed_line : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _parse_name_or_new_description , StateType . PARSED_DESCRIPTION : self . _parse_name_or_next_description , StateType . PARSED_NAME : self . _parse_dimensions , StateType . PARSING_POINTS : self . _parse_next_point , StateType . INVALID_STATE : self . _parse_name_or_new_description , } self . _finalise : Dict [ StateType , Callable [[], None ]] = { StateType . NEW_BLOCK : self . _noop , StateType . PARSED_DESCRIPTION : self . _add_current_block_as_incomplete_error , StateType . PARSED_NAME : self . _add_current_block_as_incomplete_error , StateType . PARSING_POINTS : self . _add_current_block_as_incomplete_error , StateType . INVALID_STATE : self . _noop , } self . _handle_ws : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _log_ws_warning , StateType . PARSED_DESCRIPTION : self . _log_ws_warning , StateType . PARSED_NAME : self . _log_ws_warning , StateType . PARSING_POINTS : self . _noop , StateType . INVALID_STATE : self . _noop , }","title":"__init__()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.feed_line","text":"Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/polyfile/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not Parser . _is_empty_line ( line ): self . _handle_ws [ self . _state ]( line ) self . _feed_line [ self . _state ]( line ) else : self . _handle_empty_line () self . _increment_line ()","title":"feed_line()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.finalize","text":"Finalize parsing and return the constructed PolyObject. Returns: Type Description PolyObject A PolyObject containing the constructed PolyObject instances. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Sequence [ PolyObject ]: \"\"\"Finalize parsing and return the constructed PolyObject. Returns: PolyObject: A PolyObject containing the constructed PolyObject instances. \"\"\" self . _error_builder . end_invalid_block ( self . _line ) last_error_msg = self . _error_builder . finalize_previous_error () if last_error_msg is not None : self . _handle_parse_msg ( last_error_msg ) self . _finalise [ self . _state ]() return self . _poly_objects","title":"finalize()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.StateType","text":"The types of state of a Parser.","title":"StateType"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.read_polyfile","text":"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: Optional description record consisting of one or more lines starting with '*'. These will be ignored. Name consisting of a non-blank character string Two integers, Nr and Nc, representing the numbers of rows and columns respectively Nr number of data points, consisting of Nc floats separated by whitespace For example: ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Parameters: Name Type Description Default filepath Path Path to the pli(z)/pol convention structured file. required has_z_values bool Whether to create points containing a z-value. Defaults to None. required Returns: Type Description Dict The dictionary describing the data of a PolyObject. Source code in hydrolib/core/io/polyfile/parser.py def read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict : \"\"\"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: - Optional description record consisting of one or more lines starting with '*'. These will be ignored. - Name consisting of a non-blank character string - Two integers, Nr and Nc, representing the numbers of rows and columns respectively - Nr number of data points, consisting of Nc floats separated by whitespace For example: ``` ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... ``` Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Args: filepath: Path to the pli(z)/pol convention structured file. has_z_values: Whether to create points containing a z-value. Defaults to None. Returns: Dict: The dictionary describing the data of a PolyObject. \"\"\" if has_z_values is None : has_z_values = _determine_has_z_value ( filepath ) parser = Parser ( filepath , has_z_value = has_z_values ) with filepath . open ( \"r\" ) as f : for line in f : parser . feed_line ( line ) objs = parser . finalize () return { \"has_z_values\" : has_z_values , \"objects\" : objs }","title":"read_polyfile()"},{"location":"reference/polyfile/#serializer","text":"","title":"Serializer"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer","text":"Serializer provides several static serialize methods for the models.","title":"Serializer"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_description","text":"Serialize the Description to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Description Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_description ( description : Optional [ Description ]) -> Iterable [ str ]: \"\"\"Serialize the Description to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Description \"\"\" if description is None : return [] if description . content == \"\" : return [ \"*\" , ] return ( f \"* { v . rstrip () } \" for v in description . content . splitlines ())","title":"serialize_description()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_metadata","text":"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: Type Description str The serialised equivalent of this Metadata Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_metadata ( metadata : Metadata ) -> Iterable [ str ]: \"\"\"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: str: The serialised equivalent of this Metadata \"\"\" return [ metadata . name , f \" { metadata . n_rows } { metadata . n_columns } \" ]","title":"serialize_metadata()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_point","text":"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_point ( point : Point ) -> str : \"\"\"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: str: The serialised equivalent of this Point \"\"\" z_val = f \" { point . z } \" if point . z is not None else \"\" data_vals = \" \" . join ( str ( v ) for v in point . data ) return f \" { point . x } { point . y } { z_val }{ data_vals } \" . rstrip ()","title":"serialize_point()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_poly_object","text":"Serialize this PolyObject to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ]: \"\"\"Serialize this PolyObject to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Point \"\"\" description = Serializer . serialize_description ( obj . description ) metadata = Serializer . serialize_metadata ( obj . metadata ) points = map ( Serializer . serialize_point , obj . points ) return chain ( description , metadata , points )","title":"serialize_poly_object()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.write_polyfile","text":"Write the data to a new file at path Parameters: Name Type Description Default path Path The path to write the data to required data PolyFile The data to write required Source code in hydrolib/core/io/polyfile/serializer.py def write_polyfile ( path : Path , data : Dict ) -> None : \"\"\"Write the data to a new file at path Args: path (Path): The path to write the data to data (PolyFile): The data to write \"\"\" serialized_data = chain . from_iterable ( map ( Serializer . serialize_poly_object , data [ \"objects\" ]) ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serialized_data : f . write ( line ) f . write ( \" \\n \" )","title":"write_polyfile()"},{"location":"reference/structures/","text":"TODO Implement the following structures - Bridge - Generalstructure - Long culvert - Gate - Dambreak Add comments for these structures. Maybe link them to descriptions of Field s? CulvertSubType ( str , Enum ) \u00b6 An enumeration. FlowDirection ( str , Enum ) \u00b6 An enumeration. Structure ( INIBasedModel ) pydantic-model \u00b6 validate ( v ) classmethod \u00b6 Try to iniatialize subclass based on function field. Source code in hydrolib/core/io/structure/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on function field.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"structure_type\" ) . default == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : logger . warning ( f \"Couldn't derive specific type of { cls . __name__ } \" ) return super () . validate ( v )","title":"Structures"},{"location":"reference/structures/#hydrolib.core.io.structure.models.CulvertSubType","text":"An enumeration.","title":"CulvertSubType"},{"location":"reference/structures/#hydrolib.core.io.structure.models.FlowDirection","text":"An enumeration.","title":"FlowDirection"},{"location":"reference/structures/#hydrolib.core.io.structure.models.Structure","text":"","title":"Structure"},{"location":"reference/structures/#hydrolib.core.io.structure.models.Structure.validate","text":"Try to iniatialize subclass based on function field. Source code in hydrolib/core/io/structure/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on function field.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"structure_type\" ) . default == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : logger . warning ( f \"Couldn't derive specific type of { cls . __name__ } \" ) return super () . validate ( v )","title":"validate()"},{"location":"reference/xyz/","text":"XYZ files \u00b6 Model \u00b6 XYZModel ( FileModel ) pydantic-model \u00b6 Sample or forcing file. Attributes: Name Type Description points List[hydrolib.core.io.xyz.models.XYZPoint] List of XYZPoint dict ( self , * args , ** kwargs ) \u00b6 Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/xyz/models.py def dict ( self , * args , ** kwargs ): # speed up serializing by not converting these lowest models to dict return dict ( points = self . points ) XYZPoint ( BaseModel ) pydantic-model \u00b6 Single sample or forcing point. Attributes: Name Type Description x float x or \u03bb coordinate y float y or \u03c6 coordinate z float sample value or group number (forcing) comment Optional[str] keyword for grouping (forcing) comment : str pydantic-field \u00b6 comment or group name Parser \u00b6 XYZParser \u00b6 A parser for .xyz files which are like this: number number number number number number # comment Note that the whitespace can vary and the comment left out. Serializer \u00b6","title":"Xyz"},{"location":"reference/xyz/#xyz-files","text":"","title":"XYZ files"},{"location":"reference/xyz/#model","text":"","title":"Model"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZModel","text":"Sample or forcing file. Attributes: Name Type Description points List[hydrolib.core.io.xyz.models.XYZPoint] List of XYZPoint","title":"XYZModel"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZModel.dict","text":"Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/xyz/models.py def dict ( self , * args , ** kwargs ): # speed up serializing by not converting these lowest models to dict return dict ( points = self . points )","title":"dict()"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZPoint","text":"Single sample or forcing point. Attributes: Name Type Description x float x or \u03bb coordinate y float y or \u03c6 coordinate z float sample value or group number (forcing) comment Optional[str] keyword for grouping (forcing)","title":"XYZPoint"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZPoint.comment","text":"comment or group name","title":"comment"},{"location":"reference/xyz/#parser","text":"","title":"Parser"},{"location":"reference/xyz/#hydrolib.core.io.xyz.parser.XYZParser","text":"A parser for .xyz files which are like this: number number number number number number # comment Note that the whitespace can vary and the comment left out.","title":"XYZParser"},{"location":"reference/xyz/#serializer","text":"","title":"Serializer"},{"location":"topics/principles/","text":"First principles \u00b6 hydrolib-core is structured around the input and output files (I/O) of the DHYDRO suite. Inheritance/file handling \u00b6 Model setups often consist of different files, many implicitly linked to each other. HYDROLIB makes these links explicit, by recursively loading all child configuration files. For example, when parsing a DIMR file, one could happen upon a reference to an MDU file, which contain references to other files, such as cross sections, etc. >>> dimr = DIMR ( filepath = Path ( test_data_dir / \"dimr_config.xml\" )) You can see this tree structure if you call show_tree . >>> dimr . show_tree () DIMR represented by dimr_config . xml . RRComponent FMComponent \u221f FMModel represented by FlowFM . mdu . \u221f Geometry \u221f StructureModel represented by structures . ini . \u221f CrossDefModel represented by crsdef . ini . \u221f CrossLocModel represented by crsloc . ini . \u221f FrictionModel represented by roughness - Main . ini . \u221f FrictionModel represented by roughness - Sewer1 . ini . \u221f FrictionModel represented by roughness - Sewer2 . ini . \u221f ExternalForcing \u221f ExtModel represented by FlowFM_bnd . ext . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc .","title":"First principles"},{"location":"topics/principles/#first-principles","text":"hydrolib-core is structured around the input and output files (I/O) of the DHYDRO suite.","title":"First principles"},{"location":"topics/principles/#inheritancefile-handling","text":"Model setups often consist of different files, many implicitly linked to each other. HYDROLIB makes these links explicit, by recursively loading all child configuration files. For example, when parsing a DIMR file, one could happen upon a reference to an MDU file, which contain references to other files, such as cross sections, etc. >>> dimr = DIMR ( filepath = Path ( test_data_dir / \"dimr_config.xml\" )) You can see this tree structure if you call show_tree . >>> dimr . show_tree () DIMR represented by dimr_config . xml . RRComponent FMComponent \u221f FMModel represented by FlowFM . mdu . \u221f Geometry \u221f StructureModel represented by structures . ini . \u221f CrossDefModel represented by crsdef . ini . \u221f CrossLocModel represented by crsloc . ini . \u221f FrictionModel represented by roughness - Main . ini . \u221f FrictionModel represented by roughness - Sewer1 . ini . \u221f FrictionModel represented by roughness - Sewer2 . ini . \u221f ExternalForcing \u221f ExtModel represented by FlowFM_bnd . ext . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc .","title":"Inheritance/file handling"},{"location":"tutorials/plotting_a_network/","text":"Plotting a network \u00b6 We can visualise a Network with the following code: from hydrolib.core.io.net.models import Network import matplotlib from matplotlib.collections import LineCollection import numpy as np def plot ( network : Network , ax : matplotlib . axes . _subplots . AxesSubplot , mesh1d_kwargs : dict = None , mesh2d_kwargs : dict = None , links1d2d_kwargs : dict = None , ) -> None : if mesh1d_kwargs is None : mesh1d_kwargs = { \"color\" : \"C3\" , \"lw\" : 1.0 } if mesh2d_kwargs is None : mesh2d_kwargs = { \"color\" : \"C0\" , \"lw\" : 0.5 } if links1d2d_kwargs is None : links1d2d_kwargs = { \"color\" : \"k\" , \"lw\" : 1.0 } # Mesh 1d if not network . _mesh1d . is_empty (): nodes1d = np . stack ( [ network . _mesh1d . mesh1d_node_x , network . _mesh1d . mesh1d_node_y ], axis = 1 ) edge_nodes = network . _mesh1d . mesh1d_edge_nodes lc_mesh1d = LineCollection ( nodes1d [ edge_nodes ], ** mesh1d_kwargs ) ax . add_collection ( lc_mesh1d ) # Mesh 2d if not network . _mesh2d . is_empty (): nodes2d = np . stack ( [ network . _mesh2d . mesh2d_node_x , network . _mesh2d . mesh2d_node_y ], axis = 1 ) edge_nodes = network . _mesh2d . mesh2d_edge_nodes lc_mesh2d = LineCollection ( nodes2d [ edge_nodes ], ** mesh2d_kwargs ) ax . add_collection ( lc_mesh2d ) # Links if not network . _link1d2d . is_empty (): faces2d = np . stack ( [ network . _mesh2d . mesh2d_face_x , network . _mesh2d . mesh2d_face_y ], axis = 1 ) link_coords = np . stack ( [ nodes1d [ network . _link1d2d . link1d2d [:, 0 ]], faces2d [ network . _link1d2d . link1d2d [:, 1 ]], ], axis = 1 , ) lc_link1d2d = LineCollection ( link_coords , ** links1d2d_kwargs ) ax . add_collection ( lc_link1d2d )","title":"Plotting a network"},{"location":"tutorials/plotting_a_network/#plotting-a-network","text":"We can visualise a Network with the following code: from hydrolib.core.io.net.models import Network import matplotlib from matplotlib.collections import LineCollection import numpy as np def plot ( network : Network , ax : matplotlib . axes . _subplots . AxesSubplot , mesh1d_kwargs : dict = None , mesh2d_kwargs : dict = None , links1d2d_kwargs : dict = None , ) -> None : if mesh1d_kwargs is None : mesh1d_kwargs = { \"color\" : \"C3\" , \"lw\" : 1.0 } if mesh2d_kwargs is None : mesh2d_kwargs = { \"color\" : \"C0\" , \"lw\" : 0.5 } if links1d2d_kwargs is None : links1d2d_kwargs = { \"color\" : \"k\" , \"lw\" : 1.0 } # Mesh 1d if not network . _mesh1d . is_empty (): nodes1d = np . stack ( [ network . _mesh1d . mesh1d_node_x , network . _mesh1d . mesh1d_node_y ], axis = 1 ) edge_nodes = network . _mesh1d . mesh1d_edge_nodes lc_mesh1d = LineCollection ( nodes1d [ edge_nodes ], ** mesh1d_kwargs ) ax . add_collection ( lc_mesh1d ) # Mesh 2d if not network . _mesh2d . is_empty (): nodes2d = np . stack ( [ network . _mesh2d . mesh2d_node_x , network . _mesh2d . mesh2d_node_y ], axis = 1 ) edge_nodes = network . _mesh2d . mesh2d_edge_nodes lc_mesh2d = LineCollection ( nodes2d [ edge_nodes ], ** mesh2d_kwargs ) ax . add_collection ( lc_mesh2d ) # Links if not network . _link1d2d . is_empty (): faces2d = np . stack ( [ network . _mesh2d . mesh2d_face_x , network . _mesh2d . mesh2d_face_y ], axis = 1 ) link_coords = np . stack ( [ nodes1d [ network . _link1d2d . link1d2d [:, 0 ]], faces2d [ network . _link1d2d . link1d2d [:, 1 ]], ], axis = 1 , ) lc_link1d2d = LineCollection ( link_coords , ** links1d2d_kwargs ) ax . add_collection ( lc_link1d2d )","title":"Plotting a network"},{"location":"tutorials/steps/","text":"First steps \u00b6 Let's import and create a first model. from hydrolib.core.io.structure.models import FlowDirection , StructureModel , Weir from hydrolib.core.io.mdu.models import FMModel fm = FMModel ( filepath = \"test.mdu\" ) We can now add and/or manipulate features within the model. # Start adding geometry fm . geometry . netfile . network . mesh1d_add_branch () # TODO fix example Add some structures, note this is invalid because it doesn't have a branch or coordinates yet, but it will work for demo purposes struc = Weir ( allowedflowdir = FlowDirection . none , crestlevel = 0.0 ) struc . comments . crestlevel = \"This is a comment\" fm . geometry . structurefile = [ StructureModel ( structure = [ struc ])] Note that the creation of a Weir and other models always require the use of keyword arguments. A ValidationError will be raised when the model isn't correct or complete, for instance, in the case that StructureModel was assigned directly to structurefile instead of as a list. Now let's add this model to a DIMR config and save it. from hydrolib.core.io.dimr.models import DIMR , FMComponent dimr = DIMR () dimr . component . append ( FMComponent ( name = \"test\" , workingDir = \".\" , inputfile = fm . filepath , model = fm ) ) dimr . save ( folder = \".\" ) The save on the top of the model hierarchy will result in saves of all child models, so this results in four files ( dimrconfig.xml , network.nc , structures.ini , test.mdu ) in the working directory.","title":"First steps"},{"location":"tutorials/steps/#first-steps","text":"Let's import and create a first model. from hydrolib.core.io.structure.models import FlowDirection , StructureModel , Weir from hydrolib.core.io.mdu.models import FMModel fm = FMModel ( filepath = \"test.mdu\" ) We can now add and/or manipulate features within the model. # Start adding geometry fm . geometry . netfile . network . mesh1d_add_branch () # TODO fix example Add some structures, note this is invalid because it doesn't have a branch or coordinates yet, but it will work for demo purposes struc = Weir ( allowedflowdir = FlowDirection . none , crestlevel = 0.0 ) struc . comments . crestlevel = \"This is a comment\" fm . geometry . structurefile = [ StructureModel ( structure = [ struc ])] Note that the creation of a Weir and other models always require the use of keyword arguments. A ValidationError will be raised when the model isn't correct or complete, for instance, in the case that StructureModel was assigned directly to structurefile instead of as a list. Now let's add this model to a DIMR config and save it. from hydrolib.core.io.dimr.models import DIMR , FMComponent dimr = DIMR () dimr . component . append ( FMComponent ( name = \"test\" , workingDir = \".\" , inputfile = fm . filepath , model = fm ) ) dimr . save ( folder = \".\" ) The save on the top of the model hierarchy will result in saves of all child models, so this results in four files ( dimrconfig.xml , network.nc , structures.ini , test.mdu ) in the working directory.","title":"First steps"}]}