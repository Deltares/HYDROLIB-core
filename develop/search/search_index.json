{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 HYDROLIB-core is the core library of Python wrappers around the D-HYDRO model files (input and output) and model engines (kernel libraries).","title":"Home"},{"location":"#introduction","text":"HYDROLIB-core is the core library of Python wrappers around the D-HYDRO model files (input and output) and model engines (kernel libraries).","title":"Introduction"},{"location":"changelog/","text":"0.1.5 (2021-11-02) \u00b6 0.1.4 (2021-11-02) \u00b6 0.1.3 (2021-08-05) \u00b6 Fix \u00b6 netcdf serialization path. 0.1.2 (2021-08-05) \u00b6 Fix \u00b6 test_version : Fix updated version 0.1.1 (2021-08-05) \u00b6 Fix \u00b6 NetworkModel : Fix default init of Network within NetworkModel","title":"Changelog"},{"location":"changelog/#015-2021-11-02","text":"","title":"0.1.5 (2021-11-02)"},{"location":"changelog/#014-2021-11-02","text":"","title":"0.1.4 (2021-11-02)"},{"location":"changelog/#013-2021-08-05","text":"","title":"0.1.3 (2021-08-05)"},{"location":"changelog/#fix","text":"netcdf serialization path.","title":"Fix"},{"location":"changelog/#012-2021-08-05","text":"","title":"0.1.2 (2021-08-05)"},{"location":"changelog/#fix_1","text":"test_version : Fix updated version","title":"Fix"},{"location":"changelog/#011-2021-08-05","text":"","title":"0.1.1 (2021-08-05)"},{"location":"changelog/#fix_2","text":"NetworkModel : Fix default init of Network within NetworkModel","title":"Fix"},{"location":"guides/contributing/","text":"Contributing \u00b6 Tooling \u00b6 Poetry \u00b6 We use poetry to manage our package and its dependencies. More information on the separate Poetry page. Pytest \u00b6 We use pytest to test our package. Run it with poetry run pytest to test your code changes locally. Black \u00b6 We use black as an autoformatter. It is also run during CI and will fail if it's not formatted beforehand. Isort \u00b6 We use isort as an autoformatter. Commitizen \u00b6 We use commitizen to automatically bump the version number. If you use conventional commit messages , the changelog.md is generated automatically. Development \u00b6 Branches \u00b6 For each issue or feature, a separate branch should be created from the main. To keep the branches organized a feature branch should be created with the feature/ prefix. When starting development on a branch, a pull request should be created for reviews and continous integration. During continuous integration, the checks will be run with python 3.8 and 3.9 on Windows, Ubuntu and MacOS. The checks consist of running the tests, checking the code formatting and running SonarCloud. We advise to use a draft pull request, to prevent the branch to be merged back before developement is finished. When the branch is ready for review, you can update the status of the pull request to \"ready for review\". Reviews \u00b6 When an issue is ready for review, it should be moved to the \"Ready for review\" column on the GitHub board for visibility. Merging \u00b6 Merging a branch can only happen when a pull request is accepted through review. When a pull request is accepted the changes should be merged back with the \"squash and merge\" option. Coding guidelines \u00b6 If there is code that needs to be tested, there should be tests written for it. If there are any additions or changes to the public API, the documentation should be updated. Files should be added to the appropriate folder to keep modules and objects within the correct scope.","title":"Contributing"},{"location":"guides/contributing/#contributing","text":"","title":"Contributing"},{"location":"guides/contributing/#tooling","text":"","title":"Tooling"},{"location":"guides/contributing/#poetry","text":"We use poetry to manage our package and its dependencies. More information on the separate Poetry page.","title":"Poetry"},{"location":"guides/contributing/#pytest","text":"We use pytest to test our package. Run it with poetry run pytest to test your code changes locally.","title":"Pytest"},{"location":"guides/contributing/#black","text":"We use black as an autoformatter. It is also run during CI and will fail if it's not formatted beforehand.","title":"Black"},{"location":"guides/contributing/#isort","text":"We use isort as an autoformatter.","title":"Isort"},{"location":"guides/contributing/#commitizen","text":"We use commitizen to automatically bump the version number. If you use conventional commit messages , the changelog.md is generated automatically.","title":"Commitizen"},{"location":"guides/contributing/#development","text":"","title":"Development"},{"location":"guides/contributing/#branches","text":"For each issue or feature, a separate branch should be created from the main. To keep the branches organized a feature branch should be created with the feature/ prefix. When starting development on a branch, a pull request should be created for reviews and continous integration. During continuous integration, the checks will be run with python 3.8 and 3.9 on Windows, Ubuntu and MacOS. The checks consist of running the tests, checking the code formatting and running SonarCloud. We advise to use a draft pull request, to prevent the branch to be merged back before developement is finished. When the branch is ready for review, you can update the status of the pull request to \"ready for review\".","title":"Branches"},{"location":"guides/contributing/#reviews","text":"When an issue is ready for review, it should be moved to the \"Ready for review\" column on the GitHub board for visibility.","title":"Reviews"},{"location":"guides/contributing/#merging","text":"Merging a branch can only happen when a pull request is accepted through review. When a pull request is accepted the changes should be merged back with the \"squash and merge\" option.","title":"Merging"},{"location":"guides/contributing/#coding-guidelines","text":"If there is code that needs to be tested, there should be tests written for it. If there are any additions or changes to the public API, the documentation should be updated. Files should be added to the appropriate folder to keep modules and objects within the correct scope.","title":"Coding guidelines"},{"location":"guides/devcontainers/","text":"Devcontainers: Developing HYDROLIB in an isolated environment \u00b6 A common struggle while working on any software project, is to ensure all of your dependencies are available and you can actually build the software, run the tests etc. While any developer is free to choose their own toolchain, environment etc, HYDROLIB-Core includes the necessary files to run the project within a so called devcontainer within Visual Studio Code. With the help of Docker, we can spin up an independent development environment, ensuring that HYDROLIB-Core works out of the box and you are insulated from any specific local configurations on your machines. This should allow you to start working on HYDROLIB-Core quickly. The following sub sections will walk you through the necessary dependencies, and how to use it, and modify it, to fit your own needs. This will be done in the following order: Requirements: Docker and Visual Studio Code Remote - Containers extension Dockerfile configures python, poetry and other dependencies devcontainer.json specifies how visual studio code should be configured External references Requirements: Docker and Visual Studio Code Remote - Containers extension \u00b6 In order to run HYDROLIB in a dev container we need the following dependencies Docker Visual Studio Code Visual Studio Code Remote - Containers extension Docker will ensure we can spin up an isolated container. A full tutorial on how to use Docker is outside the scope of this tutorial, however the Getting Started guide of Docker should provide you with the steps to install Docker on your machine. Visual Studio Code is the editor we will use. The website should provide you with the necessary steps to install it. Lastly, we need to install the Visual Studio Code Remote - Containers extension . The install button on the marketplace should walk you through the steps to install it. Run HYDROLIB in a devcontainer by executing \"Reopen in container\" command \u00b6 With all of the dependencies set up, we should be able to run HYDROLIB within our devcontainer. When opening the HYDROLIB-Core repository in Visual Studio Code, we should either get a pop-up asking us to reopen the project within a remote container, or we can select the \"Open a Remote Window\" button, the green button in the bottom left corner of your visual studio code window, after which we can select \"Reopen in container\". Both will then spin up a new container in which we can work. Note that if it is the first time starting our repository, or if we have made changes to the Docker Images we might need to build the container, which could take a few moments. Once opened in a separate container, we can start a terminal to verify everything is working correctly. When we start a new terminal, we should see the terminal of our container, e.g. something a long the lines of ( .venv ) root@7573572275f1:/workspaces/HYDROLIB-core# It should now be possible to run the HYDROLIB-Core tests within our container. You might get prompted to configure either the python interpreter, or the python test framework. Once this is done all tests should pass as they would normally. Dockerfile configures python, poetry and other dependencies \u00b6 The Dockerfile which specifies our specific devcontainer can be found here in the repository . Currently, it extends the python 3.9 buster image provided by the Python foundation. It then does the following: Installs Poetry 1.1.11 and configure the necessary paths Copies the poetry.lock and pyproject.toml and installs the project Installs git within the container This should provide us with a ready to go environment to run HYDROLIB-Core with. devcontainer.json specifies how visual studio code should be configured \u00b6 We can further customise our environment by editing the devcontainer.json located here in the repository . In particular, you can add any Visual Studio Code extensions you require for your work to the extensions field. Currently it is populated with several common Python extensions which we use to develop HYDROLIB. For a full overview how to customise this file, you can find the documentation here External references: \u00b6 Developing inside a Container - VS Code docs Develop with containers - VS Code docs (guide specific for python) Document docker poetry best practices - Poetry issue","title":"Developer container"},{"location":"guides/devcontainers/#devcontainers-developing-hydrolib-in-an-isolated-environment","text":"A common struggle while working on any software project, is to ensure all of your dependencies are available and you can actually build the software, run the tests etc. While any developer is free to choose their own toolchain, environment etc, HYDROLIB-Core includes the necessary files to run the project within a so called devcontainer within Visual Studio Code. With the help of Docker, we can spin up an independent development environment, ensuring that HYDROLIB-Core works out of the box and you are insulated from any specific local configurations on your machines. This should allow you to start working on HYDROLIB-Core quickly. The following sub sections will walk you through the necessary dependencies, and how to use it, and modify it, to fit your own needs. This will be done in the following order: Requirements: Docker and Visual Studio Code Remote - Containers extension Dockerfile configures python, poetry and other dependencies devcontainer.json specifies how visual studio code should be configured External references","title":"Devcontainers: Developing HYDROLIB in an isolated environment"},{"location":"guides/devcontainers/#requirements-docker-and-visual-studio-code-remote-containers-extension","text":"In order to run HYDROLIB in a dev container we need the following dependencies Docker Visual Studio Code Visual Studio Code Remote - Containers extension Docker will ensure we can spin up an isolated container. A full tutorial on how to use Docker is outside the scope of this tutorial, however the Getting Started guide of Docker should provide you with the steps to install Docker on your machine. Visual Studio Code is the editor we will use. The website should provide you with the necessary steps to install it. Lastly, we need to install the Visual Studio Code Remote - Containers extension . The install button on the marketplace should walk you through the steps to install it.","title":"Requirements: Docker and Visual Studio Code Remote - Containers extension"},{"location":"guides/devcontainers/#run-hydrolib-in-a-devcontainer-by-executing-reopen-in-container-command","text":"With all of the dependencies set up, we should be able to run HYDROLIB within our devcontainer. When opening the HYDROLIB-Core repository in Visual Studio Code, we should either get a pop-up asking us to reopen the project within a remote container, or we can select the \"Open a Remote Window\" button, the green button in the bottom left corner of your visual studio code window, after which we can select \"Reopen in container\". Both will then spin up a new container in which we can work. Note that if it is the first time starting our repository, or if we have made changes to the Docker Images we might need to build the container, which could take a few moments. Once opened in a separate container, we can start a terminal to verify everything is working correctly. When we start a new terminal, we should see the terminal of our container, e.g. something a long the lines of ( .venv ) root@7573572275f1:/workspaces/HYDROLIB-core# It should now be possible to run the HYDROLIB-Core tests within our container. You might get prompted to configure either the python interpreter, or the python test framework. Once this is done all tests should pass as they would normally.","title":"Run HYDROLIB in a devcontainer by executing \"Reopen in container\" command"},{"location":"guides/devcontainers/#dockerfile-configures-python-poetry-and-other-dependencies","text":"The Dockerfile which specifies our specific devcontainer can be found here in the repository . Currently, it extends the python 3.9 buster image provided by the Python foundation. It then does the following: Installs Poetry 1.1.11 and configure the necessary paths Copies the poetry.lock and pyproject.toml and installs the project Installs git within the container This should provide us with a ready to go environment to run HYDROLIB-Core with.","title":"Dockerfile configures python, poetry and other dependencies"},{"location":"guides/devcontainers/#devcontainerjson-specifies-how-visual-studio-code-should-be-configured","text":"We can further customise our environment by editing the devcontainer.json located here in the repository . In particular, you can add any Visual Studio Code extensions you require for your work to the extensions field. Currently it is populated with several common Python extensions which we use to develop HYDROLIB. For a full overview how to customise this file, you can find the documentation here","title":"devcontainer.json specifies how visual studio code should be configured"},{"location":"guides/devcontainers/#external-references","text":"Developing inside a Container - VS Code docs Develop with containers - VS Code docs (guide specific for python) Document docker poetry best practices - Poetry issue","title":"External references:"},{"location":"guides/documentation/","text":"Documentation \u00b6 We use MKdocs for documentation. For full documentation visit mkdocs.org . The documentation itself is written with https://documentation.divio.com/ structure in mind, creating different categories: - Guides - Tutorials - Reference - Topics Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Documentation"},{"location":"guides/documentation/#documentation","text":"We use MKdocs for documentation. For full documentation visit mkdocs.org . The documentation itself is written with https://documentation.divio.com/ structure in mind, creating different categories: - Guides - Tutorials - Reference - Topics","title":"Documentation"},{"location":"guides/documentation/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"guides/documentation/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"guides/poetry/","text":"Installation using Poetry \u00b6 You can use a Poetry-based installation if you are using hydrolib-core from a local clone of the Github repository, for example if you intend to contribute to the code. Clone the GitHub repo \u00b6 Use your own preferred way of cloning the GitHub repository of hydrolib-core. In the examples below it is placed in C:\\checkouts\\HYDROLIB-core_git . Use Poetry to install hydrolib-core \u00b6 We use poetry to manage our package and its dependencies. Note If you use conda , do not combine conda virtual environments with the poetry virtual environment. In other words, run the poetry install command from the base conda environment. Download + installation instructions for Poetry are here . After installation of Poetry itself, now use it to install your local clone of the hydrolib-core package, as follows. Make sure Poetry is available on your PATH and run poetry install in the hydrolib-core directory in your shell of choice. This will create a virtual environment in which hydrolib-core is installed and made available for use in your own scripts. For example in an Anaconda PowerShell: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry install Creating virtualenv hydrolib-core-kHkQBdtS-py3.8 in C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\virtualenvs Installing dependencies from lock file Package operations: 67 installs, 0 updates, 0 removals * Installing six (1.16.0) [..] Installing the current project: hydrolib-core (0.1.5) (base) PS C:\\checkouts\\HYDROLIB-core_git> If you need to use an already existing Python installation, you can activate it and run poetry env use system before poetry install . Test your installation, by running the hydrolib-core pytest suite via poetry: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry run pytest ===================================== test session starts ====================================== platform win32 -- Python 3.8.8, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 rootdir: C:\\checkouts\\HYDROLIB-core_git, configfile: pyproject.toml plugins: cov-2.12.1 collected 473 items / 2 deselected / 471 selected tests\\test_model.py ............... [ 3%] tests\\test_utils.py ....... [ 4%] tests\\io\\test_bc.py .... [ 5%] tests\\io\\test_bui.py ........................... [ 11%] tests\\io\\test_dimr.py ... [ 11%] tests\\io\\test_docker.py . [ 12%] tests\\io\\test_ext.py ........................................................ [ 23%] tests\\io\\test_fnm.py .................. [ 27%] tests\\io\\test_ini.py .................................................................... [ 42%] ......................................................... [ 54%] tests\\io\\test_net.py ............ [ 56%] tests\\io\\test_parser.py . [ 57%] tests\\io\\test_polyfile.py ............................................................... [ 70%] .................................... [ 78%] tests\\io\\test_structure.py .............................................................. [ 91%] ......................................... [100%] ============================== 471 passed, 2 deselected in 3.50s =============================== (base) PS C:\\checkouts\\HYDROLIB-core_git> Start using hydrolib-core. You can launch your favourite editor (for example VS Code) by first starting a poetry shell with the virtual hydrolib-core environment: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry shell (base) PS C:\\checkouts\\HYDROLIB-core_git> code Frequently asked questions \u00b6 How to fix \"File ... does not exist\" errors during poetry install as in the example below? * Installing six (1.16.0) ValueError File \\C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\artifacts\\48\\e6\\04\\8118155ae3ec3a16dd2a213bbf7a7d8a62c596b2e90f73a22c896269f1\\six-1.16.0-py2.py3-none-any.whl does not exist This may occur when a conda environment was activated. Delete the AppData\\Local\\pypoetry\\Cache directory. Then run conda deactivate to return to the base environment. Finally, rerun poetry install .","title":"Local clone + Poetry"},{"location":"guides/poetry/#installation-using-poetry","text":"You can use a Poetry-based installation if you are using hydrolib-core from a local clone of the Github repository, for example if you intend to contribute to the code.","title":"Installation using Poetry"},{"location":"guides/poetry/#clone-the-github-repo","text":"Use your own preferred way of cloning the GitHub repository of hydrolib-core. In the examples below it is placed in C:\\checkouts\\HYDROLIB-core_git .","title":"Clone the GitHub repo"},{"location":"guides/poetry/#use-poetry-to-install-hydrolib-core","text":"We use poetry to manage our package and its dependencies. Note If you use conda , do not combine conda virtual environments with the poetry virtual environment. In other words, run the poetry install command from the base conda environment. Download + installation instructions for Poetry are here . After installation of Poetry itself, now use it to install your local clone of the hydrolib-core package, as follows. Make sure Poetry is available on your PATH and run poetry install in the hydrolib-core directory in your shell of choice. This will create a virtual environment in which hydrolib-core is installed and made available for use in your own scripts. For example in an Anaconda PowerShell: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry install Creating virtualenv hydrolib-core-kHkQBdtS-py3.8 in C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\virtualenvs Installing dependencies from lock file Package operations: 67 installs, 0 updates, 0 removals * Installing six (1.16.0) [..] Installing the current project: hydrolib-core (0.1.5) (base) PS C:\\checkouts\\HYDROLIB-core_git> If you need to use an already existing Python installation, you can activate it and run poetry env use system before poetry install . Test your installation, by running the hydrolib-core pytest suite via poetry: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry run pytest ===================================== test session starts ====================================== platform win32 -- Python 3.8.8, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 rootdir: C:\\checkouts\\HYDROLIB-core_git, configfile: pyproject.toml plugins: cov-2.12.1 collected 473 items / 2 deselected / 471 selected tests\\test_model.py ............... [ 3%] tests\\test_utils.py ....... [ 4%] tests\\io\\test_bc.py .... [ 5%] tests\\io\\test_bui.py ........................... [ 11%] tests\\io\\test_dimr.py ... [ 11%] tests\\io\\test_docker.py . [ 12%] tests\\io\\test_ext.py ........................................................ [ 23%] tests\\io\\test_fnm.py .................. [ 27%] tests\\io\\test_ini.py .................................................................... [ 42%] ......................................................... [ 54%] tests\\io\\test_net.py ............ [ 56%] tests\\io\\test_parser.py . [ 57%] tests\\io\\test_polyfile.py ............................................................... [ 70%] .................................... [ 78%] tests\\io\\test_structure.py .............................................................. [ 91%] ......................................... [100%] ============================== 471 passed, 2 deselected in 3.50s =============================== (base) PS C:\\checkouts\\HYDROLIB-core_git> Start using hydrolib-core. You can launch your favourite editor (for example VS Code) by first starting a poetry shell with the virtual hydrolib-core environment: (base) PS C:\\checkouts\\HYDROLIB-core_git> poetry shell (base) PS C:\\checkouts\\HYDROLIB-core_git> code","title":"Use Poetry to install hydrolib-core"},{"location":"guides/poetry/#frequently-asked-questions","text":"How to fix \"File ... does not exist\" errors during poetry install as in the example below? * Installing six (1.16.0) ValueError File \\C:\\Users\\dam_ar\\AppData\\Local\\pypoetry\\Cache\\artifacts\\48\\e6\\04\\8118155ae3ec3a16dd2a213bbf7a7d8a62c596b2e90f73a22c896269f1\\six-1.16.0-py2.py3-none-any.whl does not exist This may occur when a conda environment was activated. Delete the AppData\\Local\\pypoetry\\Cache directory. Then run conda deactivate to return to the base environment. Finally, rerun poetry install .","title":"Frequently asked questions"},{"location":"guides/setup/","text":"Installation using pip \u00b6 You can use a pip-based installation if you simply want to use hydrolib-core, without making contributions to the package yourself. You should be able to install hydrolib-core with: pip install hydrolib-core Conda specifics \u00b6 Note If you use conda , it is advisable to install hydrolib-core within a new environment with only conda-forge as channel. If you want to create a fresh test environment for hydrolib-core, you could use the following command (only once): conda create -n hydrolib python = 3 .8 -c conda-forge Prior to the pip install , first activate the desired environment: conda activate hydrolib After successful installation, you should be able to do the \"First steps\" tutorial .","title":"pip install"},{"location":"guides/setup/#installation-using-pip","text":"You can use a pip-based installation if you simply want to use hydrolib-core, without making contributions to the package yourself. You should be able to install hydrolib-core with: pip install hydrolib-core","title":"Installation using pip"},{"location":"guides/setup/#conda-specifics","text":"Note If you use conda , it is advisable to install hydrolib-core within a new environment with only conda-forge as channel. If you want to create a fresh test environment for hydrolib-core, you could use the following command (only once): conda create -n hydrolib python = 3 .8 -c conda-forge Prior to the pip install , first activate the desired environment: conda activate hydrolib After successful installation, you should be able to do the \"First steps\" tutorial .","title":"Conda specifics"},{"location":"reference/api/","text":"BaseModel and FileModel \u00b6 Here we define our Pydantic BaseModel with custom settings, as well as a FileModel that inherits from a BaseModel but also represents a file on disk. BaseModel ( BaseModel ) pydantic-model \u00b6 __init__ ( self , ** data : Any ) -> None special \u00b6 Initializes a BaseModel with the provided data. Exceptions: Type Description ValidationError A validation error when the data is invalid. Source code in hydrolib/core/basemodel.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initializes a BaseModel with the provided data. Raises: ValidationError: A validation error when the data is invalid. \"\"\" try : super () . __init__ ( ** data ) except ValidationError as e : identifier = self . _get_identifier ( data ) if identifier is None : raise e else : # If there is an identifier, include this in the ValidationError messages. raise ValidationError ([ ErrorWrapper ( e , loc = identifier )], self . __class__ ) is_file_link ( self ) -> bool \u00b6 Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : \"\"\"Generic attribute for models backed by a file.\"\"\" return False is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/basemodel.py def is_intermediate_link ( self ) -> bool : \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\" return self . is_file_link () show_tree ( self , indent = 0 ) \u00b6 Recursive print function for showing a tree of a model. Source code in hydrolib/core/basemodel.py def show_tree ( self , indent = 0 ): \"\"\"Recursive print function for showing a tree of a model.\"\"\" angle = \"\u221f\" if indent > 0 else \"\" # Only print if we're backed by a file if self . is_file_link (): print ( \" \" * indent * 2 , angle , self ) # Otherwise we recurse through the fields of a model for _ , value in self : # Handle lists of items if not isinstance ( value , list ): value = [ value ] for v in value : if hasattr ( v , \"is_intermediate_link\" ) and v . is_intermediate_link (): # If the field is only an intermediate, print the name only if not v . is_file_link (): print ( \" \" * ( indent * 2 + 2 ), angle , v . __class__ . __name__ ) v . show_tree ( indent + 1 ) FileModel ( BaseModel , ABC ) pydantic-model \u00b6 Base class to represent models with a file representation. It therefore always has a filepath and if it is given on initilization, it will parse that file. This class extends the validate option of Pydantic, so when when a Path is given to a field with type FileModel , it doesn't error, but actually initializes the FileModel . __init__ ( self , filepath : Optional [ pathlib . Path ] = None , * args , ** kwargs ) special \u00b6 Initialize a model. The model is empty (with defaults) if no filepath is given, otherwise the file at filepath will be parsed. Source code in hydrolib/core/basemodel.py def __init__ ( self , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Initialize a model. The model is empty (with defaults) if no `filepath` is given, otherwise the file at `filepath` will be parsed.\"\"\" # Parse the file if path is given context_dir_reset_token = None if filepath : filepath = Path ( filepath ) # so we also accept strings if filepath in FileModel . _file_models_cache : return None # If not set, this is the root file path if not context_dir . get ( None ): logger . info ( f \"Set context to { filepath . parent } \" ) context_dir_reset_token = context_dir . set ( filepath . parent ) FileModel . _file_models_cache [ filepath ] = self logger . info ( f \"Loading data from { filepath } \" ) data = self . _load ( filepath ) data [ \"filepath\" ] = filepath kwargs . update ( data ) try : super () . __init__ ( * args , ** kwargs ) finally : _reset_context_dir ( context_dir_reset_token ) __new__ ( cls , filepath : Optional [ pathlib . Path ] = None , * args , ** kwargs ) special staticmethod \u00b6 Creates a new model. If the file at the provided file path was already parsed, this instance is returned. Parameters: Name Type Description Default filepath Optional[Path] The absolute file path to the file. Defaults to None. None Returns: Type Description FileModel A file model. Source code in hydrolib/core/basemodel.py def __new__ ( cls , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Creates a new model. If the file at the provided file path was already parsed, this instance is returned. Args: filepath (Optional[Path], optional): The absolute file path to the file. Defaults to None. Returns: FileModel: A file model. \"\"\" if filepath : filepath = Path ( filepath ) if filepath in FileModel . _file_models_cache : filemodel = FileModel . _file_models_cache [ filepath ] logger . info ( f \"Returning existing { type ( filemodel ) . __name__ } from cache, because { filepath } was already parsed.\" ) return filemodel return super () . __new__ ( cls ) __str__ ( self ) -> str special \u00b6 Return str(self). Source code in hydrolib/core/basemodel.py def __str__ ( self ) -> str : return str ( self . filepath if self . filepath else \"\" ) is_file_link ( self ) -> bool \u00b6 Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : return True save ( self , folder : Optional [ pathlib . Path ] = None ) -> Path \u00b6 Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given folder and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Parameters: Name Type Description Default folder Optional[pathlib.Path] path to the folder where this FileModel will be stored None Source code in hydrolib/core/basemodel.py def save ( self , folder : Optional [ Path ] = None ) -> Path : \"\"\"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given `folder` and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Args: folder: path to the folder where this FileModel will be stored \"\"\" if not self . filepath and not folder : raise ValueError ( \"Either set the `filepath` on the model or pass a `folder` when saving.\" ) if not folder : folder = self . filepath . absolute () . parent self . _apply_recurse ( \"_save\" , folder ) return self . filepath . absolute ()","title":"Api"},{"location":"reference/api/#basemodel-and-filemodel","text":"Here we define our Pydantic BaseModel with custom settings, as well as a FileModel that inherits from a BaseModel but also represents a file on disk.","title":"BaseModel and FileModel"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel","text":"","title":"BaseModel"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.__init__","text":"Initializes a BaseModel with the provided data. Exceptions: Type Description ValidationError A validation error when the data is invalid. Source code in hydrolib/core/basemodel.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initializes a BaseModel with the provided data. Raises: ValidationError: A validation error when the data is invalid. \"\"\" try : super () . __init__ ( ** data ) except ValidationError as e : identifier = self . _get_identifier ( data ) if identifier is None : raise e else : # If there is an identifier, include this in the ValidationError messages. raise ValidationError ([ ErrorWrapper ( e , loc = identifier )], self . __class__ )","title":"__init__()"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.is_file_link","text":"Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : \"\"\"Generic attribute for models backed by a file.\"\"\" return False","title":"is_file_link()"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/basemodel.py def is_intermediate_link ( self ) -> bool : \"\"\"Generic attribute for models that have children fields that could contain files.\"\"\" return self . is_file_link ()","title":"is_intermediate_link()"},{"location":"reference/api/#hydrolib.core.basemodel.BaseModel.show_tree","text":"Recursive print function for showing a tree of a model. Source code in hydrolib/core/basemodel.py def show_tree ( self , indent = 0 ): \"\"\"Recursive print function for showing a tree of a model.\"\"\" angle = \"\u221f\" if indent > 0 else \"\" # Only print if we're backed by a file if self . is_file_link (): print ( \" \" * indent * 2 , angle , self ) # Otherwise we recurse through the fields of a model for _ , value in self : # Handle lists of items if not isinstance ( value , list ): value = [ value ] for v in value : if hasattr ( v , \"is_intermediate_link\" ) and v . is_intermediate_link (): # If the field is only an intermediate, print the name only if not v . is_file_link (): print ( \" \" * ( indent * 2 + 2 ), angle , v . __class__ . __name__ ) v . show_tree ( indent + 1 )","title":"show_tree()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel","text":"Base class to represent models with a file representation. It therefore always has a filepath and if it is given on initilization, it will parse that file. This class extends the validate option of Pydantic, so when when a Path is given to a field with type FileModel , it doesn't error, but actually initializes the FileModel .","title":"FileModel"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.__init__","text":"Initialize a model. The model is empty (with defaults) if no filepath is given, otherwise the file at filepath will be parsed. Source code in hydrolib/core/basemodel.py def __init__ ( self , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Initialize a model. The model is empty (with defaults) if no `filepath` is given, otherwise the file at `filepath` will be parsed.\"\"\" # Parse the file if path is given context_dir_reset_token = None if filepath : filepath = Path ( filepath ) # so we also accept strings if filepath in FileModel . _file_models_cache : return None # If not set, this is the root file path if not context_dir . get ( None ): logger . info ( f \"Set context to { filepath . parent } \" ) context_dir_reset_token = context_dir . set ( filepath . parent ) FileModel . _file_models_cache [ filepath ] = self logger . info ( f \"Loading data from { filepath } \" ) data = self . _load ( filepath ) data [ \"filepath\" ] = filepath kwargs . update ( data ) try : super () . __init__ ( * args , ** kwargs ) finally : _reset_context_dir ( context_dir_reset_token )","title":"__init__()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.__new__","text":"Creates a new model. If the file at the provided file path was already parsed, this instance is returned. Parameters: Name Type Description Default filepath Optional[Path] The absolute file path to the file. Defaults to None. None Returns: Type Description FileModel A file model. Source code in hydrolib/core/basemodel.py def __new__ ( cls , filepath : Optional [ Path ] = None , * args , ** kwargs ): \"\"\"Creates a new model. If the file at the provided file path was already parsed, this instance is returned. Args: filepath (Optional[Path], optional): The absolute file path to the file. Defaults to None. Returns: FileModel: A file model. \"\"\" if filepath : filepath = Path ( filepath ) if filepath in FileModel . _file_models_cache : filemodel = FileModel . _file_models_cache [ filepath ] logger . info ( f \"Returning existing { type ( filemodel ) . __name__ } from cache, because { filepath } was already parsed.\" ) return filemodel return super () . __new__ ( cls )","title":"__new__()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.__str__","text":"Return str(self). Source code in hydrolib/core/basemodel.py def __str__ ( self ) -> str : return str ( self . filepath if self . filepath else \"\" )","title":"__str__()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.is_file_link","text":"Generic attribute for models backed by a file. Source code in hydrolib/core/basemodel.py def is_file_link ( self ) -> bool : return True","title":"is_file_link()"},{"location":"reference/api/#hydrolib.core.basemodel.FileModel.save","text":"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given folder and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Parameters: Name Type Description Default folder Optional[pathlib.Path] path to the folder where this FileModel will be stored None Source code in hydrolib/core/basemodel.py def save ( self , folder : Optional [ Path ] = None ) -> Path : \"\"\"Save model and child models to their set filepaths. If a folder is given, for models with an unset filepath, we generate one based on the given `folder` and a default name. Otherwise we override the folder part of already set filepaths. This can thus be used to copy complete models. Args: folder: path to the folder where this FileModel will be stored \"\"\" if not self . filepath and not folder : raise ValueError ( \"Either set the `filepath` on the model or pass a `folder` when saving.\" ) if not folder : folder = self . filepath . absolute () . parent self . _apply_recurse ( \"_save\" , folder ) return self . filepath . absolute ()","title":"save()"},{"location":"reference/bui/","text":"BUI files \u00b6 Model \u00b6 BuiModel ( FileModel ) pydantic-model \u00b6 Model that represents the file structure of a .bui file. get_station_events ( self , station : str ) -> Dict [ datetime . datetime , List [ float ]] \u00b6 Returns all the events (start time and precipitations) related to a given station. Parameters: Name Type Description Default station str Name of the station to retrieve. required Exceptions: Type Description ValueError If the station name does not exist in the BuiModel. Returns: Type Description Dict[datetime, List[float]] Dictionary with the start time and its precipitations. Source code in hydrolib/core/io/bui/models.py def get_station_events ( self , station : str ) -> Dict [ datetime , List [ float ]]: \"\"\" Returns all the events (start time and precipitations) related to a given station. Args: station (str): Name of the station to retrieve. Raises: ValueError: If the station name does not exist in the BuiModel. Returns: Dict[datetime, List[float]]: Dictionary with the start time and its precipitations. \"\"\" if station not in self . name_of_stations : raise ValueError ( \"Station {} not found BuiModel.\" . format ( station )) station_idx = self . name_of_stations . index ( station ) station_events = {} for event in self . precipitation_events : start_time , precipitations = event . get_station_precipitations ( station_idx ) station_events [ start_time ] = precipitations return station_events BuiPrecipitationEvent ( BaseModel ) pydantic-model \u00b6 get_station_precipitations ( self , station_idx : int ) -> Tuple [ datetime . datetime , List [ float ]] \u00b6 Returns all the precipitations related to the given station index (column). Parameters: Name Type Description Default station_idx int Index of the column which values need to be retrieved. required Exceptions: Type Description ValueError If the station index does not exist. Returns: Type Description Tuple[datetime, List[float]] Tuple with the start time and its precipitations. Source code in hydrolib/core/io/bui/models.py def get_station_precipitations ( self , station_idx : int ) -> Tuple [ datetime , List [ float ]]: \"\"\" Returns all the precipitations related to the given station index (column). Args: station_idx (int): Index of the column which values need to be retrieved. Raises: ValueError: If the station index does not exist. Returns: Tuple[datetime, List[float]]: Tuple with the start time and its precipitations. \"\"\" number_of_stations = len ( self . precipitation_per_timestep [ 0 ]) if station_idx >= number_of_stations : raise ValueError ( \"Station index not found, number of stations: {} \" . format ( number_of_stations ) ) return ( self . start_time , [ ts_precipitations [ station_idx ] for ts_precipitations in self . precipitation_per_timestep ], ) Parser \u00b6 BuiEventListParser \u00b6 A parser for .bui events which are like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 4.2 4.2 2021 12 21 0 0 0 1 0 4 20 2.4 2.4 2.4 parse ( raw_text : str , n_events : int , timestep : int ) -> List [ Dict ] staticmethod \u00b6 Parses a given raw text containing 0 to many text blocks representing a precipitation event. Parameters: Name Type Description Default raw_text str Text blocks representing precipitation events. required n_events int Number of events contained in the text block. required timestep int Number of seconds conforming a timestep. required Returns: Type Description List[Dict] List containing all the events represented as dictionaries. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( raw_text : str , n_events : int , timestep : int ) -> List [ Dict ]: \"\"\" Parses a given raw text containing 0 to many text blocks representing a precipitation event. Args: raw_text (str): Text blocks representing precipitation events. n_events (int): Number of events contained in the text block. timestep (int): Number of seconds conforming a timestep. Returns: List[Dict]: List containing all the events represented as dictionaries. \"\"\" def get_event_timestep_length ( raw_line : str ) -> int : timereference = BuiEventParser . parse_event_time_reference ( raw_line ) ts_length : timedelta = timereference [ \"timeseries_length\" ] return ts_length . total_seconds () def get_multiple_events ( raw_lines : List [ str ]) -> Iterator [ BuiEventParser ]: n_line = 0 while n_line < len ( raw_lines ): ts_seconds = get_event_timestep_length ( raw_lines [ n_line ]) event_lines = int ( ts_seconds / timestep ) + 1 yield BuiEventParser . parse ( \" \\n \" . join ( raw_lines [ n_line :][: event_lines ])) n_line += event_lines event_list = [] if n_events == 1 : event_list . append ( BuiEventParser . parse ( raw_text )) elif n_events > 1 : raw_lines = raw_text . splitlines ( keepends = False ) event_list = list ( get_multiple_events ( raw_lines )) return event_list BuiEventParser \u00b6 A parser for the precipitation event section within a .bui file. It resembles something like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 2.4 4.2 2.4 4.2 2.4 (it should match the timeseries length based on the seconds per timstep.) Each column of the last three lines represents a station. parse ( raw_text : str ) -> Dict staticmethod \u00b6 Given text representing a single BuiPrecipitationEvent parses it into a dictionary. Parameters: Name Type Description Default raw_text str Text containing a single precipitation event. required Returns: Type Description Dict Mapped contents of the text. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( raw_text : str ) -> Dict : \"\"\" Given text representing a single BuiPrecipitationEvent parses it into a dictionary. Args: raw_text (str): Text containing a single precipitation event. Returns: Dict: Mapped contents of the text. \"\"\" def get_precipitations_per_ts ( line : str ) -> List [ str ]: return [ prec for prec in line . split ()] event_lines = raw_text . splitlines ( keepends = False ) time_reference = BuiEventParser . parse_event_time_reference ( event_lines [ 0 ]) return dict ( start_time = time_reference [ \"start_time\" ], timeseries_length = time_reference [ \"timeseries_length\" ], precipitation_per_timestep = list ( map ( get_precipitations_per_ts , event_lines [ 1 :]) ), ) parse_event_time_reference ( raw_text : str ) -> Dict staticmethod \u00b6 Parses a single event time reference line containing both the start time and the timeseries length into a dictionary. Parameters: Name Type Description Default raw_text str Line representing both start time and timeseries length. required Returns: Type Description Dict Resulting dictionary with keys start_time and timeseries_length. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse_event_time_reference ( raw_text : str ) -> Dict : \"\"\" Parses a single event time reference line containing both the start time and the timeseries length into a dictionary. Args: raw_text (str): Line representing both start time and timeseries length. Returns: Dict: Resulting dictionary with keys start_time and timeseries_length. \"\"\" def get_start_time ( line : str ) -> datetime : return datetime . strptime ( line , \"%Y %m %d %H %M %S\" ) def get_timeseries_length ( line : str ) -> timedelta : time_fields = line . split () return timedelta ( days = int ( time_fields [ 0 ]), hours = int ( time_fields [ 1 ]), minutes = int ( time_fields [ 2 ]), seconds = int ( time_fields [ 3 ]), ) timeref = raw_text . split () return dict ( start_time = get_start_time ( \" \" . join ( timeref [: 6 ])), timeseries_length = get_timeseries_length ( \" \" . join ( timeref [ 6 :])), ) BuiParser \u00b6 A parser for .bui files which are like this: * comments Dataset type to use (always 1). * comments Number of stations. * comments Name of stations * comments Number of events Number of seconds per timestep. * comments First datetime reference. Precipitation per timestep per station. parse ( filepath : Path ) -> Dict staticmethod \u00b6 Parses a given file, in case valid, into a dictionary which can later be mapped to the BuiModel. Parameters: Name Type Description Default filepath Path Path to file containing the data to parse. required Returns: Type Description Dict Parsed values. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( filepath : Path ) -> Dict : \"\"\" Parses a given file, in case valid, into a dictionary which can later be mapped to the BuiModel. Args: filepath (Path): Path to file containing the data to parse. Returns: Dict: Parsed values. \"\"\" def get_station_ids ( line : str ) -> List [ str ]: return [ s_id for s_id in line . split ( \",\" )] def parse_events_and_timestep ( line : str ) -> Tuple [ int , int ]: n_events_timestep = line . split () return ( int ( n_events_timestep [ 0 ]), int ( n_events_timestep [ 1 ])) bui_lines = [ line for line in filepath . read_text ( encoding = \"utf8\" ) . splitlines () if not line . startswith ( \"*\" ) ] n_events , timestep = parse_events_and_timestep ( bui_lines [ 3 ]) return dict ( default_dataset = bui_lines [ 0 ], number_of_stations = bui_lines [ 1 ], name_of_stations = get_station_ids ( bui_lines [ 2 ]), number_of_events = n_events , seconds_per_timestep = timestep , precipitation_events = BuiEventListParser . parse ( \" \\n \" . join ( bui_lines [ 4 :]), n_events , timestep ), ) Serializer \u00b6 BuiEventSerializer \u00b6 Serializer class to transform a bui event into a text block. get_timedelta_fields ( duration : timedelta ) -> Dict staticmethod \u00b6 Gets a dictionary containing the time delta in days, hours, minutes and seconds. This means that the seconds field does not contain the accumulative value of days hours and minutes. Parameters: Name Type Description Default duration timedelta Timedelta to convert. required Returns: Type Description Dict Dictionary containing all fields. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def get_timedelta_fields ( duration : timedelta ) -> Dict : \"\"\" Gets a dictionary containing the time delta in days, hours, minutes and seconds. This means that the seconds field does not contain the accumulative value of days hours and minutes. Args: duration (timedelta): Timedelta to convert. Returns: Dict: Dictionary containing all fields. \"\"\" total_hours = int ( duration . seconds / ( 60 * 60 )) total_minutes = int (( duration . seconds / 60 ) - ( total_hours * 60 )) total_seconds = int ( duration . seconds - (( total_hours * 60 + total_minutes ) * 60 ) ) return dict ( d_seconds = total_seconds , d_minutes = total_minutes , d_hours = total_hours , d_days = duration . days , ) serialize ( event_data : Dict ) -> str staticmethod \u00b6 Serializes a dictionary representing an event into a text block. Parameters: Name Type Description Default event_data Dict Dictionary representing precipitation event. required Returns: Type Description str Formatted string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize ( event_data : Dict ) -> str : \"\"\" Serializes a dictionary representing an event into a text block. Args: event_data (Dict): Dictionary representing precipitation event. Returns: str: Formatted string. \"\"\" event_data [ \"start_time\" ] = BuiEventSerializer . serialize_start_time ( event_data [ \"start_time\" ] ) ts_duration = event_data [ \"timeseries_length\" ] event_data = { ** event_data , ** BuiEventSerializer . get_timedelta_fields ( ts_duration ), } event_data [ \"timeseries_length\" ] = BuiEventSerializer . serialize_timeseries_length ( event_data [ \"timeseries_length\" ] ) event_data [ \"precipitation_per_timestep\" ] = BuiEventSerializer . serialize_precipitation_per_timestep ( event_data [ \"precipitation_per_timestep\" ] ) if \"event_idx\" not in event_data . keys (): event_data [ \"event_idx\" ] = 1 return BuiEventSerializer . bui_event_template . format ( ** event_data ) serialize_precipitation_per_timestep ( data_to_serialize : List [ List [ str ]]) -> str staticmethod \u00b6 Serialized the data containing all the precipitations per timestep (and station) into a single string ready to be mapped. Parameters: Name Type Description Default data_to_serialize List[List[str]] Data to be mapped. required Returns: Type Description str Serialized string in .bui format. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_precipitation_per_timestep ( data_to_serialize : List [ List [ str ]]) -> str : \"\"\" Serialized the data containing all the precipitations per timestep (and station) into a single string ready to be mapped. Args: data_to_serialize (List[List[str]]): Data to be mapped. Returns: str: Serialized string in .bui format. \"\"\" serialized_data = str . join ( \" \\n \" , [ str . join ( \" \" , map ( str , listed_data )) for listed_data in data_to_serialize ], ) return serialized_data serialize_start_time ( data_to_serialize : datetime ) -> str staticmethod \u00b6 Serializes a datetime into the expected .bui format. Parameters: Name Type Description Default data_to_serialize datetime Datetime representing reference time. required Returns: Type Description str Converted datetime into string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_start_time ( data_to_serialize : datetime ) -> str : \"\"\" Serializes a datetime into the expected .bui format. Args: data_to_serialize (datetime): Datetime representing reference time. Returns: str: Converted datetime into string. \"\"\" # Not using the following format because we only want one digit instead of # double (day 1 -> 1, instead of 01). # data_to_serialize.strftime(\"%Y %m %d %H %M %S\") dt = data_to_serialize return f \" { dt . year } { dt . month } { dt . day } { dt . hour } { dt . minute } { dt . second } \" serialize_timeseries_length ( data_to_serialize : timedelta ) -> str staticmethod \u00b6 Serializes a given timedelta into the .bui format. Parameters: Name Type Description Default data_to_serialize timedelta Reference timespan to serialize. required Returns: Type Description str Converted timedelta in string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_timeseries_length ( data_to_serialize : timedelta ) -> str : \"\"\" Serializes a given timedelta into the .bui format. Args: data_to_serialize (timedelta): Reference timespan to serialize. Returns: str: Converted timedelta in string. \"\"\" fields_dict = BuiEventSerializer . get_timedelta_fields ( data_to_serialize ) total_hours = fields_dict [ \"d_hours\" ] total_minutes = fields_dict [ \"d_minutes\" ] total_seconds = fields_dict [ \"d_seconds\" ] return f \" { data_to_serialize . days } { total_hours } { total_minutes } { total_seconds } \" BuiSerializer \u00b6 Serializer class to transform an object into a .bui file text format. serialize ( bui_data : Dict ) -> str staticmethod \u00b6 Formats the bui_template with the content of the given data. NOTE: It requires that caller injects file_path into bui_data prior to this call. Otherwise it will crash. Parameters: Name Type Description Default bui_data Dict Data to serialize. required Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize ( bui_data : Dict ) -> str : \"\"\" Formats the bui_template with the content of the given data. NOTE: It requires that caller injects file_path into bui_data prior to this call. Otherwise it will crash. Args: bui_data (Dict): Data to serialize. \"\"\" bui_data [ \"datetime_now\" ] = datetime . now () . strftime ( \" %d -%m-%y %H:%M:%S\" ) bui_data [ \"name_of_stations\" ] = BuiSerializer . serialize_stations_ids ( bui_data [ \"name_of_stations\" ] ) bui_data [ \"precipitation_events\" ] = BuiSerializer . serialize_event_list ( bui_data [ \"precipitation_events\" ] ) return BuiSerializer . bui_template . format ( ** bui_data ) serialize_event_list ( data_to_serialize : List [ Dict ]) -> str staticmethod \u00b6 Serializes a event list dictionary into a single text block. Parameters: Name Type Description Default data_to_serialize Dict Dictionary containing list of events. required Returns: Type Description str Text block representing all precipitation events. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_event_list ( data_to_serialize : List [ Dict ]) -> str : \"\"\" Serializes a event list dictionary into a single text block. Args: data_to_serialize (Dict): Dictionary containing list of events. Returns: str: Text block representing all precipitation events. \"\"\" serialized_list = [] for n_event , event in enumerate ( data_to_serialize ): event [ \"event_idx\" ] = n_event + 1 serialized_list . append ( BuiEventSerializer . serialize ( event )) return \" \\n \" . join ( serialized_list ) serialize_stations_ids ( data_to_serialize : List [ str ]) -> str staticmethod \u00b6 Serializes the stations ids into a single string as expected in a .bui file. Parameters: Name Type Description Default data_to_serialize List[str] List of station ids. required Returns: Type Description str Serialized string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_stations_ids ( data_to_serialize : List [ str ]) -> str : \"\"\" Serializes the stations ids into a single string as expected in a .bui file. Args: data_to_serialize (List[str]): List of station ids. Returns: str: Serialized string. \"\"\" return str . join ( \" \" , data_to_serialize ) write_bui_file ( path : Path , data : Dict ) -> None \u00b6 Writes a .bui file in the given path based on the data given in a dictionary. Parameters: Name Type Description Default path Path Path where to output the text. required data Dict Data to serialize into the file. required Source code in hydrolib/core/io/bui/serializer.py def write_bui_file ( path : Path , data : Dict ) -> None : \"\"\" Writes a .bui file in the given path based on the data given in a dictionary. Args: path (Path): Path where to output the text. data (Dict): Data to serialize into the file. \"\"\" data [ \"filepath\" ] = path # This is redundant as already exists in the data. serialized_bui_data = BuiSerializer . serialize ( data ) path . parent . mkdir ( parents = True , exist_ok = True ) path . write_text ( serialized_bui_data , encoding = \"utf8\" )","title":"Bui"},{"location":"reference/bui/#bui-files","text":"","title":"BUI files"},{"location":"reference/bui/#model","text":"","title":"Model"},{"location":"reference/bui/#hydrolib.core.io.bui.models.BuiModel","text":"Model that represents the file structure of a .bui file.","title":"BuiModel"},{"location":"reference/bui/#hydrolib.core.io.bui.models.BuiModel.get_station_events","text":"Returns all the events (start time and precipitations) related to a given station. Parameters: Name Type Description Default station str Name of the station to retrieve. required Exceptions: Type Description ValueError If the station name does not exist in the BuiModel. Returns: Type Description Dict[datetime, List[float]] Dictionary with the start time and its precipitations. Source code in hydrolib/core/io/bui/models.py def get_station_events ( self , station : str ) -> Dict [ datetime , List [ float ]]: \"\"\" Returns all the events (start time and precipitations) related to a given station. Args: station (str): Name of the station to retrieve. Raises: ValueError: If the station name does not exist in the BuiModel. Returns: Dict[datetime, List[float]]: Dictionary with the start time and its precipitations. \"\"\" if station not in self . name_of_stations : raise ValueError ( \"Station {} not found BuiModel.\" . format ( station )) station_idx = self . name_of_stations . index ( station ) station_events = {} for event in self . precipitation_events : start_time , precipitations = event . get_station_precipitations ( station_idx ) station_events [ start_time ] = precipitations return station_events","title":"get_station_events()"},{"location":"reference/bui/#hydrolib.core.io.bui.models.BuiPrecipitationEvent","text":"","title":"BuiPrecipitationEvent"},{"location":"reference/bui/#hydrolib.core.io.bui.models.BuiPrecipitationEvent.get_station_precipitations","text":"Returns all the precipitations related to the given station index (column). Parameters: Name Type Description Default station_idx int Index of the column which values need to be retrieved. required Exceptions: Type Description ValueError If the station index does not exist. Returns: Type Description Tuple[datetime, List[float]] Tuple with the start time and its precipitations. Source code in hydrolib/core/io/bui/models.py def get_station_precipitations ( self , station_idx : int ) -> Tuple [ datetime , List [ float ]]: \"\"\" Returns all the precipitations related to the given station index (column). Args: station_idx (int): Index of the column which values need to be retrieved. Raises: ValueError: If the station index does not exist. Returns: Tuple[datetime, List[float]]: Tuple with the start time and its precipitations. \"\"\" number_of_stations = len ( self . precipitation_per_timestep [ 0 ]) if station_idx >= number_of_stations : raise ValueError ( \"Station index not found, number of stations: {} \" . format ( number_of_stations ) ) return ( self . start_time , [ ts_precipitations [ station_idx ] for ts_precipitations in self . precipitation_per_timestep ], )","title":"get_station_precipitations()"},{"location":"reference/bui/#parser","text":"","title":"Parser"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiEventListParser","text":"A parser for .bui events which are like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 4.2 4.2 2021 12 21 0 0 0 1 0 4 20 2.4 2.4 2.4","title":"BuiEventListParser"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiEventListParser.parse","text":"Parses a given raw text containing 0 to many text blocks representing a precipitation event. Parameters: Name Type Description Default raw_text str Text blocks representing precipitation events. required n_events int Number of events contained in the text block. required timestep int Number of seconds conforming a timestep. required Returns: Type Description List[Dict] List containing all the events represented as dictionaries. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( raw_text : str , n_events : int , timestep : int ) -> List [ Dict ]: \"\"\" Parses a given raw text containing 0 to many text blocks representing a precipitation event. Args: raw_text (str): Text blocks representing precipitation events. n_events (int): Number of events contained in the text block. timestep (int): Number of seconds conforming a timestep. Returns: List[Dict]: List containing all the events represented as dictionaries. \"\"\" def get_event_timestep_length ( raw_line : str ) -> int : timereference = BuiEventParser . parse_event_time_reference ( raw_line ) ts_length : timedelta = timereference [ \"timeseries_length\" ] return ts_length . total_seconds () def get_multiple_events ( raw_lines : List [ str ]) -> Iterator [ BuiEventParser ]: n_line = 0 while n_line < len ( raw_lines ): ts_seconds = get_event_timestep_length ( raw_lines [ n_line ]) event_lines = int ( ts_seconds / timestep ) + 1 yield BuiEventParser . parse ( \" \\n \" . join ( raw_lines [ n_line :][: event_lines ])) n_line += event_lines event_list = [] if n_events == 1 : event_list . append ( BuiEventParser . parse ( raw_text )) elif n_events > 1 : raw_lines = raw_text . splitlines ( keepends = False ) event_list = list ( get_multiple_events ( raw_lines )) return event_list","title":"parse()"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiEventParser","text":"A parser for the precipitation event section within a .bui file. It resembles something like this: StartTime (YYYY mm dd HH MM SS) TimeSeriesLength (dd HH MM SS) PrecipitationPerTimestep Example given: 2021 12 20 0 0 0 1 0 4 20 4.2 2.4 4.2 2.4 4.2 2.4 (it should match the timeseries length based on the seconds per timstep.) Each column of the last three lines represents a station.","title":"BuiEventParser"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiEventParser.parse","text":"Given text representing a single BuiPrecipitationEvent parses it into a dictionary. Parameters: Name Type Description Default raw_text str Text containing a single precipitation event. required Returns: Type Description Dict Mapped contents of the text. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( raw_text : str ) -> Dict : \"\"\" Given text representing a single BuiPrecipitationEvent parses it into a dictionary. Args: raw_text (str): Text containing a single precipitation event. Returns: Dict: Mapped contents of the text. \"\"\" def get_precipitations_per_ts ( line : str ) -> List [ str ]: return [ prec for prec in line . split ()] event_lines = raw_text . splitlines ( keepends = False ) time_reference = BuiEventParser . parse_event_time_reference ( event_lines [ 0 ]) return dict ( start_time = time_reference [ \"start_time\" ], timeseries_length = time_reference [ \"timeseries_length\" ], precipitation_per_timestep = list ( map ( get_precipitations_per_ts , event_lines [ 1 :]) ), )","title":"parse()"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiEventParser.parse_event_time_reference","text":"Parses a single event time reference line containing both the start time and the timeseries length into a dictionary. Parameters: Name Type Description Default raw_text str Line representing both start time and timeseries length. required Returns: Type Description Dict Resulting dictionary with keys start_time and timeseries_length. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse_event_time_reference ( raw_text : str ) -> Dict : \"\"\" Parses a single event time reference line containing both the start time and the timeseries length into a dictionary. Args: raw_text (str): Line representing both start time and timeseries length. Returns: Dict: Resulting dictionary with keys start_time and timeseries_length. \"\"\" def get_start_time ( line : str ) -> datetime : return datetime . strptime ( line , \"%Y %m %d %H %M %S\" ) def get_timeseries_length ( line : str ) -> timedelta : time_fields = line . split () return timedelta ( days = int ( time_fields [ 0 ]), hours = int ( time_fields [ 1 ]), minutes = int ( time_fields [ 2 ]), seconds = int ( time_fields [ 3 ]), ) timeref = raw_text . split () return dict ( start_time = get_start_time ( \" \" . join ( timeref [: 6 ])), timeseries_length = get_timeseries_length ( \" \" . join ( timeref [ 6 :])), )","title":"parse_event_time_reference()"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiParser","text":"A parser for .bui files which are like this: * comments Dataset type to use (always 1). * comments Number of stations. * comments Name of stations * comments Number of events Number of seconds per timestep. * comments First datetime reference. Precipitation per timestep per station.","title":"BuiParser"},{"location":"reference/bui/#hydrolib.core.io.bui.parser.BuiParser.parse","text":"Parses a given file, in case valid, into a dictionary which can later be mapped to the BuiModel. Parameters: Name Type Description Default filepath Path Path to file containing the data to parse. required Returns: Type Description Dict Parsed values. Source code in hydrolib/core/io/bui/parser.py @staticmethod def parse ( filepath : Path ) -> Dict : \"\"\" Parses a given file, in case valid, into a dictionary which can later be mapped to the BuiModel. Args: filepath (Path): Path to file containing the data to parse. Returns: Dict: Parsed values. \"\"\" def get_station_ids ( line : str ) -> List [ str ]: return [ s_id for s_id in line . split ( \",\" )] def parse_events_and_timestep ( line : str ) -> Tuple [ int , int ]: n_events_timestep = line . split () return ( int ( n_events_timestep [ 0 ]), int ( n_events_timestep [ 1 ])) bui_lines = [ line for line in filepath . read_text ( encoding = \"utf8\" ) . splitlines () if not line . startswith ( \"*\" ) ] n_events , timestep = parse_events_and_timestep ( bui_lines [ 3 ]) return dict ( default_dataset = bui_lines [ 0 ], number_of_stations = bui_lines [ 1 ], name_of_stations = get_station_ids ( bui_lines [ 2 ]), number_of_events = n_events , seconds_per_timestep = timestep , precipitation_events = BuiEventListParser . parse ( \" \\n \" . join ( bui_lines [ 4 :]), n_events , timestep ), )","title":"parse()"},{"location":"reference/bui/#serializer","text":"","title":"Serializer"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer","text":"Serializer class to transform a bui event into a text block.","title":"BuiEventSerializer"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer.get_timedelta_fields","text":"Gets a dictionary containing the time delta in days, hours, minutes and seconds. This means that the seconds field does not contain the accumulative value of days hours and minutes. Parameters: Name Type Description Default duration timedelta Timedelta to convert. required Returns: Type Description Dict Dictionary containing all fields. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def get_timedelta_fields ( duration : timedelta ) -> Dict : \"\"\" Gets a dictionary containing the time delta in days, hours, minutes and seconds. This means that the seconds field does not contain the accumulative value of days hours and minutes. Args: duration (timedelta): Timedelta to convert. Returns: Dict: Dictionary containing all fields. \"\"\" total_hours = int ( duration . seconds / ( 60 * 60 )) total_minutes = int (( duration . seconds / 60 ) - ( total_hours * 60 )) total_seconds = int ( duration . seconds - (( total_hours * 60 + total_minutes ) * 60 ) ) return dict ( d_seconds = total_seconds , d_minutes = total_minutes , d_hours = total_hours , d_days = duration . days , )","title":"get_timedelta_fields()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer.serialize","text":"Serializes a dictionary representing an event into a text block. Parameters: Name Type Description Default event_data Dict Dictionary representing precipitation event. required Returns: Type Description str Formatted string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize ( event_data : Dict ) -> str : \"\"\" Serializes a dictionary representing an event into a text block. Args: event_data (Dict): Dictionary representing precipitation event. Returns: str: Formatted string. \"\"\" event_data [ \"start_time\" ] = BuiEventSerializer . serialize_start_time ( event_data [ \"start_time\" ] ) ts_duration = event_data [ \"timeseries_length\" ] event_data = { ** event_data , ** BuiEventSerializer . get_timedelta_fields ( ts_duration ), } event_data [ \"timeseries_length\" ] = BuiEventSerializer . serialize_timeseries_length ( event_data [ \"timeseries_length\" ] ) event_data [ \"precipitation_per_timestep\" ] = BuiEventSerializer . serialize_precipitation_per_timestep ( event_data [ \"precipitation_per_timestep\" ] ) if \"event_idx\" not in event_data . keys (): event_data [ \"event_idx\" ] = 1 return BuiEventSerializer . bui_event_template . format ( ** event_data )","title":"serialize()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer.serialize_precipitation_per_timestep","text":"Serialized the data containing all the precipitations per timestep (and station) into a single string ready to be mapped. Parameters: Name Type Description Default data_to_serialize List[List[str]] Data to be mapped. required Returns: Type Description str Serialized string in .bui format. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_precipitation_per_timestep ( data_to_serialize : List [ List [ str ]]) -> str : \"\"\" Serialized the data containing all the precipitations per timestep (and station) into a single string ready to be mapped. Args: data_to_serialize (List[List[str]]): Data to be mapped. Returns: str: Serialized string in .bui format. \"\"\" serialized_data = str . join ( \" \\n \" , [ str . join ( \" \" , map ( str , listed_data )) for listed_data in data_to_serialize ], ) return serialized_data","title":"serialize_precipitation_per_timestep()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer.serialize_start_time","text":"Serializes a datetime into the expected .bui format. Parameters: Name Type Description Default data_to_serialize datetime Datetime representing reference time. required Returns: Type Description str Converted datetime into string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_start_time ( data_to_serialize : datetime ) -> str : \"\"\" Serializes a datetime into the expected .bui format. Args: data_to_serialize (datetime): Datetime representing reference time. Returns: str: Converted datetime into string. \"\"\" # Not using the following format because we only want one digit instead of # double (day 1 -> 1, instead of 01). # data_to_serialize.strftime(\"%Y %m %d %H %M %S\") dt = data_to_serialize return f \" { dt . year } { dt . month } { dt . day } { dt . hour } { dt . minute } { dt . second } \"","title":"serialize_start_time()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiEventSerializer.serialize_timeseries_length","text":"Serializes a given timedelta into the .bui format. Parameters: Name Type Description Default data_to_serialize timedelta Reference timespan to serialize. required Returns: Type Description str Converted timedelta in string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_timeseries_length ( data_to_serialize : timedelta ) -> str : \"\"\" Serializes a given timedelta into the .bui format. Args: data_to_serialize (timedelta): Reference timespan to serialize. Returns: str: Converted timedelta in string. \"\"\" fields_dict = BuiEventSerializer . get_timedelta_fields ( data_to_serialize ) total_hours = fields_dict [ \"d_hours\" ] total_minutes = fields_dict [ \"d_minutes\" ] total_seconds = fields_dict [ \"d_seconds\" ] return f \" { data_to_serialize . days } { total_hours } { total_minutes } { total_seconds } \"","title":"serialize_timeseries_length()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiSerializer","text":"Serializer class to transform an object into a .bui file text format.","title":"BuiSerializer"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiSerializer.serialize","text":"Formats the bui_template with the content of the given data. NOTE: It requires that caller injects file_path into bui_data prior to this call. Otherwise it will crash. Parameters: Name Type Description Default bui_data Dict Data to serialize. required Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize ( bui_data : Dict ) -> str : \"\"\" Formats the bui_template with the content of the given data. NOTE: It requires that caller injects file_path into bui_data prior to this call. Otherwise it will crash. Args: bui_data (Dict): Data to serialize. \"\"\" bui_data [ \"datetime_now\" ] = datetime . now () . strftime ( \" %d -%m-%y %H:%M:%S\" ) bui_data [ \"name_of_stations\" ] = BuiSerializer . serialize_stations_ids ( bui_data [ \"name_of_stations\" ] ) bui_data [ \"precipitation_events\" ] = BuiSerializer . serialize_event_list ( bui_data [ \"precipitation_events\" ] ) return BuiSerializer . bui_template . format ( ** bui_data )","title":"serialize()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiSerializer.serialize_event_list","text":"Serializes a event list dictionary into a single text block. Parameters: Name Type Description Default data_to_serialize Dict Dictionary containing list of events. required Returns: Type Description str Text block representing all precipitation events. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_event_list ( data_to_serialize : List [ Dict ]) -> str : \"\"\" Serializes a event list dictionary into a single text block. Args: data_to_serialize (Dict): Dictionary containing list of events. Returns: str: Text block representing all precipitation events. \"\"\" serialized_list = [] for n_event , event in enumerate ( data_to_serialize ): event [ \"event_idx\" ] = n_event + 1 serialized_list . append ( BuiEventSerializer . serialize ( event )) return \" \\n \" . join ( serialized_list )","title":"serialize_event_list()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.BuiSerializer.serialize_stations_ids","text":"Serializes the stations ids into a single string as expected in a .bui file. Parameters: Name Type Description Default data_to_serialize List[str] List of station ids. required Returns: Type Description str Serialized string. Source code in hydrolib/core/io/bui/serializer.py @staticmethod def serialize_stations_ids ( data_to_serialize : List [ str ]) -> str : \"\"\" Serializes the stations ids into a single string as expected in a .bui file. Args: data_to_serialize (List[str]): List of station ids. Returns: str: Serialized string. \"\"\" return str . join ( \" \" , data_to_serialize )","title":"serialize_stations_ids()"},{"location":"reference/bui/#hydrolib.core.io.bui.serializer.write_bui_file","text":"Writes a .bui file in the given path based on the data given in a dictionary. Parameters: Name Type Description Default path Path Path where to output the text. required data Dict Data to serialize into the file. required Source code in hydrolib/core/io/bui/serializer.py def write_bui_file ( path : Path , data : Dict ) -> None : \"\"\" Writes a .bui file in the given path based on the data given in a dictionary. Args: path (Path): Path where to output the text. data (Dict): Data to serialize into the file. \"\"\" data [ \"filepath\" ] = path # This is redundant as already exists in the data. serialized_bui_data = BuiSerializer . serialize ( data ) path . parent . mkdir ( parents = True , exist_ok = True ) path . write_text ( serialized_bui_data , encoding = \"utf8\" )","title":"write_bui_file()"},{"location":"reference/crosssection/","text":"cross section .ini files \u00b6 The crosssection module provides the specific logic for accessing cross section files (location and definition). Generic parsing and serializing functionality comes from the generic hydrolib.core.io.ini modules. Model \u00b6 CircleCrsDef ( CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=circle , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the circle input as described in UM Sec.C.16.1.1 . CrossDefGeneral ( INIGeneral ) pydantic-model \u00b6 The crosssection definition file's [General] section with file meta data. CrossDefModel ( INIModel ) pydantic-model \u00b6 The overall crosssection definition model that contains the contents of one crossdef file. This model is typically referenced under a FMModel .geometry.crossdeffile . Attributes: Name Type Description general CrossdefGeneral [General] block with file metadata. definition List[CrossSectionDefinition] List of [Definition] blocks for all cross sections. CrossLocGeneral ( INIGeneral ) pydantic-model \u00b6 The crosssection location file's [General] section with file meta data. CrossLocModel ( INIModel ) pydantic-model \u00b6 The overall crosssection location model that contains the contents of one crossloc file. This model is typically referenced under a FMModel .geometry.crosslocfile . Attributes: Name Type Description general CrossLocGeneral [General] block with file metadata. crosssection List[CrossSection] List of [CrossSection] blocks for all cross section locations. CrossSection ( INIBasedModel ) pydantic-model \u00b6 A [CrossSection] block for use inside a crosssection location file, i.e., a CrossLocModel . Attributes: Name Type Description id str Unique cross-section location id. branchid str (optional) Branch on which the cross section is located. CrossSectionDefinition ( INIBasedModel ) pydantic-model \u00b6 A [Definition] block for use inside a crosssection definition file, i.e., a CrossDefModel . This class is intended as an abstract class: various subclasses should define they actual types of crosssection definitions. validate ( v ) classmethod \u00b6 Try to iniatialize subclass based on the type field. This field is compared to each type field of the derived models of CrossSectionDefinition . The derived model with an equal crosssection definition type will be initialized. Exceptions: Type Description ValueError When the given type is not a known crosssection definition type. Source code in hydrolib/core/io/crosssection/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `type` field. This field is compared to each `type` field of the derived models of `CrossSectionDefinition`. The derived model with an equal crosssection definition type will be initialized. Raises: ValueError: When the given type is not a known crosssection definition type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"type\" ) . default . lower () == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Type of { cls . __name__ } with id= { v . get ( 'id' , '' ) } and type= { v . get ( 'type' , '' ) } is not recognized.\" ) return super () . validate ( v ) RectangleCrsDef ( CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=rectangle , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the rectangle input as described in UM Sec.C.16.1.2 . XYZCrsDef ( YZCrsDef , CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=xyz , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the xyz input as described in UM Sec.C.16.1.5 . This class extends the YZCrsDef class with x-coordinates and an optional branchId field. Most other attributes are inherited, but the coordcount is overridden under the Pydantic alias \"xyzCount\". Attributes: Name Type Description yzcount Optional[int] dummy attribute that should not be set nor used. Only present to mask the inherited attribute from parent class YZCrsDef. xyzcount int Number of XYZ-coordinates. Always use this instead of yzcount. validate_xyzcount_without_yzcount ( field_value : int , values : dict ) -> int classmethod \u00b6 Validates whether this XYZCrsDef does have attribute xyzcount, but not the parent class's yzcount. Parameters: Name Type Description Default field_value Optional[Path] Value given for xyzcount. required values dict Dictionary of values already validated. required Exceptions: Type Description ValueError When yzcount is present. Returns: Type Description int The value given for xyzcount. Source code in hydrolib/core/io/crosssection/models.py @validator ( \"xyzcount\" ) @classmethod def validate_xyzcount_without_yzcount ( cls , field_value : int , values : dict ) -> int : \"\"\" Validates whether this XYZCrsDef does have attribute xyzcount, but not the parent class's yzcount. Args: field_value (Optional[Path]): Value given for xyzcount. values (dict): Dictionary of values already validated. Raises: ValueError: When yzcount is present. Returns: int: The value given for xyzcount. \"\"\" # Retrieve the algorithm value (if not found use 0). yzcount_value = values . get ( \"yzcount\" ) if field_value is not None and yzcount_value is not None : # yzcount should not be set, when xyzcount is set. raise ValueError ( f \"xyz cross section definition should not contain field yzCount (rather: xyzCount), current value: { yzcount_value } .\" ) return field_value YZCrsDef ( CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=yz , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the yz input as described in UM Sec.C.16.1.6 . ZWCrsDef ( CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=zw , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the zw input as described in UM Sec.C.16.1.4 . ZWRiverCrsDef ( CrossSectionDefinition ) pydantic-model \u00b6 Crosssection definition with type=zwRiver , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the zwRiver input as described in UM Sec.C.16.1.3 .","title":"Crosssection"},{"location":"reference/crosssection/#cross-section-ini-files","text":"The crosssection module provides the specific logic for accessing cross section files (location and definition). Generic parsing and serializing functionality comes from the generic hydrolib.core.io.ini modules.","title":"cross section .ini files"},{"location":"reference/crosssection/#model","text":"","title":"Model"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CircleCrsDef","text":"Crosssection definition with type=circle , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the circle input as described in UM Sec.C.16.1.1 .","title":"CircleCrsDef"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossDefGeneral","text":"The crosssection definition file's [General] section with file meta data.","title":"CrossDefGeneral"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossDefModel","text":"The overall crosssection definition model that contains the contents of one crossdef file. This model is typically referenced under a FMModel .geometry.crossdeffile . Attributes: Name Type Description general CrossdefGeneral [General] block with file metadata. definition List[CrossSectionDefinition] List of [Definition] blocks for all cross sections.","title":"CrossDefModel"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossLocGeneral","text":"The crosssection location file's [General] section with file meta data.","title":"CrossLocGeneral"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossLocModel","text":"The overall crosssection location model that contains the contents of one crossloc file. This model is typically referenced under a FMModel .geometry.crosslocfile . Attributes: Name Type Description general CrossLocGeneral [General] block with file metadata. crosssection List[CrossSection] List of [CrossSection] blocks for all cross section locations.","title":"CrossLocModel"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossSection","text":"A [CrossSection] block for use inside a crosssection location file, i.e., a CrossLocModel . Attributes: Name Type Description id str Unique cross-section location id. branchid str (optional) Branch on which the cross section is located.","title":"CrossSection"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossSectionDefinition","text":"A [Definition] block for use inside a crosssection definition file, i.e., a CrossDefModel . This class is intended as an abstract class: various subclasses should define they actual types of crosssection definitions.","title":"CrossSectionDefinition"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.CrossSectionDefinition.validate","text":"Try to iniatialize subclass based on the type field. This field is compared to each type field of the derived models of CrossSectionDefinition . The derived model with an equal crosssection definition type will be initialized. Exceptions: Type Description ValueError When the given type is not a known crosssection definition type. Source code in hydrolib/core/io/crosssection/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `type` field. This field is compared to each `type` field of the derived models of `CrossSectionDefinition`. The derived model with an equal crosssection definition type will be initialized. Raises: ValueError: When the given type is not a known crosssection definition type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"type\" ) . default . lower () == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Type of { cls . __name__ } with id= { v . get ( 'id' , '' ) } and type= { v . get ( 'type' , '' ) } is not recognized.\" ) return super () . validate ( v )","title":"validate()"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.RectangleCrsDef","text":"Crosssection definition with type=rectangle , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the rectangle input as described in UM Sec.C.16.1.2 .","title":"RectangleCrsDef"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.XYZCrsDef","text":"Crosssection definition with type=xyz , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the xyz input as described in UM Sec.C.16.1.5 . This class extends the YZCrsDef class with x-coordinates and an optional branchId field. Most other attributes are inherited, but the coordcount is overridden under the Pydantic alias \"xyzCount\". Attributes: Name Type Description yzcount Optional[int] dummy attribute that should not be set nor used. Only present to mask the inherited attribute from parent class YZCrsDef. xyzcount int Number of XYZ-coordinates. Always use this instead of yzcount.","title":"XYZCrsDef"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.XYZCrsDef.validate_xyzcount_without_yzcount","text":"Validates whether this XYZCrsDef does have attribute xyzcount, but not the parent class's yzcount. Parameters: Name Type Description Default field_value Optional[Path] Value given for xyzcount. required values dict Dictionary of values already validated. required Exceptions: Type Description ValueError When yzcount is present. Returns: Type Description int The value given for xyzcount. Source code in hydrolib/core/io/crosssection/models.py @validator ( \"xyzcount\" ) @classmethod def validate_xyzcount_without_yzcount ( cls , field_value : int , values : dict ) -> int : \"\"\" Validates whether this XYZCrsDef does have attribute xyzcount, but not the parent class's yzcount. Args: field_value (Optional[Path]): Value given for xyzcount. values (dict): Dictionary of values already validated. Raises: ValueError: When yzcount is present. Returns: int: The value given for xyzcount. \"\"\" # Retrieve the algorithm value (if not found use 0). yzcount_value = values . get ( \"yzcount\" ) if field_value is not None and yzcount_value is not None : # yzcount should not be set, when xyzcount is set. raise ValueError ( f \"xyz cross section definition should not contain field yzCount (rather: xyzCount), current value: { yzcount_value } .\" ) return field_value","title":"validate_xyzcount_without_yzcount()"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.YZCrsDef","text":"Crosssection definition with type=yz , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the yz input as described in UM Sec.C.16.1.6 .","title":"YZCrsDef"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.ZWCrsDef","text":"Crosssection definition with type=zw , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the zw input as described in UM Sec.C.16.1.4 .","title":"ZWCrsDef"},{"location":"reference/crosssection/#hydrolib.core.io.crosssection.models.ZWRiverCrsDef","text":"Crosssection definition with type=zwRiver , to be included in a crossdef file. Typically inside the definition list of a FMModel .geometry.crossdeffile.definition[..] All lowercased attributes match with the zwRiver input as described in UM Sec.C.16.1.3 .","title":"ZWRiverCrsDef"},{"location":"reference/dimr/","text":"DIMR xml files \u00b6 Model \u00b6 Component ( BaseModel , ABC ) pydantic-model \u00b6 Specification of a BMI-compliant model component instance that will be executed by DIMR. Attributes: Name Type Description library str The library name of the compoment. name str The component name. workingDir Path The working directory. inputFile Path The name of the input file. process Optional[int] Number of subprocesses in the component. setting Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model before initialization. parameter Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model after initialization. mpiCommunicator Optional[str] The MPI communicator value. model Optional[hydrolib.core.basemodel.FileModel] The model represented by this component. dict ( self , * args , ** kwargs ) \u00b6 Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): # Exclude the FileModel from any DIMR serialization. kwargs [ \"exclude\" ] = { \"model\" } return super () . dict ( * args , ** kwargs ) is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : return True ComponentOrCouplerRef ( BaseModel ) pydantic-model \u00b6 Reference to a BMI-compliant model component instance. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance. ControlModel ( BaseModel ) pydantic-model \u00b6 Overrides to make sure that the control elements in the DIMR are parsed and serialized correctly. dict ( self , * args , ** kwargs ) \u00b6 Add control element prefixes for serialized data. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): \"\"\"Add control element prefixes for serialized data.\"\"\" return { str ( self . _type ): super () . dict ( * args , ** kwargs ), } validate ( v ) classmethod \u00b6 Remove control element prefixes from parsed data. Source code in hydrolib/core/io/dimr/models.py @classmethod def validate ( cls , v ): \"\"\"Remove control element prefixes from parsed data.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ) and len ( v . keys ()) == 1 : key = list ( v . keys ())[ 0 ] v = v [ key ] return super () . validate ( v ) CoupledItem ( BaseModel ) pydantic-model \u00b6 Specification of an item that has to be exchanged. Attributes: Name Type Description sourceName str Name of the item at the source component. targetName str Name of the item at the target component. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False Coupler ( BaseModel ) pydantic-model \u00b6 Specification of the coupling actions to be performed between two BMI-compliant model components. Attributes: Name Type Description name str The name of the coupler. sourceComponent str The component that provides the data to has to be exchanged. targetComponent str The component that consumes the data to has to be exchanged. item List[hydrolib.core.io.dimr.models.CoupledItem] A list of items that have to be exchanged. logger Optional[hydrolib.core.io.dimr.models.Logger] Logger for logging the values that get exchanged. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False DIMR ( FileModel ) pydantic-model \u00b6 DIMR model representation. Attributes: Name Type Description documentation Documentation File metadata. control List[Union[Start, Parallel]] The <control> element with a list of Start and Parallel sub-elements, which defines the (sequence of) program(s) to be run. May be empty while constructing, but must be non-empty when saving! Also, all referenced components must be present in component when saving. Similarly, all referenced couplers must be present in coupler . component List[Union[RRComponent, FMComponent, Component]] List of <component> elements that defines which programs can be used inside the <control> subelements. Must be non-empty when saving! coupler Optional[List[Coupler]] optional list of <coupler> elements that defines which couplers can be used inside the <parallel> elements under <control> . waitFile Optional[str] Optional waitfile name for debugging. global_settings Optional[GlobalSettings] Optional global DIMR settings. dict ( self , * args , ** kwargs ) \u00b6 Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): kwargs [ \"exclude_none\" ] = True kwargs [ \"exclude\" ] = { \"filepath\" } return super () . dict ( * args , ** kwargs ) Documentation ( BaseModel ) pydantic-model \u00b6 Information on the present DIMR configuration file. Attributes: Name Type Description fileVersion str The DIMR file version. createdBy str Creators of the DIMR file. creationDate datetime The creation date of the DIMR file. GlobalSettings ( BaseModel ) pydantic-model \u00b6 Global settings for the DIMR configuration. Attributes: Name Type Description logger_ncFormat int NetCDF format type for logging. KeyValuePair ( BaseModel ) pydantic-model \u00b6 Key value pair to specify settings and parameters. Attributes: Name Type Description key str The key. value str The value. Logger ( BaseModel ) pydantic-model \u00b6 Used to log values to the specified file in workingdir for each timestep Attributes: Name Type Description workingDir Path Directory where the log file is written. outputFile Path Name of the log file. Parallel ( ControlModel ) pydantic-model \u00b6 Specification of a parallel control flow: one main component and a group of related components and couplers. Step wise execution order according to order in parallel control flow. Attributes: Name Type Description startGroup StartGroup Group of components and couplers to be executed. start ComponentOrCouplerRef Main component to be executed step wise (provides start time, end time and time step). Start ( ControlModel ) pydantic-model \u00b6 Specification of a serial control flow: one main component. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance StartGroup ( BaseModel ) pydantic-model \u00b6 Specification of model components and couplers to be executed with a certain frequency. Attributes: Name Type Description time str Time frame specification for the present group: start time, stop time and frequency. Expressed in terms of the time frame of the main component. start List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Ordered list of components to be executed. coupler List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Oredered list of couplers to be executed. Parser \u00b6 DIMRParser \u00b6 A parser for DIMR xml files. parse ( path : Path ) -> dict staticmethod \u00b6 Parses a DIMR file to a dictionary. Parameters: Name Type Description Default path Path Path to the DIMR configuration file. required Source code in hydrolib/core/io/dimr/parser.py @staticmethod def parse ( path : Path ) -> dict : \"\"\"Parses a DIMR file to a dictionary. Args: path (Path): Path to the DIMR configuration file. \"\"\" if not path . is_file (): warn ( f \"File: ` { path } ` not found, skipped parsing.\" ) return {} parser = etree . XMLParser ( remove_comments = True , resolve_entities = False , no_network = True ) root = etree . parse ( str ( path ), parser = parser ) . getroot () return DIMRParser . _node_to_dictionary ( root , True ) Serializer \u00b6 DIMRSerializer \u00b6 A serializer for DIMR files. serialize ( path : Path , data : dict ) staticmethod \u00b6 Serializes the DIMR data to the file at the specified path. Attributes: Name Type Description path Path The path to the destination file. data Dict The data to be serialized. Source code in hydrolib/core/io/dimr/serializer.py @staticmethod def serialize ( path : Path , data : dict ): \"\"\" Serializes the DIMR data to the file at the specified path. Attributes: path (Path): The path to the destination file. data (Dict): The data to be serialized. \"\"\" path . parent . mkdir ( parents = True , exist_ok = True ) xmlns = \"http://schemas.deltares.nl/dimr\" xsi = \"http://www.w3.org/2001/XMLSchema-instance\" schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\" attrib = { e . QName ( xsi , \"schemaLocation\" ): f \" { xmlns } { schema_location } \" } namespaces = { None : xmlns , \"xsi\" : xsi } root = e . Element ( \"dimrConfig\" , attrib = attrib , nsmap = namespaces , ) DIMRSerializer . _build_tree ( root , data ) to_string = minidom . parseString ( e . tostring ( root )) xml = to_string . toprettyxml ( indent = \" \" , encoding = \"utf-8\" ) with path . open ( \"wb\" ) as f : f . write ( xml )","title":"Dimr"},{"location":"reference/dimr/#dimr-xml-files","text":"","title":"DIMR xml files"},{"location":"reference/dimr/#model","text":"","title":"Model"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Component","text":"Specification of a BMI-compliant model component instance that will be executed by DIMR. Attributes: Name Type Description library str The library name of the compoment. name str The component name. workingDir Path The working directory. inputFile Path The name of the input file. process Optional[int] Number of subprocesses in the component. setting Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model before initialization. parameter Optional[List[hydrolib.core.io.dimr.models.KeyValuePair]] A list of variables that are provided to the BMI model after initialization. mpiCommunicator Optional[str] The MPI communicator value. model Optional[hydrolib.core.basemodel.FileModel] The model represented by this component.","title":"Component"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Component.dict","text":"Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): # Exclude the FileModel from any DIMR serialization. kwargs [ \"exclude\" ] = { \"model\" } return super () . dict ( * args , ** kwargs )","title":"dict()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Component.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.ComponentOrCouplerRef","text":"Reference to a BMI-compliant model component instance. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance.","title":"ComponentOrCouplerRef"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.ControlModel","text":"Overrides to make sure that the control elements in the DIMR are parsed and serialized correctly.","title":"ControlModel"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.ControlModel.dict","text":"Add control element prefixes for serialized data. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): \"\"\"Add control element prefixes for serialized data.\"\"\" return { str ( self . _type ): super () . dict ( * args , ** kwargs ), }","title":"dict()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.ControlModel.validate","text":"Remove control element prefixes from parsed data. Source code in hydrolib/core/io/dimr/models.py @classmethod def validate ( cls , v ): \"\"\"Remove control element prefixes from parsed data.\"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ) and len ( v . keys ()) == 1 : key = list ( v . keys ())[ 0 ] v = v [ key ] return super () . validate ( v )","title":"validate()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.CoupledItem","text":"Specification of an item that has to be exchanged. Attributes: Name Type Description sourceName str Name of the item at the source component. targetName str Name of the item at the target component.","title":"CoupledItem"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.CoupledItem.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Coupler","text":"Specification of the coupling actions to be performed between two BMI-compliant model components. Attributes: Name Type Description name str The name of the coupler. sourceComponent str The component that provides the data to has to be exchanged. targetComponent str The component that consumes the data to has to be exchanged. item List[hydrolib.core.io.dimr.models.CoupledItem] A list of items that have to be exchanged. logger Optional[hydrolib.core.io.dimr.models.Logger] Logger for logging the values that get exchanged.","title":"Coupler"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Coupler.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/dimr/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.DIMR","text":"DIMR model representation. Attributes: Name Type Description documentation Documentation File metadata. control List[Union[Start, Parallel]] The <control> element with a list of Start and Parallel sub-elements, which defines the (sequence of) program(s) to be run. May be empty while constructing, but must be non-empty when saving! Also, all referenced components must be present in component when saving. Similarly, all referenced couplers must be present in coupler . component List[Union[RRComponent, FMComponent, Component]] List of <component> elements that defines which programs can be used inside the <control> subelements. Must be non-empty when saving! coupler Optional[List[Coupler]] optional list of <coupler> elements that defines which couplers can be used inside the <parallel> elements under <control> . waitFile Optional[str] Optional waitfile name for debugging. global_settings Optional[GlobalSettings] Optional global DIMR settings.","title":"DIMR"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.DIMR.dict","text":"Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/dimr/models.py def dict ( self , * args , ** kwargs ): kwargs [ \"exclude_none\" ] = True kwargs [ \"exclude\" ] = { \"filepath\" } return super () . dict ( * args , ** kwargs )","title":"dict()"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Documentation","text":"Information on the present DIMR configuration file. Attributes: Name Type Description fileVersion str The DIMR file version. createdBy str Creators of the DIMR file. creationDate datetime The creation date of the DIMR file.","title":"Documentation"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.GlobalSettings","text":"Global settings for the DIMR configuration. Attributes: Name Type Description logger_ncFormat int NetCDF format type for logging.","title":"GlobalSettings"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.KeyValuePair","text":"Key value pair to specify settings and parameters. Attributes: Name Type Description key str The key. value str The value.","title":"KeyValuePair"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Logger","text":"Used to log values to the specified file in workingdir for each timestep Attributes: Name Type Description workingDir Path Directory where the log file is written. outputFile Path Name of the log file.","title":"Logger"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Parallel","text":"Specification of a parallel control flow: one main component and a group of related components and couplers. Step wise execution order according to order in parallel control flow. Attributes: Name Type Description startGroup StartGroup Group of components and couplers to be executed. start ComponentOrCouplerRef Main component to be executed step wise (provides start time, end time and time step).","title":"Parallel"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.Start","text":"Specification of a serial control flow: one main component. Attributes: Name Type Description name str Name of the reference to a BMI-compliant model component instance","title":"Start"},{"location":"reference/dimr/#hydrolib.core.io.dimr.models.StartGroup","text":"Specification of model components and couplers to be executed with a certain frequency. Attributes: Name Type Description time str Time frame specification for the present group: start time, stop time and frequency. Expressed in terms of the time frame of the main component. start List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Ordered list of components to be executed. coupler List[hydrolib.core.io.dimr.models.ComponentOrCouplerRef] Oredered list of couplers to be executed.","title":"StartGroup"},{"location":"reference/dimr/#parser","text":"","title":"Parser"},{"location":"reference/dimr/#hydrolib.core.io.dimr.parser.DIMRParser","text":"A parser for DIMR xml files.","title":"DIMRParser"},{"location":"reference/dimr/#hydrolib.core.io.dimr.parser.DIMRParser.parse","text":"Parses a DIMR file to a dictionary. Parameters: Name Type Description Default path Path Path to the DIMR configuration file. required Source code in hydrolib/core/io/dimr/parser.py @staticmethod def parse ( path : Path ) -> dict : \"\"\"Parses a DIMR file to a dictionary. Args: path (Path): Path to the DIMR configuration file. \"\"\" if not path . is_file (): warn ( f \"File: ` { path } ` not found, skipped parsing.\" ) return {} parser = etree . XMLParser ( remove_comments = True , resolve_entities = False , no_network = True ) root = etree . parse ( str ( path ), parser = parser ) . getroot () return DIMRParser . _node_to_dictionary ( root , True )","title":"parse()"},{"location":"reference/dimr/#serializer","text":"","title":"Serializer"},{"location":"reference/dimr/#hydrolib.core.io.dimr.serializer.DIMRSerializer","text":"A serializer for DIMR files.","title":"DIMRSerializer"},{"location":"reference/dimr/#hydrolib.core.io.dimr.serializer.DIMRSerializer.serialize","text":"Serializes the DIMR data to the file at the specified path. Attributes: Name Type Description path Path The path to the destination file. data Dict The data to be serialized. Source code in hydrolib/core/io/dimr/serializer.py @staticmethod def serialize ( path : Path , data : dict ): \"\"\" Serializes the DIMR data to the file at the specified path. Attributes: path (Path): The path to the destination file. data (Dict): The data to be serialized. \"\"\" path . parent . mkdir ( parents = True , exist_ok = True ) xmlns = \"http://schemas.deltares.nl/dimr\" xsi = \"http://www.w3.org/2001/XMLSchema-instance\" schema_location = \"http://content.oss.deltares.nl/schemas/dimr-1.3.xsd\" attrib = { e . QName ( xsi , \"schemaLocation\" ): f \" { xmlns } { schema_location } \" } namespaces = { None : xmlns , \"xsi\" : xsi } root = e . Element ( \"dimrConfig\" , attrib = attrib , nsmap = namespaces , ) DIMRSerializer . _build_tree ( root , data ) to_string = minidom . parseString ( e . tostring ( root )) xml = to_string . toprettyxml ( indent = \" \" , encoding = \"utf-8\" ) with path . open ( \"wb\" ) as f : f . write ( xml )","title":"serialize()"},{"location":"reference/ext/","text":"EXT .ext files \u00b6 Model \u00b6 Boundary ( INIBasedModel ) pydantic-model \u00b6 A [Boundary] block for use inside an external forcings file, i.e., a ExtModel . All lowercased attributes match with the boundary input as described in UM Sec.C.5.2.1 . check_nodeid_or_locationfile_present ( values : Dict ) classmethod \u00b6 Verifies that either nodeid or locationfile properties have been set. Parameters: Name Type Description Default values Dict Dictionary with values already validated. required Exceptions: Type Description ValueError When none of the values are present. Returns: Type Description Dict Validated dictionary of values for Boundary. Source code in hydrolib/core/io/ext/models.py @root_validator @classmethod def check_nodeid_or_locationfile_present ( cls , values : Dict ): \"\"\" Verifies that either nodeid or locationfile properties have been set. Args: values (Dict): Dictionary with values already validated. Raises: ValueError: When none of the values are present. Returns: Dict: Validated dictionary of values for Boundary. \"\"\" node_id = values . get ( \"nodeid\" , None ) location_file = values . get ( \"locationfile\" , None ) if str_is_empty_or_none ( node_id ) and not isinstance ( location_file , Path ): raise ValueError ( \"Either nodeId or locationFile fields should be specified.\" ) return values forcing : ForcingBase property readonly \u00b6 Retrieves the corresponding forcing data for this boundary. Returns: Type Description ForcingBase The corresponding forcing data. None when this boundary does not have a forcing file or when the data cannot be found. is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/ext/models.py def is_intermediate_link ( self ) -> bool : return True ExtGeneral ( INIGeneral ) pydantic-model \u00b6 The external forcing file's [General] section with file meta data. ExtModel ( INIModel ) pydantic-model \u00b6 The overall external forcings model that contains the contents of one external forcings file (new format). This model is typically referenced under a FMModel .external_forcing.extforcefilenew . Attributes: Name Type Description general ExtGeneral [General] block with file metadata. boundary List[Boundary] List of [Boundary] blocks for all boundary conditions. lateral List[Lateral] List of [Lateral] blocks for all lateral discharges. Lateral ( INIBasedModel ) pydantic-model \u00b6 A [Lateral] block for use inside an external forcings file, i.e., a ExtModel . All lowercased attributes match with the lateral input as described in UM Sec.C.5.2.2 . validate_coordinates ( field_value : List [ int ], values : Dict ) -> List [ int ] classmethod \u00b6 Method to validate whether the given coordinates match in number to the expected value given for numcoordinates. Parameters: Name Type Description Default field_value List[int] Coordinates list (x or y) required values Dict Properties already 'validated' for Lateral class. required Exceptions: Type Description ValueError When the number of coordinates does not match expectations. Returns: Type Description List[int] Validated list of coordinates. Source code in hydrolib/core/io/ext/models.py @validator ( \"xcoordinates\" , \"ycoordinates\" ) @classmethod def validate_coordinates ( cls , field_value : List [ int ], values : Dict ) -> List [ int ]: \"\"\" Method to validate whether the given coordinates match in number to the expected value given for numcoordinates. Args: field_value (List[int]): Coordinates list (x or y) values (Dict): Properties already 'validated' for Lateral class. Raises: ValueError: When the number of coordinates does not match expectations. Returns: List[int]: Validated list of coordinates. \"\"\" num_coords = values . get ( \"numcoordinates\" , None ) if num_coords is None : raise ValueError ( \"numCoordinates should be given when providing xCoordinates or yCoordinates.\" ) assert num_coords == len ( field_value ), \"Number of coordinates given ( {} ) not matching the numCoordinates value {} .\" . format ( len ( field_value ), num_coords ) return field_value validate_location_dependencies ( values : Dict ) -> Dict classmethod \u00b6 Once all the fields have been evaluated, we verify whether the location given for this Lateral matches the expectations. Parameters: Name Type Description Default values Dict Dictionary of Laterals validated fields. required Exceptions: Type Description ValueError When neither nodeid, branchid or coordinates have been given. ValueError When either x or y coordinates were expected but not given. ValueError When locationtype should be 1d but other was specified. Returns: Type Description Dict Validated dictionary of Lateral fields. Source code in hydrolib/core/io/ext/models.py @root_validator @classmethod def validate_location_dependencies ( cls , values : Dict ) -> Dict : \"\"\" Once all the fields have been evaluated, we verify whether the location given for this Lateral matches the expectations. Args: values (Dict): Dictionary of Laterals validated fields. Raises: ValueError: When neither nodeid, branchid or coordinates have been given. ValueError: When either x or y coordinates were expected but not given. ValueError: When locationtype should be 1d but other was specified. Returns: Dict: Validated dictionary of Lateral fields. \"\"\" def validate_coordinates ( coord_name : str ) -> None : if values . get ( coord_name . lower (), None ) is None : raise ValueError ( \" {} should be given.\" . format ( coord_name )) # If nodeid or branchid and Chainage are present node_id : str = values . get ( \"nodeid\" , None ) branch_id : str = values . get ( \"branchid\" , None ) n_coords : int = values . get ( \"numcoordinates\" , 0 ) chainage : float = values . get ( \"chainage\" , None ) # First validation - at least one of the following should be specified. if str_is_empty_or_none ( node_id ) and ( str_is_empty_or_none ( branch_id )): if n_coords == 0 : raise ValueError ( \"Either nodeId, branchId (with chainage) or numCoordinates (with xCoordinates and yCoordinates) are required.\" ) else : # Second validation, coordinates should be valid. validate_coordinates ( \"xCoordinates\" ) validate_coordinates ( \"yCoordinates\" ) return values else : # Third validation, chainage should be given with branchid if not str_is_empty_or_none ( branch_id ) and chainage is None : raise ValueError ( \"Chainage should be provided when branchId is specified.\" ) # Fourth validation, when nodeid, or branchid specified, expected 1d. location_type = values . get ( \"locationtype\" , None ) if str_is_empty_or_none ( location_type ): values [ \"locationtype\" ] = \"1d\" elif location_type . lower () != \"1d\" : raise ValueError ( \"LocationType should be 1d when nodeId (or branchId and chainage) is specified.\" ) return values validate_location_type ( v : str ) -> str classmethod \u00b6 Method to validate whether the specified location type is correct. Parameters: Name Type Description Default v str Given value for the locationtype field. required Exceptions: Type Description ValueError When the value given for locationtype is unknown. Returns: Type Description str Validated locationtype string. Source code in hydrolib/core/io/ext/models.py @validator ( \"locationtype\" ) @classmethod def validate_location_type ( cls , v : str ) -> str : \"\"\" Method to validate whether the specified location type is correct. Args: v (str): Given value for the locationtype field. Raises: ValueError: When the value given for locationtype is unknown. Returns: str: Validated locationtype string. \"\"\" possible_values = [ \"1d\" , \"2d\" , \"all\" ] if v . lower () not in possible_values : raise ValueError ( \"Value given ( {} ) not accepted, should be one of: {} \" . format ( v , \", \" . join ( possible_values ) ) ) return v","title":"Ext"},{"location":"reference/ext/#ext-ext-files","text":"","title":"EXT .ext files"},{"location":"reference/ext/#model","text":"","title":"Model"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Boundary","text":"A [Boundary] block for use inside an external forcings file, i.e., a ExtModel . All lowercased attributes match with the boundary input as described in UM Sec.C.5.2.1 .","title":"Boundary"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Boundary.check_nodeid_or_locationfile_present","text":"Verifies that either nodeid or locationfile properties have been set. Parameters: Name Type Description Default values Dict Dictionary with values already validated. required Exceptions: Type Description ValueError When none of the values are present. Returns: Type Description Dict Validated dictionary of values for Boundary. Source code in hydrolib/core/io/ext/models.py @root_validator @classmethod def check_nodeid_or_locationfile_present ( cls , values : Dict ): \"\"\" Verifies that either nodeid or locationfile properties have been set. Args: values (Dict): Dictionary with values already validated. Raises: ValueError: When none of the values are present. Returns: Dict: Validated dictionary of values for Boundary. \"\"\" node_id = values . get ( \"nodeid\" , None ) location_file = values . get ( \"locationfile\" , None ) if str_is_empty_or_none ( node_id ) and not isinstance ( location_file , Path ): raise ValueError ( \"Either nodeId or locationFile fields should be specified.\" ) return values","title":"check_nodeid_or_locationfile_present()"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Boundary.forcing","text":"Retrieves the corresponding forcing data for this boundary. Returns: Type Description ForcingBase The corresponding forcing data. None when this boundary does not have a forcing file or when the data cannot be found.","title":"forcing"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Boundary.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/ext/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/ext/#hydrolib.core.io.ext.models.ExtGeneral","text":"The external forcing file's [General] section with file meta data.","title":"ExtGeneral"},{"location":"reference/ext/#hydrolib.core.io.ext.models.ExtModel","text":"The overall external forcings model that contains the contents of one external forcings file (new format). This model is typically referenced under a FMModel .external_forcing.extforcefilenew . Attributes: Name Type Description general ExtGeneral [General] block with file metadata. boundary List[Boundary] List of [Boundary] blocks for all boundary conditions. lateral List[Lateral] List of [Lateral] blocks for all lateral discharges.","title":"ExtModel"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Lateral","text":"A [Lateral] block for use inside an external forcings file, i.e., a ExtModel . All lowercased attributes match with the lateral input as described in UM Sec.C.5.2.2 .","title":"Lateral"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Lateral.validate_coordinates","text":"Method to validate whether the given coordinates match in number to the expected value given for numcoordinates. Parameters: Name Type Description Default field_value List[int] Coordinates list (x or y) required values Dict Properties already 'validated' for Lateral class. required Exceptions: Type Description ValueError When the number of coordinates does not match expectations. Returns: Type Description List[int] Validated list of coordinates. Source code in hydrolib/core/io/ext/models.py @validator ( \"xcoordinates\" , \"ycoordinates\" ) @classmethod def validate_coordinates ( cls , field_value : List [ int ], values : Dict ) -> List [ int ]: \"\"\" Method to validate whether the given coordinates match in number to the expected value given for numcoordinates. Args: field_value (List[int]): Coordinates list (x or y) values (Dict): Properties already 'validated' for Lateral class. Raises: ValueError: When the number of coordinates does not match expectations. Returns: List[int]: Validated list of coordinates. \"\"\" num_coords = values . get ( \"numcoordinates\" , None ) if num_coords is None : raise ValueError ( \"numCoordinates should be given when providing xCoordinates or yCoordinates.\" ) assert num_coords == len ( field_value ), \"Number of coordinates given ( {} ) not matching the numCoordinates value {} .\" . format ( len ( field_value ), num_coords ) return field_value","title":"validate_coordinates()"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Lateral.validate_location_dependencies","text":"Once all the fields have been evaluated, we verify whether the location given for this Lateral matches the expectations. Parameters: Name Type Description Default values Dict Dictionary of Laterals validated fields. required Exceptions: Type Description ValueError When neither nodeid, branchid or coordinates have been given. ValueError When either x or y coordinates were expected but not given. ValueError When locationtype should be 1d but other was specified. Returns: Type Description Dict Validated dictionary of Lateral fields. Source code in hydrolib/core/io/ext/models.py @root_validator @classmethod def validate_location_dependencies ( cls , values : Dict ) -> Dict : \"\"\" Once all the fields have been evaluated, we verify whether the location given for this Lateral matches the expectations. Args: values (Dict): Dictionary of Laterals validated fields. Raises: ValueError: When neither nodeid, branchid or coordinates have been given. ValueError: When either x or y coordinates were expected but not given. ValueError: When locationtype should be 1d but other was specified. Returns: Dict: Validated dictionary of Lateral fields. \"\"\" def validate_coordinates ( coord_name : str ) -> None : if values . get ( coord_name . lower (), None ) is None : raise ValueError ( \" {} should be given.\" . format ( coord_name )) # If nodeid or branchid and Chainage are present node_id : str = values . get ( \"nodeid\" , None ) branch_id : str = values . get ( \"branchid\" , None ) n_coords : int = values . get ( \"numcoordinates\" , 0 ) chainage : float = values . get ( \"chainage\" , None ) # First validation - at least one of the following should be specified. if str_is_empty_or_none ( node_id ) and ( str_is_empty_or_none ( branch_id )): if n_coords == 0 : raise ValueError ( \"Either nodeId, branchId (with chainage) or numCoordinates (with xCoordinates and yCoordinates) are required.\" ) else : # Second validation, coordinates should be valid. validate_coordinates ( \"xCoordinates\" ) validate_coordinates ( \"yCoordinates\" ) return values else : # Third validation, chainage should be given with branchid if not str_is_empty_or_none ( branch_id ) and chainage is None : raise ValueError ( \"Chainage should be provided when branchId is specified.\" ) # Fourth validation, when nodeid, or branchid specified, expected 1d. location_type = values . get ( \"locationtype\" , None ) if str_is_empty_or_none ( location_type ): values [ \"locationtype\" ] = \"1d\" elif location_type . lower () != \"1d\" : raise ValueError ( \"LocationType should be 1d when nodeId (or branchId and chainage) is specified.\" ) return values","title":"validate_location_dependencies()"},{"location":"reference/ext/#hydrolib.core.io.ext.models.Lateral.validate_location_type","text":"Method to validate whether the specified location type is correct. Parameters: Name Type Description Default v str Given value for the locationtype field. required Exceptions: Type Description ValueError When the value given for locationtype is unknown. Returns: Type Description str Validated locationtype string. Source code in hydrolib/core/io/ext/models.py @validator ( \"locationtype\" ) @classmethod def validate_location_type ( cls , v : str ) -> str : \"\"\" Method to validate whether the specified location type is correct. Args: v (str): Given value for the locationtype field. Raises: ValueError: When the value given for locationtype is unknown. Returns: str: Validated locationtype string. \"\"\" possible_values = [ \"1d\" , \"2d\" , \"all\" ] if v . lower () not in possible_values : raise ValueError ( \"Value given ( {} ) not accepted, should be one of: {} \" . format ( v , \", \" . join ( possible_values ) ) ) return v","title":"validate_location_type()"},{"location":"reference/forcing/","text":"ForcingBase ( DataBlockINIBasedModel ) pydantic-model \u00b6 validate ( v ) classmethod \u00b6 Try to iniatialize subclass based on the function field. This field is compared to each function field of the derived models of ForcingBase . The derived model with an equal function type will be initialized. Exceptions: Type Description ValueError When the given type is not a known structure type. Source code in hydrolib/core/io/bc/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `function` field. This field is compared to each `function` field of the derived models of `ForcingBase`. The derived model with an equal function type will be initialized. Raises: ValueError: When the given type is not a known structure type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"function\" ) . default . lower () == v . get ( \"function\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Function of { cls . __name__ } with name= { v . get ( 'name' , '' ) } and function= { v . get ( 'function' , '' ) } is not recognized.\" ) return v QuantityUnitPair ( tuple ) \u00b6 QuantityUnitPair(quantity, unit) __getnewargs__ ( self ) special \u00b6 Return self as a plain tuple. Used by copy and pickle. Source code in hydrolib/core/io/bc/models.py def __getnewargs__ ( self ): 'Return self as a plain tuple. Used by copy and pickle.' return _tuple ( self ) __new__ ( _cls , quantity : str , unit : str ) special staticmethod \u00b6 Create new instance of QuantityUnitPair(quantity, unit) __repr__ ( self ) special \u00b6 Return a nicely formatted representation string Source code in hydrolib/core/io/bc/models.py def __repr__ ( self ): 'Return a nicely formatted representation string' return self . __class__ . __name__ + repr_fmt % self TimeInterpolation ( str , Enum ) \u00b6 An enumeration. VerticalInterpolation ( str , Enum ) \u00b6 An enumeration. VerticalPositionType ( str , Enum ) \u00b6 An enumeration.","title":"Forcing"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.ForcingBase","text":"","title":"ForcingBase"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.ForcingBase.validate","text":"Try to iniatialize subclass based on the function field. This field is compared to each function field of the derived models of ForcingBase . The derived model with an equal function type will be initialized. Exceptions: Type Description ValueError When the given type is not a known structure type. Source code in hydrolib/core/io/bc/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `function` field. This field is compared to each `function` field of the derived models of `ForcingBase`. The derived model with an equal function type will be initialized. Raises: ValueError: When the given type is not a known structure type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"function\" ) . default . lower () == v . get ( \"function\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Function of { cls . __name__ } with name= { v . get ( 'name' , '' ) } and function= { v . get ( 'function' , '' ) } is not recognized.\" ) return v","title":"validate()"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.QuantityUnitPair","text":"QuantityUnitPair(quantity, unit)","title":"QuantityUnitPair"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.QuantityUnitPair.__getnewargs__","text":"Return self as a plain tuple. Used by copy and pickle. Source code in hydrolib/core/io/bc/models.py def __getnewargs__ ( self ): 'Return self as a plain tuple. Used by copy and pickle.' return _tuple ( self )","title":"__getnewargs__()"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.QuantityUnitPair.__new__","text":"Create new instance of QuantityUnitPair(quantity, unit)","title":"__new__()"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.QuantityUnitPair.__repr__","text":"Return a nicely formatted representation string Source code in hydrolib/core/io/bc/models.py def __repr__ ( self ): 'Return a nicely formatted representation string' return self . __class__ . __name__ + repr_fmt % self","title":"__repr__()"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.TimeInterpolation","text":"An enumeration.","title":"TimeInterpolation"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.VerticalInterpolation","text":"An enumeration.","title":"VerticalInterpolation"},{"location":"reference/forcing/#hydrolib.core.io.bc.models.VerticalPositionType","text":"An enumeration.","title":"VerticalPositionType"},{"location":"reference/friction/","text":"friction .ini files \u00b6 The friction module provides the specific logic for accessing friction/roughness files. Generic parsing and serializing functionality comes from the generic hydrolib.core.io.ini modules. Model \u00b6 FrictBranch ( INIBasedModel ) pydantic-model \u00b6 A [Branch] block for use inside a friction file. Each block can define the roughness value(s) on a particular branch. FrictGeneral ( INIGeneral ) pydantic-model \u00b6 The friction file's [General] section with file meta data. FrictGlobal ( INIBasedModel ) pydantic-model \u00b6 A [Global] block for use inside a friction file. Multiple of such blocks may be present to define multiple frictionId classes. FrictionModel ( INIModel ) pydantic-model \u00b6 The overall friction model that contains the contents of one friction file. This model is typically referenced under a FMModel .geometry.frictfile[..] . Attributes: Name Type Description general FrictGeneral [General] block with file metadata. global_ List[FrictGlobal] Definitions of [Global] friction classes. branch List[FrictBranch] Definitions of [Branch] friction values.","title":"Friction"},{"location":"reference/friction/#friction-ini-files","text":"The friction module provides the specific logic for accessing friction/roughness files. Generic parsing and serializing functionality comes from the generic hydrolib.core.io.ini modules.","title":"friction .ini files"},{"location":"reference/friction/#model","text":"","title":"Model"},{"location":"reference/friction/#hydrolib.core.io.friction.models.FrictBranch","text":"A [Branch] block for use inside a friction file. Each block can define the roughness value(s) on a particular branch.","title":"FrictBranch"},{"location":"reference/friction/#hydrolib.core.io.friction.models.FrictGeneral","text":"The friction file's [General] section with file meta data.","title":"FrictGeneral"},{"location":"reference/friction/#hydrolib.core.io.friction.models.FrictGlobal","text":"A [Global] block for use inside a friction file. Multiple of such blocks may be present to define multiple frictionId classes.","title":"FrictGlobal"},{"location":"reference/friction/#hydrolib.core.io.friction.models.FrictionModel","text":"The overall friction model that contains the contents of one friction file. This model is typically referenced under a FMModel .geometry.frictfile[..] . Attributes: Name Type Description general FrictGeneral [General] block with file metadata. global_ List[FrictGlobal] Definitions of [Global] friction classes. branch List[FrictBranch] Definitions of [Branch] friction values.","title":"FrictionModel"},{"location":"reference/glossary/","text":"Glossary \u00b6 The list below is a nonexhaustive list of terminology and concepts used in HYDROLIB(-core) and Delft3D Flexible Mesh. A \u00b6 B \u00b6 BC file \u00b6 Input file containing the actual forcing data for model forcings specified elsewhere in the model input, for example time series or astronomical components. Originates from boundary conditions as specified in the external forcings file , but nowadays also used in structure files . More details about the syntax and the various supported function types in the Delft3D FM User Manual . Boundary condition \u00b6 Flow (or constituent) boundary condition that forces a D-Flow FM model, such as waterlevel and discharge boundary conditions. Defined in the external forcings file . More details in the Delft3D FM User Manual . Branch \u00b6 The network edges in a network topology of 1D models. The computational grid points are positioned on these branches using branch id and a chainage value. Branch Id \u00b6 Identification text string for a particular branch in a 1D network. C \u00b6 Chainage \u00b6 The distance along a 1D network branch to define a specific location on that branch. Always used in combination with a branch Id . CF conventions \u00b6 Established metadata conventions for storing all kinds of data, e.g., model input and output, in NetCDF files. More details on: https://cfconventions.org/. HYDROLIB-core and Delft3D Flexible Mesh rely on CF, and extend this with UGRID conventions where unstructured grids are applicable. Computational backend \u00b6 Computational core, also called kernel. The program/library of simulation software that does the actual calculations. Often also available with a graphical user interface on top of it. Cross section files \u00b6 Input files for D-Flow FM that define the 1D network's cross sections. Two parts: cross section definition file and cross section location files . Not to be confused with observation cross section files ! Cross section definition file \u00b6 Input file for D-Flow FM that defines the various cross section shapes in a model with a 1D network. Format is INI-like. More details in the Delft3D FM User Manual . Cross section location file \u00b6 Input file for D-Flow FM that defines the location of cross section shapes in a model with a 1D network. Each location refers to a (possible shared) cross section definition . Format is INI-like. More details in the Delft3D FM User Manual . D \u00b6 Deltares conventions \u00b6 A proposal for additional NetCDF conventions that build on the existing UGRID conventions , intended to properly describe 1D network topologies as a coordinate space on which 1D computational grids are defined. Also 1D2D grid couplings are included. More details in: the Delft3D FM User Manual . D-Flow FM \u00b6 D-Flow Flexible Mesh. The computational backend that solves 1D/2D/3D hydrodynamics in the Delf3D Flexible Mesh Suite. Toplevel input is the MDU file . More details in the Delft3D FM User Manual . D-HYDRO Suite 1D2D (Beta) \u00b6 Integral software suite for hydraulic 1D2D modelling, including rainfall runoff and realtime control. More details on: https://www.deltares.nl/nl/d-hydro-suite-1d2d-beta/. DIMR \u00b6 Deltares Integrated Model Runner. Executable/library that runs integrated models by coupling multiple computational backends in a simulation timeloop. Uses a single DIMR config file as input. DIMR config file \u00b6 Input file for DIMR (typically dimr_config.xml ) for an integrated model run, describing which models are coupled and which quantities need to be exchanged. E \u00b6 Edge (mesh) \u00b6 A geometrical \"line\" in a 1D, 2D or 3D mesh. Connects two mesh nodes as its end points. Building block of the UGRID-conventions . External forcings file \u00b6 Input file for D-Flow FM describing model forcings such as boundary conditions , laterals and meteo . Format is INI-like. More details in the Delft3D FM User Manual . F \u00b6 Face (mesh) \u00b6 A geometrical \"cell\" in a 2D mesh. Formed by 3 or more mesh nodes as its vertices. Building block of the UGRID-conventions . Flow link \u00b6 An open connection/interface between two flow nodes in the staggered D-Flow FM model grid. Is the same as a \"velocity point\", and corresponds with (but is not equal to) an edge , both in 1D and in 2D. In 3D a flow link corresponds with a 3D face between two volumes . Flow node \u00b6 A single finite volume \"cell\" in the staggered D-Flow FM model grid. Is the same as a \"pressure point\", and is in fact a face in 2D/3D or a node in 1D. G \u00b6 Grid \u00b6 The computational grid on which a flow simulation is done. The grid for D-Flow FM is defined in an input net file , and also appears (slightly differently) in the output map file . Grid snapping \u00b6 The snapping of D-Flow FM model input in x,y-coordinates to discrete locations in the staggered model grid . This process makes most model input independent of the chosen model grid and grid resolution. Snapping is done either to (sets of) flow nodes or (sequence of) flow links , depending on whether pressure-point data or velocity-point data is concerned. H \u00b6 His file \u00b6 Output file of D-Flow FM containing model results as time series on a specific set of discrete locations, which are typically the hydraulic structures, observation stations and more. More details in the Delft3D FM User Manual . I \u00b6 Integrated model \u00b6 Model consisting of more than one model. Typically used when multiple computational backends are coupled, for example D-Flow FM and Rainfall Runoff or D-Flow FM and Real Time Control . Integrated models can be run using the Deltares Integrated Model Runner (DIMR) . INI-files \u00b6 Delft3D FM uses several input files that are formatted in an INI-like syntax. The abstract syntax depends on the particular file type, see: cross section files , initial field file , external forcings file , MDU file , observation files , rougness file , structure file . Initial field file \u00b6 Input file for D-Flow FM describing initial conditions and other spatially varying parameter fields. Format is INI-like. More details in the Delft3D FM User Manual . J \u00b6 K \u00b6 L \u00b6 Lateral \u00b6 Lateral discharge in D-Flow FM , which acts as a source (or sink) of volume. Defined in the external forcings file . The actual forcing data may come from timeseries in a .bc file or from RR a coupled/integrated model. More details in the Delft3D FM User Manual . M \u00b6 Map file \u00b6 Output file of D-Flow FM containing the model results on all grid points. More details in the Delft3D FM User Manual . MDU file \u00b6 Main input file of D-Flow FM . Format is INI-like. More details in the Delft3D FM User Manual . meteo \u00b6 Meteorological forcings of a model. Typically sources (or sinks) of volume via precipitation and evaporation, or forcing via wind. For D-Flow FM defined in the external forcings file . More details in the Delft3D FM User Manual . mesh \u00b6 See grid . N \u00b6 Net file \u00b6 Or grid file. Input file for D-Flow FM containing the computational model grid. Format is NetCDF, adhering to CF - and UGRID -conventions, and optionally also the Deltares-extension for 1D network topology and geometry. NetCDF \u00b6 File format used by HYDROLIB-core and Delft3D Flexible Mesh for the model input grid and for model results in output files. These files typically adhere to the CF conventions and sometimes UGRID conventions . Node (mesh) \u00b6 A geometrical \"point\" in a 1D, 2D or 3D mesh. Defined by x- and y-coordinate, in 3D also a z-coordinate. Can be connected by mesh edges , and can form the vertices of a mesh face . Building block of the UGRID-conventions . O \u00b6 Observation files \u00b6 Files that define the model locations for which output should be produced in the his file . Two types: observation point file and observation cross section file . Observation cross section file \u00b6 Input file for D-Flow FM that describes the model locations for which (cumulative) flow \"flux\" output should be produced in the his file . For example: cumulative discharge, salinity transport. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual . Observation point file \u00b6 Input file for D-Flow FM that describes the model point locations for which local output should be produced in the his file . For example: waterlevel, velocity vector/magnitude, tracer concentration as instantanous values. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual . P \u00b6 Polyline file \u00b6 File containing a sequence of polylines in model coordinates. Each polyline has header lines with a label and row+column count, and at least a list of x, y-points. More than 2 columns may be present (z, data1, ...) for particular model inputs, see for example the fixed weir file . More details in the Delft3D FM User Manual . Polygon file \u00b6 See polyline file . The point sequences are interpreted as closed polygons. Q \u00b6 R \u00b6 Rainfall runoff \u00b6 RR for short. The computational backend that solves lumped rainfall runoff, offering various runoff concepts. Toplevel input is the sobek_3b.fnm file. Part of the D-Hydrology software module. More details on: https://www.deltares.nl/en/software/module/d-hydrology. Real Time Control \u00b6 RTC for short. The computational backend for real-time control of hydraulic model components (typically hydraulic structures). Toplevel input is in various rtc*.xml files. Part of the D-Real Time Control software module. More details on: https://www.deltares.nl/en/software/module/d-real-time-control. Roughness file \u00b6 Input file for D-Flow FM describing roughness values on the 1D network. Format is INI-like. More details in the Delft3D FM User Manual . S \u00b6 Sample file \u00b6 File containing an unstructured set of sample point values. Typically used as input file for initial fields or other spatially varying fields in the initial fields file . More details in the Delft3D FM User Manual . Staggered grid \u00b6 Discretization method used in D-Flow FM where the PDE variables are not all defined on the same topological grid locations. Water level, concentrations and other volume-related variables are defined on the pressure points (also: flow nodes ), and the fluxes and other transport-related variables are defined on the velocity points (also: flow links ). Structure file \u00b6 Input file for D-Flow FM containing the hydraulic structures. Format is INI-like. More details in the Delft3D FM User Manual . T \u00b6 U \u00b6 UGRID conventions \u00b6 Metadata conventions for storing unstructured grids in NetCDF files. More details on: http://ugrid-conventions.github.io/ugrid-conventions/. V \u00b6 volume (mesh) \u00b6 A geometrical \"cell\" in a 3D mesh. Formed by 4 or more mesh nodes as its vertices (or: 4 or more mesh faces as its \"sides\"). Building block of the UGRID-conventions . W \u00b6 X \u00b6 XYZ file \u00b6 See sample file . Y \u00b6 Z \u00b6","title":"Glossary"},{"location":"reference/glossary/#glossary","text":"The list below is a nonexhaustive list of terminology and concepts used in HYDROLIB(-core) and Delft3D Flexible Mesh.","title":"Glossary"},{"location":"reference/glossary/#a","text":"","title":"A"},{"location":"reference/glossary/#b","text":"","title":"B"},{"location":"reference/glossary/#bc-file","text":"Input file containing the actual forcing data for model forcings specified elsewhere in the model input, for example time series or astronomical components. Originates from boundary conditions as specified in the external forcings file , but nowadays also used in structure files . More details about the syntax and the various supported function types in the Delft3D FM User Manual .","title":"BC file"},{"location":"reference/glossary/#boundary-condition","text":"Flow (or constituent) boundary condition that forces a D-Flow FM model, such as waterlevel and discharge boundary conditions. Defined in the external forcings file . More details in the Delft3D FM User Manual .","title":"Boundary condition"},{"location":"reference/glossary/#branch","text":"The network edges in a network topology of 1D models. The computational grid points are positioned on these branches using branch id and a chainage value.","title":"Branch"},{"location":"reference/glossary/#branch-id","text":"Identification text string for a particular branch in a 1D network.","title":"Branch Id"},{"location":"reference/glossary/#c","text":"","title":"C"},{"location":"reference/glossary/#chainage","text":"The distance along a 1D network branch to define a specific location on that branch. Always used in combination with a branch Id .","title":"Chainage"},{"location":"reference/glossary/#cf-conventions","text":"Established metadata conventions for storing all kinds of data, e.g., model input and output, in NetCDF files. More details on: https://cfconventions.org/. HYDROLIB-core and Delft3D Flexible Mesh rely on CF, and extend this with UGRID conventions where unstructured grids are applicable.","title":"CF conventions"},{"location":"reference/glossary/#computational-backend","text":"Computational core, also called kernel. The program/library of simulation software that does the actual calculations. Often also available with a graphical user interface on top of it.","title":"Computational backend"},{"location":"reference/glossary/#cross-section-files","text":"Input files for D-Flow FM that define the 1D network's cross sections. Two parts: cross section definition file and cross section location files . Not to be confused with observation cross section files !","title":"Cross section files"},{"location":"reference/glossary/#cross-section-definition-file","text":"Input file for D-Flow FM that defines the various cross section shapes in a model with a 1D network. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Cross section definition file"},{"location":"reference/glossary/#cross-section-location-file","text":"Input file for D-Flow FM that defines the location of cross section shapes in a model with a 1D network. Each location refers to a (possible shared) cross section definition . Format is INI-like. More details in the Delft3D FM User Manual .","title":"Cross section location file"},{"location":"reference/glossary/#d","text":"","title":"D"},{"location":"reference/glossary/#deltares-conventions","text":"A proposal for additional NetCDF conventions that build on the existing UGRID conventions , intended to properly describe 1D network topologies as a coordinate space on which 1D computational grids are defined. Also 1D2D grid couplings are included. More details in: the Delft3D FM User Manual .","title":"Deltares conventions"},{"location":"reference/glossary/#d-flow-fm","text":"D-Flow Flexible Mesh. The computational backend that solves 1D/2D/3D hydrodynamics in the Delf3D Flexible Mesh Suite. Toplevel input is the MDU file . More details in the Delft3D FM User Manual .","title":"D-Flow FM"},{"location":"reference/glossary/#d-hydro-suite-1d2d-beta","text":"Integral software suite for hydraulic 1D2D modelling, including rainfall runoff and realtime control. More details on: https://www.deltares.nl/nl/d-hydro-suite-1d2d-beta/.","title":"D-HYDRO Suite 1D2D (Beta)"},{"location":"reference/glossary/#dimr","text":"Deltares Integrated Model Runner. Executable/library that runs integrated models by coupling multiple computational backends in a simulation timeloop. Uses a single DIMR config file as input.","title":"DIMR"},{"location":"reference/glossary/#dimr-config-file","text":"Input file for DIMR (typically dimr_config.xml ) for an integrated model run, describing which models are coupled and which quantities need to be exchanged.","title":"DIMR config file"},{"location":"reference/glossary/#e","text":"","title":"E"},{"location":"reference/glossary/#edge-mesh","text":"A geometrical \"line\" in a 1D, 2D or 3D mesh. Connects two mesh nodes as its end points. Building block of the UGRID-conventions .","title":"Edge (mesh)"},{"location":"reference/glossary/#external-forcings-file","text":"Input file for D-Flow FM describing model forcings such as boundary conditions , laterals and meteo . Format is INI-like. More details in the Delft3D FM User Manual .","title":"External forcings file"},{"location":"reference/glossary/#f","text":"","title":"F"},{"location":"reference/glossary/#face-mesh","text":"A geometrical \"cell\" in a 2D mesh. Formed by 3 or more mesh nodes as its vertices. Building block of the UGRID-conventions .","title":"Face (mesh)"},{"location":"reference/glossary/#flow-link","text":"An open connection/interface between two flow nodes in the staggered D-Flow FM model grid. Is the same as a \"velocity point\", and corresponds with (but is not equal to) an edge , both in 1D and in 2D. In 3D a flow link corresponds with a 3D face between two volumes .","title":"Flow link"},{"location":"reference/glossary/#flow-node","text":"A single finite volume \"cell\" in the staggered D-Flow FM model grid. Is the same as a \"pressure point\", and is in fact a face in 2D/3D or a node in 1D.","title":"Flow node"},{"location":"reference/glossary/#g","text":"","title":"G"},{"location":"reference/glossary/#grid","text":"The computational grid on which a flow simulation is done. The grid for D-Flow FM is defined in an input net file , and also appears (slightly differently) in the output map file .","title":"Grid"},{"location":"reference/glossary/#grid-snapping","text":"The snapping of D-Flow FM model input in x,y-coordinates to discrete locations in the staggered model grid . This process makes most model input independent of the chosen model grid and grid resolution. Snapping is done either to (sets of) flow nodes or (sequence of) flow links , depending on whether pressure-point data or velocity-point data is concerned.","title":"Grid snapping"},{"location":"reference/glossary/#h","text":"","title":"H"},{"location":"reference/glossary/#his-file","text":"Output file of D-Flow FM containing model results as time series on a specific set of discrete locations, which are typically the hydraulic structures, observation stations and more. More details in the Delft3D FM User Manual .","title":"His file"},{"location":"reference/glossary/#i","text":"","title":"I"},{"location":"reference/glossary/#integrated-model","text":"Model consisting of more than one model. Typically used when multiple computational backends are coupled, for example D-Flow FM and Rainfall Runoff or D-Flow FM and Real Time Control . Integrated models can be run using the Deltares Integrated Model Runner (DIMR) .","title":"Integrated model"},{"location":"reference/glossary/#ini-files","text":"Delft3D FM uses several input files that are formatted in an INI-like syntax. The abstract syntax depends on the particular file type, see: cross section files , initial field file , external forcings file , MDU file , observation files , rougness file , structure file .","title":"INI-files"},{"location":"reference/glossary/#initial-field-file","text":"Input file for D-Flow FM describing initial conditions and other spatially varying parameter fields. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Initial field file"},{"location":"reference/glossary/#j","text":"","title":"J"},{"location":"reference/glossary/#k","text":"","title":"K"},{"location":"reference/glossary/#l","text":"","title":"L"},{"location":"reference/glossary/#lateral","text":"Lateral discharge in D-Flow FM , which acts as a source (or sink) of volume. Defined in the external forcings file . The actual forcing data may come from timeseries in a .bc file or from RR a coupled/integrated model. More details in the Delft3D FM User Manual .","title":"Lateral"},{"location":"reference/glossary/#m","text":"","title":"M"},{"location":"reference/glossary/#map-file","text":"Output file of D-Flow FM containing the model results on all grid points. More details in the Delft3D FM User Manual .","title":"Map file"},{"location":"reference/glossary/#mdu-file","text":"Main input file of D-Flow FM . Format is INI-like. More details in the Delft3D FM User Manual .","title":"MDU file"},{"location":"reference/glossary/#meteo","text":"Meteorological forcings of a model. Typically sources (or sinks) of volume via precipitation and evaporation, or forcing via wind. For D-Flow FM defined in the external forcings file . More details in the Delft3D FM User Manual .","title":"meteo"},{"location":"reference/glossary/#mesh","text":"See grid .","title":"mesh"},{"location":"reference/glossary/#n","text":"","title":"N"},{"location":"reference/glossary/#net-file","text":"Or grid file. Input file for D-Flow FM containing the computational model grid. Format is NetCDF, adhering to CF - and UGRID -conventions, and optionally also the Deltares-extension for 1D network topology and geometry.","title":"Net file"},{"location":"reference/glossary/#netcdf","text":"File format used by HYDROLIB-core and Delft3D Flexible Mesh for the model input grid and for model results in output files. These files typically adhere to the CF conventions and sometimes UGRID conventions .","title":"NetCDF"},{"location":"reference/glossary/#node-mesh","text":"A geometrical \"point\" in a 1D, 2D or 3D mesh. Defined by x- and y-coordinate, in 3D also a z-coordinate. Can be connected by mesh edges , and can form the vertices of a mesh face . Building block of the UGRID-conventions .","title":"Node (mesh)"},{"location":"reference/glossary/#o","text":"","title":"O"},{"location":"reference/glossary/#observation-files","text":"Files that define the model locations for which output should be produced in the his file . Two types: observation point file and observation cross section file .","title":"Observation files"},{"location":"reference/glossary/#observation-cross-section-file","text":"Input file for D-Flow FM that describes the model locations for which (cumulative) flow \"flux\" output should be produced in the his file . For example: cumulative discharge, salinity transport. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Observation cross section file"},{"location":"reference/glossary/#observation-point-file","text":"Input file for D-Flow FM that describes the model point locations for which local output should be produced in the his file . For example: waterlevel, velocity vector/magnitude, tracer concentration as instantanous values. Applies both to 1D, 2D, 1D2D and 3D models. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Observation point file"},{"location":"reference/glossary/#p","text":"","title":"P"},{"location":"reference/glossary/#polyline-file","text":"File containing a sequence of polylines in model coordinates. Each polyline has header lines with a label and row+column count, and at least a list of x, y-points. More than 2 columns may be present (z, data1, ...) for particular model inputs, see for example the fixed weir file . More details in the Delft3D FM User Manual .","title":"Polyline file"},{"location":"reference/glossary/#polygon-file","text":"See polyline file . The point sequences are interpreted as closed polygons.","title":"Polygon file"},{"location":"reference/glossary/#q","text":"","title":"Q"},{"location":"reference/glossary/#r","text":"","title":"R"},{"location":"reference/glossary/#rainfall-runoff","text":"RR for short. The computational backend that solves lumped rainfall runoff, offering various runoff concepts. Toplevel input is the sobek_3b.fnm file. Part of the D-Hydrology software module. More details on: https://www.deltares.nl/en/software/module/d-hydrology.","title":"Rainfall runoff"},{"location":"reference/glossary/#real-time-control","text":"RTC for short. The computational backend for real-time control of hydraulic model components (typically hydraulic structures). Toplevel input is in various rtc*.xml files. Part of the D-Real Time Control software module. More details on: https://www.deltares.nl/en/software/module/d-real-time-control.","title":"Real Time Control"},{"location":"reference/glossary/#roughness-file","text":"Input file for D-Flow FM describing roughness values on the 1D network. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Roughness file"},{"location":"reference/glossary/#s","text":"","title":"S"},{"location":"reference/glossary/#sample-file","text":"File containing an unstructured set of sample point values. Typically used as input file for initial fields or other spatially varying fields in the initial fields file . More details in the Delft3D FM User Manual .","title":"Sample file"},{"location":"reference/glossary/#staggered-grid","text":"Discretization method used in D-Flow FM where the PDE variables are not all defined on the same topological grid locations. Water level, concentrations and other volume-related variables are defined on the pressure points (also: flow nodes ), and the fluxes and other transport-related variables are defined on the velocity points (also: flow links ).","title":"Staggered grid"},{"location":"reference/glossary/#structure-file","text":"Input file for D-Flow FM containing the hydraulic structures. Format is INI-like. More details in the Delft3D FM User Manual .","title":"Structure file"},{"location":"reference/glossary/#t","text":"","title":"T"},{"location":"reference/glossary/#u","text":"","title":"U"},{"location":"reference/glossary/#ugrid-conventions","text":"Metadata conventions for storing unstructured grids in NetCDF files. More details on: http://ugrid-conventions.github.io/ugrid-conventions/.","title":"UGRID conventions"},{"location":"reference/glossary/#v","text":"","title":"V"},{"location":"reference/glossary/#volume-mesh","text":"A geometrical \"cell\" in a 3D mesh. Formed by 4 or more mesh nodes as its vertices (or: 4 or more mesh faces as its \"sides\"). Building block of the UGRID-conventions .","title":"volume (mesh)"},{"location":"reference/glossary/#w","text":"","title":"W"},{"location":"reference/glossary/#x","text":"","title":"X"},{"location":"reference/glossary/#xyz-file","text":"See sample file .","title":"XYZ file"},{"location":"reference/glossary/#y","text":"","title":"Y"},{"location":"reference/glossary/#z","text":"","title":"Z"},{"location":"reference/ini/","text":"ini \u00b6 The ini module provides the generic logic for parsing Deltares ini based files, such as the mdu, structures files, as well as more complex files such as the boundary condition (bc) files. Note that specific attribute files that employ this ini format often have their own dedicated module (and separate API doc page). These include: MDU file ( hydrolib.core.io.mdu ) cross section files ( hydrolib.core.io.crosssection ) external forcing file ( hydrolib.core.io.ext ) friction ( hydrolib.core.io.friction ) structure file ( hydrolib.core.io.structure ) Model \u00b6 DataBlockINIBasedModel ( INIBasedModel ) pydantic-model \u00b6 DataBlockINIBasedModel defines the base model for ini models with datablocks. INIBasedModel ( BaseModel , ABC ) pydantic-model \u00b6 INIBasedModel defines the base model for ini models INIBasedModel instances can be created from Section instances obtained through parsing ini documents. It further supports adding arbitrary fields to it, which will be written to file. Lastly, no arbitrary types are allowed for the defined fields. Attributes: Name Type Description comments Optional[Comments] Optional Comments if defined by the user. Comments ( BaseModel , ABC ) pydantic-model \u00b6 Comments defines the comments of an INIBasedModel INIModel ( FileModel ) pydantic-model \u00b6 INI Model representation. Parser \u00b6 Parser \u00b6 Parser defines a generic Parser for Deltares ini files. The Parser can be configured with a ParserConfig object. __init__ ( self , config : ParserConfig ) -> None special \u00b6 Creates a new Parser configured with the provided config Parameters: Name Type Description Default config ParserConfig The configuration of this Parser required Source code in hydrolib/core/io/ini/parser.py def __init__ ( self , config : ParserConfig ) -> None : \"\"\"Creates a new Parser configured with the provided config Args: config (ParserConfig): The configuration of this Parser \"\"\" self . _config = config self . _document = Document () self . _current_section : Optional [ _IntermediateSection ] = None self . _current_header_block : Optional [ _IntermediateCommentBlock ] = None self . _state = self . _StateType . NO_SECTION_FOUND self . _line_index = 0 # TODO add invalid blocks self . _feed_line : Dict [ Parser . _StateType , List [ Tuple [ Callable [[ str ], bool ], Callable [[ str ], None ]]] ] = { Parser . _StateType . NO_SECTION_FOUND : [ ( self . _is_comment , self . _handle_header_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ], Parser . _StateType . PARSING_PROPERTIES : [ ( self . _is_comment , self . _handle_section_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_property , self . _handle_property ), ( self . _is_datarow , self . _handle_new_datarow ), ], Parser . _StateType . PARSING_DATABLOCK : [ ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_datarow , self . _handle_datarow ), ], } self . _handle_emptyline : Dict [ Parser . _StateType , Callable [[], None ]] = { self . _StateType . NO_SECTION_FOUND : self . _finish_current_header_block , self . _StateType . PARSING_PROPERTIES : self . _noop , self . _StateType . PARSING_DATABLOCK : self . _noop , } feed_line ( self , line : str ) -> None \u00b6 Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/ini/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not self . _is_empty_line ( line ): for ( is_line_type , handle_line_type ) in self . _feed_line [ self . _state ]: if is_line_type ( line ): handle_line_type ( line ) break else : # handle exception pass else : self . _handle_emptyline [ self . _state ]() self . _increment_line () finalize ( self ) -> Document \u00b6 Finalize parsing and return the constructed Document. Returns: Type Description Document A Document describing the parsed ini file. Source code in hydrolib/core/io/ini/parser.py def finalize ( self ) -> Document : \"\"\"Finalize parsing and return the constructed Document. Returns: Document: A Document describing the parsed ini file. \"\"\" # TODO handle invalid block self . _finish_current_header_block () self . _finalise_current_section () return self . _document ParserConfig ( BaseModel ) pydantic-model \u00b6 ParserConfig defines the configuration options of the Parser Note that we cannot set both allow_only_keywords and parse_datablocks to True because we cannot distinguish between datablocks and key only properties. As such this will lead to a validation error. Attributes: Name Type Description allow_only_keywords bool Whether to allow properties with only keys (no '=' or value). Defaults to True. parse_datablocks bool Whether to allow parsing of datablocks at the bottom of sections. Defaults to False. parse_comments bool Whether we allow parsing of comments defined with the comment_delimeter. Defaults to True. comment_delimiter str The character or sequence of character used to define a comment. Defaults to '#'. Serializer \u00b6 MaxLengths ( BaseModel ) pydantic-model \u00b6 MaxLengths defines the maxmimum lengths of the parts of a section Attributes: Name Type Description key int The maximum length of all the keys of the properties within a section. If no properties are present it should be 0. value int The maximum length of all the non None values of the properties within a section. If no properties are present, or all values are None, it should be 0. datablock Optional[Sequence[int]] The maximum length of the values of each column of the Datablock. If no datablock is present it defaults to None. from_section ( section : Section ) -> MaxLengths classmethod \u00b6 Generate a MaxLengths instance from the given Section Parameters: Name Type Description Default section Section The section of which the MaxLengths are calculated required Returns: Type Description MaxLengths The MaxLengths corresponding with the provided section Source code in hydrolib/core/io/ini/serializer.py @classmethod def from_section ( cls , section : Section ) -> \"MaxLengths\" : \"\"\"Generate a MaxLengths instance from the given Section Args: section (Section): The section of which the MaxLengths are calculated Returns: MaxLengths: The MaxLengths corresponding with the provided section \"\"\" properties = list ( p for p in section . content if isinstance ( p , Property )) keys = ( prop . key for prop in properties ) values = ( prop . value for prop in properties if prop . value is not None ) max_key_length = max (( len ( k ) for k in keys ), default = 0 ) max_value_length = max (( len ( v ) for v in values ), default = 0 ) max_datablock_lengths = MaxLengths . _of_datablock ( section . datablock ) return cls ( key = max_key_length , value = max_value_length , datablock = max_datablock_lengths , ) SectionSerializer \u00b6 SectionSerializer provides the serialize method to serialize a Section The entrypoint of this method is the serialize method, which will construct an actual instance and serializes the Section with it. __init__ ( self , config : SerializerConfig , max_length : MaxLengths ) special \u00b6 Create a new SectionSerializer Parameters: Name Type Description Default config SerializerConfig The config describing the serialization options required max_length MaxLengths The max lengths of the section being serialized required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig , max_length : MaxLengths ): \"\"\"Create a new SectionSerializer Args: config (SerializerConfig): The config describing the serialization options max_length (MaxLengths): The max lengths of the section being serialized \"\"\" self . _config = config self . _max_length = max_length config : SerializerConfig property readonly \u00b6 The SerializerConfig used while serializing the section. max_length : MaxLengths property readonly \u00b6 The MaxLengths of the Section being serialized by this SectionSerializer. serialize ( section : Section , config : SerializerConfig ) -> Iterable [ str ] classmethod \u00b6 Serialize the provided section with the given config Parameters: Name Type Description Default section Section The section to serialize required config SerializerConfig The config describing the serialization options required Returns: Type Description Lines The iterable lines of the serialized section Source code in hydrolib/core/io/ini/serializer.py @classmethod def serialize ( cls , section : Section , config : SerializerConfig ) -> Lines : \"\"\"Serialize the provided section with the given config Args: section (Section): The section to serialize config (SerializerConfig): The config describing the serialization options Returns: Lines: The iterable lines of the serialized section \"\"\" serializer = cls ( config , MaxLengths . from_section ( section )) return serializer . _serialize_section ( section ) Serializer \u00b6 Serializer serializes Document to its corresponding lines. __init__ ( self , config : SerializerConfig ) special \u00b6 Creates a new Serializer with the provided configuration. Parameters: Name Type Description Default config SerializerConfig The configuration of this Serializer. required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig ): \"\"\"Creates a new Serializer with the provided configuration. Args: config (SerializerConfig): The configuration of this Serializer. \"\"\" self . _config = config serialize ( self , document : Document ) -> Iterable [ str ] \u00b6 Serialize the provided document into an iterable of lines. Parameters: Name Type Description Default document Document The Document to serialize. required Returns: Type Description Lines An iterable returning each line of the serialized Document. Source code in hydrolib/core/io/ini/serializer.py def serialize ( self , document : Document ) -> Lines : \"\"\"Serialize the provided document into an iterable of lines. Args: document (Document): The Document to serialize. Returns: Lines: An iterable returning each line of the serialized Document. \"\"\" header_iterable = self . _serialize_document_header ( document . header_comment ) serialize_section = lambda s : SectionSerializer . serialize ( s , self . _config ) sections = ( serialize_section ( section ) for section in document . sections ) sections_with_spacing = Serializer . _interweave ( sections , [ \"\" ]) sections_iterable = chain . from_iterable ( sections_with_spacing ) return chain ( header_iterable , sections_iterable ) SerializerConfig ( BaseModel ) pydantic-model \u00b6 SerializerConfig defines the configuration options of the Serializer Attributes: Name Type Description section_indent int The number of spaces with which whole sections should be indented. Defaults to 0. property_indent int The number of spaces with which properties should be indented relative to the section header (i.e. the full indent equals the section_indent plus property_indent). Defaults to 4. datablock_indent int The number of spaces with which datablock rows are indented relative to the section header (i.e. the full indent equals the section_indent plus datablock_indent). Defaults to 8. datablock_spacing int The number of spaces between datablock columns. Note that there might be additional offset to ensure . is lined out. Defaults to 4. comment_delimiter str The character used to delimit comments. Defaults to '#'. total_datablock_indent : int property readonly \u00b6 The combined datablock indentation, i.e. section_indent + datablock_indent total_property_indent : int property readonly \u00b6 The combined property indentation, i.e. section_indent + property_indent write_ini ( path : Path , document : Document , config : Optional [ hydrolib . core . io . ini . serializer . SerializerConfig ] = None ) -> None \u00b6 Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Parameters: Name Type Description Default path Path The path to which the document should be written. required document Document The document to serialize to the specified path. required config Optional[SerializerConfig] An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. None Source code in hydrolib/core/io/ini/serializer.py def write_ini ( path : Path , document : Document , config : Optional [ SerializerConfig ] = None , ) -> None : \"\"\"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Args: path (Path): The path to which the document should be written. document (Document): The document to serialize to the specified path. config (Optional[SerializerConfig], optional): An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. \"\"\" if config is None : config = SerializerConfig () serializer = Serializer ( config ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"wb\" ) as f : for line in serializer . serialize ( document ): f . write (( line + \" \\n \" ) . encode ( \"utf8\" ))","title":"Ini"},{"location":"reference/ini/#ini","text":"The ini module provides the generic logic for parsing Deltares ini based files, such as the mdu, structures files, as well as more complex files such as the boundary condition (bc) files. Note that specific attribute files that employ this ini format often have their own dedicated module (and separate API doc page). These include: MDU file ( hydrolib.core.io.mdu ) cross section files ( hydrolib.core.io.crosssection ) external forcing file ( hydrolib.core.io.ext ) friction ( hydrolib.core.io.friction ) structure file ( hydrolib.core.io.structure )","title":"ini"},{"location":"reference/ini/#model","text":"","title":"Model"},{"location":"reference/ini/#hydrolib.core.io.ini.models.DataBlockINIBasedModel","text":"DataBlockINIBasedModel defines the base model for ini models with datablocks.","title":"DataBlockINIBasedModel"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIBasedModel","text":"INIBasedModel defines the base model for ini models INIBasedModel instances can be created from Section instances obtained through parsing ini documents. It further supports adding arbitrary fields to it, which will be written to file. Lastly, no arbitrary types are allowed for the defined fields. Attributes: Name Type Description comments Optional[Comments] Optional Comments if defined by the user.","title":"INIBasedModel"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIBasedModel.Comments","text":"Comments defines the comments of an INIBasedModel","title":"Comments"},{"location":"reference/ini/#hydrolib.core.io.ini.models.INIModel","text":"INI Model representation.","title":"INIModel"},{"location":"reference/ini/#parser","text":"","title":"Parser"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser","text":"Parser defines a generic Parser for Deltares ini files. The Parser can be configured with a ParserConfig object.","title":"Parser"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.__init__","text":"Creates a new Parser configured with the provided config Parameters: Name Type Description Default config ParserConfig The configuration of this Parser required Source code in hydrolib/core/io/ini/parser.py def __init__ ( self , config : ParserConfig ) -> None : \"\"\"Creates a new Parser configured with the provided config Args: config (ParserConfig): The configuration of this Parser \"\"\" self . _config = config self . _document = Document () self . _current_section : Optional [ _IntermediateSection ] = None self . _current_header_block : Optional [ _IntermediateCommentBlock ] = None self . _state = self . _StateType . NO_SECTION_FOUND self . _line_index = 0 # TODO add invalid blocks self . _feed_line : Dict [ Parser . _StateType , List [ Tuple [ Callable [[ str ], bool ], Callable [[ str ], None ]]] ] = { Parser . _StateType . NO_SECTION_FOUND : [ ( self . _is_comment , self . _handle_header_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ], Parser . _StateType . PARSING_PROPERTIES : [ ( self . _is_comment , self . _handle_section_comment ), ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_property , self . _handle_property ), ( self . _is_datarow , self . _handle_new_datarow ), ], Parser . _StateType . PARSING_DATABLOCK : [ ( self . _is_section_header , self . _handle_next_section_header ), ( self . _is_datarow , self . _handle_datarow ), ], } self . _handle_emptyline : Dict [ Parser . _StateType , Callable [[], None ]] = { self . _StateType . NO_SECTION_FOUND : self . _finish_current_header_block , self . _StateType . PARSING_PROPERTIES : self . _noop , self . _StateType . PARSING_DATABLOCK : self . _noop , }","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.feed_line","text":"Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/ini/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not self . _is_empty_line ( line ): for ( is_line_type , handle_line_type ) in self . _feed_line [ self . _state ]: if is_line_type ( line ): handle_line_type ( line ) break else : # handle exception pass else : self . _handle_emptyline [ self . _state ]() self . _increment_line ()","title":"feed_line()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.Parser.finalize","text":"Finalize parsing and return the constructed Document. Returns: Type Description Document A Document describing the parsed ini file. Source code in hydrolib/core/io/ini/parser.py def finalize ( self ) -> Document : \"\"\"Finalize parsing and return the constructed Document. Returns: Document: A Document describing the parsed ini file. \"\"\" # TODO handle invalid block self . _finish_current_header_block () self . _finalise_current_section () return self . _document","title":"finalize()"},{"location":"reference/ini/#hydrolib.core.io.ini.parser.ParserConfig","text":"ParserConfig defines the configuration options of the Parser Note that we cannot set both allow_only_keywords and parse_datablocks to True because we cannot distinguish between datablocks and key only properties. As such this will lead to a validation error. Attributes: Name Type Description allow_only_keywords bool Whether to allow properties with only keys (no '=' or value). Defaults to True. parse_datablocks bool Whether to allow parsing of datablocks at the bottom of sections. Defaults to False. parse_comments bool Whether we allow parsing of comments defined with the comment_delimeter. Defaults to True. comment_delimiter str The character or sequence of character used to define a comment. Defaults to '#'.","title":"ParserConfig"},{"location":"reference/ini/#serializer","text":"","title":"Serializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.MaxLengths","text":"MaxLengths defines the maxmimum lengths of the parts of a section Attributes: Name Type Description key int The maximum length of all the keys of the properties within a section. If no properties are present it should be 0. value int The maximum length of all the non None values of the properties within a section. If no properties are present, or all values are None, it should be 0. datablock Optional[Sequence[int]] The maximum length of the values of each column of the Datablock. If no datablock is present it defaults to None.","title":"MaxLengths"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.MaxLengths.from_section","text":"Generate a MaxLengths instance from the given Section Parameters: Name Type Description Default section Section The section of which the MaxLengths are calculated required Returns: Type Description MaxLengths The MaxLengths corresponding with the provided section Source code in hydrolib/core/io/ini/serializer.py @classmethod def from_section ( cls , section : Section ) -> \"MaxLengths\" : \"\"\"Generate a MaxLengths instance from the given Section Args: section (Section): The section of which the MaxLengths are calculated Returns: MaxLengths: The MaxLengths corresponding with the provided section \"\"\" properties = list ( p for p in section . content if isinstance ( p , Property )) keys = ( prop . key for prop in properties ) values = ( prop . value for prop in properties if prop . value is not None ) max_key_length = max (( len ( k ) for k in keys ), default = 0 ) max_value_length = max (( len ( v ) for v in values ), default = 0 ) max_datablock_lengths = MaxLengths . _of_datablock ( section . datablock ) return cls ( key = max_key_length , value = max_value_length , datablock = max_datablock_lengths , )","title":"from_section()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer","text":"SectionSerializer provides the serialize method to serialize a Section The entrypoint of this method is the serialize method, which will construct an actual instance and serializes the Section with it.","title":"SectionSerializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.__init__","text":"Create a new SectionSerializer Parameters: Name Type Description Default config SerializerConfig The config describing the serialization options required max_length MaxLengths The max lengths of the section being serialized required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig , max_length : MaxLengths ): \"\"\"Create a new SectionSerializer Args: config (SerializerConfig): The config describing the serialization options max_length (MaxLengths): The max lengths of the section being serialized \"\"\" self . _config = config self . _max_length = max_length","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.config","text":"The SerializerConfig used while serializing the section.","title":"config"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.max_length","text":"The MaxLengths of the Section being serialized by this SectionSerializer.","title":"max_length"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SectionSerializer.serialize","text":"Serialize the provided section with the given config Parameters: Name Type Description Default section Section The section to serialize required config SerializerConfig The config describing the serialization options required Returns: Type Description Lines The iterable lines of the serialized section Source code in hydrolib/core/io/ini/serializer.py @classmethod def serialize ( cls , section : Section , config : SerializerConfig ) -> Lines : \"\"\"Serialize the provided section with the given config Args: section (Section): The section to serialize config (SerializerConfig): The config describing the serialization options Returns: Lines: The iterable lines of the serialized section \"\"\" serializer = cls ( config , MaxLengths . from_section ( section )) return serializer . _serialize_section ( section )","title":"serialize()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer","text":"Serializer serializes Document to its corresponding lines.","title":"Serializer"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer.__init__","text":"Creates a new Serializer with the provided configuration. Parameters: Name Type Description Default config SerializerConfig The configuration of this Serializer. required Source code in hydrolib/core/io/ini/serializer.py def __init__ ( self , config : SerializerConfig ): \"\"\"Creates a new Serializer with the provided configuration. Args: config (SerializerConfig): The configuration of this Serializer. \"\"\" self . _config = config","title":"__init__()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.Serializer.serialize","text":"Serialize the provided document into an iterable of lines. Parameters: Name Type Description Default document Document The Document to serialize. required Returns: Type Description Lines An iterable returning each line of the serialized Document. Source code in hydrolib/core/io/ini/serializer.py def serialize ( self , document : Document ) -> Lines : \"\"\"Serialize the provided document into an iterable of lines. Args: document (Document): The Document to serialize. Returns: Lines: An iterable returning each line of the serialized Document. \"\"\" header_iterable = self . _serialize_document_header ( document . header_comment ) serialize_section = lambda s : SectionSerializer . serialize ( s , self . _config ) sections = ( serialize_section ( section ) for section in document . sections ) sections_with_spacing = Serializer . _interweave ( sections , [ \"\" ]) sections_iterable = chain . from_iterable ( sections_with_spacing ) return chain ( header_iterable , sections_iterable )","title":"serialize()"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig","text":"SerializerConfig defines the configuration options of the Serializer Attributes: Name Type Description section_indent int The number of spaces with which whole sections should be indented. Defaults to 0. property_indent int The number of spaces with which properties should be indented relative to the section header (i.e. the full indent equals the section_indent plus property_indent). Defaults to 4. datablock_indent int The number of spaces with which datablock rows are indented relative to the section header (i.e. the full indent equals the section_indent plus datablock_indent). Defaults to 8. datablock_spacing int The number of spaces between datablock columns. Note that there might be additional offset to ensure . is lined out. Defaults to 4. comment_delimiter str The character used to delimit comments. Defaults to '#'.","title":"SerializerConfig"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig.total_datablock_indent","text":"The combined datablock indentation, i.e. section_indent + datablock_indent","title":"total_datablock_indent"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.SerializerConfig.total_property_indent","text":"The combined property indentation, i.e. section_indent + property_indent","title":"total_property_indent"},{"location":"reference/ini/#hydrolib.core.io.ini.serializer.write_ini","text":"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Parameters: Name Type Description Default path Path The path to which the document should be written. required document Document The document to serialize to the specified path. required config Optional[SerializerConfig] An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. None Source code in hydrolib/core/io/ini/serializer.py def write_ini ( path : Path , document : Document , config : Optional [ SerializerConfig ] = None , ) -> None : \"\"\"Write the provided document to the specified path If the provided path already exists, it will be overwritten. If the parent folder do not exist, they will be created. Args: path (Path): The path to which the document should be written. document (Document): The document to serialize to the specified path. config (Optional[SerializerConfig], optional): An optional configuration of the serializer. If none provided, it will default to the standard SerializerConfig. Defaults to None. \"\"\" if config is None : config = SerializerConfig () serializer = Serializer ( config ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"wb\" ) as f : for line in serializer . serialize ( document ): f . write (( line + \" \\n \" ) . encode ( \"utf8\" ))","title":"write_ini()"},{"location":"reference/mdu/","text":"ExternalForcing ( INIBasedModel ) pydantic-model \u00b6 The [External Forcing] section in an MDU file. This model is typically referenced under FMModel .external_forcing . All lowercased attributes match with the [External Forcing] input as described in UM Sec.A . is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True FMModel ( INIModel ) pydantic-model \u00b6 The overall FM model that contains the contents of the toplevel MDU file. All lowercased attributes match with the supported \"[section]\"s as described in UM Sec.A . Each of these class attributes refers to an underlying model class for that particular section. Geometry ( INIBasedModel ) pydantic-model \u00b6 The [Geometry] section in an MDU file. This model is typically referenced under FMModel .geometry . All lowercased attributes match with the [Geometry] input as described in UM Sec.A . is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True Hydrology ( INIBasedModel ) pydantic-model \u00b6 The [Hydrology] section in an MDU file. This model is typically referenced under FMModel .hydrology . All lowercased attributes match with the [Hydrology] input as described in UM Sec.A . Numerics ( INIBasedModel ) pydantic-model \u00b6 The [Numerics] section in an MDU file. This model is typically referenced under FMModel .numerics . All lowercased attributes match with the [Numerics] input as described in UM Sec.A . Output ( INIBasedModel ) pydantic-model \u00b6 The [Output] section in an MDU file. This model is typically referenced under FMModel .output . All lowercased attributes match with the [Output] input as described in UM Sec.A . is_intermediate_link ( self ) -> bool \u00b6 Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False Physics ( INIBasedModel ) pydantic-model \u00b6 The [Physics] section in an MDU file. This model is typically referenced under FMModel .physics . All lowercased attributes match with the [Physics] input as described in UM Sec.A . Restart ( INIBasedModel ) pydantic-model \u00b6 The [Restart] section in an MDU file. This model is typically referenced under FMModel .restart . All lowercased attributes match with the [Restart] input as described in UM Sec.A . Time ( INIBasedModel ) pydantic-model \u00b6 The [Time] section in an MDU file. This model is typically referenced under FMModel .time . All lowercased attributes match with the [Time] input as described in UM Sec.A . Trachytopes ( INIBasedModel ) pydantic-model \u00b6 The [Trachytopes] section in an MDU file. This model is typically referenced under FMModel .trachytopes . All lowercased attributes match with the [Trachytopes] input as described in UM Sec.A . VolumeTables ( INIBasedModel ) pydantic-model \u00b6 The [VolumeTables] section in an MDU file. This model is typically referenced under FMModel .volumetables . All lowercased attributes match with the [VolumeTables] input as described in UM Sec.A . Waves ( INIBasedModel ) pydantic-model \u00b6 The [Waves] section in an MDU file. This model is typically referenced under FMModel .waves . All lowercased attributes match with the [Waves] input as described in UM Sec.A . Wind ( INIBasedModel ) pydantic-model \u00b6 The [Wind] section in an MDU file. This model is typically referenced under FMModel .wind . All lowercased attributes match with the [Wind] input as described in UM Sec.A .","title":"Mdu"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.ExternalForcing","text":"The [External Forcing] section in an MDU file. This model is typically referenced under FMModel .external_forcing . All lowercased attributes match with the [External Forcing] input as described in UM Sec.A .","title":"ExternalForcing"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.ExternalForcing.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.FMModel","text":"The overall FM model that contains the contents of the toplevel MDU file. All lowercased attributes match with the supported \"[section]\"s as described in UM Sec.A . Each of these class attributes refers to an underlying model class for that particular section.","title":"FMModel"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Geometry","text":"The [Geometry] section in an MDU file. This model is typically referenced under FMModel .geometry . All lowercased attributes match with the [Geometry] input as described in UM Sec.A .","title":"Geometry"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Geometry.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : return True","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Hydrology","text":"The [Hydrology] section in an MDU file. This model is typically referenced under FMModel .hydrology . All lowercased attributes match with the [Hydrology] input as described in UM Sec.A .","title":"Hydrology"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Numerics","text":"The [Numerics] section in an MDU file. This model is typically referenced under FMModel .numerics . All lowercased attributes match with the [Numerics] input as described in UM Sec.A .","title":"Numerics"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Output","text":"The [Output] section in an MDU file. This model is typically referenced under FMModel .output . All lowercased attributes match with the [Output] input as described in UM Sec.A .","title":"Output"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Output.is_intermediate_link","text":"Generic attribute for models that have children fields that could contain files. Source code in hydrolib/core/io/mdu/models.py def is_intermediate_link ( self ) -> bool : # TODO set to True once we replace Paths with FileModels return False","title":"is_intermediate_link()"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Physics","text":"The [Physics] section in an MDU file. This model is typically referenced under FMModel .physics . All lowercased attributes match with the [Physics] input as described in UM Sec.A .","title":"Physics"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Restart","text":"The [Restart] section in an MDU file. This model is typically referenced under FMModel .restart . All lowercased attributes match with the [Restart] input as described in UM Sec.A .","title":"Restart"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Time","text":"The [Time] section in an MDU file. This model is typically referenced under FMModel .time . All lowercased attributes match with the [Time] input as described in UM Sec.A .","title":"Time"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Trachytopes","text":"The [Trachytopes] section in an MDU file. This model is typically referenced under FMModel .trachytopes . All lowercased attributes match with the [Trachytopes] input as described in UM Sec.A .","title":"Trachytopes"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.VolumeTables","text":"The [VolumeTables] section in an MDU file. This model is typically referenced under FMModel .volumetables . All lowercased attributes match with the [VolumeTables] input as described in UM Sec.A .","title":"VolumeTables"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Waves","text":"The [Waves] section in an MDU file. This model is typically referenced under FMModel .waves . All lowercased attributes match with the [Waves] input as described in UM Sec.A .","title":"Waves"},{"location":"reference/mdu/#hydrolib.core.io.mdu.models.Wind","text":"The [Wind] section in an MDU file. This model is typically referenced under FMModel .wind . All lowercased attributes match with the [Wind] input as described in UM Sec.A .","title":"Wind"},{"location":"reference/net/","text":"Branch \u00b6 interpolate ( self , distance : npt . ArrayLike ) -> np . ndarray \u00b6 Interpolate coordinates along branch by length Parameters: Name Type Description Default distance npt.ArrayLike Length required Source code in hydrolib/core/io/net/models.py def interpolate ( self , distance : npt . ArrayLike ) -> np . ndarray : \"\"\"Interpolate coordinates along branch by length Args: distance (npt.ArrayLike): Length \"\"\" intpcoords = np . stack ( [ np . interp ( distance , self . _distance , self . _x_coordinates ), np . interp ( distance , self . _distance , self . _y_coordinates ), ], axis = 1 , ) return intpcoords Link1d2d ( BaseModel ) pydantic-model \u00b6 Link1d2d defines the 1D2D Links of a model network. Attributes: Name Type Description meshkernel Optional[mk.MeshKernel] The MeshKernel used to interact with this Link1d2d link1d2d_id np.ndarray The id of this Link1d2d link1d2d_long_name np.ndarray The long name of this Link1d2d link1d2d_contact_type np.ndarray The contact type of this Link1d2d link1d2d np.ndarray The underlying data object of this Link1d2d clear ( self ) -> None \u00b6 Remove all saved links from the links administration Source code in hydrolib/core/io/net/models.py def clear ( self ) -> None : \"\"\"Remove all saved links from the links administration\"\"\" self . link1d2d_id = Field ( default_factory = lambda : np . empty ( 0 , object )) self . link1d2d_long_name = Field ( default_factory = lambda : np . empty ( 0 , object )) self . link1d2d_contact_type = Field ( default_factory = lambda : np . empty ( 0 , np . int32 ) ) self . link1d2d = Field ( default_factory = lambda : np . empty (( 0 , 2 ), np . int32 )) is_empty ( self ) -> bool \u00b6 Whether this Link1d2d is currently empty. Returns: Type Description bool True if the Link1d2d is currently empty; False otherwise. Source code in hydrolib/core/io/net/models.py def is_empty ( self ) -> bool : \"\"\"Whether this Link1d2d is currently empty. Returns: bool: True if the Link1d2d is currently empty; False otherwise. \"\"\" return self . link1d2d . size == 0 read_file ( self , file_path : Path ) -> None \u00b6 Read the Link1d2d data from the specified netCDF file at file_path into this Parameters: Name Type Description Default file_path Path Path to the netCDF file. required Source code in hydrolib/core/io/net/models.py def read_file ( self , file_path : Path ) -> None : \"\"\"Read the Link1d2d data from the specified netCDF file at file_path into this Args: file_path (Path): Path to the netCDF file. \"\"\" reader = UgridReader ( file_path ) reader . read_link1d2d ( self ) Mesh1d ( BaseModel ) pydantic-model \u00b6 get_node_mask ( self , branchids : List [ str ] = None ) \u00b6 Get node mask, give a mask with True for each node that is in the given branchid list Source code in hydrolib/core/io/net/models.py def get_node_mask ( self , branchids : List [ str ] = None ): \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\" mask = np . full ( self . mesh1d_node_id . shape , False , dtype = bool ) if branchids is None : mask [:] = True return mask # Get number (index) of given branches idx = np . where ( np . isin ( self . network1d_branch_id , branchids ))[ 0 ] if idx . size == 0 : raise KeyError ( \"No branches corresponding to the given keys were found.\" ) mask [ np . isin ( self . mesh1d_node_branch_id , idx )] = True return mask Mesh2d ( BaseModel ) pydantic-model \u00b6 Mesh2d defines a single two dimensional grid. Attributes: Name Type Description meshkernel mk.MeshKernel The meshkernel used to manimpulate this Mesh2d. mesh2d_node_x np.ndarray The node positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_node_y np.ndarray The node positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_node_z np.ndarray The node positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_x np.ndarray The edge positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_y np.ndarray The edge positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_z np.ndarray The edge positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_nodes np.ndarray The mapping of edges to node indices. Defaults to np.empty((0, 2), dtype=np.int32). mesh2d_face_x np.ndarray The face positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_y np.ndarray The face positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_z np.ndarray The face positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_nodes np.ndarray The mapping of faces to node indices. Defaults to np.empty((0, 0), dtype=np.int32) clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ) -> None \u00b6 Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Parameters: Name Type Description Default polygon GeometryList Polygon stored as GeometryList required deletemeshoption int [description]. Defaults to 1. 1 Source code in hydrolib/core/io/net/models.py def clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ) -> None : \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Args: polygon (GeometryList): Polygon stored as GeometryList deletemeshoption (int, optional): [description]. Defaults to 1. \"\"\" # Add current mesh to Mesh2d instance self . _set_mesh2d () # Delete outside polygon deletemeshoption = mk . DeleteMeshOption ( deletemeshoption ) parts = split_by ( polygon , - 998.0 ) # Check if parts are closed for part in parts : if not ( part . x_coordinates [ 0 ], part . y_coordinates [ 0 ]) == ( part . x_coordinates [ - 1 ], part . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) self . meshkernel . mesh2d_delete ( parts [ 0 ], deletemeshoption , True ) # Delete all holes for interior in parts [ 1 :]: self . meshkernel . mesh2d_delete ( interior , deletemeshoption , False ) # Process self . _process ( self . meshkernel . mesh2d_get ()) create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None \u00b6 Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Parameters: Name Type Description Default extent tuple Bounding box of mesh (left, bottom, right, top) required dx float Horizontal distance required dy float Vertical distance required TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Exceptions: Type Description NotImplementedError MultiPolygons Source code in hydrolib/core/io/net/models.py def create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None : \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Args: extent (tuple): Bounding box of mesh (left, bottom, right, top) dx (float): Horizontal distance dy (float): Vertical distance TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Raises: NotImplementedError: MultiPolygons \"\"\" xmin , ymin , xmax , ymax = extent # Generate mesh mesh2d_input = mk . Mesh2dFactory . create_rectilinear_mesh ( rows = int (( ymax - ymin ) / dy ), columns = int (( xmax - xmin ) / dx ), origin_x = xmin , origin_y = ymin , spacing_x = dx , spacing_y = dy , ) # Process self . _process ( mesh2d_input ) get_mesh2d ( self ) -> mk . Mesh2d \u00b6 Get the mesh2d as represented in the MeshKernel Returns: Type Description (mk.Mesh2d) The mesh2d as represented in the MeshKernel Source code in hydrolib/core/io/net/models.py def get_mesh2d ( self ) -> mk . Mesh2d : \"\"\"Get the mesh2d as represented in the MeshKernel Returns: (mk.Mesh2d): The mesh2d as represented in the MeshKernel \"\"\" return self . meshkernel . mesh2d_get () is_empty ( self ) -> bool \u00b6 Determine whether this Mesh2d is empty. Returns: Type Description (bool) Whether this Mesh2d is empty. Source code in hydrolib/core/io/net/models.py def is_empty ( self ) -> bool : \"\"\"Determine whether this Mesh2d is empty. Returns: (bool): Whether this Mesh2d is empty. \"\"\" return self . mesh2d_node_x . size == 0 read_file ( self , file_path : Path ) -> None \u00b6 Read the Mesh2d from the file at file_path. Parameters: Name Type Description Default file_path Path Path to the file to be read. required Source code in hydrolib/core/io/net/models.py def read_file ( self , file_path : Path ) -> None : \"\"\"Read the Mesh2d from the file at file_path. Args: file_path (Path): Path to the file to be read. \"\"\" reader = UgridReader ( file_path ) reader . read_mesh2d ( self ) refine ( self , polygon : mk . GeometryList , level : int ) \u00b6 Refine the mesh within a polygon, by a number of steps (level) Parameters: Name Type Description Default polygon GeometryList Polygon in which to refine required level int Number of refinement steps required Source code in hydrolib/core/io/net/models.py def refine ( self , polygon : mk . GeometryList , level : int ): \"\"\"Refine the mesh within a polygon, by a number of steps (level) Args: polygon (GeometryList): Polygon in which to refine level (int): Number of refinement steps \"\"\" # Add current mesh to Mesh2d instance mesh2d_input = mk . Mesh2d ( node_x = self . mesh2d_node_x , node_y = self . mesh2d_node_y , edge_nodes = self . mesh2d_edge_nodes . ravel (), ) self . meshkernel . mesh2d_set ( mesh2d_input ) # Check if parts are closed if not ( polygon . x_coordinates [ 0 ], polygon . y_coordinates [ 0 ]) == ( polygon . x_coordinates [ - 1 ], polygon . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) parameters = mk . MeshRefinementParameters ( refine_intersected = True , use_mass_center_when_refining = False , min_face_size = 10.0 , # Does nothing? refinement_type = 1 , connect_hanging_nodes = True , account_for_samples_outside_face = False , max_refinement_iterations = level , ) self . meshkernel . mesh2d_refine_based_on_polygon ( polygon , parameters ) # Process self . _process ( self . meshkernel . mesh2d_get ()) Network \u00b6 from_file ( file_path : Path ) -> Network classmethod \u00b6 Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Parameters: Name Type Description Default file_path Path path to netcdf file with network data required Returns: Type Description Network The instance of the class itself that is returned Source code in hydrolib/core/io/net/models.py @classmethod def from_file ( cls , file_path : Path ) -> Network : \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Args: file_path (Path): path to netcdf file with network data Returns: Network: The instance of the class itself that is returned \"\"\" network = cls () ds = nc . Dataset ( file_path ) # type: ignore[import] reader = UgridReader ( file_path ) reader . read_mesh1d_network1d ( network . _mesh1d ) reader . read_mesh2d ( network . _mesh2d ) reader . read_link1d2d ( network . _link1d2d ) ds . close () return network to_file ( self , file : Path ) -> None \u00b6 Write network to file Parameters: Name Type Description Default file Path File where _net.nc is written to. required Source code in hydrolib/core/io/net/models.py def to_file ( self , file : Path ) -> None : \"\"\"Write network to file Args: file (Path): File where _net.nc is written to. \"\"\" writer = UgridWriter () writer . write ( self , file ) NetworkModel ( FileModel ) pydantic-model \u00b6 Network model representation. split_by ( gl : mk . GeometryList , by : float ) -> list \u00b6 Function to split mk.GeometryList by seperator. Parameters: Name Type Description Default gl mk.GeometryList The geometry list to split. required by float The value by which to split the gl. required Returns: Type Description list The split lists. Source code in hydrolib/core/io/net/models.py def split_by ( gl : mk . GeometryList , by : float ) -> list : \"\"\"Function to split mk.GeometryList by seperator. Args: gl (mk.GeometryList): The geometry list to split. by (float): The value by which to split the gl. Returns: list: The split lists. \"\"\" x , y = gl . x_coordinates . copy (), gl . y_coordinates . copy () idx = np . where ( x == by )[ 0 ] xparts = np . split ( x , idx ) yparts = np . split ( y , idx ) lists = [ mk . GeometryList ( xp [ min ( i , 1 ) :], yp [ min ( i , 1 ) :]) for i , ( xp , yp ) in enumerate ( zip ( xparts , yparts )) ] return lists","title":"Net"},{"location":"reference/net/#hydrolib.core.io.net.models.Branch","text":"","title":"Branch"},{"location":"reference/net/#hydrolib.core.io.net.models.Branch.interpolate","text":"Interpolate coordinates along branch by length Parameters: Name Type Description Default distance npt.ArrayLike Length required Source code in hydrolib/core/io/net/models.py def interpolate ( self , distance : npt . ArrayLike ) -> np . ndarray : \"\"\"Interpolate coordinates along branch by length Args: distance (npt.ArrayLike): Length \"\"\" intpcoords = np . stack ( [ np . interp ( distance , self . _distance , self . _x_coordinates ), np . interp ( distance , self . _distance , self . _y_coordinates ), ], axis = 1 , ) return intpcoords","title":"interpolate()"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d","text":"Link1d2d defines the 1D2D Links of a model network. Attributes: Name Type Description meshkernel Optional[mk.MeshKernel] The MeshKernel used to interact with this Link1d2d link1d2d_id np.ndarray The id of this Link1d2d link1d2d_long_name np.ndarray The long name of this Link1d2d link1d2d_contact_type np.ndarray The contact type of this Link1d2d link1d2d np.ndarray The underlying data object of this Link1d2d","title":"Link1d2d"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d.clear","text":"Remove all saved links from the links administration Source code in hydrolib/core/io/net/models.py def clear ( self ) -> None : \"\"\"Remove all saved links from the links administration\"\"\" self . link1d2d_id = Field ( default_factory = lambda : np . empty ( 0 , object )) self . link1d2d_long_name = Field ( default_factory = lambda : np . empty ( 0 , object )) self . link1d2d_contact_type = Field ( default_factory = lambda : np . empty ( 0 , np . int32 ) ) self . link1d2d = Field ( default_factory = lambda : np . empty (( 0 , 2 ), np . int32 ))","title":"clear()"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d.is_empty","text":"Whether this Link1d2d is currently empty. Returns: Type Description bool True if the Link1d2d is currently empty; False otherwise. Source code in hydrolib/core/io/net/models.py def is_empty ( self ) -> bool : \"\"\"Whether this Link1d2d is currently empty. Returns: bool: True if the Link1d2d is currently empty; False otherwise. \"\"\" return self . link1d2d . size == 0","title":"is_empty()"},{"location":"reference/net/#hydrolib.core.io.net.models.Link1d2d.read_file","text":"Read the Link1d2d data from the specified netCDF file at file_path into this Parameters: Name Type Description Default file_path Path Path to the netCDF file. required Source code in hydrolib/core/io/net/models.py def read_file ( self , file_path : Path ) -> None : \"\"\"Read the Link1d2d data from the specified netCDF file at file_path into this Args: file_path (Path): Path to the netCDF file. \"\"\" reader = UgridReader ( file_path ) reader . read_link1d2d ( self )","title":"read_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh1d","text":"","title":"Mesh1d"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh1d.get_node_mask","text":"Get node mask, give a mask with True for each node that is in the given branchid list Source code in hydrolib/core/io/net/models.py def get_node_mask ( self , branchids : List [ str ] = None ): \"\"\"Get node mask, give a mask with True for each node that is in the given branchid list\"\"\" mask = np . full ( self . mesh1d_node_id . shape , False , dtype = bool ) if branchids is None : mask [:] = True return mask # Get number (index) of given branches idx = np . where ( np . isin ( self . network1d_branch_id , branchids ))[ 0 ] if idx . size == 0 : raise KeyError ( \"No branches corresponding to the given keys were found.\" ) mask [ np . isin ( self . mesh1d_node_branch_id , idx )] = True return mask","title":"get_node_mask()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d","text":"Mesh2d defines a single two dimensional grid. Attributes: Name Type Description meshkernel mk.MeshKernel The meshkernel used to manimpulate this Mesh2d. mesh2d_node_x np.ndarray The node positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_node_y np.ndarray The node positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_node_z np.ndarray The node positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_x np.ndarray The edge positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_y np.ndarray The edge positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_z np.ndarray The edge positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_edge_nodes np.ndarray The mapping of edges to node indices. Defaults to np.empty((0, 2), dtype=np.int32). mesh2d_face_x np.ndarray The face positions on the x-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_y np.ndarray The face positions on the y-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_z np.ndarray The face positions on the z-axis. Defaults to np.empty(0, dtype=np.double). mesh2d_face_nodes np.ndarray The mapping of faces to node indices. Defaults to np.empty((0, 0), dtype=np.int32)","title":"Mesh2d"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.clip","text":"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Parameters: Name Type Description Default polygon GeometryList Polygon stored as GeometryList required deletemeshoption int [description]. Defaults to 1. 1 Source code in hydrolib/core/io/net/models.py def clip ( self , polygon : mk . GeometryList , deletemeshoption : int = 1 ) -> None : \"\"\"Clip the 2D mesh by a polygon. Both outside the exterior and inside the interiors is clipped Args: polygon (GeometryList): Polygon stored as GeometryList deletemeshoption (int, optional): [description]. Defaults to 1. \"\"\" # Add current mesh to Mesh2d instance self . _set_mesh2d () # Delete outside polygon deletemeshoption = mk . DeleteMeshOption ( deletemeshoption ) parts = split_by ( polygon , - 998.0 ) # Check if parts are closed for part in parts : if not ( part . x_coordinates [ 0 ], part . y_coordinates [ 0 ]) == ( part . x_coordinates [ - 1 ], part . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) self . meshkernel . mesh2d_delete ( parts [ 0 ], deletemeshoption , True ) # Delete all holes for interior in parts [ 1 :]: self . meshkernel . mesh2d_delete ( interior , deletemeshoption , False ) # Process self . _process ( self . meshkernel . mesh2d_get ())","title":"clip()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.create_rectilinear","text":"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Parameters: Name Type Description Default extent tuple Bounding box of mesh (left, bottom, right, top) required dx float Horizontal distance required dy float Vertical distance required TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Exceptions: Type Description NotImplementedError MultiPolygons Source code in hydrolib/core/io/net/models.py def create_rectilinear ( self , extent : tuple , dx : float , dy : float ) -> None : \"\"\"Create a rectilinear mesh within a polygon. A rectangular grid is generated within the polygon bounds Args: extent (tuple): Bounding box of mesh (left, bottom, right, top) dx (float): Horizontal distance dy (float): Vertical distance TODO: Perhaps the polygon processing part should be part of Hydrolib (not core)! Raises: NotImplementedError: MultiPolygons \"\"\" xmin , ymin , xmax , ymax = extent # Generate mesh mesh2d_input = mk . Mesh2dFactory . create_rectilinear_mesh ( rows = int (( ymax - ymin ) / dy ), columns = int (( xmax - xmin ) / dx ), origin_x = xmin , origin_y = ymin , spacing_x = dx , spacing_y = dy , ) # Process self . _process ( mesh2d_input )","title":"create_rectilinear()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.get_mesh2d","text":"Get the mesh2d as represented in the MeshKernel Returns: Type Description (mk.Mesh2d) The mesh2d as represented in the MeshKernel Source code in hydrolib/core/io/net/models.py def get_mesh2d ( self ) -> mk . Mesh2d : \"\"\"Get the mesh2d as represented in the MeshKernel Returns: (mk.Mesh2d): The mesh2d as represented in the MeshKernel \"\"\" return self . meshkernel . mesh2d_get ()","title":"get_mesh2d()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.is_empty","text":"Determine whether this Mesh2d is empty. Returns: Type Description (bool) Whether this Mesh2d is empty. Source code in hydrolib/core/io/net/models.py def is_empty ( self ) -> bool : \"\"\"Determine whether this Mesh2d is empty. Returns: (bool): Whether this Mesh2d is empty. \"\"\" return self . mesh2d_node_x . size == 0","title":"is_empty()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.read_file","text":"Read the Mesh2d from the file at file_path. Parameters: Name Type Description Default file_path Path Path to the file to be read. required Source code in hydrolib/core/io/net/models.py def read_file ( self , file_path : Path ) -> None : \"\"\"Read the Mesh2d from the file at file_path. Args: file_path (Path): Path to the file to be read. \"\"\" reader = UgridReader ( file_path ) reader . read_mesh2d ( self )","title":"read_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.Mesh2d.refine","text":"Refine the mesh within a polygon, by a number of steps (level) Parameters: Name Type Description Default polygon GeometryList Polygon in which to refine required level int Number of refinement steps required Source code in hydrolib/core/io/net/models.py def refine ( self , polygon : mk . GeometryList , level : int ): \"\"\"Refine the mesh within a polygon, by a number of steps (level) Args: polygon (GeometryList): Polygon in which to refine level (int): Number of refinement steps \"\"\" # Add current mesh to Mesh2d instance mesh2d_input = mk . Mesh2d ( node_x = self . mesh2d_node_x , node_y = self . mesh2d_node_y , edge_nodes = self . mesh2d_edge_nodes . ravel (), ) self . meshkernel . mesh2d_set ( mesh2d_input ) # Check if parts are closed if not ( polygon . x_coordinates [ 0 ], polygon . y_coordinates [ 0 ]) == ( polygon . x_coordinates [ - 1 ], polygon . y_coordinates [ - 1 ], ): raise ValueError ( \"First and last coordinate of each GeometryList part should match.\" ) parameters = mk . MeshRefinementParameters ( refine_intersected = True , use_mass_center_when_refining = False , min_face_size = 10.0 , # Does nothing? refinement_type = 1 , connect_hanging_nodes = True , account_for_samples_outside_face = False , max_refinement_iterations = level , ) self . meshkernel . mesh2d_refine_based_on_polygon ( polygon , parameters ) # Process self . _process ( self . meshkernel . mesh2d_get ())","title":"refine()"},{"location":"reference/net/#hydrolib.core.io.net.models.Network","text":"","title":"Network"},{"location":"reference/net/#hydrolib.core.io.net.models.Network.from_file","text":"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Parameters: Name Type Description Default file_path Path path to netcdf file with network data required Returns: Type Description Network The instance of the class itself that is returned Source code in hydrolib/core/io/net/models.py @classmethod def from_file ( cls , file_path : Path ) -> Network : \"\"\"Read network from file. This classmethod checks what mesh components (mesh1d & network1d, mesh2d, link1d2d) are present, and loads them one by one. Args: file_path (Path): path to netcdf file with network data Returns: Network: The instance of the class itself that is returned \"\"\" network = cls () ds = nc . Dataset ( file_path ) # type: ignore[import] reader = UgridReader ( file_path ) reader . read_mesh1d_network1d ( network . _mesh1d ) reader . read_mesh2d ( network . _mesh2d ) reader . read_link1d2d ( network . _link1d2d ) ds . close () return network","title":"from_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.Network.to_file","text":"Write network to file Parameters: Name Type Description Default file Path File where _net.nc is written to. required Source code in hydrolib/core/io/net/models.py def to_file ( self , file : Path ) -> None : \"\"\"Write network to file Args: file (Path): File where _net.nc is written to. \"\"\" writer = UgridWriter () writer . write ( self , file )","title":"to_file()"},{"location":"reference/net/#hydrolib.core.io.net.models.NetworkModel","text":"Network model representation.","title":"NetworkModel"},{"location":"reference/net/#hydrolib.core.io.net.models.split_by","text":"Function to split mk.GeometryList by seperator. Parameters: Name Type Description Default gl mk.GeometryList The geometry list to split. required by float The value by which to split the gl. required Returns: Type Description list The split lists. Source code in hydrolib/core/io/net/models.py def split_by ( gl : mk . GeometryList , by : float ) -> list : \"\"\"Function to split mk.GeometryList by seperator. Args: gl (mk.GeometryList): The geometry list to split. by (float): The value by which to split the gl. Returns: list: The split lists. \"\"\" x , y = gl . x_coordinates . copy (), gl . y_coordinates . copy () idx = np . where ( x == by )[ 0 ] xparts = np . split ( x , idx ) yparts = np . split ( y , idx ) lists = [ mk . GeometryList ( xp [ min ( i , 1 ) :], yp [ min ( i , 1 ) :]) for i , ( xp , yp ) in enumerate ( zip ( xparts , yparts )) ] return lists","title":"split_by()"},{"location":"reference/polyfile/","text":"polyfile: .pli(z) and .pol files \u00b6 Model \u00b6 models.py defines all classes and functions related to representing pol/pli(z) files. Description ( BaseModel ) pydantic-model \u00b6 Description of a single PolyObject. The Description will be prepended to a block. Each line will start with a '*'. Attributes: Name Type Description content str The content of this Description. Metadata ( BaseModel ) pydantic-model \u00b6 Metadata of a single PolyObject. Attributes: Name Type Description name str The name of the PolyObject n_rows int The number of rows (i.e. Point instances) of the PolyObject n_columns int The total number of values in a Point, including x, y, and z. Point ( BaseModel ) pydantic-model \u00b6 Point consisting of a x and y coordinate, an optional z coordinate and data. Attributes: Name Type Description x float The x-coordinate of this Point y float The y-coordinate of this Point z Optional[float] An optional z-coordinate of this Point. data Sequence[float] The additional data variables of this Point. PolyFile ( FileModel ) pydantic-model \u00b6 Poly-file (.pol/.pli/.pliz) representation. PolyObject ( BaseModel ) pydantic-model \u00b6 PolyObject describing a single block in a poly file. The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the metadata. Attributes: Name Type Description description Optional[Description] An optional description of this PolyObject metadata Metadata The Metadata of this PolObject, describing the structure points List[Point] The points describing this PolyObject, structured according to the Metadata Parser \u00b6 parser.py defines all classes and functions related to parsing pol/pli(z) files. Block ( BaseModel ) pydantic-model \u00b6 Block is a temporary object which will be converted into a PolyObject. The fields are supposed to be set during the lifetime of this object. When all fields are set, finalize can be called. Attributes: Name Type Description start_line int The starting line of this current block. name Optional[str] The name of this block. Defaults to None. dimensions Optional[Tuple[int, int]] The dimensions (n_rows, n_columns) of this Block. Defaults to None. points Optional[List[Point]] The points of this block. Defaults to None. ws_warnings List[ParseMsg] The whitespace warnings associated with this block. Defaults to an empty list. empty_lines List[int] The line numbers of the empty lines. Defaults to an empty list. finalize ( self ) -> Optional [ Tuple [ hydrolib . core . io . polyfile . models . PolyObject , List [ hydrolib . core . io . polyfile . parser . ParseMsg ]]] \u00b6 Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Type Description Optional[Tuple[PolyObject, List[ParseMsg]]] The constructed PolyObject and warnings encountered while parsing it. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Optional [ Tuple [ PolyObject , List [ ParseMsg ]]]: \"\"\"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Optional[Tuple[PolyObject, List[ParseMsg]]]: The constructed PolyObject and warnings encountered while parsing it. \"\"\" metadata = self . _get_metadata () if metadata is None or self . points is None : return None obj = PolyObject ( description = self . _get_description (), metadata = metadata , points = self . points ) return obj , self . ws_warnings + self . _get_empty_line_warnings () ErrorBuilder \u00b6 ErrorBuilder provides the functionality to the Parser to keep track of errors. __init__ ( self ) -> None special \u00b6 Create a new ErorrorBuilder Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self ) -> None : \"\"\"Create a new ErorrorBuilder\"\"\" self . _current_block : Optional [ InvalidBlock ] = None end_invalid_block ( self , line : int ) -> None \u00b6 Store the end line of the current block If no invalid block currently exists, nothing will be done. Parameters: Name Type Description Default line int the final line of this invalid block required Source code in hydrolib/core/io/polyfile/parser.py def end_invalid_block ( self , line : int ) -> None : \"\"\"Store the end line of the current block If no invalid block currently exists, nothing will be done. Args: line (int): the final line of this invalid block \"\"\" if self . _current_block is not None : self . _current_block . end_line = line finalize_previous_error ( self ) -> Optional [ hydrolib . core . io . polyfile . parser . ParseMsg ] \u00b6 Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Type Description Optional[ParseMsg] The corresponding ParseMsg if an InvalidBlock exists. Source code in hydrolib/core/io/polyfile/parser.py def finalize_previous_error ( self ) -> Optional [ ParseMsg ]: \"\"\"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists. \"\"\" if self . _current_block is not None : msg = self . _current_block . to_msg () self . _current_block = None return msg else : return None start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None \u00b6 Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Parameters: Name Type Description Default block_start int The start of the invalid block. required invalid_line int The actual offending line number. required reason str The reason why this block is invalid. required Source code in hydrolib/core/io/polyfile/parser.py def start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None : \"\"\"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Args: block_start (int): The start of the invalid block. invalid_line (int): The actual offending line number. reason (str): The reason why this block is invalid. \"\"\" if self . _current_block is None : self . _current_block = InvalidBlock ( start_line = block_start , invalid_line = invalid_line , reason = reason ) InvalidBlock ( BaseModel ) pydantic-model \u00b6 InvalidBlock is a temporary object which will be converted into a ParseMsg. Attributes: Name Type Description start_line int The start line of this InvalidBlock end_line Optional[int] The end line of this InvalidBlock if it is set. Defaults to None. invalid_line int The line which is causing this block to be invalid. reason str A human-readable string detailing the reason of the ParseMsg. to_msg ( self ) -> ParseMsg \u00b6 Convert this InvalidBlock to the corresponding ParseMsg Returns: Type Description ParseMsg The ParseMsg corresponding with this InvalidBlock Source code in hydrolib/core/io/polyfile/parser.py def to_msg ( self ) -> ParseMsg : \"\"\"Convert this InvalidBlock to the corresponding ParseMsg Returns: ParseMsg: The ParseMsg corresponding with this InvalidBlock \"\"\" return ParseMsg ( line_start = self . start_line , line_end = self . end_line , reason = f \" { self . reason } at line { self . invalid_line } .\" , ) ParseMsg ( BaseModel ) pydantic-model \u00b6 ParseMsg defines a single message indicating a significant parse event. Attributes: Name Type Description line_start int The start line of the block to which this ParseMsg refers. line_end int The end line of the block to which this ParseMsg refers. column Optional[Tuple[int, int]] An optional begin and end column to which this ParseMsg refers. reason str A human-readable string detailing the reason of the ParseMsg. notify_as_warning ( self , file_path : Optional [ pathlib . Path ] = None ) \u00b6 Call warnings.warn with a formatted string describing this ParseMsg Parameters: Name Type Description Default file_path Optional[Path] The file path mentioned in the warning if specified. Defaults to None. None Source code in hydrolib/core/io/polyfile/parser.py def notify_as_warning ( self , file_path : Optional [ Path ] = None ): \"\"\"Call warnings.warn with a formatted string describing this ParseMsg Args: file_path (Optional[Path], optional): The file path mentioned in the warning if specified. Defaults to None. \"\"\" if self . line_start != self . line_end : block_suffix = f \" \\n Invalid block { self . line_start } : { self . line_end } \" else : block_suffix = f \" \\n Invalid line { self . line_start } \" col_suffix = ( f \" \\n Columns { self . column [ 0 ] } : { self . column [ 1 ] } \" if self . column is not None else \"\" ) file_suffix = f \" \\n File: { file_path } \" if file_path is not None else \"\" warnings . warn ( f \" { self . reason }{ block_suffix }{ col_suffix }{ file_suffix } \" ) Parser \u00b6 Parser provides the functionality to parse a polyfile line by line. The Parser parses blocks describing PolyObject instances by relying on a rudimentary state machine. The states are encoded with the StateType. New lines are fed through the feed_line method. After each line the internal state will be updated. When a complete block is read, it will be converted into a PolyObject and stored internally. When finalise is called, the constructed objects, as well as any warnings and errors describing invalid blocks, will be returned. Each state defines a feed_line method, stored in the _feed_line dict, which consumes a line and potentially transitions the state into the next. Each state further defines a finalise method, stored in the _finalise dict, which is called upon finalising the parser. Invalid states are encoded with INVALID_STATE. In this state the Parser attempts to find a new block, and thus looks for a new description or name. Unexpected whitespace before comments, names, and dimensions, as well as empty lines will generate a warning, and will be ignored by the parser. __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None special \u00b6 Create a new Parser Parameters: Name Type Description Default file_path Path Name of the file being parsed, only used for providing proper warnings. required has_z_value bool Whether to interpret the third column as z-coordinates. Defaults to False. False Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None : \"\"\"Create a new Parser Args: file_path (Path): Name of the file being parsed, only used for providing proper warnings. has_z_value (bool, optional): Whether to interpret the third column as z-coordinates. Defaults to False. \"\"\" self . _has_z_value = has_z_value self . _file_path = file_path self . _line = 0 self . _new_block () self . _error_builder = ErrorBuilder () self . _poly_objects : List [ PolyObject ] = [] self . _current_point : int = 0 self . _feed_line : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _parse_name_or_new_description , StateType . PARSED_DESCRIPTION : self . _parse_name_or_next_description , StateType . PARSED_NAME : self . _parse_dimensions , StateType . PARSING_POINTS : self . _parse_next_point , StateType . INVALID_STATE : self . _parse_name_or_new_description , } self . _finalise : Dict [ StateType , Callable [[], None ]] = { StateType . NEW_BLOCK : self . _noop , StateType . PARSED_DESCRIPTION : self . _add_current_block_as_incomplete_error , StateType . PARSED_NAME : self . _add_current_block_as_incomplete_error , StateType . PARSING_POINTS : self . _add_current_block_as_incomplete_error , StateType . INVALID_STATE : self . _noop , } self . _handle_ws : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _log_ws_warning , StateType . PARSED_DESCRIPTION : self . _log_ws_warning , StateType . PARSED_NAME : self . _log_ws_warning , StateType . PARSING_POINTS : self . _noop , StateType . INVALID_STATE : self . _noop , } feed_line ( self , line : str ) -> None \u00b6 Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/polyfile/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not Parser . _is_empty_line ( line ): self . _handle_ws [ self . _state ]( line ) self . _feed_line [ self . _state ]( line ) else : self . _handle_empty_line () self . _increment_line () finalize ( self ) -> Sequence [ hydrolib . core . io . polyfile . models . PolyObject ] \u00b6 Finalize parsing and return the constructed PolyObject. Returns: Type Description PolyObject A PolyObject containing the constructed PolyObject instances. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Sequence [ PolyObject ]: \"\"\"Finalize parsing and return the constructed PolyObject. Returns: PolyObject: A PolyObject containing the constructed PolyObject instances. \"\"\" self . _error_builder . end_invalid_block ( self . _line ) last_error_msg = self . _error_builder . finalize_previous_error () if last_error_msg is not None : self . _handle_parse_msg ( last_error_msg ) self . _finalise [ self . _state ]() return self . _poly_objects StateType ( IntEnum ) \u00b6 The types of state of a Parser. read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict \u00b6 Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: Optional description record consisting of one or more lines starting with '*'. These will be ignored. Name consisting of a non-blank character string Two integers, Nr and Nc, representing the numbers of rows and columns respectively Nr number of data points, consisting of Nc floats separated by whitespace For example: ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Parameters: Name Type Description Default filepath Path Path to the pli(z)/pol convention structured file. required has_z_values bool Whether to create points containing a z-value. Defaults to None. required Returns: Type Description Dict The dictionary describing the data of a PolyObject. Source code in hydrolib/core/io/polyfile/parser.py def read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict : \"\"\"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: - Optional description record consisting of one or more lines starting with '*'. These will be ignored. - Name consisting of a non-blank character string - Two integers, Nr and Nc, representing the numbers of rows and columns respectively - Nr number of data points, consisting of Nc floats separated by whitespace For example: ``` ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... ``` Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Args: filepath: Path to the pli(z)/pol convention structured file. has_z_values: Whether to create points containing a z-value. Defaults to None. Returns: Dict: The dictionary describing the data of a PolyObject. \"\"\" if has_z_values is None : has_z_values = _determine_has_z_value ( filepath ) parser = Parser ( filepath , has_z_value = has_z_values ) with filepath . open ( \"r\" ) as f : for line in f : parser . feed_line ( line ) objs = parser . finalize () return { \"has_z_values\" : has_z_values , \"objects\" : objs } Serializer \u00b6 Serializer \u00b6 Serializer provides several static serialize methods for the models. serialize_description ( description : Optional [ hydrolib . core . io . polyfile . models . Description ]) -> Iterable [ str ] staticmethod \u00b6 Serialize the Description to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Description Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_description ( description : Optional [ Description ]) -> Iterable [ str ]: \"\"\"Serialize the Description to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Description \"\"\" if description is None : return [] if description . content == \"\" : return [ \"*\" , ] return ( f \"* { v . rstrip () } \" for v in description . content . splitlines ()) serialize_metadata ( metadata : Metadata ) -> Iterable [ str ] staticmethod \u00b6 Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: Type Description str The serialised equivalent of this Metadata Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_metadata ( metadata : Metadata ) -> Iterable [ str ]: \"\"\"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: str: The serialised equivalent of this Metadata \"\"\" return [ metadata . name , f \" { metadata . n_rows } { metadata . n_columns } \" ] serialize_point ( point : Point ) -> str staticmethod \u00b6 Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_point ( point : Point ) -> str : \"\"\"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: str: The serialised equivalent of this Point \"\"\" z_val = f \" { point . z } \" if point . z is not None else \"\" data_vals = \" \" . join ( str ( v ) for v in point . data ) return f \" { point . x } { point . y } { z_val }{ data_vals } \" . rstrip () serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ] staticmethod \u00b6 Serialize this PolyObject to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ]: \"\"\"Serialize this PolyObject to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Point \"\"\" description = Serializer . serialize_description ( obj . description ) metadata = Serializer . serialize_metadata ( obj . metadata ) points = map ( Serializer . serialize_point , obj . points ) return chain ( description , metadata , points ) write_polyfile ( path : Path , data : Dict ) -> None \u00b6 Write the data to a new file at path Parameters: Name Type Description Default path Path The path to write the data to required data PolyFile The data to write required Source code in hydrolib/core/io/polyfile/serializer.py def write_polyfile ( path : Path , data : Dict ) -> None : \"\"\"Write the data to a new file at path Args: path (Path): The path to write the data to data (PolyFile): The data to write \"\"\" serialized_data = chain . from_iterable ( map ( Serializer . serialize_poly_object , data [ \"objects\" ]) ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serialized_data : f . write ( line ) f . write ( \" \\n \" )","title":"Polyfile"},{"location":"reference/polyfile/#polyfile-pliz-and-pol-files","text":"","title":"polyfile: .pli(z) and .pol files"},{"location":"reference/polyfile/#model","text":"models.py defines all classes and functions related to representing pol/pli(z) files.","title":"Model"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Description","text":"Description of a single PolyObject. The Description will be prepended to a block. Each line will start with a '*'. Attributes: Name Type Description content str The content of this Description.","title":"Description"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Metadata","text":"Metadata of a single PolyObject. Attributes: Name Type Description name str The name of the PolyObject n_rows int The number of rows (i.e. Point instances) of the PolyObject n_columns int The total number of values in a Point, including x, y, and z.","title":"Metadata"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.Point","text":"Point consisting of a x and y coordinate, an optional z coordinate and data. Attributes: Name Type Description x float The x-coordinate of this Point y float The y-coordinate of this Point z Optional[float] An optional z-coordinate of this Point. data Sequence[float] The additional data variables of this Point.","title":"Point"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.PolyFile","text":"Poly-file (.pol/.pli/.pliz) representation.","title":"PolyFile"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.models.PolyObject","text":"PolyObject describing a single block in a poly file. The metadata should be consistent with the points: - The number of points should be equal to number of rows defined in the metadata - The data of each point should be equal to the number of columns defined in the metadata. Attributes: Name Type Description description Optional[Description] An optional description of this PolyObject metadata Metadata The Metadata of this PolObject, describing the structure points List[Point] The points describing this PolyObject, structured according to the Metadata","title":"PolyObject"},{"location":"reference/polyfile/#parser","text":"parser.py defines all classes and functions related to parsing pol/pli(z) files.","title":"Parser"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Block","text":"Block is a temporary object which will be converted into a PolyObject. The fields are supposed to be set during the lifetime of this object. When all fields are set, finalize can be called. Attributes: Name Type Description start_line int The starting line of this current block. name Optional[str] The name of this block. Defaults to None. dimensions Optional[Tuple[int, int]] The dimensions (n_rows, n_columns) of this Block. Defaults to None. points Optional[List[Point]] The points of this block. Defaults to None. ws_warnings List[ParseMsg] The whitespace warnings associated with this block. Defaults to an empty list. empty_lines List[int] The line numbers of the empty lines. Defaults to an empty list.","title":"Block"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Block.finalize","text":"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Type Description Optional[Tuple[PolyObject, List[ParseMsg]]] The constructed PolyObject and warnings encountered while parsing it. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Optional [ Tuple [ PolyObject , List [ ParseMsg ]]]: \"\"\"Finalise this Block and return the constructed PolyObject and warnings If the metadata or the points are None, then None is returned. Returns: Optional[Tuple[PolyObject, List[ParseMsg]]]: The constructed PolyObject and warnings encountered while parsing it. \"\"\" metadata = self . _get_metadata () if metadata is None or self . points is None : return None obj = PolyObject ( description = self . _get_description (), metadata = metadata , points = self . points ) return obj , self . ws_warnings + self . _get_empty_line_warnings ()","title":"finalize()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder","text":"ErrorBuilder provides the functionality to the Parser to keep track of errors.","title":"ErrorBuilder"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.__init__","text":"Create a new ErorrorBuilder Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self ) -> None : \"\"\"Create a new ErorrorBuilder\"\"\" self . _current_block : Optional [ InvalidBlock ] = None","title":"__init__()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.end_invalid_block","text":"Store the end line of the current block If no invalid block currently exists, nothing will be done. Parameters: Name Type Description Default line int the final line of this invalid block required Source code in hydrolib/core/io/polyfile/parser.py def end_invalid_block ( self , line : int ) -> None : \"\"\"Store the end line of the current block If no invalid block currently exists, nothing will be done. Args: line (int): the final line of this invalid block \"\"\" if self . _current_block is not None : self . _current_block . end_line = line","title":"end_invalid_block()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.finalize_previous_error","text":"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Type Description Optional[ParseMsg] The corresponding ParseMsg if an InvalidBlock exists. Source code in hydrolib/core/io/polyfile/parser.py def finalize_previous_error ( self ) -> Optional [ ParseMsg ]: \"\"\"Finalize the current invalid block if it exists If no current invalid block exists, None will be returned, and nothing will change. If a current block exists, it will be converted into a ParseMsg and returned. The current invalid block will be reset. Returns: Optional[ParseMsg]: The corresponding ParseMsg if an InvalidBlock exists. \"\"\" if self . _current_block is not None : msg = self . _current_block . to_msg () self . _current_block = None return msg else : return None","title":"finalize_previous_error()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ErrorBuilder.start_invalid_block","text":"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Parameters: Name Type Description Default block_start int The start of the invalid block. required invalid_line int The actual offending line number. required reason str The reason why this block is invalid. required Source code in hydrolib/core/io/polyfile/parser.py def start_invalid_block ( self , block_start : int , invalid_line : int , reason : str ) -> None : \"\"\"Start a new invalid block if none exists at the moment If we are already in an invalid block, or the previous one was never finalised, we will not log the reason, and assume it is one long invalid block. Args: block_start (int): The start of the invalid block. invalid_line (int): The actual offending line number. reason (str): The reason why this block is invalid. \"\"\" if self . _current_block is None : self . _current_block = InvalidBlock ( start_line = block_start , invalid_line = invalid_line , reason = reason )","title":"start_invalid_block()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.InvalidBlock","text":"InvalidBlock is a temporary object which will be converted into a ParseMsg. Attributes: Name Type Description start_line int The start line of this InvalidBlock end_line Optional[int] The end line of this InvalidBlock if it is set. Defaults to None. invalid_line int The line which is causing this block to be invalid. reason str A human-readable string detailing the reason of the ParseMsg.","title":"InvalidBlock"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.InvalidBlock.to_msg","text":"Convert this InvalidBlock to the corresponding ParseMsg Returns: Type Description ParseMsg The ParseMsg corresponding with this InvalidBlock Source code in hydrolib/core/io/polyfile/parser.py def to_msg ( self ) -> ParseMsg : \"\"\"Convert this InvalidBlock to the corresponding ParseMsg Returns: ParseMsg: The ParseMsg corresponding with this InvalidBlock \"\"\" return ParseMsg ( line_start = self . start_line , line_end = self . end_line , reason = f \" { self . reason } at line { self . invalid_line } .\" , )","title":"to_msg()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ParseMsg","text":"ParseMsg defines a single message indicating a significant parse event. Attributes: Name Type Description line_start int The start line of the block to which this ParseMsg refers. line_end int The end line of the block to which this ParseMsg refers. column Optional[Tuple[int, int]] An optional begin and end column to which this ParseMsg refers. reason str A human-readable string detailing the reason of the ParseMsg.","title":"ParseMsg"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.ParseMsg.notify_as_warning","text":"Call warnings.warn with a formatted string describing this ParseMsg Parameters: Name Type Description Default file_path Optional[Path] The file path mentioned in the warning if specified. Defaults to None. None Source code in hydrolib/core/io/polyfile/parser.py def notify_as_warning ( self , file_path : Optional [ Path ] = None ): \"\"\"Call warnings.warn with a formatted string describing this ParseMsg Args: file_path (Optional[Path], optional): The file path mentioned in the warning if specified. Defaults to None. \"\"\" if self . line_start != self . line_end : block_suffix = f \" \\n Invalid block { self . line_start } : { self . line_end } \" else : block_suffix = f \" \\n Invalid line { self . line_start } \" col_suffix = ( f \" \\n Columns { self . column [ 0 ] } : { self . column [ 1 ] } \" if self . column is not None else \"\" ) file_suffix = f \" \\n File: { file_path } \" if file_path is not None else \"\" warnings . warn ( f \" { self . reason }{ block_suffix }{ col_suffix }{ file_suffix } \" )","title":"notify_as_warning()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser","text":"Parser provides the functionality to parse a polyfile line by line. The Parser parses blocks describing PolyObject instances by relying on a rudimentary state machine. The states are encoded with the StateType. New lines are fed through the feed_line method. After each line the internal state will be updated. When a complete block is read, it will be converted into a PolyObject and stored internally. When finalise is called, the constructed objects, as well as any warnings and errors describing invalid blocks, will be returned. Each state defines a feed_line method, stored in the _feed_line dict, which consumes a line and potentially transitions the state into the next. Each state further defines a finalise method, stored in the _finalise dict, which is called upon finalising the parser. Invalid states are encoded with INVALID_STATE. In this state the Parser attempts to find a new block, and thus looks for a new description or name. Unexpected whitespace before comments, names, and dimensions, as well as empty lines will generate a warning, and will be ignored by the parser.","title":"Parser"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.__init__","text":"Create a new Parser Parameters: Name Type Description Default file_path Path Name of the file being parsed, only used for providing proper warnings. required has_z_value bool Whether to interpret the third column as z-coordinates. Defaults to False. False Source code in hydrolib/core/io/polyfile/parser.py def __init__ ( self , file_path : Path , has_z_value : bool = False ) -> None : \"\"\"Create a new Parser Args: file_path (Path): Name of the file being parsed, only used for providing proper warnings. has_z_value (bool, optional): Whether to interpret the third column as z-coordinates. Defaults to False. \"\"\" self . _has_z_value = has_z_value self . _file_path = file_path self . _line = 0 self . _new_block () self . _error_builder = ErrorBuilder () self . _poly_objects : List [ PolyObject ] = [] self . _current_point : int = 0 self . _feed_line : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _parse_name_or_new_description , StateType . PARSED_DESCRIPTION : self . _parse_name_or_next_description , StateType . PARSED_NAME : self . _parse_dimensions , StateType . PARSING_POINTS : self . _parse_next_point , StateType . INVALID_STATE : self . _parse_name_or_new_description , } self . _finalise : Dict [ StateType , Callable [[], None ]] = { StateType . NEW_BLOCK : self . _noop , StateType . PARSED_DESCRIPTION : self . _add_current_block_as_incomplete_error , StateType . PARSED_NAME : self . _add_current_block_as_incomplete_error , StateType . PARSING_POINTS : self . _add_current_block_as_incomplete_error , StateType . INVALID_STATE : self . _noop , } self . _handle_ws : Dict [ StateType , Callable [[ str ], None ]] = { StateType . NEW_BLOCK : self . _log_ws_warning , StateType . PARSED_DESCRIPTION : self . _log_ws_warning , StateType . PARSED_NAME : self . _log_ws_warning , StateType . PARSING_POINTS : self . _noop , StateType . INVALID_STATE : self . _noop , }","title":"__init__()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.feed_line","text":"Parse the next line with this Parser. Parameters: Name Type Description Default line str The line to parse required Source code in hydrolib/core/io/polyfile/parser.py def feed_line ( self , line : str ) -> None : \"\"\"Parse the next line with this Parser. Args: line (str): The line to parse \"\"\" if not Parser . _is_empty_line ( line ): self . _handle_ws [ self . _state ]( line ) self . _feed_line [ self . _state ]( line ) else : self . _handle_empty_line () self . _increment_line ()","title":"feed_line()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.Parser.finalize","text":"Finalize parsing and return the constructed PolyObject. Returns: Type Description PolyObject A PolyObject containing the constructed PolyObject instances. Source code in hydrolib/core/io/polyfile/parser.py def finalize ( self ) -> Sequence [ PolyObject ]: \"\"\"Finalize parsing and return the constructed PolyObject. Returns: PolyObject: A PolyObject containing the constructed PolyObject instances. \"\"\" self . _error_builder . end_invalid_block ( self . _line ) last_error_msg = self . _error_builder . finalize_previous_error () if last_error_msg is not None : self . _handle_parse_msg ( last_error_msg ) self . _finalise [ self . _state ]() return self . _poly_objects","title":"finalize()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.StateType","text":"The types of state of a Parser.","title":"StateType"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.parser.read_polyfile","text":"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: Optional description record consisting of one or more lines starting with '*'. These will be ignored. Name consisting of a non-blank character string Two integers, Nr and Nc, representing the numbers of rows and columns respectively Nr number of data points, consisting of Nc floats separated by whitespace For example: ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Parameters: Name Type Description Default filepath Path Path to the pli(z)/pol convention structured file. required has_z_values bool Whether to create points containing a z-value. Defaults to None. required Returns: Type Description Dict The dictionary describing the data of a PolyObject. Source code in hydrolib/core/io/polyfile/parser.py def read_polyfile ( filepath : Path , has_z_values : bool ) -> Dict : \"\"\"Read the specified file and return the corresponding data. The file is expected to follow the .pli(z) / .pol convention. A .pli(z) or .pol file is defined as consisting of a number of blocks of lines adhering to the following format: - Optional description record consisting of one or more lines starting with '*'. These will be ignored. - Name consisting of a non-blank character string - Two integers, Nr and Nc, representing the numbers of rows and columns respectively - Nr number of data points, consisting of Nc floats separated by whitespace For example: ``` ... * * Polyline L008 * L008 4 2 131595.0 549685.0 131750.0 549865.0 131595.0 550025.0 131415.0 550175.0 ... ``` Note that the points can be arbitrarily indented, and the comments are optional. if no has_z_value has been defined, it will be based on the file path extensions of the filepath: - .pliz will default to True - .pli and .pol will default to False Empty lines and unexpected whitespace will be flagged as warnings, and ignored. If invalid syntax is detected within a block, an error will be created. This block will be ignored for the purpose of creating PolyObject instances. Once an error is encountered, any following lines will be marked as part of the invalid block, until a new valid block is found. Note that this means that sequential invalid blocks will be reported as a single invalid block. Such invalid blocks will be reported as warnings. Args: filepath: Path to the pli(z)/pol convention structured file. has_z_values: Whether to create points containing a z-value. Defaults to None. Returns: Dict: The dictionary describing the data of a PolyObject. \"\"\" if has_z_values is None : has_z_values = _determine_has_z_value ( filepath ) parser = Parser ( filepath , has_z_value = has_z_values ) with filepath . open ( \"r\" ) as f : for line in f : parser . feed_line ( line ) objs = parser . finalize () return { \"has_z_values\" : has_z_values , \"objects\" : objs }","title":"read_polyfile()"},{"location":"reference/polyfile/#serializer","text":"","title":"Serializer"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer","text":"Serializer provides several static serialize methods for the models.","title":"Serializer"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_description","text":"Serialize the Description to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Description Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_description ( description : Optional [ Description ]) -> Iterable [ str ]: \"\"\"Serialize the Description to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Description \"\"\" if description is None : return [] if description . content == \"\" : return [ \"*\" , ] return ( f \"* { v . rstrip () } \" for v in description . content . splitlines ())","title":"serialize_description()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_metadata","text":"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: Type Description str The serialised equivalent of this Metadata Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_metadata ( metadata : Metadata ) -> Iterable [ str ]: \"\"\"Serialize this Metadata to a string which can be used within a polyfile. The number of rows and number of columns are separated by four spaces. Returns: str: The serialised equivalent of this Metadata \"\"\" return [ metadata . name , f \" { metadata . n_rows } { metadata . n_columns } \" ]","title":"serialize_metadata()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_point","text":"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_point ( point : Point ) -> str : \"\"\"Serialize this Point to a string which can be used within a polyfile. the point data is indented with 4 spaces, and the individual values are separated by 4 spaces as well. Returns: str: The serialised equivalent of this Point \"\"\" z_val = f \" { point . z } \" if point . z is not None else \"\" data_vals = \" \" . join ( str ( v ) for v in point . data ) return f \" { point . x } { point . y } { z_val }{ data_vals } \" . rstrip ()","title":"serialize_point()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.Serializer.serialize_poly_object","text":"Serialize this PolyObject to a string which can be used within a polyfile. Returns: Type Description str The serialised equivalent of this Point Source code in hydrolib/core/io/polyfile/serializer.py @staticmethod def serialize_poly_object ( obj : PolyObject ) -> Iterable [ str ]: \"\"\"Serialize this PolyObject to a string which can be used within a polyfile. Returns: str: The serialised equivalent of this Point \"\"\" description = Serializer . serialize_description ( obj . description ) metadata = Serializer . serialize_metadata ( obj . metadata ) points = map ( Serializer . serialize_point , obj . points ) return chain ( description , metadata , points )","title":"serialize_poly_object()"},{"location":"reference/polyfile/#hydrolib.core.io.polyfile.serializer.write_polyfile","text":"Write the data to a new file at path Parameters: Name Type Description Default path Path The path to write the data to required data PolyFile The data to write required Source code in hydrolib/core/io/polyfile/serializer.py def write_polyfile ( path : Path , data : Dict ) -> None : \"\"\"Write the data to a new file at path Args: path (Path): The path to write the data to data (PolyFile): The data to write \"\"\" serialized_data = chain . from_iterable ( map ( Serializer . serialize_poly_object , data [ \"objects\" ]) ) path . parent . mkdir ( parents = True , exist_ok = True ) with path . open ( \"w\" ) as f : for line in serialized_data : f . write ( line ) f . write ( \" \\n \" )","title":"write_polyfile()"},{"location":"reference/structure/","text":"Structure .ini files \u00b6 Models \u00b6 structure namespace for storing the contents of an FMModel 's structure file. Bridge ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=bridge , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the bridge input as described in UM Sec.C.12.5 . Compound ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=compound , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the compound input as described in UM Sec.C.12.11 . Culvert ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=culvert , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the culvert input as described in UM Sec.C.12.3 . CulvertSubType ( str , Enum ) \u00b6 Enum class to store a Culvert 's subType. Dambreak ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=dambreak , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the dambreak input as described in UM Sec.C.12.10 . check_location ( values : dict ) -> dict classmethod \u00b6 Verifies whether the location for this structure contains valid values for numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file. Parameters: Name Type Description Default values dict Dictionary of validated values to create a Dambreak. required Exceptions: Type Description ValueError When the values dictionary does not contain valid coordinates or polyline file.. Returns: Type Description dict Dictionary of validated values. Source code in hydrolib/core/io/structure/models.py @root_validator @classmethod def check_location ( cls , values : dict ) -> dict : \"\"\" Verifies whether the location for this structure contains valid values for numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file. Args: values (dict): Dictionary of validated values to create a Dambreak. Raises: ValueError: When the values dictionary does not contain valid coordinates or polyline file.. Returns: dict: Dictionary of validated values. \"\"\" if ( Structure . validate_coordinates_in_model ( values ) or values . get ( \"polylinefile\" , None ) is not None ): return values raise ValueError ( \"`num/x/yCoordinates` or `polylineFile` are mandatory for a Dambreak structure.\" ) validate_algorithm ( value : str ) -> DambreakAlgorithm classmethod \u00b6 Validates the algorithm parameter for the dambreak structure. Parameters: Name Type Description Default value int algorithm value read from the user's input. required Exceptions: Type Description ValueError When the value given is not of type int. ValueError When the value given is not in the range [1,3] Returns: Type Description int Validated value. Source code in hydrolib/core/io/structure/models.py @validator ( \"algorithm\" , pre = True ) @classmethod def validate_algorithm ( cls , value : str ) -> DambreakAlgorithm : \"\"\" Validates the algorithm parameter for the dambreak structure. Args: value (int): algorithm value read from the user's input. Raises: ValueError: When the value given is not of type int. ValueError: When the value given is not in the range [1,3] Returns: int: Validated value. \"\"\" int_value = - 1 try : int_value = int ( value ) except Exception : raise ValueError ( \"Dambreak algorithm value should be of type int.\" ) if 0 < int_value <= 3 : return DambreakAlgorithm ( int_value ) raise ValueError ( \"Dambreak algorithm value should be 1, 2 or 3.\" ) validate_dambreak_levels_and_widths ( field_value : Optional [ pathlib . Path ], values : dict ) -> Optional [ pathlib . Path ] classmethod \u00b6 Validates whether a dambreak can be created with the given dambreakLevelsAndWidths property. This property should be given when the algorithm value is 3. Parameters: Name Type Description Default field_value Optional[Path] Value given for dambreakLevelsAndWidths. required values dict Dictionary of values already validated (assuming algorithm is in it). required Exceptions: Type Description ValueError When algorithm value is not 3 and field_value has a value. Returns: Type Description Optional[Path] The value given for dambreakLevelsAndwidths. Source code in hydrolib/core/io/structure/models.py @validator ( \"dambreaklevelsandwidths\" ) @classmethod def validate_dambreak_levels_and_widths ( cls , field_value : Optional [ Path ], values : dict ) -> Optional [ Path ]: \"\"\" Validates whether a dambreak can be created with the given dambreakLevelsAndWidths property. This property should be given when the algorithm value is 3. Args: field_value (Optional[Path]): Value given for dambreakLevelsAndWidths. values (dict): Dictionary of values already validated (assuming algorithm is in it). Raises: ValueError: When algorithm value is not 3 and field_value has a value. Returns: Optional[Path]: The value given for dambreakLevelsAndwidths. \"\"\" # Retrieve the algorithm value (if not found use 0). algorithm_value = values . get ( \"algorithm\" , 0 ) if field_value is not None and algorithm_value != 3 : # dambreakLevelsAndWidths can only be set when algorithm = 3 raise ValueError ( f \"Dambreak field dambreakLevelsAndWidths can only be set when algorithm = 3, current value: { algorithm_value } .\" ) return field_value DambreakAlgorithm ( int , Enum ) \u00b6 An enumeration. FlowDirection ( str , Enum ) \u00b6 Enum class containing the valid values for the allowedFlowDirection attribute in several subclasses of Structure. GateOpeningHorizontalDirection ( str , Enum ) \u00b6 Horizontal opening direction of gate door[s]. Orifice ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=orifice , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the orifice input as described in UM Sec.C.12.7 . Pump ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=pump , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the pump input as described in UM Sec.C.12.6 . Structure ( INIBasedModel ) pydantic-model \u00b6 check_location ( values : dict ) -> dict classmethod \u00b6 Validates the location of the structure based on the given parameters. For instance, if a branchid is given, then it is expected also the chainage, otherwise numcoordinates xcoordinates and ycoordinates shall be expected. Parameters: Name Type Description Default values dict Dictionary of values validated for the new structure. required Exceptions: Type Description ValueError When branchid or chainage values are not valid (empty strings). ValueError When the number of xcoordinates and ycoordinates do not match numcoordinates. Returns: Type Description dict Dictionary of values validated for the new structure. Source code in hydrolib/core/io/structure/models.py @root_validator @classmethod def check_location ( cls , values : dict ) -> dict : \"\"\" Validates the location of the structure based on the given parameters. For instance, if a branchid is given, then it is expected also the chainage, otherwise numcoordinates xcoordinates and ycoordinates shall be expected. Args: values (dict): Dictionary of values validated for the new structure. Raises: ValueError: When branchid or chainage values are not valid (empty strings). ValueError: When the number of xcoordinates and ycoordinates do not match numcoordinates. Returns: dict: Dictionary of values validated for the new structure. \"\"\" filtered_values = { k : v for k , v in values . items () if v is not None } structype = filtered_values . get ( \"type\" , \"\" ) . lower () # TODO This seems to be a bit of a hack. if not ( structype == \"compound\" or issubclass ( cls , ( Compound , Dambreak ))): # Compound structure does not require a location specification. only_coordinates_structures = dict ( longculvert = \"LongCulvert\" , dambreak = \"Dambreak\" ) coordinates_in_model = Structure . validate_coordinates_in_model ( filtered_values ) # Exception -> LongCulvert requires coordinates_in_model, but not branchId and chainage. if structype in only_coordinates_structures . keys (): assert ( coordinates_in_model ), f \"`num/x/yCoordinates` are mandatory for a { only_coordinates_structures [ structype ] } structure.\" branch_and_chainage_in_model = ( Structure . validate_branch_and_chainage_in_model ( filtered_values ) ) assert ( branch_and_chainage_in_model or coordinates_in_model ), \"Specify location either by setting `branchId` and `chainage` or `num/x/yCoordinates` fields.\" return values validate ( v ) classmethod \u00b6 Try to iniatialize subclass based on the type field. This field is compared to each type field of the derived models of Structure . The derived model with an equal structure type will be initialized. Exceptions: Type Description ValueError When the given type is not a known structure type. Source code in hydrolib/core/io/structure/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `type` field. This field is compared to each `type` field of the derived models of `Structure`. The derived model with an equal structure type will be initialized. Raises: ValueError: When the given type is not a known structure type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"type\" ) . default . lower () == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Type of { cls . __name__ } with id= { v . get ( 'id' , '' ) } and type= { v . get ( 'type' , '' ) } is not recognized.\" ) return super () . validate ( v ) validate_branch_and_chainage_in_model ( values : dict ) -> bool staticmethod \u00b6 Static method to validate whether the given branchid and chainage values match the expectation of a new structure. Parameters: Name Type Description Default values dict Dictionary of values to be used to generate a structure. required Exceptions: Type Description ValueError When the value for branchid or chainage are not valid. Returns: Type Description bool Result of valid branchid / chainage in dictionary. Source code in hydrolib/core/io/structure/models.py @staticmethod def validate_branch_and_chainage_in_model ( values : dict ) -> bool : \"\"\" Static method to validate whether the given branchid and chainage values match the expectation of a new structure. Args: values (dict): Dictionary of values to be used to generate a structure. Raises: ValueError: When the value for branchid or chainage are not valid. Returns: bool: Result of valid branchid / chainage in dictionary. \"\"\" branchid = values . get ( \"branchid\" , None ) if branchid is None : return False chainage = values . get ( \"chainage\" , None ) if str_is_empty_or_none ( branchid ) or chainage is None : raise ValueError ( \"A valid value for branchId and chainage is required when branchId key is specified.\" ) return True validate_coordinates_in_model ( values : dict ) -> bool staticmethod \u00b6 Static method to validate whether the given values match the expectations of a structure to define its coordinates. Parameters: Name Type Description Default values dict Dictionary of values to be used to generate a structure. required Exceptions: Type Description ValueError When the given coordinates is less than 2. ValueError When the given coordinates do not match in expected size. Returns: Type Description bool Result of valid coordinates in dictionary. Source code in hydrolib/core/io/structure/models.py @staticmethod def validate_coordinates_in_model ( values : dict ) -> bool : \"\"\" Static method to validate whether the given values match the expectations of a structure to define its coordinates. Args: values (dict): Dictionary of values to be used to generate a structure. Raises: ValueError: When the given coordinates is less than 2. ValueError: When the given coordinates do not match in expected size. Returns: bool: Result of valid coordinates in dictionary. \"\"\" searched_keys = [ \"numcoordinates\" , \"xcoordinates\" , \"ycoordinates\" ] if any ( values . get ( k , None ) is None for k in searched_keys ): return False n_coords = values [ \"numcoordinates\" ] if n_coords < 2 : raise ValueError ( f \"Expected at least 2 coordinates, but only { n_coords } declared.\" ) def get_coord_len ( coord : str ) -> int : if values [ coord ] is None : return 0 return len ( values [ coord ]) len_x_coords = get_coord_len ( \"xcoordinates\" ) len_y_coords = get_coord_len ( \"ycoordinates\" ) if n_coords == len_x_coords == len_y_coords : return True raise ValueError ( f \"Expected { n_coords } coordinates, given { len_x_coords } for xCoordinates and { len_y_coords } for yCoordinates.\" ) StructureGeneral ( INIGeneral ) pydantic-model \u00b6 [General] section with structure file metadata. StructureModel ( INIModel ) pydantic-model \u00b6 The overall structure model that contains the contents of one structure file. This model is typically referenced under a FMModel .geometry.structurefile[..] . Attributes: Name Type Description general StructureGeneral [General] block with file metadata. branch List[Structure] List of [Structure] blocks for all hydraulic structures. UniversalWeir ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=universalWeir , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the universal weir input as described in UM Sec.C.12.2 . Weir ( Structure ) pydantic-model \u00b6 Hydraulic structure with type=weir , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the weir input as described in UM Sec.C.12.1 .","title":"Structure"},{"location":"reference/structure/#structure-ini-files","text":"","title":"Structure .ini files"},{"location":"reference/structure/#models","text":"structure namespace for storing the contents of an FMModel 's structure file.","title":"Models"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Bridge","text":"Hydraulic structure with type=bridge , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the bridge input as described in UM Sec.C.12.5 .","title":"Bridge"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Compound","text":"Hydraulic structure with type=compound , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the compound input as described in UM Sec.C.12.11 .","title":"Compound"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Culvert","text":"Hydraulic structure with type=culvert , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the culvert input as described in UM Sec.C.12.3 .","title":"Culvert"},{"location":"reference/structure/#hydrolib.core.io.structure.models.CulvertSubType","text":"Enum class to store a Culvert 's subType.","title":"CulvertSubType"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Dambreak","text":"Hydraulic structure with type=dambreak , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the dambreak input as described in UM Sec.C.12.10 .","title":"Dambreak"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Dambreak.check_location","text":"Verifies whether the location for this structure contains valid values for numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file. Parameters: Name Type Description Default values dict Dictionary of validated values to create a Dambreak. required Exceptions: Type Description ValueError When the values dictionary does not contain valid coordinates or polyline file.. Returns: Type Description dict Dictionary of validated values. Source code in hydrolib/core/io/structure/models.py @root_validator @classmethod def check_location ( cls , values : dict ) -> dict : \"\"\" Verifies whether the location for this structure contains valid values for numCoordinates, xCoordinates and yCoordinates or instead is using a polyline file. Args: values (dict): Dictionary of validated values to create a Dambreak. Raises: ValueError: When the values dictionary does not contain valid coordinates or polyline file.. Returns: dict: Dictionary of validated values. \"\"\" if ( Structure . validate_coordinates_in_model ( values ) or values . get ( \"polylinefile\" , None ) is not None ): return values raise ValueError ( \"`num/x/yCoordinates` or `polylineFile` are mandatory for a Dambreak structure.\" )","title":"check_location()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Dambreak.validate_algorithm","text":"Validates the algorithm parameter for the dambreak structure. Parameters: Name Type Description Default value int algorithm value read from the user's input. required Exceptions: Type Description ValueError When the value given is not of type int. ValueError When the value given is not in the range [1,3] Returns: Type Description int Validated value. Source code in hydrolib/core/io/structure/models.py @validator ( \"algorithm\" , pre = True ) @classmethod def validate_algorithm ( cls , value : str ) -> DambreakAlgorithm : \"\"\" Validates the algorithm parameter for the dambreak structure. Args: value (int): algorithm value read from the user's input. Raises: ValueError: When the value given is not of type int. ValueError: When the value given is not in the range [1,3] Returns: int: Validated value. \"\"\" int_value = - 1 try : int_value = int ( value ) except Exception : raise ValueError ( \"Dambreak algorithm value should be of type int.\" ) if 0 < int_value <= 3 : return DambreakAlgorithm ( int_value ) raise ValueError ( \"Dambreak algorithm value should be 1, 2 or 3.\" )","title":"validate_algorithm()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Dambreak.validate_dambreak_levels_and_widths","text":"Validates whether a dambreak can be created with the given dambreakLevelsAndWidths property. This property should be given when the algorithm value is 3. Parameters: Name Type Description Default field_value Optional[Path] Value given for dambreakLevelsAndWidths. required values dict Dictionary of values already validated (assuming algorithm is in it). required Exceptions: Type Description ValueError When algorithm value is not 3 and field_value has a value. Returns: Type Description Optional[Path] The value given for dambreakLevelsAndwidths. Source code in hydrolib/core/io/structure/models.py @validator ( \"dambreaklevelsandwidths\" ) @classmethod def validate_dambreak_levels_and_widths ( cls , field_value : Optional [ Path ], values : dict ) -> Optional [ Path ]: \"\"\" Validates whether a dambreak can be created with the given dambreakLevelsAndWidths property. This property should be given when the algorithm value is 3. Args: field_value (Optional[Path]): Value given for dambreakLevelsAndWidths. values (dict): Dictionary of values already validated (assuming algorithm is in it). Raises: ValueError: When algorithm value is not 3 and field_value has a value. Returns: Optional[Path]: The value given for dambreakLevelsAndwidths. \"\"\" # Retrieve the algorithm value (if not found use 0). algorithm_value = values . get ( \"algorithm\" , 0 ) if field_value is not None and algorithm_value != 3 : # dambreakLevelsAndWidths can only be set when algorithm = 3 raise ValueError ( f \"Dambreak field dambreakLevelsAndWidths can only be set when algorithm = 3, current value: { algorithm_value } .\" ) return field_value","title":"validate_dambreak_levels_and_widths()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.DambreakAlgorithm","text":"An enumeration.","title":"DambreakAlgorithm"},{"location":"reference/structure/#hydrolib.core.io.structure.models.FlowDirection","text":"Enum class containing the valid values for the allowedFlowDirection attribute in several subclasses of Structure.","title":"FlowDirection"},{"location":"reference/structure/#hydrolib.core.io.structure.models.GateOpeningHorizontalDirection","text":"Horizontal opening direction of gate door[s].","title":"GateOpeningHorizontalDirection"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Orifice","text":"Hydraulic structure with type=orifice , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the orifice input as described in UM Sec.C.12.7 .","title":"Orifice"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Pump","text":"Hydraulic structure with type=pump , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the pump input as described in UM Sec.C.12.6 .","title":"Pump"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Structure","text":"","title":"Structure"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Structure.check_location","text":"Validates the location of the structure based on the given parameters. For instance, if a branchid is given, then it is expected also the chainage, otherwise numcoordinates xcoordinates and ycoordinates shall be expected. Parameters: Name Type Description Default values dict Dictionary of values validated for the new structure. required Exceptions: Type Description ValueError When branchid or chainage values are not valid (empty strings). ValueError When the number of xcoordinates and ycoordinates do not match numcoordinates. Returns: Type Description dict Dictionary of values validated for the new structure. Source code in hydrolib/core/io/structure/models.py @root_validator @classmethod def check_location ( cls , values : dict ) -> dict : \"\"\" Validates the location of the structure based on the given parameters. For instance, if a branchid is given, then it is expected also the chainage, otherwise numcoordinates xcoordinates and ycoordinates shall be expected. Args: values (dict): Dictionary of values validated for the new structure. Raises: ValueError: When branchid or chainage values are not valid (empty strings). ValueError: When the number of xcoordinates and ycoordinates do not match numcoordinates. Returns: dict: Dictionary of values validated for the new structure. \"\"\" filtered_values = { k : v for k , v in values . items () if v is not None } structype = filtered_values . get ( \"type\" , \"\" ) . lower () # TODO This seems to be a bit of a hack. if not ( structype == \"compound\" or issubclass ( cls , ( Compound , Dambreak ))): # Compound structure does not require a location specification. only_coordinates_structures = dict ( longculvert = \"LongCulvert\" , dambreak = \"Dambreak\" ) coordinates_in_model = Structure . validate_coordinates_in_model ( filtered_values ) # Exception -> LongCulvert requires coordinates_in_model, but not branchId and chainage. if structype in only_coordinates_structures . keys (): assert ( coordinates_in_model ), f \"`num/x/yCoordinates` are mandatory for a { only_coordinates_structures [ structype ] } structure.\" branch_and_chainage_in_model = ( Structure . validate_branch_and_chainage_in_model ( filtered_values ) ) assert ( branch_and_chainage_in_model or coordinates_in_model ), \"Specify location either by setting `branchId` and `chainage` or `num/x/yCoordinates` fields.\" return values","title":"check_location()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Structure.validate","text":"Try to iniatialize subclass based on the type field. This field is compared to each type field of the derived models of Structure . The derived model with an equal structure type will be initialized. Exceptions: Type Description ValueError When the given type is not a known structure type. Source code in hydrolib/core/io/structure/models.py @classmethod def validate ( cls , v ): \"\"\"Try to iniatialize subclass based on the `type` field. This field is compared to each `type` field of the derived models of `Structure`. The derived model with an equal structure type will be initialized. Raises: ValueError: When the given type is not a known structure type. \"\"\" # should be replaced by discriminated unions once merged # https://github.com/samuelcolvin/pydantic/pull/2336 if isinstance ( v , dict ): for c in cls . __subclasses__ (): if ( c . __fields__ . get ( \"type\" ) . default . lower () == v . get ( \"type\" , \"\" ) . lower () ): v = c ( ** v ) break else : raise ValueError ( f \"Type of { cls . __name__ } with id= { v . get ( 'id' , '' ) } and type= { v . get ( 'type' , '' ) } is not recognized.\" ) return super () . validate ( v )","title":"validate()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Structure.validate_branch_and_chainage_in_model","text":"Static method to validate whether the given branchid and chainage values match the expectation of a new structure. Parameters: Name Type Description Default values dict Dictionary of values to be used to generate a structure. required Exceptions: Type Description ValueError When the value for branchid or chainage are not valid. Returns: Type Description bool Result of valid branchid / chainage in dictionary. Source code in hydrolib/core/io/structure/models.py @staticmethod def validate_branch_and_chainage_in_model ( values : dict ) -> bool : \"\"\" Static method to validate whether the given branchid and chainage values match the expectation of a new structure. Args: values (dict): Dictionary of values to be used to generate a structure. Raises: ValueError: When the value for branchid or chainage are not valid. Returns: bool: Result of valid branchid / chainage in dictionary. \"\"\" branchid = values . get ( \"branchid\" , None ) if branchid is None : return False chainage = values . get ( \"chainage\" , None ) if str_is_empty_or_none ( branchid ) or chainage is None : raise ValueError ( \"A valid value for branchId and chainage is required when branchId key is specified.\" ) return True","title":"validate_branch_and_chainage_in_model()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Structure.validate_coordinates_in_model","text":"Static method to validate whether the given values match the expectations of a structure to define its coordinates. Parameters: Name Type Description Default values dict Dictionary of values to be used to generate a structure. required Exceptions: Type Description ValueError When the given coordinates is less than 2. ValueError When the given coordinates do not match in expected size. Returns: Type Description bool Result of valid coordinates in dictionary. Source code in hydrolib/core/io/structure/models.py @staticmethod def validate_coordinates_in_model ( values : dict ) -> bool : \"\"\" Static method to validate whether the given values match the expectations of a structure to define its coordinates. Args: values (dict): Dictionary of values to be used to generate a structure. Raises: ValueError: When the given coordinates is less than 2. ValueError: When the given coordinates do not match in expected size. Returns: bool: Result of valid coordinates in dictionary. \"\"\" searched_keys = [ \"numcoordinates\" , \"xcoordinates\" , \"ycoordinates\" ] if any ( values . get ( k , None ) is None for k in searched_keys ): return False n_coords = values [ \"numcoordinates\" ] if n_coords < 2 : raise ValueError ( f \"Expected at least 2 coordinates, but only { n_coords } declared.\" ) def get_coord_len ( coord : str ) -> int : if values [ coord ] is None : return 0 return len ( values [ coord ]) len_x_coords = get_coord_len ( \"xcoordinates\" ) len_y_coords = get_coord_len ( \"ycoordinates\" ) if n_coords == len_x_coords == len_y_coords : return True raise ValueError ( f \"Expected { n_coords } coordinates, given { len_x_coords } for xCoordinates and { len_y_coords } for yCoordinates.\" )","title":"validate_coordinates_in_model()"},{"location":"reference/structure/#hydrolib.core.io.structure.models.StructureGeneral","text":"[General] section with structure file metadata.","title":"StructureGeneral"},{"location":"reference/structure/#hydrolib.core.io.structure.models.StructureModel","text":"The overall structure model that contains the contents of one structure file. This model is typically referenced under a FMModel .geometry.structurefile[..] . Attributes: Name Type Description general StructureGeneral [General] block with file metadata. branch List[Structure] List of [Structure] blocks for all hydraulic structures.","title":"StructureModel"},{"location":"reference/structure/#hydrolib.core.io.structure.models.UniversalWeir","text":"Hydraulic structure with type=universalWeir , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the universal weir input as described in UM Sec.C.12.2 .","title":"UniversalWeir"},{"location":"reference/structure/#hydrolib.core.io.structure.models.Weir","text":"Hydraulic structure with type=weir , to be included in a structure file. Typically inside the structure list of a FMModel .geometry.structurefile[0].structure[..] All lowercased attributes match with the weir input as described in UM Sec.C.12.1 .","title":"Weir"},{"location":"reference/xyz/","text":"XYZ files \u00b6 Model \u00b6 XYZModel ( FileModel ) pydantic-model \u00b6 Sample or forcing file. Attributes: Name Type Description points List[hydrolib.core.io.xyz.models.XYZPoint] List of XYZPoint dict ( self , * args , ** kwargs ) \u00b6 Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/xyz/models.py def dict ( self , * args , ** kwargs ): # speed up serializing by not converting these lowest models to dict return dict ( points = self . points ) XYZPoint ( BaseModel ) pydantic-model \u00b6 Single sample or forcing point. Attributes: Name Type Description x float x or \u03bb coordinate y float y or \u03c6 coordinate z float sample value or group number (forcing) comment Optional[str] keyword for grouping (forcing) comment : str pydantic-field \u00b6 comment or group name Parser \u00b6 XYZParser \u00b6 A parser for .xyz files which are like this: number number number number number number # comment Note that the whitespace can vary and the comment left out. Serializer \u00b6","title":"Xyz"},{"location":"reference/xyz/#xyz-files","text":"","title":"XYZ files"},{"location":"reference/xyz/#model","text":"","title":"Model"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZModel","text":"Sample or forcing file. Attributes: Name Type Description points List[hydrolib.core.io.xyz.models.XYZPoint] List of XYZPoint","title":"XYZModel"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZModel.dict","text":"Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. Source code in hydrolib/core/io/xyz/models.py def dict ( self , * args , ** kwargs ): # speed up serializing by not converting these lowest models to dict return dict ( points = self . points )","title":"dict()"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZPoint","text":"Single sample or forcing point. Attributes: Name Type Description x float x or \u03bb coordinate y float y or \u03c6 coordinate z float sample value or group number (forcing) comment Optional[str] keyword for grouping (forcing)","title":"XYZPoint"},{"location":"reference/xyz/#hydrolib.core.io.xyz.models.XYZPoint.comment","text":"comment or group name","title":"comment"},{"location":"reference/xyz/#parser","text":"","title":"Parser"},{"location":"reference/xyz/#hydrolib.core.io.xyz.parser.XYZParser","text":"A parser for .xyz files which are like this: number number number number number number # comment Note that the whitespace can vary and the comment left out.","title":"XYZParser"},{"location":"reference/xyz/#serializer","text":"","title":"Serializer"},{"location":"topics/dhydro_support/","text":"List of D-HYDRO functionalities and support in HYDROLIB-core \u00b6 Below is a list of D-HYDRO functionalities, grouped by kernel, and the current status of support inside hydrolib-core. Symbology \u00b6 : All toplevel file contents can be read/written. : Partial support, see notes. : No support yet, but may come in future. : No support foreseen. Out of scope. * indicates a scheduled release that is not out yet. DIMR \u00b6 Functionality Read Write Supported since API ref Notes DIMR dimr_config.xml 0.1.6* DIMR Critical bugfix for [#127][https://github.com/Deltares/HYDROLIB-core/issues/127]. FM component 0.1.1 FMComponent RR component 0.1.1 RRComponent RTC component parallel MPI models 0.1.1 Component coupler elements 0.1.1 Coupler FM \u00b6 Functionality Read Write Supported since API ref Notes FM MDU file 0.1.1 FMModel Network file _net.nc 0.1.1 Mesh2d Structure file 0.1.1 StructureModel * Weir 0.1.1 Weir * Universal weir 0.1.1 UniversalWeir * Culvert 0.1.1 Culvert * Long culvert * Bridge 0.1.5 Bridge * Pump 0.1.1 Pump * Orifice 0.1.1 Orifice * Gate * General structure 0.1.6* GeneralStructure * Dambreak 0.1.5 Dambreak * Compound structure 0.1.1 Compound External forcings file (old) External forcings file (new) 0.1.1 ExtModel * Boundary 0.1.1 Boundary * Lateral 0.1.1 Lateral * Meteo * .bc file 0.1.1 ForcingModel Cross section files Moved to io.crosssections in 0.1.6. Cross section definition file 0.1.1 CrossDefModel * Circle 0.1.5 CircleCrsDef * Rectangle 0.1.5 RectangleCrsDef * Tabulated river 0.1.5 ZWRiverCrsDef * ZW (tabulated) 0.1.5 ZWCrsDef * XYZ 0.1.5 XYZCrsDef * YZ 0.1.5 YZCrsDef Cross section location file 0.1.1 CrossLocModel 1D roughness file 0.1.6* FrictionModel Output Observation station file (old) Observation station file (new) Observation crosssection file (old) Observation crosssection file (new) History file _his.nc Map file (old) Map file (UGRID) _map.nc Fourier input file Fourier output file _fou.nc via map file reader Class map file via map file reader RR \u00b6 Functionality Read Write Supported since API ref Notes RR Main sobek_3b.fnm 0.1.5 RainfallRunoffModel Moved to io.rr in 0.1.6 Rainfall .bui file 0.1.5 BuiModel Moved to io.rr in 0.1.6 Topology layer Node file 3b_node.tp 0.1.6* NodeFile Link file 3b_link.tp 0.1.6* LinkFile (Table source available on: https://github.com/Deltares/HYDROLIB-core/blob/main/docs/topics/dhydro_support_hydrolib-core.xlsx )","title":"List of D-HYDRO functionalities and support in HYDROLIB-core"},{"location":"topics/dhydro_support/#list-of-d-hydro-functionalities-and-support-in-hydrolib-core","text":"Below is a list of D-HYDRO functionalities, grouped by kernel, and the current status of support inside hydrolib-core.","title":"List of D-HYDRO functionalities and support in HYDROLIB-core"},{"location":"topics/dhydro_support/#symbology","text":": All toplevel file contents can be read/written. : Partial support, see notes. : No support yet, but may come in future. : No support foreseen. Out of scope. * indicates a scheduled release that is not out yet.","title":"Symbology"},{"location":"topics/dhydro_support/#dimr","text":"Functionality Read Write Supported since API ref Notes DIMR dimr_config.xml 0.1.6* DIMR Critical bugfix for [#127][https://github.com/Deltares/HYDROLIB-core/issues/127]. FM component 0.1.1 FMComponent RR component 0.1.1 RRComponent RTC component parallel MPI models 0.1.1 Component coupler elements 0.1.1 Coupler","title":"DIMR"},{"location":"topics/dhydro_support/#fm","text":"Functionality Read Write Supported since API ref Notes FM MDU file 0.1.1 FMModel Network file _net.nc 0.1.1 Mesh2d Structure file 0.1.1 StructureModel * Weir 0.1.1 Weir * Universal weir 0.1.1 UniversalWeir * Culvert 0.1.1 Culvert * Long culvert * Bridge 0.1.5 Bridge * Pump 0.1.1 Pump * Orifice 0.1.1 Orifice * Gate * General structure 0.1.6* GeneralStructure * Dambreak 0.1.5 Dambreak * Compound structure 0.1.1 Compound External forcings file (old) External forcings file (new) 0.1.1 ExtModel * Boundary 0.1.1 Boundary * Lateral 0.1.1 Lateral * Meteo * .bc file 0.1.1 ForcingModel Cross section files Moved to io.crosssections in 0.1.6. Cross section definition file 0.1.1 CrossDefModel * Circle 0.1.5 CircleCrsDef * Rectangle 0.1.5 RectangleCrsDef * Tabulated river 0.1.5 ZWRiverCrsDef * ZW (tabulated) 0.1.5 ZWCrsDef * XYZ 0.1.5 XYZCrsDef * YZ 0.1.5 YZCrsDef Cross section location file 0.1.1 CrossLocModel 1D roughness file 0.1.6* FrictionModel Output Observation station file (old) Observation station file (new) Observation crosssection file (old) Observation crosssection file (new) History file _his.nc Map file (old) Map file (UGRID) _map.nc Fourier input file Fourier output file _fou.nc via map file reader Class map file via map file reader","title":"FM"},{"location":"topics/dhydro_support/#rr","text":"Functionality Read Write Supported since API ref Notes RR Main sobek_3b.fnm 0.1.5 RainfallRunoffModel Moved to io.rr in 0.1.6 Rainfall .bui file 0.1.5 BuiModel Moved to io.rr in 0.1.6 Topology layer Node file 3b_node.tp 0.1.6* NodeFile Link file 3b_link.tp 0.1.6* LinkFile (Table source available on: https://github.com/Deltares/HYDROLIB-core/blob/main/docs/topics/dhydro_support_hydrolib-core.xlsx )","title":"RR"},{"location":"topics/principles/","text":"First principles \u00b6 hydrolib-core is structured around the input and output files (I/O) of the DHYDRO suite. Inheritance/file handling \u00b6 Model setups often consist of different files, many implicitly linked to each other. HYDROLIB makes these links explicit, by recursively loading all child configuration files. For example, when parsing a DIMR file, one could happen upon a reference to an MDU file, which contain references to other files, such as cross sections, etc. >>> dimr = DIMR ( filepath = Path ( test_data_dir / \"dimr_config.xml\" )) You can see this tree structure if you call show_tree . >>> dimr . show_tree () DIMR represented by dimr_config . xml . RRComponent FMComponent \u221f FMModel represented by FlowFM . mdu . \u221f Geometry \u221f StructureModel represented by structures . ini . \u221f CrossDefModel represented by crsdef . ini . \u221f CrossLocModel represented by crsloc . ini . \u221f FrictionModel represented by roughness - Main . ini . \u221f FrictionModel represented by roughness - Sewer1 . ini . \u221f FrictionModel represented by roughness - Sewer2 . ini . \u221f ExternalForcing \u221f ExtModel represented by FlowFM_bnd . ext . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . Program flow while recursively creating FileModels \u00b6 In short: \u00b6 The root folder is stored in the global variable context_dir , so that referenced files can be found. Parsed data from files will be cached in the class variable FileModel._file_models_cache , so that duplicate references do not lead to duplicate parsing and multiple object instances. For all duplicate references, the same cached FileModel instance is used. Pydantic first calls the FileModel.validate and then the initializer ( FileModel.__new__ and FileModel.__init__ ). In detail: \u00b6 => User initializes a new root FileModel from file : 1. FileModel.__new__(cls, filepath: str/Path) - Returns the result of the default __new__ function 2. FileModel.__init__(self, filepath: str/Path) - self holds the FileModel instance that was returned in step 1. - filepath is assumed to hold the absolute file path to the root file. - Updates the global variable context_dir with the parent directory of filepath . - Caches this FileModel instance ( self ) in the static class variable FileModel._file_models_cache with the filepath . - Loads the data ( dict ) from the file. - Initialize self with the data. - => Pydantic tries to convert the data to objects, a.o. sub FileModels : 3. FileModel.validate(value: str) - value holds a relative or absolute file path to the referenced file. - If value is not an absolute file path, resolves the absolute path by using the directory stored in the context_dir , previously set in step 2. - Calls super().validate(value) with the absolute file path stored in value . - => Pydantic create a new FileModel with the data : 4. FileModel.__new__(cls, filepath: str) - filepath holds the absolute file path that was resolved in step 3. - If FileModel._file_models_cache already contains a FileModel instance with this filepath , returns the cached instance, - Otherwise, returns the result of the default __new__ function. 5. FileModel.__init__(self, filepath: str) - self holds the FileModel instance that was returned in step 4. - filepath holds the absolute file path that was resolved in step 3. - If FileModel._file_models_cache already contains a FileModel instance with this filepath , returns immediately: no initialization is done. - Else, caches this FileModel instance ( self ) in the static class variable FileModel._file_models_cache with the filepath . - Loads the data ( dict ) from the file. - Initialize self with the data. - => Pydantic tries to convert the data to objects, a.o. sub FileModels : 6. Repeat steps 3-5 Parsing and serializing INIBasedModels \u00b6 Parsing an INI file should be case-insensitive. To achieve this, the parsable field names of each INIBasedModel should be equal to the expected key in the file in lower case. Some property values are explicitly made case-insensitive for parsing as well. This applies to enum values and values that represent a specific type of INIBasedModel , such as the type property of a structure. To support this, custom validators are placed to compare the given value with the available known values. Structures are initialized based on the value in the type field. The value of this field of each subclass of a Structure is compared to the input and the subclass with the corresponding type is initialized. The serialization of an INIBasedModel to an INI file should respect certain casing rules (overriding the casing used by the user): - Property keys need to be \"lowerCamelCase\" - Section headers need to be \"UpperCamelCase\" To achieve this, each serializable field in a INIBasedModel has an alias. This alias will be written as property key to file. Each INIBasedModel that represents an INI section, has a field _header . The default value of this field will be written to file. Enum values and the values that represent a specific type of INIBasedModel will be serialized to file by how they are defined.","title":"First principles"},{"location":"topics/principles/#first-principles","text":"hydrolib-core is structured around the input and output files (I/O) of the DHYDRO suite.","title":"First principles"},{"location":"topics/principles/#inheritancefile-handling","text":"Model setups often consist of different files, many implicitly linked to each other. HYDROLIB makes these links explicit, by recursively loading all child configuration files. For example, when parsing a DIMR file, one could happen upon a reference to an MDU file, which contain references to other files, such as cross sections, etc. >>> dimr = DIMR ( filepath = Path ( test_data_dir / \"dimr_config.xml\" )) You can see this tree structure if you call show_tree . >>> dimr . show_tree () DIMR represented by dimr_config . xml . RRComponent FMComponent \u221f FMModel represented by FlowFM . mdu . \u221f Geometry \u221f StructureModel represented by structures . ini . \u221f CrossDefModel represented by crsdef . ini . \u221f CrossLocModel represented by crsloc . ini . \u221f FrictionModel represented by roughness - Main . ini . \u221f FrictionModel represented by roughness - Sewer1 . ini . \u221f FrictionModel represented by roughness - Sewer2 . ini . \u221f ExternalForcing \u221f ExtModel represented by FlowFM_bnd . ext . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc . \u221f Boundary \u221f ForcingModel represented by FlowFM_boundaryconditions1d . bc .","title":"Inheritance/file handling"},{"location":"topics/principles/#program-flow-while-recursively-creating-filemodels","text":"","title":"Program flow while recursively creating FileModels"},{"location":"topics/principles/#in-short","text":"The root folder is stored in the global variable context_dir , so that referenced files can be found. Parsed data from files will be cached in the class variable FileModel._file_models_cache , so that duplicate references do not lead to duplicate parsing and multiple object instances. For all duplicate references, the same cached FileModel instance is used. Pydantic first calls the FileModel.validate and then the initializer ( FileModel.__new__ and FileModel.__init__ ).","title":"In short:"},{"location":"topics/principles/#in-detail","text":"=> User initializes a new root FileModel from file : 1. FileModel.__new__(cls, filepath: str/Path) - Returns the result of the default __new__ function 2. FileModel.__init__(self, filepath: str/Path) - self holds the FileModel instance that was returned in step 1. - filepath is assumed to hold the absolute file path to the root file. - Updates the global variable context_dir with the parent directory of filepath . - Caches this FileModel instance ( self ) in the static class variable FileModel._file_models_cache with the filepath . - Loads the data ( dict ) from the file. - Initialize self with the data. - => Pydantic tries to convert the data to objects, a.o. sub FileModels : 3. FileModel.validate(value: str) - value holds a relative or absolute file path to the referenced file. - If value is not an absolute file path, resolves the absolute path by using the directory stored in the context_dir , previously set in step 2. - Calls super().validate(value) with the absolute file path stored in value . - => Pydantic create a new FileModel with the data : 4. FileModel.__new__(cls, filepath: str) - filepath holds the absolute file path that was resolved in step 3. - If FileModel._file_models_cache already contains a FileModel instance with this filepath , returns the cached instance, - Otherwise, returns the result of the default __new__ function. 5. FileModel.__init__(self, filepath: str) - self holds the FileModel instance that was returned in step 4. - filepath holds the absolute file path that was resolved in step 3. - If FileModel._file_models_cache already contains a FileModel instance with this filepath , returns immediately: no initialization is done. - Else, caches this FileModel instance ( self ) in the static class variable FileModel._file_models_cache with the filepath . - Loads the data ( dict ) from the file. - Initialize self with the data. - => Pydantic tries to convert the data to objects, a.o. sub FileModels : 6. Repeat steps 3-5","title":"In detail:"},{"location":"topics/principles/#parsing-and-serializing-inibasedmodels","text":"Parsing an INI file should be case-insensitive. To achieve this, the parsable field names of each INIBasedModel should be equal to the expected key in the file in lower case. Some property values are explicitly made case-insensitive for parsing as well. This applies to enum values and values that represent a specific type of INIBasedModel , such as the type property of a structure. To support this, custom validators are placed to compare the given value with the available known values. Structures are initialized based on the value in the type field. The value of this field of each subclass of a Structure is compared to the input and the subclass with the corresponding type is initialized. The serialization of an INIBasedModel to an INI file should respect certain casing rules (overriding the casing used by the user): - Property keys need to be \"lowerCamelCase\" - Section headers need to be \"UpperCamelCase\" To achieve this, each serializable field in a INIBasedModel has an alias. This alias will be written as property key to file. Each INIBasedModel that represents an INI section, has a field _header . The default value of this field will be written to file. Enum values and the values that represent a specific type of INIBasedModel will be serialized to file by how they are defined.","title":"Parsing and serializing INIBasedModels"},{"location":"topics/pydantic/","text":"Pydantic \u00b6 Pydantic override \u00b6 We love using Pydantic , but we need have multiple overrides in place to enable specific functionality. This document tries to document these instances, as they are in essence exceptions to an otherwise well understood and documented architecture. BaseModel __init__ override \u00b6 We override de __init__ method to catch all validation errors and reissue them with an better error message. FileModel override \u00b6 We override both __new__ and __init__ to cache models from disk. Specifically we also use it to load a filepath from disk. This mostly happens in validate , a Pydantic override, to make sure that if we initialize with a single unnamed argument (Pydantic only accepts keyword arguments) we try to parse it as a filepath. DIMR __init__ override \u00b6 We override the __init__ method of DIMR to parse any underlying FileModels. These are not loaded automatically because they're deeply nested in components . NetworkModel init override \u00b6 We override the __init__ method of the NetworkModel because we initalize an underlying Network (based on Meshkernel) with the given filepath. ForcingBase, Structure and CrossSectionDefinition validate override \u00b6 Validate is overriden to try to initialize the correct subclass of ForcingBase and CrossSectionDefinition, as discriminated unions do not work yet in Pydantic. I.e. if you specify Union{A, B} and A and B have clearly defined Literals it still can't choose whether to create A or B. The PR to fix this hasn't been merged yet. The code is duplicated in three places. INIBasedModel validate override \u00b6 In INIBasedModel we override validate to make sure we can flatten any Section input coming from the parser. Couldn't this be done in the parser? Structure Root validator explicitely checks subclass \u00b6 Because the validation behaviour is different for Compound , Dambreak etc. We might want to split these things once a new Pydantic release has been made that allows a root_validator to be overriden.","title":"Pydantic"},{"location":"topics/pydantic/#pydantic","text":"","title":"Pydantic"},{"location":"topics/pydantic/#pydantic-override","text":"We love using Pydantic , but we need have multiple overrides in place to enable specific functionality. This document tries to document these instances, as they are in essence exceptions to an otherwise well understood and documented architecture.","title":"Pydantic override"},{"location":"topics/pydantic/#basemodel-__init__-override","text":"We override de __init__ method to catch all validation errors and reissue them with an better error message.","title":"BaseModel __init__ override"},{"location":"topics/pydantic/#filemodel-override","text":"We override both __new__ and __init__ to cache models from disk. Specifically we also use it to load a filepath from disk. This mostly happens in validate , a Pydantic override, to make sure that if we initialize with a single unnamed argument (Pydantic only accepts keyword arguments) we try to parse it as a filepath.","title":"FileModel override"},{"location":"topics/pydantic/#dimr-__init__-override","text":"We override the __init__ method of DIMR to parse any underlying FileModels. These are not loaded automatically because they're deeply nested in components .","title":"DIMR __init__ override"},{"location":"topics/pydantic/#networkmodel-init-override","text":"We override the __init__ method of the NetworkModel because we initalize an underlying Network (based on Meshkernel) with the given filepath.","title":"NetworkModel init override"},{"location":"topics/pydantic/#forcingbase-structure-and-crosssectiondefinition-validate-override","text":"Validate is overriden to try to initialize the correct subclass of ForcingBase and CrossSectionDefinition, as discriminated unions do not work yet in Pydantic. I.e. if you specify Union{A, B} and A and B have clearly defined Literals it still can't choose whether to create A or B. The PR to fix this hasn't been merged yet. The code is duplicated in three places.","title":"ForcingBase, Structure and CrossSectionDefinition validate override"},{"location":"topics/pydantic/#inibasedmodel-validate-override","text":"In INIBasedModel we override validate to make sure we can flatten any Section input coming from the parser. Couldn't this be done in the parser?","title":"INIBasedModel validate override"},{"location":"topics/pydantic/#structure-root-validator-explicitely-checks-subclass","text":"Because the validation behaviour is different for Compound , Dambreak etc. We might want to split these things once a new Pydantic release has been made that allows a root_validator to be overriden.","title":"Structure Root validator explicitely checks subclass"},{"location":"tutorials/dataframe_handling/","text":"Dataframe handling \u00b6 We can use DataFrame s from pandas together with hydrolib-core. Note that this functionality can only work on files that are in essence tables and are represented by a List of objects in hydrolib-core. Examples of such FileModel s with their List fields are: - ForcingModel.forcing - CrossDefModel.definition - CrossLocModel.crosssection - ExtModel.boundary - ExtModel.lateral Say we load in a .bc file and want the resulting forcing in a dataframe. from hydrolib.core.io.bc.models import ForcingModel filepath = ( \"tests/data/input/e02/f101_1D-boundaries/c01_steady-state-flow/BoundaryConditions.bc\" ) m = ForcingModel ( filepath ) m . forcing [ Constant ( comments = None , datablock = [[ 2.5 ]], name = 'T1_Dwn_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 100.0 ]], name = 'T1_Up_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 2.5 ]], name = 'T2_Dwn_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]], name = 'T2_Up_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 2.5 ], [ 4320.0 , 2.5 ]], name = 'T3_Dwn_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 100.0 ]], name = 'T3_Up_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]], name = 'T4_Up_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), QHTable ( comments = None , datablock = [[ 50.0 , 1.25 ], [ 100.0 , 2.5 ], [ 150.0 , 3.75 ]], name = 'T4_Dwn_Bnd' , function = 'qhtable' , quantityunitpair = [ QuantityUnitPair ( quantity = 'qhbnd discharge' , unit = 'm\u00b3/s' ), QuantityUnitPair ( quantity = 'qhbnd waterlevel' , unit = 'm' )]), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'wind_speed' , unit = 'm/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'wind_from_direction' , unit = 'degree' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'air_temperature' , unit = 'degrees C' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'humidity' , unit = 'percentage' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'cloudiness' , unit = 'percentage' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 )] We now have a list of forcings that we can convert into a DataFrame. import pandas as pd df = pd . DataFrame ([ f . __dict__ for f in m . forcing ]) comments datablock name function ... offset factor _header timeinterpolation 0 None [[ 2.5 ]] T1_Dwn_Bnd constant ... 0.0 1.0 forcing linear 1 None [[ 100.0 ]] T1_Up_Bnd constant ... 0.0 1.0 forcing linear 2 None [[ 2.5 ]] T2_Dwn_Bnd constant ... 0.0 1.0 forcing linear 3 None [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]] T2_Up_Bnd timeseries ... 0.0 1.0 forcing linear 4 None [[ 0.0 , 0.0 ], [ 1800.0 , 2.5 ], [ 4320.0 , 2.5 ]] T3_Dwn_Bnd timeseries ... 0.0 1.0 forcing linear 5 None [[ 100.0 ]] T3_Up_Bnd constant ... 0.0 1.0 forcing linear 6 None [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]] T4_Up_Bnd timeseries ... 0.0 1.0 forcing linear 7 None [[ 50.0 , 1.25 ], [ 100.0 , 2.5 ], [ 150.0 , 3.75 ]] T4_Dwn_Bnd qhtable ... NaN NaN forcing NaN 8 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 9 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 10 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 11 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 12 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear [ 13 rows x 10 columns ] Note that because there are several types of forcings, with different fields, some values have become NaN. We can also convert this DataFrame back to a ForcingModel . fm = ForcingModel ( forcing = df . to_dict ( 'records' )) fm . forcing == m . forcing True","title":"Dataframe handling"},{"location":"tutorials/dataframe_handling/#dataframe-handling","text":"We can use DataFrame s from pandas together with hydrolib-core. Note that this functionality can only work on files that are in essence tables and are represented by a List of objects in hydrolib-core. Examples of such FileModel s with their List fields are: - ForcingModel.forcing - CrossDefModel.definition - CrossLocModel.crosssection - ExtModel.boundary - ExtModel.lateral Say we load in a .bc file and want the resulting forcing in a dataframe. from hydrolib.core.io.bc.models import ForcingModel filepath = ( \"tests/data/input/e02/f101_1D-boundaries/c01_steady-state-flow/BoundaryConditions.bc\" ) m = ForcingModel ( filepath ) m . forcing [ Constant ( comments = None , datablock = [[ 2.5 ]], name = 'T1_Dwn_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 100.0 ]], name = 'T1_Up_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 2.5 ]], name = 'T2_Dwn_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]], name = 'T2_Up_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 2.5 ], [ 4320.0 , 2.5 ]], name = 'T3_Dwn_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'waterlevelbnd' , unit = 'm' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), Constant ( comments = None , datablock = [[ 100.0 ]], name = 'T3_Up_Bnd' , function = 'constant' , quantityunitpair = [ QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]], name = 'T4_Up_Bnd' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'dischargebnd' , unit = 'm\u00b3/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), QHTable ( comments = None , datablock = [[ 50.0 , 1.25 ], [ 100.0 , 2.5 ], [ 150.0 , 3.75 ]], name = 'T4_Dwn_Bnd' , function = 'qhtable' , quantityunitpair = [ QuantityUnitPair ( quantity = 'qhbnd discharge' , unit = 'm\u00b3/s' ), QuantityUnitPair ( quantity = 'qhbnd waterlevel' , unit = 'm' )]), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'wind_speed' , unit = 'm/s' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'wind_from_direction' , unit = 'degree' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'air_temperature' , unit = 'degrees C' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'humidity' , unit = 'percentage' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 ), TimeSeries ( comments = None , datablock = [[ - 2629440.0 , 0.0 ]], name = 'model_wide' , function = 'timeseries' , quantityunitpair = [ QuantityUnitPair ( quantity = 'time' , unit = 'minutes since 2015-01-01 00:00:00' ), QuantityUnitPair ( quantity = 'cloudiness' , unit = 'percentage' )], timeinterpolation = 'linear' , offset = 0.0 , factor = 1.0 )] We now have a list of forcings that we can convert into a DataFrame. import pandas as pd df = pd . DataFrame ([ f . __dict__ for f in m . forcing ]) comments datablock name function ... offset factor _header timeinterpolation 0 None [[ 2.5 ]] T1_Dwn_Bnd constant ... 0.0 1.0 forcing linear 1 None [[ 100.0 ]] T1_Up_Bnd constant ... 0.0 1.0 forcing linear 2 None [[ 2.5 ]] T2_Dwn_Bnd constant ... 0.0 1.0 forcing linear 3 None [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]] T2_Up_Bnd timeseries ... 0.0 1.0 forcing linear 4 None [[ 0.0 , 0.0 ], [ 1800.0 , 2.5 ], [ 4320.0 , 2.5 ]] T3_Dwn_Bnd timeseries ... 0.0 1.0 forcing linear 5 None [[ 100.0 ]] T3_Up_Bnd constant ... 0.0 1.0 forcing linear 6 None [[ 0.0 , 0.0 ], [ 1800.0 , 100.0 ], [ 4320.0 , 100.0 ]] T4_Up_Bnd timeseries ... 0.0 1.0 forcing linear 7 None [[ 50.0 , 1.25 ], [ 100.0 , 2.5 ], [ 150.0 , 3.75 ]] T4_Dwn_Bnd qhtable ... NaN NaN forcing NaN 8 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 9 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 10 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 11 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear 12 None [[ - 2629440.0 , 0.0 ]] model_wide timeseries ... 0.0 1.0 forcing linear [ 13 rows x 10 columns ] Note that because there are several types of forcings, with different fields, some values have become NaN. We can also convert this DataFrame back to a ForcingModel . fm = ForcingModel ( forcing = df . to_dict ( 'records' )) fm . forcing == m . forcing True","title":"Dataframe handling"},{"location":"tutorials/plotting_a_network/","text":"Plotting a network \u00b6 We can visualise a Network with the following code: from hydrolib.core.io.net.models import Network import matplotlib from matplotlib.collections import LineCollection import numpy as np def plot ( network : Network , ax : matplotlib . axes . _subplots . AxesSubplot , mesh1d_kwargs : dict = None , mesh2d_kwargs : dict = None , links1d2d_kwargs : dict = None , ) -> None : if mesh1d_kwargs is None : mesh1d_kwargs = { \"color\" : \"C3\" , \"lw\" : 1.0 } if mesh2d_kwargs is None : mesh2d_kwargs = { \"color\" : \"C0\" , \"lw\" : 0.5 } if links1d2d_kwargs is None : links1d2d_kwargs = { \"color\" : \"k\" , \"lw\" : 1.0 } # Mesh 1d if not network . _mesh1d . is_empty (): nodes1d = np . stack ( [ network . _mesh1d . mesh1d_node_x , network . _mesh1d . mesh1d_node_y ], axis = 1 ) edge_nodes = network . _mesh1d . mesh1d_edge_nodes lc_mesh1d = LineCollection ( nodes1d [ edge_nodes ], ** mesh1d_kwargs ) ax . add_collection ( lc_mesh1d ) # Mesh 2d if not network . _mesh2d . is_empty (): nodes2d = np . stack ( [ network . _mesh2d . mesh2d_node_x , network . _mesh2d . mesh2d_node_y ], axis = 1 ) edge_nodes = network . _mesh2d . mesh2d_edge_nodes lc_mesh2d = LineCollection ( nodes2d [ edge_nodes ], ** mesh2d_kwargs ) ax . add_collection ( lc_mesh2d ) # Links if not network . _link1d2d . is_empty (): faces2d = np . stack ( [ network . _mesh2d . mesh2d_face_x , network . _mesh2d . mesh2d_face_y ], axis = 1 ) link_coords = np . stack ( [ nodes1d [ network . _link1d2d . link1d2d [:, 0 ]], faces2d [ network . _link1d2d . link1d2d [:, 1 ]], ], axis = 1 , ) lc_link1d2d = LineCollection ( link_coords , ** links1d2d_kwargs ) ax . add_collection ( lc_link1d2d )","title":"Plotting a network"},{"location":"tutorials/plotting_a_network/#plotting-a-network","text":"We can visualise a Network with the following code: from hydrolib.core.io.net.models import Network import matplotlib from matplotlib.collections import LineCollection import numpy as np def plot ( network : Network , ax : matplotlib . axes . _subplots . AxesSubplot , mesh1d_kwargs : dict = None , mesh2d_kwargs : dict = None , links1d2d_kwargs : dict = None , ) -> None : if mesh1d_kwargs is None : mesh1d_kwargs = { \"color\" : \"C3\" , \"lw\" : 1.0 } if mesh2d_kwargs is None : mesh2d_kwargs = { \"color\" : \"C0\" , \"lw\" : 0.5 } if links1d2d_kwargs is None : links1d2d_kwargs = { \"color\" : \"k\" , \"lw\" : 1.0 } # Mesh 1d if not network . _mesh1d . is_empty (): nodes1d = np . stack ( [ network . _mesh1d . mesh1d_node_x , network . _mesh1d . mesh1d_node_y ], axis = 1 ) edge_nodes = network . _mesh1d . mesh1d_edge_nodes lc_mesh1d = LineCollection ( nodes1d [ edge_nodes ], ** mesh1d_kwargs ) ax . add_collection ( lc_mesh1d ) # Mesh 2d if not network . _mesh2d . is_empty (): nodes2d = np . stack ( [ network . _mesh2d . mesh2d_node_x , network . _mesh2d . mesh2d_node_y ], axis = 1 ) edge_nodes = network . _mesh2d . mesh2d_edge_nodes lc_mesh2d = LineCollection ( nodes2d [ edge_nodes ], ** mesh2d_kwargs ) ax . add_collection ( lc_mesh2d ) # Links if not network . _link1d2d . is_empty (): faces2d = np . stack ( [ network . _mesh2d . mesh2d_face_x , network . _mesh2d . mesh2d_face_y ], axis = 1 ) link_coords = np . stack ( [ nodes1d [ network . _link1d2d . link1d2d [:, 0 ]], faces2d [ network . _link1d2d . link1d2d [:, 1 ]], ], axis = 1 , ) lc_link1d2d = LineCollection ( link_coords , ** links1d2d_kwargs ) ax . add_collection ( lc_link1d2d )","title":"Plotting a network"},{"location":"tutorials/steps/","text":"First steps \u00b6 Let's import and create a first model. from hydrolib.core.io.structure.models import FlowDirection , StructureModel , Weir from hydrolib.core.io.mdu.models import FMModel fm = FMModel () fm . filepath = \"test.mdu\" Add some structures, note this is invalid because it doesn't have a branch or coordinates yet, but it will work for demo purposes struc = Weir ( branchId = 'someBranch' , chainage = 123.0 , allowedflowdir = FlowDirection . none , crestlevel = 0.0 ) struc . comments . crestlevel = \"This is a comment\" fm . geometry . structurefile = [ StructureModel ( structure = [ struc ])] Note that the creation of a Weir and other models always require the use of keyword arguments. A ValidationError will be raised when the model isn't correct or complete, for instance, in the case that StructureModel was assigned directly to structurefile instead of as a list. Now let's add this model to a DIMR config and save it. from hydrolib.core.io.dimr.models import DIMR , FMComponent from pathlib import Path dimr = DIMR () dimr . component . append ( FMComponent ( name = \"test\" , workingDir = \".\" , inputfile = fm . filepath , model = fm ) ) dimr . save ( folder = Path ( \".\" )) The save on the top of the model hierarchy will result in saves of all child models, so this results in four files ( dimr_config.xml , network.nc , structures.ini , test.mdu ) in the working directory.","title":"First steps"},{"location":"tutorials/steps/#first-steps","text":"Let's import and create a first model. from hydrolib.core.io.structure.models import FlowDirection , StructureModel , Weir from hydrolib.core.io.mdu.models import FMModel fm = FMModel () fm . filepath = \"test.mdu\" Add some structures, note this is invalid because it doesn't have a branch or coordinates yet, but it will work for demo purposes struc = Weir ( branchId = 'someBranch' , chainage = 123.0 , allowedflowdir = FlowDirection . none , crestlevel = 0.0 ) struc . comments . crestlevel = \"This is a comment\" fm . geometry . structurefile = [ StructureModel ( structure = [ struc ])] Note that the creation of a Weir and other models always require the use of keyword arguments. A ValidationError will be raised when the model isn't correct or complete, for instance, in the case that StructureModel was assigned directly to structurefile instead of as a list. Now let's add this model to a DIMR config and save it. from hydrolib.core.io.dimr.models import DIMR , FMComponent from pathlib import Path dimr = DIMR () dimr . component . append ( FMComponent ( name = \"test\" , workingDir = \".\" , inputfile = fm . filepath , model = fm ) ) dimr . save ( folder = Path ( \".\" )) The save on the top of the model hierarchy will result in saves of all child models, so this results in four files ( dimr_config.xml , network.nc , structures.ini , test.mdu ) in the working directory.","title":"First steps"}]}